[
    {
        "content": "<p>Sooo <a href=\"#narrow/stream/242791-t-infra/topic/what.20happened.20in.20july.202020.3F\">https://rust-lang.zulipchat.com/#narrow/stream/242791-t-infra/topic/what.20happened.20in.20july.202020.3F</a> made me think about <a href=\"https://github.com/rust-lang/cargo/issues/7396\">https://github.com/rust-lang/cargo/issues/7396</a> again and I tried to think a bit about how one could perhaps implement some very rough time-based scheduling.</p>\n<p>Here we could probably not only take the current subtree-depth into account but also something like the total last build-time of all the edges.<br>\n<a href=\"https://github.com/rust-lang/cargo/blob/58a961314437258065e23cb6316dfc121d96fb71/src/cargo/util/dependency_queue.rs#L157\">https://github.com/rust-lang/cargo/blob/58a961314437258065e23cb6316dfc121d96fb71/src/cargo/util/dependency_queue.rs#L157</a></p>\n<p>We would somehow need to save build times for each rustc invocation.<br>\nI hacked a  small println into <a href=\"https://github.com/rust-lang/cargo/blob/0a98b1de5c0c944ac737e172b14ea2aa4f56f374/src/cargo/core/compiler/timings.rs#L230\">https://github.com/rust-lang/cargo/blob/0a98b1de5c0c944ac737e172b14ea2aa4f56f374/src/cargo/core/compiler/timings.rs#L230</a> which seems to provide all the interesting data already.</p>\n<p>I wondered first if we could just save the timings into their respective <code>cargo-ok</code> files that are already inside the extracted sources/git checkouts inside the <code>$CARGO_HOME</code>, but then we wouldn't have data on path dependencies, which is not optimal.</p>\n<p>So we might need to have some kind of centralized file inside the <code>CARGO_HOME</code> which contains all the data BUT this file would also need to be writable and readable by several processes at the same time because we can run several <code>cargo builds</code> at a time which seems a bit tricky, it should not be a bottleneck when build like 128 mini-crates at once. :) </p>\n<p>I'm not sure if having one data-file per crate source is the best solution here (we could still build the same source twice at the same time, but it's less likely)</p>\n<p>On what the data looks like,  I think maybe we can get away with just the path to the dependencies Cargo.toml as key (in most cases it should already contain crate name as well as crate version, in case of cargos download cache at least) and a list of perhaps the last 10-20 timings that we collected. <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span></p>",
        "id": 268040799,
        "sender_full_name": "matthiaskrgr",
        "timestamp": 1642179232
    },
    {
        "content": "<p>For the effectiveness of different algorithms, feel free to add necessary data to the timing's report. Then we can after the fact approximate how long different scheduling algorithms would take, and how much we're leaving on the table.</p>",
        "id": 268041966,
        "sender_full_name": "Eh2406",
        "timestamp": 1642179679
    },
    {
        "content": "<p>For storing the data between runs, <span class=\"user-mention\" data-user-id=\"120518\">@Eric Huss</span> has been doing some experimentation based on <span class=\"user-mention\" data-user-id=\"245964\">@Weihang Lo</span> 's research. I don't know when they will be ready to discuss it publicly, but keep your eyes peeled.</p>",
        "id": 268042251,
        "sender_full_name": "Eh2406",
        "timestamp": 1642179811
    }
]