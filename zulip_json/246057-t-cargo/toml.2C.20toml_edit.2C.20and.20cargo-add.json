[
    {
        "content": "<p>I'd like to follow up from <a href=\"https://github.com/rust-lang/cargo/issues/5586\">https://github.com/rust-lang/cargo/issues/5586</a> , because I think I'm not following the discussion on what the goals are.</p>",
        "id": 248501862,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1628181160
    },
    {
        "content": "<p>I understand that there was originally a proposed plan of factoring out a common lexer from toml and toml_edit, and then using both: toml in cargo, and toml_edit in cargo-edit.</p>",
        "id": 248501926,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1628181200
    },
    {
        "content": "<p>From what I can tell, <span class=\"user-mention\" data-user-id=\"424212\">@Ed Page</span> is proposing the alternate plan of improving toml_edit to the point that it can serve the function of toml, and then use toml_edit <em>as</em> the one toml library in Cargo. As far as I can tell, that would address all the requirements that were previously stated in that issue, and would result in Cargo only using one toml library (not just one lexer, one toml library).</p>",
        "id": 248502148,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1628181311
    },
    {
        "content": "<p>Assuming that toml_edit parses all of toml, and passes the testsuite, that seems to me like a reasonable approach to solve the problem.</p>",
        "id": 248502538,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1628181497
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"120518\">@Eric Huss</span>, I think I'm not following your most recent comments on the issue, and I'd like to better understand your feedback on that proposed approach.</p>",
        "id": 248502626,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1628181562
    },
    {
        "content": "<p>It originally seemed like the primary requirement was to avoid having two toml parsers in Cargo, and I think that's exactly what motivated the proposed solution (fixing toml_edit so that it can do everything toml can).</p>",
        "id": 248502816,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1628181668
    },
    {
        "content": "<p>I guess I would need to see what that looks like. I'm a bit skeptical how it might work, since serde's model is so different.  I'm also a little uncomfortable taking on a new, large dependency that is a fundamental part of Cargo that we don't have direct control over.  We would also need to be careful about performance, since that is a problem we have today, and definitely don't want to make it worse.  I imagine also <span class=\"user-mention\" data-user-id=\"116015\">@Alex Crichton</span>  might have some thoughts.</p>",
        "id": 248533427,
        "sender_full_name": "Eric Huss",
        "timestamp": 1628196070
    },
    {
        "content": "<p>I'd basically just echo Eric, changing toml parsers is a really serious thing and would require a nontrivial amount of validation. Not only in terms of correctness but also speed as Eric mentioned.</p>",
        "id": 248534313,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1628196524
    },
    {
        "content": "<p>Can we define what our performance targets are for what use cases?</p>",
        "id": 248534605,
        "sender_full_name": "Ed Page",
        "timestamp": 1628196693
    },
    {
        "content": "<p>I think at a bare minimum would be to be no worse than it is today.  Use cases would be everything cargo does (parsing Cargo.toml, Cargo.lock, cargo config, etc.).</p>",
        "id": 248534912,
        "sender_full_name": "Eric Huss",
        "timestamp": 1628196871
    },
    {
        "content": "<p>Ideally we'd be on a road to improve it.  That has been something I've been thinking of looking at sometime soon.</p>",
        "id": 248535005,
        "sender_full_name": "Eric Huss",
        "timestamp": 1628196922
    },
    {
        "content": "<p>AFAIK toml parsing is a relatively performance-critical operation since Cargo will parse the manifest of all your dependencies on all builds, which can sometimes reach hundreds of files not-really-all-that-small files. Measuring may not be the easiest but that's generally where the performance-sensitivity comes into play</p>",
        "id": 248535041,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1628196943
    },
    {
        "content": "<p>and yeah I would agree that toml parsing has shown up in profiles I've seen recently, so what we have already is by no means a \"gold standard\"</p>",
        "id": 248535108,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1628196968
    },
    {
        "content": "<p>I also know very little about toml-edit, so if it's already just like 10% slower that's fine, we can probably optimize it</p>",
        "id": 248535181,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1628197010
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"116015\">@Alex Crichton</span> for the use case of parsing an entire dependency of <code>Cargo.toml</code> files!</p>\n<p>Do <code>Cargo.lock</code>s also show up?  Any suggested projects that would be good cases?</p>",
        "id": 248535322,
        "sender_full_name": "Ed Page",
        "timestamp": 1628197082
    },
    {
        "content": "<p><code>Cargo.lock</code> is always rewritten in its entirety by cargo without preserving order or unknown fields.</p>",
        "id": 248535821,
        "sender_full_name": "bjorn3",
        "timestamp": 1628197251
    },
    {
        "content": "<p>For parsing full dependency trees, I assume the registry is immutable.  Have we looked into doing one-time parsing and saving the result to a faster-to-parse format?  Seems like we'd hit a limit in improving parsing speeds with toml and bypassing toml would be the next step.</p>",
        "id": 248535860,
        "sender_full_name": "Ed Page",
        "timestamp": 1628197268
    },
    {
        "content": "<p>Since there are unknowns to work out, I want to keep all options in mind.  I had a question on the original thread that hasn't been answered regarding our other options.  The suggestion for sharing was to share lexers for the sake of lower maintenance and consistent parsing behavior.  From my own parsing experience (though not toml), sharing lexers seems like there is only minimal sharing, that we still have to have a large surface area on top to maintain and keep consistent.  What is it I am missing?</p>",
        "id": 248536420,
        "sender_full_name": "Ed Page",
        "timestamp": 1628197476
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"133247\">@bjorn3</span> to be clear, I wasn't thinking we'd try to preserve format on <code>Cargo.lock</code> but was bringing it up for performance considerations if we had a <code>toml-rs</code> compatibility layer on top of <code>toml-edit</code> that was being used for <code>Cargo.lock</code></p>",
        "id": 248537591,
        "sender_full_name": "Ed Page",
        "timestamp": 1628197993
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"424212\">@Ed Page</span> <code>Cargo.lock</code> parsing does always happen but the performance is pretty inconsequential since it's just one file. It is sometimes thousands of lines so it shouldn't be <em>too</em> slow but making it 5x slower than what it is today probably wouldn't have any impact on perceived performance</p>",
        "id": 248543565,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1628201219
    },
    {
        "content": "<p>Thanks for clarifying!</p>",
        "id": 248543604,
        "sender_full_name": "Ed Page",
        "timestamp": 1628201242
    },
    {
        "content": "<p>For the registry, we could do that (we actually do that for JSON blobs from the registry), but I think the optimization is a bit less applicable since we couldn't do similar caching for workspace path dependencies and projects sometimes have at least dozens of those (e.g. rustc itself), and that's a lot of TOML to still parse on each run</p>",
        "id": 248543660,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1628201279
    },
    {
        "content": "<p>From my perspective I found the lexing to be one of the trickier parts of the toml crate, and while I agree it still leaves out a lot it's at least <em>something</em> shared between the thing editing and the thing parsing. I  think ideally we'd use the exact same dependency, but I'm not sure if either toml or toml-edit is up for that task (I haven't looked very closely at toml-edit with an eye for this)</p>",
        "id": 248543779,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1628201357
    },
    {
        "content": "<p>I also want to be clear that these are hypothetical concerns about performance. It could be that switching to toml-edit has no measurable impact on performance. In that situation correctness would be paramount to verify (and I'm sure there's at least one bug in toml-rs that we've parsed bad TOML or something like that and we'd need a compatibility hack for)</p>",
        "id": 248543896,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1628201431
    },
    {
        "content": "<p>Cargo's handling of manifests is extremely far from optimal, there's tons of string clones and things like that IIRC, so it could be that toml parsing is a relatively small part of all this. Basically I'm saying that this should all be data-driven from real benchmarks with real profilers rather than purely from the gesticulations of us working on Cargo</p>",
        "id": 248543945,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1628201477
    },
    {
        "content": "<p>also, sorry if I'm slow to respond lol didn't see the ping here until just now</p>",
        "id": 248543981,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1628201499
    },
    {
        "content": "<p>Yeah, identifying a case to optimize and digging into the performance would be a fun project later down the road.  </p>\n<p>Speaking of allocations, I imagine <code>smol_str</code> or <code>kstring</code>, with their small-string optimizations, would help <em>if</em> thats a problem.</p>",
        "id": 248544185,
        "sender_full_name": "Ed Page",
        "timestamp": 1628201612
    },
    {
        "content": "<blockquote>\n<p>From my perspective I found the lexing to be one of the trickier parts of the toml crate</p>\n</blockquote>\n<p>Oh interesting, I would not have expected that.  Good to know.</p>",
        "id": 248544268,
        "sender_full_name": "Ed Page",
        "timestamp": 1628201648
    },
    {
        "content": "<p>Other future interests of mine for improving cargo is sharing definitions of messages between <code>cargo</code> and <code>cargo-metadata</code> / <code>escargot</code> and making it easier to share logic between <code>cargo</code> and external subcommands (e.g. get rid of the need for  duplicating logic in<code>clap-cargo</code>)</p>",
        "id": 248544540,
        "sender_full_name": "Ed Page",
        "timestamp": 1628201821
    },
    {
        "content": "<blockquote>\n<p>I imagine <code>smol_str</code> or <code>kstring</code></p>\n</blockquote>\n<p>Cargo has an <code>InternedString</code> type that <em>may</em> be useful.</p>",
        "id": 248656742,
        "sender_full_name": "Eh2406",
        "timestamp": 1628277741
    }
]