[
    {
        "content": "<p>I have basic resolver benchmarking working:</p>\n<div class=\"codehilite\"><pre><span></span><code>resolve_ws/empty        time:   [343.20 us 344.65 us 346.11 us]\nresolve_ws/toml-rs      time:   [5.2462 ms 5.3742 ms 5.5166 ms]\nresolve_ws/cargo        time:   [65.070 ms 65.563 ms 66.052 ms]\nresolve_ws/rust         time:   [235.68 ms 237.31 ms 239.04 ms]\nresolve_ws/gecko-dev    time:   [341.92 ms 346.19 ms 351.11 ms]\nresolve_ws/tikv         time:   [376.43 ms 379.93 ms 384.06 ms]\nresolve_ws/diem         time:   [393.93 ms 395.52 ms 397.08 ms]\nresolve_ws/substrate    time:   [575.69 ms 577.35 ms 579.07 ms]\nresolve_ws/servo        time:   [690.91 ms 699.96 ms 710.48 ms]\n</code></pre></div>\n<p>It is curious that servo is so much slower than firefox or substrate, which have substantially more packages.</p>",
        "id": 255664282,
        "sender_full_name": "Eric Huss",
        "timestamp": 1633043798
    },
    {
        "content": "<p>What's the root crate for servo?</p>",
        "id": 255706085,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633075626
    },
    {
        "content": "<p>It is a virtual workspace with 74 members.</p>",
        "id": 255774586,
        "sender_full_name": "Eric Huss",
        "timestamp": 1633107282
    },
    {
        "content": "<p>Servo currently has 663 packages, substrate has 952.</p>",
        "id": 255774737,
        "sender_full_name": "Eric Huss",
        "timestamp": 1633107353
    },
    {
        "content": "<p>I'm wondering if there's some scaling issue present, where perhaps servo has a different branching factor at some level where we don't scale linearly.</p>",
        "id": 255793130,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633115354
    },
    {
        "content": "<p>What's the next biggest virtual workspace?</p>",
        "id": 255793161,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633115374
    },
    {
        "content": "<p>These are wonderful questions to look at after we have a benchmarking system set up. Lets not delay getting measurements on understanding them. (Unless that is what Eric would find Fun, then don't let me stop you!)</p>",
        "id": 255793658,
        "sender_full_name": "Eh2406",
        "timestamp": 1633115585
    },
    {
        "content": "<p>(Agreed, and none of that was meant to be a delay on the benchmarking infrastructure.)</p>",
        "id": 255794544,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633116032
    },
    {
        "content": "<p>hah, no worries, I wasn't going to dig into it. I just found it curious.</p>\n<p>Here are the workspace sizes:</p>\n<p>1 empty  <br>\n14 toml-rs  <br>\n165 cargo  <br>\n513 rust  <br>\n521 tikv  <br>\n570 gecko-dev  <br>\n663 servo  <br>\n740 diem  <br>\n952 substrate</p>",
        "id": 255798588,
        "sender_full_name": "Eric Huss",
        "timestamp": 1633118020
    },
    {
        "content": "<p>The main concern was whether or not the benchmark was working correctly, but I think it is.</p>",
        "id": 255798675,
        "sender_full_name": "Eric Huss",
        "timestamp": 1633118058
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"120518\">@Eric Huss</span> How many projects are in the top-level workspace, vs pulled in via dependencies?</p>",
        "id": 255801384,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633119285
    },
    {
        "content": "<p>This is the number of members:</p>\n<p>1 cargo<br>\n1 empty<br>\n2 toml-rs<br>\n66 tikv<br>\n72 gecko-dev<br>\n74 servo<br>\n115 rust<br>\n189 diem<br>\n216 substrate</p>",
        "id": 255801706,
        "sender_full_name": "Eric Huss",
        "timestamp": 1633119433
    },
    {
        "content": "<p>Huh, interesting. That <em>really</em> makes me wonder what's up with servo then, yeah.</p>",
        "id": 255990281,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633306335
    },
    {
        "content": "<p>That'll be fun to profile in the future.</p>",
        "id": 255990288,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633306346
    },
    {
        "content": "<p>Thanks for working on the benchmarks!</p>",
        "id": 255990291,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633306351
    },
    {
        "content": "<p>I'm struggling to figure out how to have an expensive setup function that only runs once when the benchmark is run. In our case, we have a group <code>resolve_ws</code> with several bench functions (<code>cargo</code>, <code>tikv</code>, <code>servo</code>, etc.). I want to prepare the workspace once for each bench function, and then have criterion run the iterator repeatedly. However, that does not appear to be the way criterion works. It seems to run the entire bunch function multiple times based on whatever rules it has.</p>\n<p>I see <a href=\"https://github.com/bheisler/criterion.rs/issues/514\">https://github.com/bheisler/criterion.rs/issues/514</a> which implies it is not possible. I've tried using <a href=\"https://docs.rs/criterion/0.3.5/criterion/struct.Bencher.html#method.iter_batched\"><code>iter_batched</code></a>, but that doesn't help even though it claims to be made for this case.</p>\n<p>Anyone have any ideas about that? I feel like I really don't understand how criterion works.</p>",
        "id": 256476718,
        "sender_full_name": "Eric Huss",
        "timestamp": 1633551172
    },
    {
        "content": "<p><code>iter_batched</code> is for a slightly different case. It is for when you don't want to time the set up code. Where as you don't want to run the set up code.</p>",
        "id": 256478600,
        "sender_full_name": "Eh2406",
        "timestamp": 1633551985
    },
    {
        "content": "<p>How big is the overhead of setting up the workspace more often?</p>",
        "id": 256478827,
        "sender_full_name": "Eh2406",
        "timestamp": 1633552094
    },
    {
        "content": "<p>Oh I thought setup was basically \"do it outside the <code>iter</code> closure\"?</p>",
        "id": 256479497,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1633552378
    },
    {
        "content": "<p>oh but you probably want per-iteration setup that isn't timed</p>",
        "id": 256479549,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1633552403
    },
    {
        "content": "<p>Hm, I'm looking more closely, I think I was confused, and it does seem to be working mostly how I expect.  I'm still trying to figure out how it decides the batch size automatically, since it often ends up with a batch of 1 which seems unnecessary.</p>",
        "id": 256480311,
        "sender_full_name": "Eric Huss",
        "timestamp": 1633552733
    },
    {
        "content": "<p>there is <a href=\"https://docs.rs/criterion/0.3.5/criterion/enum.BatchSize.html\">https://docs.rs/criterion/0.3.5/criterion/enum.BatchSize.html</a> witch is one piece of the puzzle</p>",
        "id": 256480658,
        "sender_full_name": "Eh2406",
        "timestamp": 1633552895
    },
    {
        "content": "<p>Yea, I was thinking about using <code>NumIterations</code>, though there seem to be plenty of warnings telling you not to do that.   I'm still trying to figure out what the warmup does, since I'm guessing that is how it decides how to batch things.</p>",
        "id": 256480904,
        "sender_full_name": "Eric Huss",
        "timestamp": 1633552999
    }
]