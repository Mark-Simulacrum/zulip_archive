[
    {
        "content": "<p>Hello. I'm new-ish to Rust and very new to community involvement. If this is an inappropriate place to post this, I apologize in advance. </p>\n<p>I have a story (maybe a few?) they are closely related to the \"Grace wants a zero-copy API\". I do ultra-low latency work. Think high-frequency trading or stock exchanges. I've been using Rust for some pet projects, but I'm now evaluating Rust for an upcoming ULL project.  Specifically, I'm looking at the async / await abstraction, as it's a lot nicer to read/write async code rather than callback-hell. If I can make it performant enough, I'd like to use it.</p>\n<p>So first a little background, and then the issues I've run into.  ULL code has these properties :</p>\n<p>It will use one and only one thread.<br>\nIt will never call epool/poll/select. It only communicates via shared memory. Either DMA'd data from the NICs (EFVI, DPDK, OpenOnload, etc). Or from other processes on the box. A big spin-loop across multiple queues.<br>\nIt will never cancel a task. Most are created at startup. The few ephemeral ones that pop up, exit when finished (TCP backpressure. A task works that \"socket\" until the stream is \"current\", then goes away).</p>\n<p>So the problem I've run into is that in a single-threaded context, async / await seems to devolve into coroutines except way harder to use. The abstraction to separate executors and reactors breaks down. If they aren't the same code, they are calling into each other. Every call to wake() is a direct call to poll().   The Future itself loses meaning. Getting data from the reactor into the Future is a PIA (await holds the mut ref on the Future). Moving data from the Future to the reactor is less hard but awkward.</p>\n<p>Unrelated to my problem, but every runtime has a multi-threaded and single-threaded version that only differs by the requirement for mutex/sync. (at least from a users POV)</p>\n<p>This is likely unworkable, but I'm gonna throw it out here anyway: I was playing with zig, and they have a --single-threaded you can pass to the compiler. It does a bunch of neat tricks, like:<br>\nmaking mutex a no-op<br>\nmaking Async Functions equivalent to function call overhead<br>\nconverting thread-local data to continer/statc data.<br>\nSo in theory Rust could convert sync/mutex to rc/refcell (might break every library in existence though). You wouldn't need two different APIs for each runtime anymore. Also maybe the bower checker could \"ease up\" a little if the developer pinky swears there will only be 1 thread? </p>\n<p>If this is a domain Rust is interested in working on, I'd be happy to help. It's pretty niche though. It might not be worth the changes required. </p>\n<p>I'm working on some benchmarks of different async implementations in various languages. I hope to have something to submit for review if anyone is interested.</p>\n<p>Thanks for your time,</p>\n<p>-Jon</p>",
        "id": 256018871,
        "sender_full_name": "JonRoss",
        "timestamp": 1633333739
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"418973\">@JonRoss</span>, if you want to contribute a status quo story, we'd be happy to take one. It sounds like your domain has some interesting constraints, so another story would definitely give some new aspects to consider.</p>",
        "id": 256083483,
        "sender_full_name": "eholk",
        "timestamp": 1633363411
    },
    {
        "content": "<p>I'd be interesting in seeing your benchmark results when you have them. For example, I don't see any reason why async calls in Rust (at least that are immediately awaited) couldn't be about as cheap as a function call, but if we aren't there yet it'd be interesting to see why.</p>",
        "id": 256083718,
        "sender_full_name": "eholk",
        "timestamp": 1633363495
    },
    {
        "content": "<blockquote>\n<p>The abstraction to separate executors and reactors breaks down.</p>\n</blockquote>\n<p>I don't think there's much of an abstraction to separate these in general, FWIW. That's something we would likely tackle as part of the <a href=\"https://rust-lang.github.io/wg-async-foundations/vision/roadmap/portable.html\">portability across runtimes</a> goal.</p>",
        "id": 256337815,
        "sender_full_name": "tmandry",
        "timestamp": 1633478442
    },
    {
        "content": "<p>Generality across single/multi-threadedness is something I care about too</p>",
        "id": 256338085,
        "sender_full_name": "tmandry",
        "timestamp": 1633478628
    },
    {
        "content": "<p>See <a href=\"https://rust-lang.github.io/wg-async-foundations/vision/roadmap/threadsafe_portability.html\">threadsafe portability</a> :)</p>",
        "id": 256338164,
        "sender_full_name": "tmandry",
        "timestamp": 1633478656
    },
    {
        "content": "<p>Also <a href=\"https://rust-lang.github.io/wg-async-foundations/vision/roadmap/async_overloading.html\">async overloading</a></p>",
        "id": 256338186,
        "sender_full_name": "tmandry",
        "timestamp": 1633478680
    },
    {
        "content": "<p>I'll take a stab at a draft in the next week or so.<br>\nI should have benchmarks to review by then as well. so far the results are... odd? rust-async is faster than plain rust. Same w/ zig, but only on AMD CPUs. Maybe something wrong with my methodology.</p>",
        "id": 256382196,
        "sender_full_name": "JonRoss",
        "timestamp": 1633512369
    },
    {
        "content": "<p>There is the cost of running the state machine</p>",
        "id": 256672850,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1633654386
    },
    {
        "content": "<p>I can't see how that could be as cheap as a regular function call</p>",
        "id": 256673117,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1633654586
    },
    {
        "content": "<p>Here are my benchmarks. Happy to hear feedback:<br>\n<a href=\"https://github.com/TwoClocks/coroutine-benchmarks\">https://github.com/TwoClocks/coroutine-benchmarks</a></p>",
        "id": 257444428,
        "sender_full_name": "JonRoss",
        "timestamp": 1634161877
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"363998\">Ibraheem Ahmed</span> <a href=\"#narrow/stream/187312-wg-async-foundations/topic/Hello.20.26.20maybe.20new.20Status.20Quo.20story.3F/near/256672850\">said</a>:</p>\n<blockquote>\n<p>There is the cost of running the state machine</p>\n</blockquote>\n<p>I think in the basic coroutines use case, it should/could get down to a function call. Or close to it.</p>",
        "id": 257445672,
        "sender_full_name": "JonRoss",
        "timestamp": 1634162438
    },
    {
        "content": "<p>Hey <span class=\"user-mention\" data-user-id=\"418973\">@JonRoss</span>, thanks for the benchmarks! I know you weren't really trying to compare languages, but it looks like all the languages were actually pretty similar.</p>",
        "id": 258120541,
        "sender_full_name": "eholk",
        "timestamp": 1634601456
    },
    {
        "content": "<p>I didn't read as deeply into the code, so I could probably find this there, but it wasn't really clear to me how each of the variants you tried were different.</p>",
        "id": 258120614,
        "sender_full_name": "eholk",
        "timestamp": 1634601488
    },
    {
        "content": "<p>Is there one that corresponds to kind of a vanilla async/await implementation in Rust?</p>",
        "id": 258120630,
        "sender_full_name": "eholk",
        "timestamp": 1634601501
    },
    {
        "content": "<p>Thanks for looking. Does the Rust implementation look sane?</p>\n<p>The absolute #s are small. But Rust's behavior seems variable across<br>\ndifferent CPUs. For example, callbacks are fast everywhere, except<br>\nRust on Intel. That seems odd / bug? I also think the absolute #s are<br>\na bit higher than the C++/Zig. The market for people who care about<br>\nthat kind of difference is small, it might not be worth addressing. On<br>\nthe other hand, it could be made to be the same.</p>\n<p>I think the most apparent ergonomic difference is that in all the<br>\nother languages, the event-loop doing the suspend needs no information<br>\nabout the task being suspended. It just gets handed a magic context<br>\nfrom the compiler that it can resume later. In Rust, the future needs<br>\nto somehow get it's waker to the event-loop on the first call to<br>\npoll(). I could not figure out how to do that w/o a  RefCell to some<br>\nshared context.</p>\n<p>Perhaps for the more general case, the Rust model is better. But for<br>\nmy use case, where I just want to use suspend everywhere I'd normally<br>\nhave a callback, it's \"funky\" to use, and hard to encapsulate into a<br>\nlibrary (I think?).</p>\n<p>In the future, if you have other version to try, I'd be happy to<br>\nre-run the tests on the same hardware.</p>\n<p>I'd be happy to write coroutine version on nightly, if you fell that<br>\ncode is stable enough for the results to be useful.</p>",
        "id": 258123830,
        "sender_full_name": "JonRoss",
        "timestamp": 1634603797
    }
]