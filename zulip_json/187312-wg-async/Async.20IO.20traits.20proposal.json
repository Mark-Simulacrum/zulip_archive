[
    {
        "content": "<p><a href=\"https://www.ncameron.org/blog/async-read-and-write-traits/\">https://www.ncameron.org/blog/async-read-and-write-traits/</a></p>",
        "id": 271979680,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644934668
    },
    {
        "content": "<p>The publish date is tomorrow?</p>",
        "id": 271980591,
        "sender_full_name": "Alice Ryhl",
        "timestamp": 1644935019
    },
    {
        "content": "<p>Probably thinks I'm in NZ?</p>",
        "id": 271980780,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644935082
    },
    {
        "content": "<p>Did you consider <code>trait AsyncRead: Read</code> versus <code>non_blocking_*</code>?</p>",
        "id": 271983194,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1644936032
    },
    {
        "content": "<p>I think the distinction is useful, but worth a mention</p>",
        "id": 271983234,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1644936051
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"256841\">@Nick Cameron</span> do you have a link to carl's proposal? Wonder if it would be useful to link that</p>",
        "id": 271985312,
        "sender_full_name": "Lucio Franco",
        "timestamp": 1644936885
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"207781\">@Lucio Franco</span> <a href=\"https://gist.github.com/carllerche/5d7037bd55dac1cb72891529a4ff1540\">https://gist.github.com/carllerche/5d7037bd55dac1cb72891529a4ff1540</a></p>",
        "id": 271985421,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644936938
    },
    {
        "content": "<p>I can add that link</p>",
        "id": 271985443,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644936949
    },
    {
        "content": "<p><a href=\"https://rust-lang.github.io/wg-async/vision/roadmap/portable/read_write.html?highlight=CArl#variant-a-readiness\">https://rust-lang.github.io/wg-async/vision/roadmap/portable/read_write.html?highlight=CArl#variant-a-readiness</a></p>",
        "id": 271985507,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1644936963
    },
    {
        "content": "<p>Oh, beat me to it :)</p>",
        "id": 271985523,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1644936972
    },
    {
        "content": "<p>done</p>",
        "id": 271985595,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644937002
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"363998\">@Ibraheem Ahmed</span> I did consider that, but its a requirement that the sync read function is non-blocking, i.e., returns on e-would-block, rather than blocks on it, so the implemention of Read::read will be different to async::Read::non_blocking_read</p>",
        "id": 271985766,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644937075
    },
    {
        "content": "<p>That is required so that one can use the readiness loop for many readers simultaneously</p>",
        "id": 271985865,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644937103
    },
    {
        "content": "<p>The idea would be Read implementations on an async resource would be non blocking</p>",
        "id": 271985944,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1644937138
    },
    {
        "content": "<p>Like a std::TcpStream in non blocking mode</p>",
        "id": 271985977,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1644937161
    },
    {
        "content": "<p>I do like an explicitly different method with that requirement better though</p>",
        "id": 271986032,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1644937186
    },
    {
        "content": "<p>I can see people accidentally calling Read::read on an async type</p>",
        "id": 271986423,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1644937312
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"256841\">@Nick Cameron</span> thanks! whats the reason for <code>non_blocking</code> over <code>try_</code>?</p>",
        "id": 271986766,
        "sender_full_name": "Lucio Franco",
        "timestamp": 1644937437
    },
    {
        "content": "<p>Its unfortunate that io uring will still need a BufRead so won't be 100% drop in</p>",
        "id": 271986836,
        "sender_full_name": "Lucio Franco",
        "timestamp": 1644937456
    },
    {
        "content": "<p>try_ is conventionally used to indicate a version of a function which returns a Result rather than making an assumption, which is not what is going on here</p>",
        "id": 271986915,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644937496
    },
    {
        "content": "<p>There might be a better name than non_blocking_, but I dislike try_ for the above reason and non_blocking_ seems ok since it is a version of read which does not block</p>",
        "id": 271987026,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644937552
    },
    {
        "content": "<p>I think it's potentially confusing, I've seen people try to use a non-blocking std type like an async IO type, people might call nom_blocking_read instead of read().await because they want \"non blocking IO\"</p>",
        "id": 271987273,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1644937668
    },
    {
        "content": "<p>there's also a conceptual issue (at least in my mind) about implying that the read is non-blocking, which it may not be</p>",
        "id": 271988808,
        "sender_full_name": "Toby Lawrence",
        "timestamp": 1644938298
    },
    {
        "content": "<p>I suppose <code>try_</code> vs <code>non_blocking_</code> is six of one/half a dozen of the other in that case, but... intent in naming can be useful</p>",
        "id": 271988870,
        "sender_full_name": "Toby Lawrence",
        "timestamp": 1644938332
    },
    {
        "content": "<blockquote>\n<p>However, this approach adds some complexity for the simple cases of read, would be a radical departure from the existing sync traits, and it's unclear if the lifetimes can be made to work in all cases.</p>\n</blockquote>\n<p>I was hoping to see a more thorough evaluation of this alternative, instead of just asserting that it has certain qualities. This applies to the other alternatives as well. It's hard to assess whether the proposal put forward is indeed optimal, if none of the alternatives are evaluated in the same way.</p>\n<p>For example if I ask: \"Okay, and <em>how</em> does it add complexity for the simple cases of read\", the post provides no answer.</p>",
        "id": 271991755,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1644939597
    },
    {
        "content": "<p>I guess I'm hoping to see a follow-up to this post which goes in more depth (doesn't need to be a post itself necessarily; for example an mdbook might work well for this level of detail).</p>",
        "id": 271991866,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1644939628
    },
    {
        "content": "<p>Does that make sense?</p>",
        "id": 271991907,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1644939654
    },
    {
        "content": "<p>Yeah, it makes sense but if I gave each alternative that much detail it would be very long</p>",
        "id": 271992775,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644940075
    },
    {
        "content": "<p>Probably some examples to illustrate in the repo would be good</p>",
        "id": 271992874,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644940105
    },
    {
        "content": "<p>heh, yeah I understand that - but this is also very important, and I'd actually like to understand every aspect that lead you to this conclusion. Right now it doesn't feel like I can meaningfully engage with your conclusion because I don't have the same information you have when you arrived at it.</p>",
        "id": 271993136,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1644940216
    },
    {
        "content": "<p>I like the list of \"goals\" put forward at the start of the post. I'd like to see all other alternatives evaluated against these goals too.</p>",
        "id": 271993390,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1644940310
    },
    {
        "content": "<p>is this happening prior to or in parallel with an actual RFC? I love blogs for reading about ideas, but they kind of suck for meaningfully engaging in terms of trying to go from idea to design/plan</p>",
        "id": 271998524,
        "sender_full_name": "Toby Lawrence",
        "timestamp": 1644942147
    },
    {
        "content": "<p>I would like to discuss now, then implement in futures-rs, getting buy-in from runtimes in parallel with these two steps, then RFC to land in std</p>",
        "id": 271999179,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644942441
    },
    {
        "content": "<p>yeah, I guess the mdbook approach hits this mark, but said another way: something more amenable to commenting inline would be appreciated; blogs fail badly on that front <span aria-label=\"pray\" class=\"emoji emoji-1f64f\" role=\"img\" title=\"pray\">:pray:</span></p>",
        "id": 271999387,
        "sender_full_name": "Toby Lawrence",
        "timestamp": 1644942523
    },
    {
        "content": "<p>err, not mdbook, I was thinking of hackmd</p>",
        "id": 271999540,
        "sender_full_name": "Toby Lawrence",
        "timestamp": 1644942585
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"256841\">@Nick Cameron</span> I'm not getting syntax highlighting on my end, is that expected?</p>\n<p><a href=\"/user_uploads/4715/eVWobt-K4uQr_UPWILW76V-l/Screen-Shot-2022-02-15-at-19.45.43.png\">Screen-Shot-2022-02-15-at-19.45.43.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/4715/eVWobt-K4uQr_UPWILW76V-l/Screen-Shot-2022-02-15-at-19.45.43.png\" title=\"Screen-Shot-2022-02-15-at-19.45.43.png\"><img src=\"/user_uploads/4715/eVWobt-K4uQr_UPWILW76V-l/Screen-Shot-2022-02-15-at-19.45.43.png\"></a></div>",
        "id": 272019669,
        "sender_full_name": "Daniel Henry-Mantilla",
        "timestamp": 1644950753
    },
    {
        "content": "<p>Unfortunately yeah</p>",
        "id": 272022248,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644951828
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"363998\">Ibraheem Ahmed</span> <a href=\"#narrow/stream/187312-wg-async/topic/Async.20IO.20traits.20proposal/near/271985944\">said</a>:</p>\n<blockquote>\n<p>The idea would be Read implementations on an async resource would be non blocking</p>\n</blockquote>\n<p>I don't think that assumption would work in some cases. Some resources may want to support both blocking and non-blocking operations.</p>",
        "id": 272035077,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1644957841
    },
    {
        "content": "<p>Regarding the <code>AsyncIo</code> trait, that seems like it would break something that <code>AsyncRead</code> and <code>AsyncWrite</code> don't: with <code>AsyncRead</code> and <code>AsyncWrite</code> it's possible to handle underlying systems that can't wait for something without providing a buffer.</p>",
        "id": 272035284,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1644957948
    },
    {
        "content": "<p><code>select</code>/<code>epoll</code>-style systems work on a file descriptor, and can just ask for readiness; those would work just fine with <code>AsyncIo</code>.</p>",
        "id": 272035377,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1644957987
    },
    {
        "content": "<p>iocb-based systems or Windows overlapped I/O or EFI I/O or io_uring, on the other hand, all really want to have the buffer available to queue the read/write with.</p>",
        "id": 272035454,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1644958038
    },
    {
        "content": "<p>Yeah, if you want optimal performance for completion systems you have to use the BufRead trait. They’ll work with Read and Ready, but it will need to do a copy</p>",
        "id": 272039283,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644959743
    },
    {
        "content": "<p>Same with <code>Write</code>: you want to supply the data to be written as early as possible, not just when the device is ready.</p>",
        "id": 272040622,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1644960397
    },
    {
        "content": "<p>(It's less of an issue with <code>Write</code> because OSes typically indicate things as ready even when they're not, to be able to capture and queue things sooner, but still.)</p>",
        "id": 272040661,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1644960423
    },
    {
        "content": "<p>Yeah, everything applies the same to writing as reading</p>",
        "id": 272041058,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644960613
    },
    {
        "content": "<p>Another potential footgun with <code>AsyncReady</code>: you can't wait for two or more things to be ready, and assume they all will be simultaneously. So, for instance, you can't wait for a reader and a writer to be ready, then read from the reader and write to the writer and assume the latter won't block and leave you holding a buffer.</p>",
        "id": 272051697,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1644966788
    },
    {
        "content": "<p>Since another reader might have consumed the data, or another writer might have written data to the writer and filled it up.</p>",
        "id": 272051738,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1644966834
    },
    {
        "content": "<blockquote>\n<p>The optimal way to use completion-based IO is to use the async version of the BufRead trait. The design of that is left for future work, but I don't anticipate any significant issues.</p>\n</blockquote>\n<p>I do think we want the design of that to be present <em>before</em> we commit to a read/write design that assumes BufRead will be feasible for that case.</p>",
        "id": 272051830,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1644966889
    },
    {
        "content": "<p>On a different note: since we're designing these traits without a backwards compatibility concern, should we have <em>any</em> implementation that uses initialized buffers rather than <code>ReadBuf</code>?</p>",
        "id": 272051997,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1644967005
    },
    {
        "content": "<p>It seems like we can make <code>ReadBuf</code> sufficiently ergonomic to use that we don't need <code>&amp;[u8]</code> versions.</p>",
        "id": 272052046,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1644967047
    },
    {
        "content": "<p>I plan on doing BufRead next, so should be done way before moving into std</p>",
        "id": 272084683,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644999254
    },
    {
        "content": "<p>It’s a good question about whether we need the bytes version at all, I’ll add it as an alternative. My feeling is that we should try to be as close as possible to the sync versions and it’s worth the small cost to have the extra methods, but I don’t feel strongly about it</p>",
        "id": 272084764,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644999325
    },
    {
        "content": "<p>I should clarify that ready can always return false positives, so the caller needs to be prepared for these situations</p>",
        "id": 272084844,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1644999367
    },
    {
        "content": "<p>Wait, false <em>positives</em>? So ready can say that it's ready when it isn't ready?</p>",
        "id": 272090935,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1645003371
    },
    {
        "content": "<p>So if you called <code>read</code> after <code>ready</code>, expecting data, you could just hang? And <code>non_blocking_read</code> could return no data?</p>",
        "id": 272091002,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1645003437
    },
    {
        "content": "<p>What's the use case for that?</p>",
        "id": 272091011,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1645003441
    },
    {
        "content": "<p>Yep. There's not so much a use case as a constraint of the underlying systems. AIUI, epoll can return false positives, but even if not, another process could have another handle to the same resource and read from it before our process gets a chance so that when we read there is nothing left. This is why the non-blocking functions can return would block errors and the memory-optimal path has to deal with those explicitly rather than leaving them to the runtime</p>",
        "id": 272095227,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645005900
    },
    {
        "content": "<p>To be clear, nothing hangs, you would immediately get WouldBlock</p>",
        "id": 272095261,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645005925
    },
    {
        "content": "<p>if a goal is to mimic the sync traits, the methods should probably use [u8] slices. and if we'd rather have ReadBuf, then maybe it should be adopted by the sync traits first?</p>",
        "id": 272148070,
        "sender_full_name": "Justin Karneges",
        "timestamp": 1645032287
    },
    {
        "content": "<p>ReadBuf has been adopted on nightly</p>",
        "id": 272149210,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645032718
    },
    {
        "content": "<p>oh! well then :)</p>",
        "id": 272149772,
        "sender_full_name": "Justin Karneges",
        "timestamp": 1645032928
    },
    {
        "content": "<p>how about <code>read_nonblocking</code> instead of <code>non_blocking_read</code> ? thinking about existing methods like <code>TcpStream::set_nonblocking</code> and the fact that most of the methods in the Read trait begin with <code>read_</code></p>",
        "id": 272150273,
        "sender_full_name": "Justin Karneges",
        "timestamp": 1645033127
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"256841\">@Nick Cameron</span> I'm curious, you referenced <code>smol</code> in your post, have you seen the <code>smol::Async</code> helper and its readiness functions, and the style of implementation those support?</p>",
        "id": 272151257,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1645033526
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"462944\">Justin Karneges</span> <a href=\"#narrow/stream/187312-wg-async/topic/Async.20IO.20traits.20proposal/near/272150273\">said</a>:</p>\n<blockquote>\n<p>how about <code>read_nonblocking</code> instead of <code>non_blocking_read</code> ? thinking about existing methods like <code>TcpStream::set_nonblocking</code> and </p>\n</blockquote>\n<p>That sounds reasonable and at the least it sounds like we should drop the <code>_</code>. I'll note though that TcpStream::set_nonblocking sets a property called non-blocking, it is not a variant of a set function which does not block.</p>\n<blockquote>\n<p>the fact that most of the methods in the Read trait begin with <code>read_</code></p>\n</blockquote>\n<p>I think it might be useful to distinguish at a glance the non-blocking functions from the various other read variants - if nonblocking is a suffix then the suffix position for all these functions gets very busy.</p>",
        "id": 272152630,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645034048
    },
    {
        "content": "<blockquote>\n<p>I'm curious, you referenced smol in your post, have you seen the smol::Async helper and its readiness functions, and the style of implementation those support?</p>\n</blockquote>\n<p>I've seen Async but not looked at the implementation, I'm not sure which readiness functions you're referring to?</p>",
        "id": 272152858,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645034150
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"256841\">@Nick Cameron</span> <code>Async&lt;T&gt;</code> wraps anything that has a file descriptor or handle, automatically puts it into non-blocking mode, and then provides async functions <code>readable</code> and <code>writable</code> that wait until that condition, or helpers like <code>read_with</code>/<code>read_with_mut</code> that handle the readiness conditions automatically and call your closure when the condition is met.</p>",
        "id": 272153898,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1645034501
    },
    {
        "content": "<p>Very convenient for implementing async types.</p>",
        "id": 272153946,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1645034517
    },
    {
        "content": "<p>another idea I'll throw out there, which may be crazy, is to consider having the async traits depend on the sync traits, and using the sync traits for I/O. after all, people use the sync traits for non-blocking I/O and this is a legitimate use of them</p>",
        "id": 272157557,
        "sender_full_name": "Justin Karneges",
        "timestamp": 1645035889
    },
    {
        "content": "<p>The first memory-sensitive implementation made me think that the <code>ready()</code> method should return a separate type that you can run the <code>non_blocking_read()</code> against</p>",
        "id": 272238377,
        "sender_full_name": "Dirkjan Ochtman",
        "timestamp": 1645092817
    },
    {
        "content": "<p>You don't have to wait for ready(), its perfectly safe and legal (though sub-optimal) to just poll the non_blocking methods and handle the would-block errors</p>",
        "id": 272241128,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645094316
    },
    {
        "content": "<p>(not sure if there is any reason to actually do that)</p>",
        "id": 272241164,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645094338
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/187312-wg-async/topic/Async.20IO.20traits.20proposal/near/272153946\">said</a>:</p>\n<blockquote>\n<p>Very convenient for implementing async types.</p>\n</blockquote>\n<p>That's actually a good point. If <code>std</code> would provide a <code>smol::Async</code>-like type, then those who want to could just open a <code>std::fs::File</code> in non-blocking mode, and manually wait for readiness events. Afaict there's no real difference between <code>std::io::Read::read</code> and <code>AsyncRead::read_non_blocking</code>.</p>\n<p>Instead of extending the async APIs with non-async capabilities for performance, this builds up the non-async APIs with the ability to wait for readiness events.</p>",
        "id": 272247348,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1645098281
    },
    {
        "content": "<p>In std we could even imagine that for example <code>std::async_fs::File</code> is implemented in terms of an <code>Async&lt;std::fs::File&gt;</code>. So we could expose a safe cast to access the internal value for specialized uses.</p>",
        "id": 272247571,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1645098426
    },
    {
        "content": "<p>I feel like we've already acknowledged that waiting on readiness APIs and <code>non_blocking_read</code> is a niche (but valid!) use case. So moving it off the main API into its own section might be the right way to go about this.</p>\n<p>Idk, this feels like the most balanced direction I've seen proposed so far. And I wonder if we could try thinking this through entirely.</p>",
        "id": 272247869,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1645098620
    },
    {
        "content": "<p>Stepped away for a sec, and now realizing that <code>smol::Async</code> is in fact a <em>concrete</em> runtime building block, and what we're looking for is an <em>abstract</em> interface that expresses the same capabilities. So we can't lift the implementation 1:1 for this purpose - so this will require some design work. But I think this has potential.</p>",
        "id": 272250599,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1645100255
    },
    {
        "content": "<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">struct</span> <span class=\"nc\">Token</span><span class=\"p\">(</span><span class=\"kt\">u64</span><span class=\"p\">);</span><span class=\"w\"></span>\n\n<span class=\"k\">trait</span><span class=\"w\"> </span><span class=\"n\">Registry</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">fn</span> <span class=\"nf\">register</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">fd</span>: <span class=\"nc\">RawFd</span><span class=\"p\">)</span><span class=\"w\"> </span>-&gt; <span class=\"nc\">io</span>::<span class=\"nb\">Result</span><span class=\"o\">&lt;</span><span class=\"n\">Token</span><span class=\"o\">&gt;</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">fn</span> <span class=\"nf\">poll_ready</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">token</span>: <span class=\"nc\">Token</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">interest</span>: <span class=\"nc\">Interest</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">cx</span>: <span class=\"kp\">&amp;</span><span class=\"nc\">mut</span><span class=\"w\"> </span><span class=\"n\">Context</span><span class=\"o\">&lt;'</span><span class=\"nb\">_</span><span class=\"o\">&gt;</span><span class=\"p\">)</span><span class=\"w\"> </span>-&gt; <span class=\"nc\">io</span>::<span class=\"nb\">Result</span><span class=\"o\">&lt;</span><span class=\"n\">Poll</span><span class=\"o\">&lt;</span><span class=\"p\">()</span><span class=\"o\">&gt;&gt;</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">fn</span> <span class=\"nf\">deregister</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">token</span>: <span class=\"nc\">Token</span><span class=\"p\">)</span><span class=\"w\"> </span>-&gt; <span class=\"nc\">io</span>::<span class=\"nb\">Result</span><span class=\"o\">&lt;</span><span class=\"p\">()</span><span class=\"o\">&gt;</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n\n<span class=\"k\">struct</span> <span class=\"nc\">Async</span><span class=\"o\">&lt;</span><span class=\"n\">T</span>: <span class=\"nc\">AsRawFd</span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">fd</span>: <span class=\"nc\">RawFd</span><span class=\"p\">,</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">token</span>: <span class=\"nc\">Token</span><span class=\"p\">,</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n\n<span class=\"k\">impl</span><span class=\"o\">&lt;</span><span class=\"n\">T</span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"n\">Async</span><span class=\"o\">&lt;</span><span class=\"n\">T</span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">fn</span> <span class=\"nf\">new</span><span class=\"p\">(</span><span class=\"n\">io</span>: <span class=\"nc\">T</span><span class=\"p\">)</span><span class=\"w\"> </span>-&gt; <span class=\"nc\">io</span>::<span class=\"nb\">Result</span><span class=\"o\">&lt;</span><span class=\"bp\">Self</span><span class=\"o\">&gt;</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"n\">with</span><span class=\"w\"> </span><span class=\"n\">registry</span>: <span class=\"nc\">Registry</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"c1\">// ...</span>\n<span class=\"w\">    </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 272263641,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1645106798
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"256841\">@Nick Cameron</span> I shared your blog post with the Fuchsia filesystems team and got this feedback:</p>\n<blockquote>\n<p>The proposal suggests that for optimal performance, Ready should be used followed by a read call later. I think that might be quite challenging for us to implement because it would require locking between the ready notification and the read (to prevent the kernel discarding pages under memory pressure) and AFAICT, there's no indication of how much should be locked in the ready call.</p>\n</blockquote>",
        "id": 272349153,
        "sender_full_name": "tmandry",
        "timestamp": 1645148284
    },
    {
        "content": "<p>I'm wondering if a byte count could be added to <code>Interest</code></p>",
        "id": 272349237,
        "sender_full_name": "tmandry",
        "timestamp": 1645148395
    },
    {
        "content": "<p>Thanks for running it by them! So, I know nothing about Fuchsia, so excuse my basic questions :-) Is it a readiness model for async IO it supports? Do they want to lock the pages for correctness or performance? The ready method is allowed false positives, so from the APIs PoV, if Fuchsia says a resource is ready but the page is discarded so read/write returns would-block, that is fine. Of course if that happens a lot then it isn't very performant. OTOH if ready locks a page and the user never calls read/write, then that seems bad unless the lock can timeout?</p>",
        "id": 272377766,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645175844
    },
    {
        "content": "<p>We could add a byte count to interest</p>",
        "id": 272377928,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645175956
    },
    {
        "content": "<p>I wonder whether this might be a case where the optimal API for Fuchsia is different to epoll? Similarly to how for IOCP or io_uring the BufRead API will be more optimal?</p>",
        "id": 272378081,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645176053
    },
    {
        "content": "<blockquote>\n<p>another idea I'll throw out there, which may be crazy, is to consider having the async traits depend on the sync traits, and using the sync traits for I/O. after all, people use the sync traits for non-blocking I/O and this is a legitimate use of them</p>\n</blockquote>",
        "id": 272378779,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645176485
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/187312-wg-async/topic/Async.20IO.20traits.20proposal/near/272153898\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"256841\">Nick Cameron</span> <code>Async&lt;T&gt;</code> wraps anything that has a file descriptor or handle, automatically puts it into non-blocking mode, and then provides async functions <code>readable</code> and <code>writable</code> that wait until that condition, or helpers like <code>read_with</code>/<code>read_with_mut</code> that handle the readiness conditions automatically and call your closure when the condition is met.</p>\n</blockquote>\n<p>So, readable/writable are less general forms of the <code>ready</code> method from my proposal, I discuss having methods like readable /writable as an alternative, and it seems reasonable though not as flexible. The read_with style of helper looks interesting, that could potentially make the memory-optimal path more ergonomic.</p>",
        "id": 272379479,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645176977
    },
    {
        "content": "<p>However, for that seems limited to waiting for a single operation on a single resource, whereas often users will want to wait on either multiple resources in a single loop and/or multiple operations on a resource, and in that case the helper methods wouldn't help. I'm not sure how often these use cases come up though. It would depend on how often a user would just use the async fn vs use the helper vs write the loop, whether its worth adding them</p>",
        "id": 272379723,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645177143
    },
    {
        "content": "<p>In any case, I'll add a note on the tracking issue. Thanks for pointing it out!</p>",
        "id": 272379768,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645177172
    },
    {
        "content": "<blockquote>\n<p>Stepped away for a sec, and now realizing that smol::Async is in fact a concrete runtime building block, and what we're looking for is an abstract interface that expresses the same capabilities. So we can't lift the implementation 1:1 for this purpose - so this will require some design work. But I think this has potential.</p>\n</blockquote>\n<p>This seems like a really interesting idea, though I don't see exactly how this would work without fleshing out the design. A couple of problems I see are making sure this still works nicely for generic programming, i.e., we can still write a bound equivalent to <code>T: AsyncRead + AsyncWrite</code>, and I'm wary of adding to the sync traits anything that is not relevant for people not doing async programming, since that would be making the 'easy' path in the language harder. (Violating some principal of zero-cost abstractions applied to ergonomics rather than performance)</p>",
        "id": 272380164,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645177458
    },
    {
        "content": "<blockquote>\n<p>the sync ones should handle would-block internally</p>\n</blockquote>\n<p>if you mean using std::io::Read/Write for blocking I/O shouldn't return WouldBlock, I agree. however, those traits can be used for non-blocking I/O too. perhaps \"sync\" is the wrong word to describe the std::io traits, since they are not strictly limited to synchronous use-cases</p>\n<blockquote>\n<p>They may also want to be different concrete types</p>\n</blockquote>\n<p>sure, and they still could be, unless I'm missing something. for example, std::net::TcpStream implements std::io::Read/Write, and a hypothetical async::TcpStream could implement both async::Read/Write and std::io::Read/Write.</p>\n<blockquote>\n<p>having types with modes (in this case sync vs async) which are not reflected in the types is confusing and error-prone</p>\n</blockquote>\n<p>I suspect most developers would create multiple types rather than create single types with modes. what I'm mainly suggesting here is a way to avoid duplicating interfaces. if async::Read needs a helper method that is more or else identical to the read method in std::io::Read, then there could be value in reusing the interface. it may also make wrapping &amp; forwarding easier. for example, async::TcpStream wrapping a std::net::TcpStream, setting it to non-blocking mode, and forwarding the std::io methods</p>",
        "id": 272435308,
        "sender_full_name": "Justin Karneges",
        "timestamp": 1645207308
    },
    {
        "content": "<p>I think that would still be a bit confusing, especially with generic programming - a function which takes an impl or dyn Read expects blocking behaviour and won't handle the would-block error properly</p>",
        "id": 272443321,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645211072
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"256841\">Nick Cameron</span> <a href=\"#narrow/stream/187312-wg-async/topic/Async.20IO.20traits.20proposal/near/272443321\">said</a>:</p>\n<blockquote>\n<p>I think that would still be a bit confusing, especially with generic programming - a function which takes an impl or dyn Read expects blocking behaviour and won't handle the would-block error properly</p>\n</blockquote>\n<p>That's not entirely true, there are APIs that expect a <code>T: Read</code> set to non-blocking mode</p>",
        "id": 272451092,
        "sender_full_name": "Ibraheem Ahmed",
        "timestamp": 1645214844
    },
    {
        "content": "<p>Right but that’s a requirement of the api, this would be up to the concrete type so there is no way that the callee could always do the right thing</p>",
        "id": 272455150,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645217175
    },
    {
        "content": "<p>it's always up to the concrete type to decide whether to operate in blocking mode or not</p>",
        "id": 272461929,
        "sender_full_name": "Justin Karneges",
        "timestamp": 1645220870
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"256841\">Nick Cameron</span> <a href=\"#narrow/stream/187312-wg-async/topic/Async.20IO.20traits.20proposal/near/272377766\">said</a>:</p>\n<blockquote>\n<p>Is it a readiness model for async IO it supports?</p>\n</blockquote>\n<p>Just catching up from vacation, sorry for the delay. Yes, the readiness model seems like a good fit for the <a href=\"https://fuchsia.googlesource.com/fuchsia/+/refs/heads/main/sdk/lib/zxio/#asynchronously-waiting-for-state-changes\">zxio APIs</a></p>",
        "id": 273029961,
        "sender_full_name": "tmandry",
        "timestamp": 1645661106
    },
    {
        "content": "<p>I'm waiting to hear back on the locking question</p>",
        "id": 273029989,
        "sender_full_name": "tmandry",
        "timestamp": 1645661127
    },
    {
        "content": "<p>Another thing that was brought up:</p>\n<blockquote>\n<p>one thing to be concerned with is how readiness works when it's queued multiple times, there are subtle differences between kqueue/epoll/uring/etc behavior for those use cases, and the api might want to be clear about user expectations if it's trying to be portable</p>\n</blockquote>",
        "id": 273030058,
        "sender_full_name": "tmandry",
        "timestamp": 1645661163
    },
    {
        "content": "<p>Hi folks! I work on parts of Fuchsia's IO stack (such as zxio mentioned by Tyler). There was a question earlier about the readiness model. We do support a readiness model for all IO objects. Whether that's the right model to use for a given operation and the details of the operation is a different issue. Catching up here it's not clear to me exactly what the intended use cases are for this API vs others.</p>",
        "id": 273031412,
        "sender_full_name": "James Robinson",
        "timestamp": 1645662236
    },
    {
        "content": "<p>At a high level, it'll generally be more efficient to have clients tell the OS what operation they want completed in order for them to make progress and then we can signal them when that is complete. In the read case a program can usually make useful forward progress once the data that they want to read is available, not just when they can start the read. There's sometimes more refinement - such as asking to be informed when a socket has at least a certain amount of data available.</p>",
        "id": 273032102,
        "sender_full_name": "James Robinson",
        "timestamp": 1645662757
    },
    {
        "content": "<p>I think this boils down to adding an optional byte count to the <code>Interest</code> type.</p>",
        "id": 273034803,
        "sender_full_name": "tmandry",
        "timestamp": 1645664744
    },
    {
        "content": "<blockquote>\n<p>Catching up here it's not clear to me exactly what the intended use cases are for this API vs others.</p>\n</blockquote>\n<p>To summarize my understanding (<span class=\"user-mention\" data-user-id=\"256841\">@Nick Cameron</span> can correct me if I'm wrong), it's to provide an asynchronous analogue to the <a href=\"https://doc.rust-lang.org/stable/std/io/trait.Read.html\"><code>io::Read</code></a> and <a href=\"https://doc.rust-lang.org/stable/std/io/trait.Write.html\"><code>io::Write</code></a> traits, which <em>allow the caller to fully manage the target buffer</em> between calls and are used for file I/O, sockets, and \"middleware\" layers. The interface should resemble the original traits without giving up performance (under the constraint that the caller fully manages the target buffer).</p>\n<p>Interfaces that allow the underlying implementation to manage the target buffer (i.e. completion-backed APIs that hand the kernel a target buffer to write to) would be abstracted behind an async version of the <a href=\"https://doc.rust-lang.org/nightly/std/io/trait.BufRead.html\"><code>io::BufRead</code></a> trait, which hasn't been specced out yet.</p>",
        "id": 273035457,
        "sender_full_name": "tmandry",
        "timestamp": 1645665224
    },
    {
        "content": "<p>Yep, that's a good summary</p>",
        "id": 273089474,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645709836
    },
    {
        "content": "<p>It sounds from the above and from the zxio docs that zxio is more of a completion based system? I.e., for a read, the kernel gets a buffer pointer, fills the buffer, and notifies the client when the read is done (i.e., data has been written in to the buffer). Even though the user is responsible for keeping the buffer alive for the duration of the call, I think ownership is still morally transferred to the kernel. Thus the BufRead/BufWrite traits are going to be a better match for Fuschia.</p>",
        "id": 273089941,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645710072
    },
    {
        "content": "<blockquote>\n<p>I think this boils down to adding an optional byte count to the Interest type.</p>\n</blockquote>\n<p>I think this makes more sense for the BufRead case than for Read. For Read, I'd expect a notification as soon as any data is ready to be read, and the kernel may not even know how much there is. For BufRead, it makes sense because it is customising the notion of when the IO is complete</p>",
        "id": 273090082,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1645710157
    },
    {
        "content": "<p>In zxio there are two modes of asynchronous operations. One is to ask the object to perform the operation and asynchronously notify the caller when it is complete (completion based, as you say). We support this on some operations and plan to expand support. The other is a two-phase approach where you first ask the object to notify you asynchronously when an operation of a certain type (read/write/etc) could start, and when you ask the object to attempt the operation (zxio doesn't block if the operation can't be performed but it returns an error). The two-phase approach is supported by all objects and maps naturally to common patterns like select/poll/epoll and O_NONBLOCK semantics. I believe it's pretty similar to the async Read proposal above. The completion based approach may map well to BufRead - although I'm not sure precisely what that proposal is</p>\n<p>While we do support the two-phase mode universally it can be significantly less efficient than performing the operation itself asynchronously. There are several challenges for the implementation of the file object (kernel, filesystem, whatnot). The implementation has to maintain many invariants on the file for each operation - such as atomicity and ordering w.r.t. the seek positioning and size - so it can't perform much work when told that someone is interested in a type. It's also difficult to avoid thundering herds when many clients are asking to perform the same operation on the same object.</p>",
        "id": 273308379,
        "sender_full_name": "James Robinson",
        "timestamp": 1645839820
    },
    {
        "content": "<p>BTW, I'm the author of the \"The proposal suggests that for optimal performance\" comment. I'm interested in this API for filesystem I/O (not so much stream based I/O) and I've been thinking about an async kernel interface (which we haven't really done yet on Fuchsia). Even with a byte count for Interest, I think it's still problematic for the reasons mentioned: locking pages is impractical so we'd end up retrying but that's undesirable for a high performance interface — the last thing you want is for performance to drop off a cliff at the limits. One thing that might be worth thinking about is how cancellation is going to work and limiting the number of memory copies we do. We'd either need to support a syscall that cancels a queued I/O operation, or buffers need to change owners or be 'static or something else (cf. BufReader). It would be nice to sketch out the ideal kernel interface for Rust async I/O.</p>",
        "id": 274581403,
        "sender_full_name": "Chris Suter",
        "timestamp": 1646763161
    },
    {
        "content": "<p>I've started to write up the IO traits proposal in a GH repo and will continue to evolve it there: <a href=\"https://github.com/nrc/portable-interoperable/tree/master/io-traits\">https://github.com/nrc/portable-interoperable/tree/master/io-traits</a></p>",
        "id": 275674626,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1647532203
    },
    {
        "content": "<p>I haven't started to address the 'Fuchsia' comments yet, but I'll try and get a better understanding of those issues next</p>",
        "id": 275674760,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1647532245
    },
    {
        "content": "<p>cc <span class=\"user-mention\" data-user-id=\"211722\">@Yoshua Wuyts [he/they]</span> I've included some expanded discussion of the alternatives for async::Read/Write. Could you file issues or send a PR for anything you think is misrepresented or should be further addressed?</p>",
        "id": 275674928,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1647532310
    },
    {
        "content": "<p>Will do! -- I'll make sure to make some time for that</p>",
        "id": 275679258,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1647533286
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"256841\">@Nick Cameron</span> done: <a href=\"https://github.com/nrc/portable-interoperable/issues/7\">https://github.com/nrc/portable-interoperable/issues/7</a> -- it's a chonky issue that suggests a rather large change. But I can make time to help with this work.</p>",
        "id": 275697971,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1647538138
    },
    {
        "content": "<p>I guess what I'm suggesting is loosely inspired by the \"decision tree\" approach we've taken for other designs in the past.  That worked rather well in creating shared understanding, ensuring everyone's opinion was represented, and allowing others to follow along with the rationale.</p>\n<p>I believe <span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> introduced me to that? - was it for the <code>async/.await</code> syntax?</p>",
        "id": 275698453,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1647538334
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"256841\">@Nick Cameron</span> Under what circumstances do you expect the Ready trait to be implemented via some means other than epoll/WaitForMultipleObjects?</p>",
        "id": 275702278,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1647540025
    },
    {
        "content": "<p>I'm asking because I wonder if we could simplify the design by relying on AsFd/AsHandle.</p>",
        "id": 275702447,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1647540100
    },
    {
        "content": "<p>I'm not quite clear what that means. I would expect all IO systems to implement Ready. For completion systems it would be a sub-optimal implementation and the optimal path is using BufRead, but they would probably still want to implement it for completeness. I would expect any readiness system to implement it directly. I don't have an exhaustive list of these systems, but KQueue is an example. I'm not sure either what a simplification using FDs/handles would look like?</p>",
        "id": 275771753,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1647592005
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211722\">@Yoshua Wuyts [he/they]</span> one thing is that the designs should be read in conjunction with the blog posts which explicitly list requirements (under 'goals'), etc. I would like to evolve the design work in the repo to include that (and more) so that they standalone, but for now there is a lot of supporting work in the blog posts. I also list for the alternatives where they fall down against those goals. So I think there is most of the information you want but in a different format?</p>",
        "id": 275772547,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1647592564
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"256841\">Nick Cameron</span> <a href=\"#narrow/stream/187312-wg-async/topic/Async.20IO.20traits.20proposal/near/275772547\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"211722\">Yoshua Wuyts [he/they]</span> I would like to evolve the design work in the repo to include that (and more) so that they standalone [...].</p>\n</blockquote>\n<p>Yes, that would be fantastic. I'm looking forward to it!</p>",
        "id": 275788692,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1647602236
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"256841\">Nick Cameron</span> <a href=\"#narrow/stream/187312-wg-async/topic/Async.20IO.20traits.20proposal/near/275772547\">said</a>:</p>\n<blockquote>\n<p>So I think there is most of the information you want but in a different format?</p>\n</blockquote>\n<p>I'm not sure. I feel like some of the requirements I care about haven't been sufficiently addressed. And there are definitely experiments which I think we should conduct which don't have a clear place to put. The way the information is currently structured makes it hard to say anything for sure, so that's why I'm keen that on us addressing that first.</p>",
        "id": 275788717,
        "sender_full_name": "Yoshua Wuyts [he/they]",
        "timestamp": 1647602255
    },
    {
        "content": "<p>I've started moving blog post text to the repo, including the requirements and some accounting of how well the proposal meets them</p>",
        "id": 275816480,
        "sender_full_name": "Nick Cameron",
        "timestamp": 1647616586
    }
]