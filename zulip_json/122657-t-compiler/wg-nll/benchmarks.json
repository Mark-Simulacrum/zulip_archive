[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116113\">@lqd</span> (cc <span class=\"user-mention\" data-user-id=\"116609\">@Frank McSherry</span>) — it looks like some new benchmarks were recently added to <a href=\"http://perf.rust-lang.org/\" target=\"_blank\" title=\"http://perf.rust-lang.org/\">perf</a> — in particular <code>webrender</code> seems to exhibit ungreat NLL perf, maybe we should add that one for testing.</p>",
        "id": 127071473,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527238398
    },
    {
        "content": "<p>also <code>cargo</code></p>",
        "id": 127071483,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527238434
    },
    {
        "content": "<p><span class=\"emoji emoji-1f44d\" title=\"thumbs up\">:thumbs_up:</span></p>",
        "id": 127071533,
        "sender_full_name": "lqd",
        "timestamp": 1527238497
    },
    {
        "content": "<p>did Reed's PR to have the invalidates facts land in rustc ?</p>",
        "id": 127071542,
        "sender_full_name": "lqd",
        "timestamp": 1527238525
    },
    {
        "content": "<p>at least so I can quickly try 1) leapfrog on it, 2) the loc-insensitive prepass on it</p>",
        "id": 127071663,
        "sender_full_name": "lqd",
        "timestamp": 1527238701
    },
    {
        "content": "<p>/me tries -Znll-facts :3, result: it does have them all yay</p>",
        "id": 127071787,
        "sender_full_name": "lqd",
        "timestamp": 1527238877
    },
    {
        "content": "<p>one challenge: figuring out which fns are slow. Might be just the biggest ones. Before I did timing measurements. (Would also be worth looking again at clap to see which other fns are slow.) I don't know if those timing measurements are in nightly or not though (you could see the results for indiv functions with <code>-Ztime-passes</code>, I probably would have to recreate the patch)</p>",
        "id": 127072868,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527240914
    },
    {
        "content": "<p>this is what was inside my reply box but didn't hit send :) webrender has 4-5 subcrates, dependencies, etc &amp; must have a lot of functions</p>",
        "id": 127072918,
        "sender_full_name": "lqd",
        "timestamp": 1527240968
    },
    {
        "content": "<p>More benchmarks is great. Is there any reason a <span class=\"emoji emoji-1f438\" title=\"frog\">:frog:</span> based non-NLL phase (perhaps this is the location-invariant version) which does the old LL borrow checking should be any slower? Probably not worth worrying too much about the perf on problems well addressed by that, and rather just on the gap between the two.</p>",
        "id": 127072936,
        "sender_full_name": "Frank McSherry",
        "timestamp": 1527241036
    },
    {
        "content": "<p>(( Also, just responded to <span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span>'s mention, and then realized that there is already some chitchat, sorry. ))</p>",
        "id": 127072947,
        "sender_full_name": "Frank McSherry",
        "timestamp": 1527241079
    },
    {
        "content": "<p>this is basically the location-insensitive variant (although it is not <em>lexical</em>)</p>",
        "id": 127072992,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241113
    },
    {
        "content": "<p>the location-insensitive variant is actually less expressive in some ways — notably it doesn't track where a borrow was introduced and limit its effects to locations reachable from there — but I think likely still serves as an effective pre-screen</p>",
        "id": 127073006,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241152
    },
    {
        "content": "<p>keep in mind though that the NLL numbers we see on perf — at least based on the profiles i've done elsewhere, i'll have to repeat for the new cases — are often registering overhead that occurs before/after the \"core analysis\" that polonius models anyway</p>",
        "id": 127073012,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241186
    },
    {
        "content": "<p>(although a major source of the overhead for clap is still squarely in the dataflow that polonius subsumes)</p>",
        "id": 127073060,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241225
    },
    {
        "content": "<p>(if needed, we could make the location-insensitive variant somewhat more precise of course)</p>",
        "id": 127073078,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241286
    },
    {
        "content": "<p>just trying it on cargo/webrender would answer if we need to make it more precise right ?</p>",
        "id": 127073089,
        "sender_full_name": "lqd",
        "timestamp": 1527241315
    },
    {
        "content": "<p>or would the imprecisions be in what it doesn't output, most likely ?</p>",
        "id": 127073133,
        "sender_full_name": "lqd",
        "timestamp": 1527241331
    },
    {
        "content": "<p>My intuition (based only on programs that I've written) is that most borrowing / lifetimes don't require NLL, and for the borrows that can be dispatched early with traditional reasoning, they just all get dropped from the NLL input and hooray.</p>",
        "id": 127073139,
        "sender_full_name": "Frank McSherry",
        "timestamp": 1527241355
    },
    {
        "content": "<p>if we try it and find it emits no errors, then we are satisfied (for now)</p>",
        "id": 127073143,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241363
    },
    {
        "content": "<p>if it <em>does</em> emit errors, then <em>either</em> we try and adopt the approach where we use those errors to limit the work of the location-sensitive variant — or else we make it more precise so that it screens out errors</p>",
        "id": 127073159,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241401
    },
    {
        "content": "<p>Sort of related Q: are there any/many benchmarks of programs that exercise the NLL nature of NLL? Like, large programs that don't pass current borrow_ck but should.</p>",
        "id": 127073161,
        "sender_full_name": "Frank McSherry",
        "timestamp": 1527241407
    },
    {
        "content": "<p>no</p>",
        "id": 127073163,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241417
    },
    {
        "content": "<p>I guess they will come in time :)</p>",
        "id": 127073165,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241429
    },
    {
        "content": "<p>So, hypothetically if NLL gets turned on there may be a spike in \"whoa, we didn't see this sort of behavior before.\"</p>",
        "id": 127073209,
        "sender_full_name": "Frank McSherry",
        "timestamp": 1527241444
    },
    {
        "content": "<p>(relating to your intution, clearly every extant rust program does not need NLL...)</p>",
        "id": 127073219,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241481
    },
    {
        "content": "<p>I'm not sure exactly what you mean by \"this behavior\" — like, these sorts of compile times? oh, just \"programs exhibiting these properties\"?</p>",
        "id": 127073234,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241521
    },
    {
        "content": "<p>I guess I was thinking \"performance defects in NLL reasoning\" akin to whatever might be stressing out webrender.</p>",
        "id": 127073282,
        "sender_full_name": "Frank McSherry",
        "timestamp": 1527241585
    },
    {
        "content": "<p>seems plausible</p>",
        "id": 127073290,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241613
    },
    {
        "content": "<p>I certainly expect a period — after turning on NLL — of bug reports related to it, whether they be perf or correctness...</p>",
        "id": 127073311,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241665
    },
    {
        "content": "<p>can we get facts when using cargo ?</p>",
        "id": 127073377,
        "sender_full_name": "lqd",
        "timestamp": 1527241792
    },
    {
        "content": "<p><code>cargo rustc -- -Znll-facts</code> probably works</p>",
        "id": 127073425,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527241821
    },
    {
        "content": "<p>It would be pretty not-hard to add in a bit of diagnostic code: in each of the <code>join</code> things, one can run a timer and attribute the resulting <code>Duration</code> to the destination relation, and print everything out in <code>Drop</code> code. I've got something that does this for tuple counts already, but .. should the need arise for more consistent diagnosis stuff (a la souffle).</p>",
        "id": 127073557,
        "sender_full_name": "Frank McSherry",
        "timestamp": 1527242110
    },
    {
        "content": "<p>unfortunately facts with cargo doesn't produce anything, this is going to be tougher than I expected :) it's time to bring out cargo -v :3</p>",
        "id": 127073608,
        "sender_full_name": "lqd",
        "timestamp": 1527242180
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116113\">@lqd</span> I think you need to add <code>#![feature(nll)]</code> too (or the suitable <code>-Z</code> flags)</p>",
        "id": 127074030,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527242808
    },
    {
        "content": "<p>oh interesting, rustc-perf is a bit obscure from the outside :)</p>",
        "id": 127074042,
        "sender_full_name": "lqd",
        "timestamp": 1527242854
    },
    {
        "content": "<p>good to know, indeed cargo + the feature = <span class=\"emoji emoji-1f44d\" title=\"thumbs up\">:thumbs_up:</span></p>",
        "id": 127074502,
        "sender_full_name": "lqd",
        "timestamp": 1527243503
    },
    {
        "content": "<p>interesting, just checking the facts, it might also be not a single slow function, they seem small-ish for webrender itself (the biggest 20 fns combined are less than the clap dataset) so maybe time-passes would be indeed worthwhile (or could also be shared in slow dependencies)</p>",
        "id": 127074905,
        "sender_full_name": "lqd",
        "timestamp": 1527244305
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> what I seeing is this: 1) <code>time: 130.060; rss: 292MB  MIR borrow checking</code> 2) a couple thousand <code>solve_nll_region_constraints</code>timed at 0.000 3) 2 or 3 timed at 0.001 -- should I be looking at something in particular ?</p>",
        "id": 127075322,
        "sender_full_name": "lqd",
        "timestamp": 1527245156
    },
    {
        "content": "<p>(btw, is rustc doing the NLL analysis in parallel, e.g. $nb_cores functions at a time ? if not, could we now ? there must some intricacies collating results, but at least spinning multiple datafrog computations at the same time seems doable)</p>",
        "id": 127075730,
        "sender_full_name": "lqd",
        "timestamp": 1527245847
    },
    {
        "content": "<p>We are not. I would encourage you not to think about parallelism: I think we should strive to make it work on a single core.</p>",
        "id": 127078765,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251128
    },
    {
        "content": "<p>My reasoning:</p>",
        "id": 127078768,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251134
    },
    {
        "content": "<p>1. we are actively working on adding parallelism within crates and queries, which would mean taht we would process N functions at once.</p>",
        "id": 127078783,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251159
    },
    {
        "content": "<p>2. we often compile N crates at once</p>",
        "id": 127078825,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251171
    },
    {
        "content": "<p>3. once we have those pieces in place, we can yes imagine doing parallel sorts and so forth — but we would want to balance resource usage overall</p>",
        "id": 127078831,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251196
    },
    {
        "content": "<p>I think we have a story there, but we shouldn't look to parallelism alone as the \"salvation\", I guess is what i'm saying .. often the cores will be busy elsewhere :)</p>",
        "id": 127078842,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251216
    },
    {
        "content": "<p>agreed, it was just a random thought :)</p>",
        "id": 127078844,
        "sender_full_name": "lqd",
        "timestamp": 1527251221
    },
    {
        "content": "<p>that said, we <em>should</em> probably try it out</p>",
        "id": 127078846,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251221
    },
    {
        "content": "<p>so let me weaken my statement :)</p>",
        "id": 127078853,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251231
    },
    {
        "content": "<p>that is, once we <em>have</em> those pieces in place — in particular, rustc will have a fork of rayon that will hopefully eventually be the real rayon — it'd be nice if we already knew how best to take advantage of it!</p>",
        "id": 127078862,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251262
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> btw did you see the previous \"130s mir borrow checking\" without easy to notice slow subtasks ? is there maybe a way to have more information about the times passes (besides profiling rustc)</p>",
        "id": 127078994,
        "sender_full_name": "lqd",
        "timestamp": 1527251429
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116113\">@lqd</span> so time-passes is basically useless</p>",
        "id": 127078998,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251455
    },
    {
        "content": "<p>and you should ignore it</p>",
        "id": 127079000,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251459
    },
    {
        "content": "<p>that is, it is not telling you what it looks like it is telling you</p>",
        "id": 127079010,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251477
    },
    {
        "content": "<p>we are in the process of replacing it with something that will give realistic numbers</p>",
        "id": 127079014,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251494
    },
    {
        "content": "<p>e.g., in that output, it is not clear what composes those 130s</p>",
        "id": 127079016,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251501
    },
    {
        "content": "<p>it includes at least mir borrow checking...but quite possibly other things, like mir construction</p>",
        "id": 127079019,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251511
    },
    {
        "content": "<p>that said, I had a locally extended version of the compiler</p>",
        "id": 127079060,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251525
    },
    {
        "content": "<p>that hijacked time-passes to dump per-fn information in a very narrow way :)</p>",
        "id": 127079068,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251535
    },
    {
        "content": "<p>and I was using that to identify slow functions</p>",
        "id": 127079073,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251541
    },
    {
        "content": "<p>nifty :)</p>",
        "id": 127079090,
        "sender_full_name": "lqd",
        "timestamp": 1527251569
    },
    {
        "content": "<p>so <span class=\"user-mention\" data-user-id=\"116113\">@lqd</span> what info were you looking for exactly? (before I went on my rant...)</p>",
        "id": 127079104,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251599
    },
    {
        "content": "<p>I guess the short answer is no, there is no easy way to get info — profiling rustc (e.g., with perf) is the way to do it</p>",
        "id": 127079112,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251624
    },
    {
        "content": "<p>I tried compiling webrender with NLL and it was indeed \"slow\", so I was looking for a way to narrow down where this time was spent</p>",
        "id": 127079114,
        "sender_full_name": "lqd",
        "timestamp": 1527251635
    },
    {
        "content": "<p>more precisely which \"use case\" could be extracted for benchmarking in polonius</p>",
        "id": 127079172,
        "sender_full_name": "lqd",
        "timestamp": 1527251686
    },
    {
        "content": "<p>(before I leave for rustfest until tuesday)</p>",
        "id": 127079195,
        "sender_full_name": "lqd",
        "timestamp": 1527251744
    },
    {
        "content": "<p>got it</p>",
        "id": 127079197,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251750
    },
    {
        "content": "<p>let me go looking for my patch</p>",
        "id": 127079201,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1527251754
    },
    {
        "content": "<p>If anyone feels like setting up LTTNG on their machine, I do have a local patch that dumps some stats about variable updates over the their user-space tracing (UST) channels.</p>",
        "id": 127090969,
        "sender_full_name": "Reed Koser",
        "timestamp": 1527267492
    },
    {
        "content": "<p>Should be possible to upstream it, it's all behind a feature flag but I'm not sure how useful it would be</p>",
        "id": 127090978,
        "sender_full_name": "Reed Koser",
        "timestamp": 1527267524
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116106\">@Reed Koser</span> LTTNG is an interesting project! Do you happen to know if it supports macOS or an alternate that might?</p>",
        "id": 127093895,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1527271862
    },
    {
        "content": "<p>I believe it's linux-only unfortunately. Probably not for technical reasons (i.e. you could port it) but just because there is only a relatively small number of contributors. I don't know what OSX has for tracing unfortunately</p>",
        "id": 127094149,
        "sender_full_name": "Reed Koser",
        "timestamp": 1527272188
    },
    {
        "content": "<p>most of the really robust tracing tools are deeply hooked in to the kernels of their respective systems (general purpose tracers) or bespoke (things like Chrome/V8's internal profiler/Gecko's profiling tools, etc.)</p>",
        "id": 127094212,
        "sender_full_name": "Reed Koser",
        "timestamp": 1527272290
    },
    {
        "content": "<p>even LTTNG started as a kernel tracing tool, and TraceCompass (the officially sanctioned graphical frontend) is... sub par. You define visualizations using this weird and feature-incomplete XML DSL or by using <code>babeltrace</code> to pull the traces into Python and then using some of the stuff from Python's data science community to generate imagery</p>",
        "id": 127094359,
        "sender_full_name": "Reed Koser",
        "timestamp": 1527272489
    },
    {
        "content": "<p>cross-platform userspace tracing is on the (extremely long...) list of yaks I want to shave some day <span class=\"emoji emoji-1f643\" title=\"upside down face\">:upside_down_face:</span></p>",
        "id": 127094523,
        "sender_full_name": "Reed Koser",
        "timestamp": 1527272699
    }
]