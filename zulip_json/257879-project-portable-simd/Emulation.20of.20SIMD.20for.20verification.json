[
    {
        "content": "<p>This is interesting: it looks like there's movement towards emulation of vectorized code. <a href=\"https://project-oak.github.io/rust-verification-tools/2021/05/15/verifying-vectorized-code2.html\">https://project-oak.github.io/rust-verification-tools/2021/05/15/verifying-vectorized-code2.html</a></p>",
        "id": 238923067,
        "sender_full_name": "Jubilee",
        "timestamp": 1621110298
    },
    {
        "content": "<p>The emulation library is here: <a href=\"https://github.com/project-oak/rust-verification-tools/tree/main/simd_emulation\">https://github.com/project-oak/rust-verification-tools/tree/main/simd_emulation</a><br>\nCurrently x86 only, only supports the architecture specific instructions that I see in LLVM IR when I compile programs.<br>\nI wrote it to support formal verification with one particular verifier (KLEE) but my goal is that it should be usable by any verifier whether LLVM-based or MIR-based or by miri or, indeed, by anything that needs to know  the semantics of a SIMD instruction.</p>\n<p>To do this, more instructions, architectures, etc. will need to be added; we'll need a plan for testing the library (it is basically untested at present); etc.<br>\nI'm happy to work with other potential users to get there.</p>",
        "id": 238926878,
        "sender_full_name": "Alastair Reid",
        "timestamp": 1621114367
    },
    {
        "content": "<p>Interesting. This looks a lot like what we'll have to do for the Cranelift-friendly-intrinsics plan, and is definitely similar to what we've been doing for our own testing rigs.</p>",
        "id": 238929285,
        "sender_full_name": "Jubilee",
        "timestamp": 1621117059
    },
    {
        "content": "<p>What's really weird is the repo is invisible from <a href=\"https://github.com/project-oak\">https://github.com/project-oak</a></p>",
        "id": 238929594,
        "sender_full_name": "Jubilee",
        "timestamp": 1621117380
    },
    {
        "content": "<p>Okay, so you're operating on the bitcode, examining that, finding the LLVM signature for a given x86 assembly instruction or intrinsic, and then executing a function based on that.</p>",
        "id": 238929768,
        "sender_full_name": "Jubilee",
        "timestamp": 1621117598
    },
    {
        "content": "<p>I imagine the architecture-agnostic LLVM instructions do not need to be emulated?</p>",
        "id": 238929936,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1621117810
    },
    {
        "content": "<p>It depends on what stage Alastair is operating at. It seems to be after bitcode is constructed, which is pretty late in the game, so I think it winds up with everything being lowered to a given architecture-specific instruction set anyways?</p>",
        "id": 238930001,
        "sender_full_name": "Jubilee",
        "timestamp": 1621117921
    },
    {
        "content": "<p>No, the LLVM instructions are compiled to assembly</p>",
        "id": 238930204,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1621118089
    },
    {
        "content": "<p>They're the same as scalar instructions</p>",
        "id": 238930230,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1621118120
    },
    {
        "content": "<p>hmmm.</p>",
        "id": 238930389,
        "sender_full_name": "Jubilee",
        "timestamp": 1621118319
    },
    {
        "content": "<p>I wonder if it wouldn't be easier to emulate the x86 assembly instructions directly and then map LLVM's model of the intrinsics to that.</p>",
        "id": 238930893,
        "sender_full_name": "Jubilee",
        "timestamp": 1621118935
    },
    {
        "content": "<p>Why do LLVM's need to be emulated?</p>",
        "id": 238930983,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1621119028
    },
    {
        "content": "<p>I don't think we run into this with cranelift either, because cranelift is just going to implement the intrinsics</p>",
        "id": 238931106,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1621119225
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span> Our intrinsics are a directory within a broader repo containing tools, libraries, scripts, etc to support formal verification of Rust. Making it a separate repository adds friction in various forms - so it made sense not to make it standalone right from the start. If others want to work on it, the right thing would obviously be to move that crate to a more 'central' place.</p>",
        "id": 238931171,
        "sender_full_name": "Alastair Reid",
        "timestamp": 1621119287
    },
    {
        "content": "<p>OH I have an extension that's bugging for me, ignore that remark about repos being invisible.</p>",
        "id": 238931257,
        "sender_full_name": "Jubilee",
        "timestamp": 1621119385
    },
    {
        "content": "<p>Yeah with it off suddenly everything is fixed and everything I expect to see is seen! cool.</p>",
        "id": 238931273,
        "sender_full_name": "Jubilee",
        "timestamp": 1621119430
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"312331\">@Caleb Zulawski</span> For our <em>current</em> purposes, we don't need to emulate the architecture agnostic SIMD intrinsics because (as far as I can tell), LLVM is able to expand those intrinsics on demand. Specifically, we are using the KLEE symbolic execution tool and it calls an LLVM function that lowers a bunch of different LLVM intrinsics including (I believe) the agnostic SIMD intrinsics but not the x86 specific intrinsics.</p>",
        "id": 238931351,
        "sender_full_name": "Alastair Reid",
        "timestamp": 1621119546
    },
    {
        "content": "<p>Okay, cool, just confirming because we only use the agnostic ones</p>",
        "id": 238931363,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1621119584
    },
    {
        "content": "<p>Well, there's some dirty hacks in <code>cg_llvm</code>, so idk if we can rule out ever using an arch-specific one from the perspective of someone touching LLVM bitcode.</p>",
        "id": 238931425,
        "sender_full_name": "Jubilee",
        "timestamp": 1621119616
    },
    {
        "content": "<p>Hmm I've never seen one.  But I think it should be the rule</p>",
        "id": 238931624,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1621119792
    },
    {
        "content": "<p>But that does point to a thing: anyone interpreting LLVM bitcode emitted by Rust <em>mostly</em> needs to worry about known <code>link_llvm_intrinsics</code>.</p>",
        "id": 238931631,
        "sender_full_name": "Jubilee",
        "timestamp": 1621119799
    },
    {
        "content": "<p>which, effectively, we have lists of, since we have them listed in <code>core::arch</code>.</p>",
        "id": 238931643,
        "sender_full_name": "Jubilee",
        "timestamp": 1621119832
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span> The way we work is:</p>\n<ol>\n<li>Use RUSTFLAGS to make cargo compile code with LTO enabled and emitting LLVM-IR.</li>\n<li>Grovel around in the target directory to find the resulting .bc file </li>\n<li>Postprocess the .bc file using a tool based on the Inkwell LLVM-IR crate. Postprocessing substitutes emulation functions for SIMD intrinsics, replaces GNU-libc initializer section magic with code, and &lt;something else I forget&gt;.</li>\n<li>Run KLEE on the postprocessed file.</li>\n</ol>\n<p>Along the way, assembly code containing actual x86 instructions is generated - but only because there is no obvious way to disable it.</p>\n<p>(Actually, we do use the x86 binary for one purpose: we want to emulate 'cargo test' which requires us to get a list of all the #[test] functions. We do this by running the output of 'cargo test' with a flag that makes it print out the names of all the tests. Then we mangle the names and use the mangled names as the names of entrypoints for KLEE. Alas, this disgusting hack stopped working with more recent rustc versions...)</p>",
        "id": 238931820,
        "sender_full_name": "Alastair Reid",
        "timestamp": 1621120019
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"312331\">@Caleb Zulawski</span> I'm not sure if you <em>need</em> to emulate the LLVM intrinsics. But one reason that you might want to (even if using cranelift) is that, at the moment, some of the x86 intrinsics are implemented as ordinary functions which then call the LLVM intrinsic. e.g., vector add, sub, mul, and other simple/obvious/portable instructions are handled this way.</p>\n<p>Of course, the introduction of cranelift might result in a layer of indirection being introduced so that the path is<br>\nx86-intrinsic --&gt; Rust intrinsic --&gt; {cranelift intrinsic, LLVM intrinsic}.<br>\nBut, still ends up with the need for emulation of the second or final step in that path.</p>",
        "id": 238932130,
        "sender_full_name": "Alastair Reid",
        "timestamp": 1621120350
    },
    {
        "content": "<p>btw Although I am working at the LLVM level and only need to cope with things that LLVM cannot lower for me, I think the approach I am taking would also work for MIR-based tools like miri, for formal verification tools like Crux-MIR, MIRAI, RMC, Prusti, and, I think, CTFE, portable SIMD, etc.<br>\nI am very keen that the library should support these other users because I think it would be crazy if every formal verification tool had its own independent solution to the problem - resulting in duplicated work, highly variable levels of testing (at present, my crate is basically untested), incomplete coverage, etc.<br>\nProbably requires some compromises to make it useful to a wide range of different uses - but well worth doing.</p>\n<p>(I think this is basically the only way that large artifacts like this can be created/maintained/etc. - I did something very similar when I created Arm's formal ISA specification - making sure that there were lots of different uses within Arm for an executable specification.)</p>",
        "id": 238932872,
        "sender_full_name": "Alastair Reid",
        "timestamp": 1621121177
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"336739\">Alastair Reid</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/Emulation.20of.20SIMD.20for.20verification/near/238931820\">said</a>:</p>\n<blockquote>\n<p>Along the way, assembly code containing actual x86 instructions is generated - but only because there is no obvious way to disable it.</p>\n</blockquote>\n<p>Hmm, do you know at what step x86 assembly is generated? Is it before Inkwell or after?</p>",
        "id": 238933200,
        "sender_full_name": "Jubilee",
        "timestamp": 1621121561
    },
    {
        "content": "<blockquote>\n<p>at the moment, some of the x86 intrinsics are implemented as ordinary functions which then call the LLVM intrinsic. e.g., vector add, sub, mul, and other simple/obvious/portable instructions are handled this way.</p>\n</blockquote>\n<p>Yeah, what we do internally at the moment is we call a rustc \"platform function\" that has to be implemented by any target which wants to compile Rust. One of the things we hope to do is implement a way that these functions can be understood in a portable manner internally and lowered to scalar code if necessary.</p>\n<blockquote>\n<p>Of course, the introduction of cranelift might result in a layer of indirection being introduced so that the path is<br>\nx86-intrinsic --&gt; Rust intrinsic --&gt; {cranelift intrinsic, LLVM intrinsic}.<br>\nBut, still ends up with the need for emulation of the second or final step in that path.</p>\n</blockquote>\n<p>That actually exists internally already: there is a <code>rustc_codegen_ssa</code> crate that describes an abstraction shared by the codegen backends, so that they mostly describe the specifics of their individual lowerings.</p>",
        "id": 238933820,
        "sender_full_name": "Jubilee",
        "timestamp": 1621122275
    },
    {
        "content": "<blockquote>\n<p>Hmm, do you know at what step x86 assembly is generated? Is it before Inkwell or after?</p>\n</blockquote>\n<p>rustc generates LLVM IR and saves it somewhere in the target directory. LLVM then uses the LLVM IR to generate assembly. Once cargo is all done (i.e. has generated an x86 binary), we grab the LLVM IR and run our postprocessor tool.  Our postprocessor uses the Inkwell crate to read and write LLVM IR from a file. In the middle of that process [edit: i.e., the postprocessing process], we scan for x86 intrinsics for which we have an emulation function and replace them.<br>\nSo, if you drew a dataflow graph, it is a Y-shaped graph where one fork leads to x86 assembly (that we basically ignore) and the other fork leads to LLVM IR that we postprocess to patch up the x86-specific intrinsics in.<br>\n(Note that, instead of using a postprocessor, we could have patched KLEE to perform the substitution as it executes each instruction. This would probably be the right choice for miri, for example.)</p>",
        "id": 238936193,
        "sender_full_name": "Alastair Reid",
        "timestamp": 1621125061
    }
]