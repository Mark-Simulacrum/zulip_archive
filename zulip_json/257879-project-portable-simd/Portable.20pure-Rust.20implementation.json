[
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125270\">scottmcm</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/cranelift.20backend/near/213368109\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/cranelift.20backend/near/213362674\">said</a>:</p>\n<blockquote>\n<p>if it lowers to non-simd, for example, on cranelift that seems fine</p>\n</blockquote>\n<p>Having non-simd lowering seems generally useful.  I could imagine some targets only using that, for example.</p>\n<p>(No idea what the best way to pick it for cranelift would be, though.)</p>\n</blockquote>\n<p>In general, it seems like portable SIMD <em>needs</em> to have a portable pure-Rust implementation that can compile anywhere, so that that can be used for things like MIRI, or new platforms being ported to, or similar. That also means we can add new intrinsics without writing a version of them for every target, because targets without an implementation will just use the pure-Rust implementation until they have a native one.</p>",
        "id": 213479405,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602791797
    },
    {
        "content": "<p>It wouldn't be something that only existed for the cranelift backend. It'd also be used for any Rust target that doesn't have SIMD, or hasn't implemented it yet. And it'd be used for any operation that a target can't or doesn't accelerate.</p>",
        "id": 213479643,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602791905
    },
    {
        "content": "<p>Ideally, we'd have a checklist for each target of \"here are things for which the target is using the generic version\", which would make it easy for people to contribute more optimized versions (along with benchmarks).</p>",
        "id": 213479700,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602791943
    },
    {
        "content": "<p>That'd make it much more incremental work.</p>",
        "id": 213479725,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602791955
    },
    {
        "content": "<p>Adding a new function would still require designing a reasonable interface for it, but it wouldn't require implementing multiple target backends immediately. It'd just require a portable implementation and at least one target-specific implementation.</p>",
        "id": 213479891,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602792019
    },
    {
        "content": "<p>The portable implementation would also help for testsuites: tests could assert that the portable and non-portable versions match in behavior (modulo allowable precision variations in some cases).</p>",
        "id": 213479948,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602792053
    },
    {
        "content": "<p>Yeah, that seems like a very reasonable way forward :)</p>",
        "id": 213480070,
        "sender_full_name": "simulacrum",
        "timestamp": 1602792110
    },
    {
        "content": "<p>Though maybe not an easy one.</p>",
        "id": 213480088,
        "sender_full_name": "simulacrum",
        "timestamp": 1602792118
    },
    {
        "content": "<p>it sounds a lot tractable than getting new simd_foo apis for any unsupported ops</p>",
        "id": 213480180,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602792150
    },
    {
        "content": "<p>The most critical thing would be a reasonable framework/pattern for selecting which implementation to use on each target, without writing piles of <code>cfg</code> goo everywhere.</p>",
        "id": 213480235,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602792183
    },
    {
        "content": "<p>Ideally in a way that allows easily extracting the \"which implementation\" information for target documentation tables.</p>",
        "id": 213480258,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602792200
    },
    {
        "content": "<p>(And in a way that allows tests to also pull in the portable implementations, without compiling the portable implementations into std/core.)</p>",
        "id": 213480298,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602792231
    },
    {
        "content": "<p>I'd like to be able to have, like, a #[scalar] and a #[vectorized] version? Just throwing-at-wall level of musing on what that would look like.</p>",
        "id": 213484698,
        "sender_full_name": "Jubilee",
        "timestamp": 1602794514
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span> Can you clarify the distinction there?</p>",
        "id": 213485588,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602794904
    },
    {
        "content": "<p>Oh, like... I'm sort of presuming a scalar fallback in my head that essentially just reduces \"SIMD\" to \"a bunch of Rusty arrays\", and then that is the initial presentation for anything, and then on certain platforms we have #[vectorized] optimizations so we select #[vectorized] for them.</p>",
        "id": 213485889,
        "sender_full_name": "Jubilee",
        "timestamp": 1602795078
    },
    {
        "content": "<p>and #[vectorized] attempts to use a true SIMD codegen path, or rather is expressing it will.</p>",
        "id": 213485993,
        "sender_full_name": "Jubilee",
        "timestamp": 1602795125
    },
    {
        "content": "<p>\"cfg goo but nice and tidy\"</p>",
        "id": 213486101,
        "sender_full_name": "Jubilee",
        "timestamp": 1602795168
    },
    {
        "content": "<p>It might be more subtle than that if we're to allow:</p>\n<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/Portable.20pure-Rust.20implementation/near/213479891\">said</a>:</p>\n<blockquote>\n<p>Adding a new function would still require designing a reasonable interface for it, but it wouldn't require implementing multiple target backends immediately. It'd just require a portable implementation and at least one target-specific implementation.</p>\n</blockquote>\n<p>(which i think is desirable)</p>",
        "id": 213486143,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602795186
    },
    {
        "content": "<p>I guess what I'm trying to do is nail down in my head what \"portable pure Rust\" really means in a world where codegen lowers to LLVM instructions or sometimes not, it's not like we actually _have_ a Rust machine. :^)</p>",
        "id": 213486401,
        "sender_full_name": "Jubilee",
        "timestamp": 1602795307
    },
    {
        "content": "<p>I mean if you give me an FPGA and cover my bills for a few months I'd be happy to try but... :^)</p>",
        "id": 213486509,
        "sender_full_name": "Jubilee",
        "timestamp": 1602795353
    },
    {
        "content": "<p>By \"portable pure Rust\", I mean \"target-independent\". If the platform can autovectorize, that's great, but if it can't, the same code should still work.</p>",
        "id": 213487322,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602795702
    },
    {
        "content": "<p>Technically that is what already exists... because we were not considering \"LLVM\" as part of our target triple... quad? quint? whatever. Target spec. Now we do have to, because of the functional differences between LLVM and cranelift. At the moment, any such fallback would be scalar, unless Rust develops the ability to think about vectors directly.</p>",
        "id": 213487673,
        "sender_full_name": "Jubilee",
        "timestamp": 1602795874
    },
    {
        "content": "<p>My understanding is that we'd manually implement the operations, e.g. instead of calling simd_add, we'd construct a new vector with the fields of the elementwise addition of each field in turn</p>",
        "id": 213487885,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602795974
    },
    {
        "content": "<p>Right.</p>",
        "id": 213488240,
        "sender_full_name": "Jubilee",
        "timestamp": 1602796185
    },
    {
        "content": "<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"n\">a</span><span class=\"p\">.</span><span class=\"n\">into_iter</span><span class=\"p\">().</span><span class=\"n\">zip</span><span class=\"p\">(</span><span class=\"n\">b</span><span class=\"p\">.</span><span class=\"n\">into_iter</span><span class=\"p\">()).</span><span class=\"n\">map</span><span class=\"p\">(</span><span class=\"o\">|</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"p\">)</span><span class=\"o\">|</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"p\">).</span><span class=\"n\">collect</span>::<span class=\"o\">&lt;</span><span class=\"n\">TxN</span><span class=\"o\">&gt;</span><span class=\"p\">()</span><span class=\"w\"></span>\n</code></pre></div>\n\n<p>is simple enough to write, I'm just thinking about the avoiding-cfg-goo part.</p>",
        "id": 213488633,
        "sender_full_name": "Jubilee",
        "timestamp": 1602796393
    },
    {
        "content": "<p>The portable fallbacks could also use things like \"safe-transmute to u64s and operate on those\", for that matter.</p>",
        "id": 213488765,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602796433
    },
    {
        "content": "<p>And yeah, avoiding the cfg goo is the hard part here. Code generation is a possibility, but annoying. Turning the abstraction layer upside down and having targets either implement or <code>pub use</code> things would help, but there'd be a lot of wrappers (especially for traits or methods where we can't just import an implementation with a single <code>pub use</code>).</p>",
        "id": 213488872,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602796490
    },
    {
        "content": "<p>So I think we're still going to be describing \"default vectorization\" (i.e. not, use scalar) vs. \"explicit vectorization\" at least once, internally, and I think it's best if we just not try at all inside stdsimd to abstract over the fact we're dropping to scalar, so we do use some flavor of cfg at least once and everything does get written twice.</p>",
        "id": 213489878,
        "sender_full_name": "Jubilee",
        "timestamp": 1602797108
    },
    {
        "content": "<p>So that whatever is selecting algorithms from us during compilation has a lookup table and at least one entry per algorithm in its lookup table.</p>",
        "id": 213490219,
        "sender_full_name": "Jubilee",
        "timestamp": 1602797311
    },
    {
        "content": "<p>I'm trying to interpret what you mean by \"and everything does get written twice\". Do you mean \"once portably, and at least once per target platform that wants to optimize\"? Or do you mean multiple portable implementations?</p>",
        "id": 213490477,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602797488
    },
    {
        "content": "<p>I'm <em>hoping</em> that we have just one portable version, and then a bunch of target-specific versions.</p>",
        "id": 213490501,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602797505
    },
    {
        "content": "<p>Once for the scalar fallback, and the required number of times to enable per-target optimizations with whatever additional abstractions we deem necessary.</p>",
        "id": 213490681,
        "sender_full_name": "Jubilee",
        "timestamp": 1602797604
    },
    {
        "content": "<p>Got it. Yeah, that's what I'd expect.</p>",
        "id": 213490857,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602797711
    },
    {
        "content": "<p>There's one additional desirable property I'd like if we can get it: targets shouldn't have to list which things they <em>don't</em> have implementations for.</p>",
        "id": 213490988,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602797749
    },
    {
        "content": "<p>We should be able to generate that list, and document it in per-target documentation, but we shouldn't have to <em>write</em> and <em>update</em> it.</p>",
        "id": 213491065,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602797772
    },
    {
        "content": "<p>Because when we add a new portable operation, we shouldn't have to go to every target and say \"no implementation here\".</p>",
        "id": 213491083,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602797787
    },
    {
        "content": "<p>A patch for a new portable operation shouldn't have to touch targets that don't implement it, at all.</p>",
        "id": 213491099,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602797798
    },
    {
        "content": "<p>Adding new <code>simd_*</code> platform intrinsics to cg_llvm is really easy if there is already an LLVM intrinsic for it. cg_clif also has a few functions to easily implement new per lane <code>simd_*</code> platform intrinsics using scalar operations only.</p>",
        "id": 213491194,
        "sender_full_name": "bjorn3",
        "timestamp": 1602797855
    },
    {
        "content": "<p>What should happen is that during compilation, a selection function awakens, inspects the available functions it can compile in according to the currently defined spec, sorts them in a predictable order, and then walks away with the last one.</p>",
        "id": 213491607,
        "sender_full_name": "Jubilee",
        "timestamp": 1602798083
    },
    {
        "content": "<p>if there is only one, it's the last one.</p>",
        "id": 213491621,
        "sender_full_name": "Jubilee",
        "timestamp": 1602798095
    },
    {
        "content": "<p>This is why my brain jumped ahead to two distinct annotations for use within stdsimd... one would signal that it should always be moved into std and so always available for selection, and the library should be able to notice if it has 1 item that is <strong>not</strong> the scalar implementation.</p>",
        "id": 213492569,
        "sender_full_name": "Jubilee",
        "timestamp": 1602798644
    },
    {
        "content": "<p>Oh, I see.</p>",
        "id": 213494512,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602799952
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span> Is your intention here that std may need to supply <em>multiple</em> functions, to be selected from at either compile-time or runtime depending on target capabilities and target feature selection?</p>",
        "id": 213494541,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602799980
    },
    {
        "content": "<p>(e.g. x86_64 with AVX, x86_64 with only SSE2...)</p>",
        "id": 213494565,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602800000
    },
    {
        "content": "<p>And then the portable function may or may not be the \"last\" of those, depending on if the target features are sufficient to <em>always</em> allow a better one?</p>",
        "id": 213494597,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602800027
    },
    {
        "content": "<p>This is what I understand as required to meet the constraints in a sane manner, yes, even if the selector's choice does not actually pull out code from std but instead fires off a codegen path or something.</p>",
        "id": 213494899,
        "sender_full_name": "Jubilee",
        "timestamp": 1602800210
    },
    {
        "content": "<p>and even if the selection process is actually done on a significantly winnowed field from the full set of possible implementations because of some other previously-applied constraint.</p>",
        "id": 213495036,
        "sender_full_name": "Jubilee",
        "timestamp": 1602800296
    },
    {
        "content": "<p>So I just read through this thread and I'm not sure that everyone is on the same page with this.  Just a few thoughts I have:</p>\n<ul>\n<li>The compiler is aware of which backend is used when lowering, right? (AST to HIR, HIR to MIR, etc, not just codegen)</li>\n<li>The compiler is aware of which target-features are enabled during codegen (at least it could be, in practice I think this is mostly deferred to LLVM?)</li>\n<li>The compiler can query the backend for support of a particular SIMD intrinsic, if it doesn't exist it can be lowered to pure rust before codegen, if it does exist it can send the intrinsic as is to the backend</li>\n</ul>\n<p>If we're going 100% platform-intrinsics I don't think there needs to be anything special going on in stdsimd or any other rust crate, no cfg or any other special attributes.  Maybe some of this is obvious or maybe some of it is not a good idea but I'm not sure anyone is even on the same page of where the backend intrinsic/pure rust implementation delegation should be occurring</p>",
        "id": 213497233,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602801938
    },
    {
        "content": "<p>To clarify my slowly-forming mental picture of how this looks:</p>\n<p>To my mind, the stdsimd calls are currently essentially a façade for calls to LLVM.<br>\nWhat I would suggest is that in stdsimd live &gt;=1 branches:</p>\n<ul>\n<li>The scalar fallback.</li>\n<li>For explicit SIMD ops, 0 or more façades that could denote compiler calls to explicitly vectorize.</li>\n</ul>",
        "id": 213499234,
        "sender_full_name": "Jubilee",
        "timestamp": 1602803356
    },
    {
        "content": "<p>The selection function itself would live in rustc, in a codegen-path-agnostic location. It is called once sufficient information has been gathered to make a decision. It makes a choice and it always has at least 1 choice available (the scalar fallback). By doing so there, it can handle whether or not it calls something. By having at least an initial facade live in std::simd, we don't have to go exploring the bowels of rustc just to try to guarantee the two implementations are correctly aligned.</p>\n<p>After that, if it is appropriate for more information to live in stdsimd, we can put it there.<br>\nIf it is appropriate for more information to live inside the codegen crates, we can put it there.</p>\n<p>But I am not wild about the thought of putting absolutely <strong>all</strong> information inside the compiler for all things here.<br>\nI would go so far as to say that if everything-everything lives in the compiler, at that point we should just build out and stabilize <code>#![feature(platform_intrinsics)]</code> for public usage.</p>",
        "id": 213500625,
        "sender_full_name": "Jubilee",
        "timestamp": 1602804509
    },
    {
        "content": "<p>Is there a reason to provide the scalar fallback in stdsimd instead of having rustc lower simd_add etc appropriately for the backend in use?</p>",
        "id": 213501009,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602804839
    },
    {
        "content": "<p>We make the workings of the library more opaque and we weaken the ability to describe more specialized versions for a given arch.</p>",
        "id": 213501186,
        "sender_full_name": "Jubilee",
        "timestamp": 1602804977
    },
    {
        "content": "<p>There's still a difference between our API and the platform-intrinsics API, notably at least some of the ops are inherently unsafe</p>",
        "id": 213501188,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602804978
    },
    {
        "content": "<p>What do you mean by more specialized versions for a given arch?</p>",
        "id": 213501218,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602805028
    },
    {
        "content": "<p>If we wish to write an implementation of a given function that uses certain intrinsic functions for an architecture.</p>",
        "id": 213501326,
        "sender_full_name": "Jubilee",
        "timestamp": 1602805133
    },
    {
        "content": "<p>Since there's no way to interact with target-feature I feel like that's unlikely. But I do see your point</p>",
        "id": 213502448,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602806169
    },
    {
        "content": "<p>We are already talking about compiler commits, so.</p>",
        "id": 213502488,
        "sender_full_name": "Jubilee",
        "timestamp": 1602806226
    },
    {
        "content": "<p>True.  I suppose something that might be somewhat in between what we're both suggesting is something like <code>#[cfg(backend_supports = \"simd_add\")]</code></p>",
        "id": 213502587,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602806295
    },
    {
        "content": "<p>I'm not sure we should be checking which particular backend is in use</p>",
        "id": 213502613,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602806334
    },
    {
        "content": "<p>I think stdsimd should just provide information and then the compiler uses that.</p>",
        "id": 213502630,
        "sender_full_name": "Jubilee",
        "timestamp": 1602806352
    },
    {
        "content": "<p>I'm not sure how that would work, for example if you have a function in stdsimd that uses multiple intrinsics, a backend may support some subset but not all of them</p>",
        "id": 213502744,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602806427
    },
    {
        "content": "<p>unless we are saying a backend supports all or none</p>",
        "id": 213502767,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602806448
    },
    {
        "content": "<p>Mmm, I think we are, aren't we?</p>",
        "id": 213502838,
        "sender_full_name": "Jubilee",
        "timestamp": 1602806511
    },
    {
        "content": "<p>Like... at least within a function, it either has to support everything that went on inside that function, or it has to use fallback.</p>",
        "id": 213502902,
        "sender_full_name": "Jubilee",
        "timestamp": 1602806544
    },
    {
        "content": "<p>Right, but I could imagine for example a microcontroller-specific backend that supports <code>simd_add</code>, <code>simd_sub</code>, etc, but not say transcendental functions</p>",
        "id": 213502956,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602806610
    },
    {
        "content": "<p>Continuations, I guess.</p>",
        "id": 213503018,
        "sender_full_name": "Jubilee",
        "timestamp": 1602806662
    },
    {
        "content": "<p>you might just end up copying a lot of scalar fallback code into the backend</p>",
        "id": 213503019,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602806663
    },
    {
        "content": "<p>well, here's something else.  LLVM doesn't have a vectorized round-to-int (<code>lround</code>/<code>llround</code>). does this mean all backends are prevented from implementing it because it's all-or-nothing?</p>",
        "id": 213503901,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602807342
    },
    {
        "content": "<p>right, thats the reason for wanting the flexibility to implement things in a target specific manner with a scalar fallback</p>",
        "id": 213503982,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602807397
    },
    {
        "content": "<p>maybe the answer is \"that's fine\" but just want to suss out the implications</p>",
        "id": 213503985,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602807404
    },
    {
        "content": "<p>Continuations and the query system exist. Multiple attempts to expand the code correctly can be performed and then the scalar fallback can literally be fallen back to.</p>",
        "id": 213504031,
        "sender_full_name": "Jubilee",
        "timestamp": 1602807452
    },
    {
        "content": "<p>Is your intent that depending on the backend, various <code>simd_*</code> functions may or may not be available?</p>",
        "id": 213504143,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602807535
    },
    {
        "content": "<p>Given that such seems to be the motivating complaint, yes.</p>",
        "id": 213504174,
        "sender_full_name": "Jubilee",
        "timestamp": 1602807565
    },
    {
        "content": "<p>there's also a lot of stuff without a simd_* equivalent</p>",
        "id": 213504203,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602807592
    },
    {
        "content": "<p>that would be nice to support</p>",
        "id": 213504212,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602807598
    },
    {
        "content": "<p>Okay, so I think we're on the same page with that, but I think simply using cfg to indicate if the intrinsic is available or not is a lot more \"typical\" rust.  Just like using <code>target_arch</code> to determine which <code>std::arch</code> intrinsics you have available</p>",
        "id": 213504298,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602807644
    },
    {
        "content": "<p>This is a lot lower granularity of course, but I think it's the same idea</p>",
        "id": 213504338,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602807684
    },
    {
        "content": "<p>higher granularity?</p>",
        "id": 213504351,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602807701
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"209168\">@Thom Chiovoloni</span> I would hope that pretty much everything \"fundamental\" would end up with a platform intrinsic</p>",
        "id": 213504507,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602807837
    },
    {
        "content": "<p>An attr can expand to other attrs.</p>",
        "id": 213504509,
        "sender_full_name": "Jubilee",
        "timestamp": 1602807839
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"312331\">@Caleb Zulawski</span> Maybe, but there's an appeal to all it takes to include is for there to be a reasonable interface, a portable implementation, and at least one target specific one. Getting patches into LLVM that are usable in rust is slow and difficult.</p>",
        "id": 213504694,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602807971
    },
    {
        "content": "<p>Getting patches in rustc is less slow but still challenging since its a separate repo and requires experience with the compiler.</p>",
        "id": 213504723,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602808015
    },
    {
        "content": "<p>I guess my point is that the following is pretty much trivial:</p>\n<div class=\"codehilite\"><pre><span></span><code>#[cfg(backend_supports = &quot;simd_neg&quot;)]\nfn neg(self) -&gt; Self { unsafe { simd_neg(self) } }\n\n#[cfg(not(backend_supports = &quot;simd_neg&quot;))]\nfn neg(self) -&gt; Self { /* scalar code */ }\n</code></pre></div>\n\n\n<p>but replacing those attributes with <code>#[vector]</code> and <code>#[scalar]</code> or whatever involves a fair bit of magic</p>",
        "id": 213504768,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602808063
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"209168\">@Thom Chiovoloni</span> sorry, the terminology isn't great, \"platform intrinsics\" are rustc's intrinsics, not LLVM's, as in <code>extern \"platform-intrinsics\" {}</code></p>",
        "id": 213504846,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602808099
    },
    {
        "content": "<p>it was just a draft idea with some placeholders.</p>",
        "id": 213504857,
        "sender_full_name": "Jubilee",
        "timestamp": 1602808111
    },
    {
        "content": "<p>thats not particularly the sort of thing i'm talking about. i have no opinion about #[vector] and #[scalar], but think the granularity needs to be a little more fine than that in practice</p>",
        "id": 213504862,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602808121
    },
    {
        "content": "<p>i also don't think it would be hard to add #[vector] or #[scalar] tho</p>",
        "id": 213504876,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602808141
    },
    {
        "content": "<p>I guess my point is I don't see any reason it _shouldn't_ just be cfg, instead of something more magic, regardless of the syntax of the attribute</p>",
        "id": 213504894,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602808168
    },
    {
        "content": "<p>I don't... care about that? I just don't.</p>",
        "id": 213504901,
        "sender_full_name": "Jubilee",
        "timestamp": 1602808179
    },
    {
        "content": "<p>thats just the color of the bikeshed honestly</p>",
        "id": 213504974,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602808219
    },
    {
        "content": "<p>I suppose I do though, I'm very much against magic attributes that make the code much less approachable</p>",
        "id": 213504975,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602808221
    },
    {
        "content": "<p>cfg seems sufficient to me and broadly understood</p>",
        "id": 213504999,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602808250
    },
    {
        "content": "<p>whatever. I just described two different markings meant to be read as distinct and representing a higher-level organization.</p>",
        "id": 213505008,
        "sender_full_name": "Jubilee",
        "timestamp": 1602808260
    },
    {
        "content": "<p>i'm not if they're useful. i don't think this matters or is the place to make this decision.</p>",
        "id": 213505013,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602808263
    },
    {
        "content": "<p>I'm not really sure what else there is to discuss then--the only thing missing for that is compiler support for indicating whether to use scalar or vector implementations, I think?</p>",
        "id": 213505129,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602808375
    },
    {
        "content": "<p>what else <strong>is</strong> there to discuss?</p>",
        "id": 213505191,
        "sender_full_name": "Jubilee",
        "timestamp": 1602808441
    },
    {
        "content": "<p>isn't there no way of moving forward until we have compiler support?</p>",
        "id": 213505263,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602808478
    },
    {
        "content": "<p>Sure, that's why I was trying to warm up to draft some compiler commits two hours ago, but the time seems to have flown since then.</p>",
        "id": 213505329,
        "sender_full_name": "Jubilee",
        "timestamp": 1602808561
    },
    {
        "content": "<p>well, I thought that's what we were going to discuss before implementing it</p>",
        "id": 213505434,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602808665
    },
    {
        "content": "<p>sorry, I didn't realize you were already doing that</p>",
        "id": 213505480,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602808695
    },
    {
        "content": "<p>I got distracted before even really getting started, as usual.</p>",
        "id": 213505517,
        "sender_full_name": "Jubilee",
        "timestamp": 1602808738
    },
    {
        "content": "<p>doesn't adding a new attribute with new semantics probably require an RFC?</p>",
        "id": 213505605,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602808826
    },
    {
        "content": "<p>I'm not really sure where the threshold is but that seems past it</p>",
        "id": 213505615,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602808837
    },
    {
        "content": "<p>No.<br>\nThere are already ways to describe unstable annotations where necessary for compiler usage.<br>\nAnd the names really did mean about as much to me as #[foo] and #[bar].</p>",
        "id": 213505879,
        "sender_full_name": "Jubilee",
        "timestamp": 1602809066
    },
    {
        "content": "<p>I wasn't concerned so much about the names as continuations</p>",
        "id": 213506049,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602809246
    },
    {
        "content": "<p>That also was purely a thought regarding implementation details, and the internals of the compiler are not foreign to resumable or retryable logic.</p>",
        "id": 213506117,
        "sender_full_name": "Jubilee",
        "timestamp": 1602809298
    },
    {
        "content": "<p>I'm sure the actual attributes will fall out of however the implementation works</p>",
        "id": 213506120,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602809301
    },
    {
        "content": "<p>Right, my argument was just that it seems like an overcomplication</p>",
        "id": 213506171,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602809383
    },
    {
        "content": "<p>I'm certain it could be done, I'm just not sure it should be</p>",
        "id": 213506243,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602809439
    },
    {
        "content": "<p>So my experience is that it is... very painful to implement heavily cfg'd code because it is incredibly leaky. It is really not meant for selecting between logic paths on the sort of fine-grained level we would need here, because if a function block wants to vectorize, it really wants to go all in one step. If it hops back and forth between vector registers and other registers or the stack a lot, we introduce the potential to be slower than scalar. We don't want to fallback in a piecemeal fashion.</p>\n<p>And currently the codegen logic for simd_* ops lives in rustc_codegen_llvm, and that is a MIR-&gt;LLVM step. Also, logic has been implemented in the (I presume similar) rustc_codegen_cranelift crate in anticipation of landing in order to handle this. So, we would want to be able to have a backend support whatever they can support or not if they don't.</p>\n<p>So in order to lift the relevant aspects (to us) of SIMD codegen out of LLVM and compile nicely, we either have to devise a way to ask the backend to try twice on a given function block, with different arguments each time, or we have to just teach rustc about vectors and hope the backend makes the best of it.</p>",
        "id": 213507625,
        "sender_full_name": "Jubilee",
        "timestamp": 1602811051
    },
    {
        "content": "<blockquote>\n<p>So my experience is that it is... very painful to implement heavily cfg'd code because it is incredibly leaky. It is really not meant for selecting between logic paths on the sort of fine-grained level we would need here, because if a function block wants to vectorize, it really wants to go all in one step. If it hops back and forth between vector registers and other registers or the stack a lot, we introduce the potential to be slower than scalar. We don't want to fallback in a piecemeal fashion.</p>\n</blockquote>\n<p>Isn't this more of an argument for something cfg-like, then?  If there are only two options (scalar or vector) aren't we not looking for fine-grained control?  Also, I think that's very x86-centric, since other architectures can just as easily perform scalar and vector ops without changing registers</p>",
        "id": 213509282,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602812908
    },
    {
        "content": "<p>I am not sure I understand what you are saying. ARMv8 zeros the other bits of a vector register like x86 does when a lower-bit value is written to it.</p>",
        "id": 213509655,
        "sender_full_name": "Jubilee",
        "timestamp": 1602813401
    },
    {
        "content": "<p>Right, but those are the same registers and don't result in a pipeline stall or anything like that</p>",
        "id": 213510178,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602813989
    },
    {
        "content": "<p>...so we let the selector do different things when it's targeting ARM, sure I guess?</p>",
        "id": 213511486,
        "sender_full_name": "Jubilee",
        "timestamp": 1602815669
    },
    {
        "content": "<p>orrrr we can just add vectors to MIR I guess!</p>",
        "id": 213511574,
        "sender_full_name": "Jubilee",
        "timestamp": 1602815858
    },
    {
        "content": "<p>are you suggesting that once you use a scalar implementation (like <code>Div</code> for integers on many architectures) the entire thing falls back to scalar?</p>",
        "id": 213511636,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602815942
    },
    {
        "content": "<p>I'm not sure what the scope of this is</p>",
        "id": 213511676,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602815992
    },
    {
        "content": "<p>I'm also not implying that you should have all of the answers, I just think it needs a broader discussion</p>",
        "id": 213511809,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602816133
    },
    {
        "content": "<p>I don't know either now, and I don't feel like I have a clearer idea of anything.</p>",
        "id": 213511822,
        "sender_full_name": "Jubilee",
        "timestamp": 1602816167
    },
    {
        "content": "<p>The difference with simd_div is that the implementation of it means LLVM knows (or claims to know) how to intelligently optimize it, it's not an actual statement about the relative speed.</p>",
        "id": 213511845,
        "sender_full_name": "Jubilee",
        "timestamp": 1602816228
    },
    {
        "content": "<p>Yeah I agree with that to some extent.</p>",
        "id": 213512056,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602816451
    },
    {
        "content": "<p>My proposal was for an abstracted selector function that can use an equally abstract comparator to attempt to use core::simd's contents so that work can continue inside stdsimd and that once the commits are done I can actually go back to not learning every grisly detail about how LLVM (or Cranelift, for that matter) works. If we introduce a bunch of cfgs, we have to cfg on <strong>all of them everywhere</strong> and now the details of backend codegen APIs are inside ours to an unnecessary degree.</p>",
        "id": 213512063,
        "sender_full_name": "Jubilee",
        "timestamp": 1602816471
    },
    {
        "content": "<p>I suppose that's my point, if we're simply addressing backend inadequacy I feel like we can just select on whether or not SIMD is supported at all</p>",
        "id": 213512307,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602816627
    },
    {
        "content": "<p>a binary yes/no means that every time a new intrinsic arrives, support has to also appear in every single codegen backend or else we don't use SIMD at all.</p>",
        "id": 213512466,
        "sender_full_name": "Jubilee",
        "timestamp": 1602816728
    },
    {
        "content": "<p>do we expect that to be a common occurrence? I assume not</p>",
        "id": 213512553,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602816806
    },
    {
        "content": "<p>also, from a practical sense, there's only one backend that supports SIMD at all, anyway</p>",
        "id": 213512590,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602816840
    },
    {
        "content": "<p>I have \"add simd_fneg\" on my todo list still.</p>",
        "id": 213512690,
        "sender_full_name": "Jubilee",
        "timestamp": 1602816914
    },
    {
        "content": "<p>there's lots of simd ops that aren't implemented in rustc's backends.</p>",
        "id": 213512700,
        "sender_full_name": "Jubilee",
        "timestamp": 1602816934
    },
    {
        "content": "<p>there are definitely tons right now that aren't implemented, but I expect once stdsimd stabilizes there will be very few to add</p>",
        "id": 213512811,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602817017
    },
    {
        "content": "<p>the entire AVX512 instruction set is about as old as Rust.</p>",
        "id": 213512821,
        "sender_full_name": "Jubilee",
        "timestamp": 1602817024
    },
    {
        "content": "<p>that doesn't involve a new set of platform-intrinsics, though?</p>",
        "id": 213512855,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602817055
    },
    {
        "content": "<p>does it?</p>",
        "id": 213512858,
        "sender_full_name": "Jubilee",
        "timestamp": 1602817061
    },
    {
        "content": "<p>it should already support AVX512</p>",
        "id": 213512859,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602817061
    },
    {
        "content": "<p>Every time they add a new concept, it will.</p>",
        "id": 213512925,
        "sender_full_name": "Jubilee",
        "timestamp": 1602817093
    },
    {
        "content": "<p>only if that's something we decide to make portable</p>",
        "id": 213513023,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602817175
    },
    {
        "content": "<p>or if LLVM does, for that matter</p>",
        "id": 213513095,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602817219
    },
    {
        "content": "<p>If something arrives in core::arch it will lead to updates in the platform intrinsics.</p>",
        "id": 213513098,
        "sender_full_name": "Jubilee",
        "timestamp": 1602817222
    },
    {
        "content": "<p>with some low probability, but with enough intrinsics added, low probability becomes a certainty.</p>",
        "id": 213513122,
        "sender_full_name": "Jubilee",
        "timestamp": 1602817255
    },
    {
        "content": "<p>well in its current state core:;arch uses llvm intrinsics primarily</p>",
        "id": 213513140,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602817269
    },
    {
        "content": "<p>Exactly.</p>",
        "id": 213513150,
        "sender_full_name": "Jubilee",
        "timestamp": 1602817275
    },
    {
        "content": "<p>are you suggesting the entire breadth of all vendor intrinsics be converted to platform-intrinsics?</p>",
        "id": 213513220,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602817318
    },
    {
        "content": "<p>I think that's significantly outside of the scope of this project group</p>",
        "id": 213513272,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602817331
    },
    {
        "content": "<p>No, I am saying that probabilistically it will happen anyways.</p>",
        "id": 213513279,
        "sender_full_name": "Jubilee",
        "timestamp": 1602817333
    },
    {
        "content": "<p>Yes, and there was an expressed desire to untether our API's backend from LLVM.</p>",
        "id": 213513298,
        "sender_full_name": "Jubilee",
        "timestamp": 1602817352
    },
    {
        "content": "<p>I have no problem with extending platform intrinsics for stdsimd and not using any llvm, but I'm concerned about risking stabilization of std::simd for a huge feature that is primarily motivated by something else</p>",
        "id": 213513354,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602817414
    },
    {
        "content": "<p>we may go another who knows how many years before anyone even attempts to make another backend that supports SIMD.  it could also be very soon but I think it should be addressed when that comes up</p>",
        "id": 213513619,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602817569
    },
    {
        "content": "<p>I think it's completely possible it _never_ happens</p>",
        "id": 213513749,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602817686
    },
    {
        "content": "<p>\"huge feature\"?</p>",
        "id": 213513916,
        "sender_full_name": "Jubilee",
        "timestamp": 1602817899
    },
    {
        "content": "<p>if it's bleeding into caller functions that seems like a big deal to me</p>",
        "id": 213514041,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602818041
    },
    {
        "content": "<p>#[cfg] does bleed a lot, yes.</p>",
        "id": 213514118,
        "sender_full_name": "Jubilee",
        "timestamp": 1602818114
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>fn foo(x: f32x4, y: f32x4) -&gt; i32x4 {\n    (x + y).round_to_int()\n}\n</code></pre></div>\n\n\n<p>if <code>round_to_int</code> only has a scalar function, what happens to the add?</p>",
        "id": 213514199,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602818194
    },
    {
        "content": "<p>That is literally already a concern with target feature.</p>",
        "id": 213514238,
        "sender_full_name": "Jubilee",
        "timestamp": 1602818250
    },
    {
        "content": "<p>With target-feature they explicitly don't bleed into the caller, and the functions don't inline</p>",
        "id": 213514327,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602818320
    },
    {
        "content": "<p>Well yes, and that's a problem because it's sloooow.</p>",
        "id": 213514345,
        "sender_full_name": "Jubilee",
        "timestamp": 1602818340
    },
    {
        "content": "<p>I would also consider target-feature to be a huge feature</p>",
        "id": 213514353,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602818349
    },
    {
        "content": "<p>I agree it's a problem but the solution was generally \"wait for an effects system\", as far as I know</p>",
        "id": 213514377,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602818394
    },
    {
        "content": "<p>target-feature 1.1 has already been proposed (and still unstable) for longer than the entire proposed duration of this project group</p>",
        "id": 213514472,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602818517
    },
    {
        "content": "<p>Well yes. <a href=\"https://doc.rust-lang.org/unstable-book/language-features/repr-simd.html\">https://doc.rust-lang.org/unstable-book/language-features/repr-simd.html</a></p>",
        "id": 213514721,
        "sender_full_name": "Jubilee",
        "timestamp": 1602818817
    },
    {
        "content": "<p>There's quite a lot of these. <a href=\"https://github.com/rust-lang/rust/issues/39954\">https://github.com/rust-lang/rust/issues/39954</a></p>",
        "id": 213514749,
        "sender_full_name": "Jubilee",
        "timestamp": 1602818867
    },
    {
        "content": "<p>Another disadvantage of <code>#[cfg(codegen_backend)]</code> is that it prevents mixing a libstd compiled with one backend with user code compiled with another backend even when they are ABI compatible. (I plan to mix cg_clif with a cg_llvm sysroot in the future. And a game may want to compile the engine with cg_llvm in release mode for performance and the game code with cg_clif for fast iteration times.)</p>",
        "id": 213529550,
        "sender_full_name": "bjorn3",
        "timestamp": 1602835525
    },
    {
        "content": "<p>I'm not sure that's true, but if it is it can still use a new attribute with similar semantics but allows for that possibility. I'm not opposed to adding some new attribute, I'm mostly opposed to the magic of continuations which makes it very unclear how any particular function actually lowers, and opposed to doing so much work for supporting multiple SIMD backends when there is no immediate plan for any</p>",
        "id": 213557441,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602853827
    },
    {
        "content": "<p>If something like function multiversioning is outside of the scope of this project group, I think supporting multiple SIMD backends is definitely outside the scope.  But I think I've made my position clear at this point haha.</p>",
        "id": 213557535,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602853889
    },
    {
        "content": "<p>I feel like this needs a mechanism similar to the way the link attribute can specify a cfg that gets evaluated in the final crate that links the library, to determine if it applies.</p>",
        "id": 213591914,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602870329
    },
    {
        "content": "<p>Something that allows selecting from a set of these functions in std/core at compile time of the user's code, not just when std/core is compiled.</p>",
        "id": 213592044,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602870379
    },
    {
        "content": "<p>(That's leaving aside runtime detection.)</p>",
        "id": 213592067,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602870389
    },
    {
        "content": "<p>I do very much think that we need to be able to add new operations on a regular basis without having to touch every architecture.</p>",
        "id": 213592145,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602870437
    },
    {
        "content": "<p>And the architectures we don't touch should automatically use the portable pure-Rust implementations.</p>",
        "id": 213592195,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602870472
    },
    {
        "content": "<p>One version of this could be to lower it in MIR where a target needs to opt-out of that once it supports the intrinsic.</p>",
        "id": 213592365,
        "sender_full_name": "scottmcm",
        "timestamp": 1602870558
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125270\">@scottmcm</span> I think that's my preferred mechanism.  The intrinsics are always available, but rustc may or may not lower them to pure rust depending on backend?</p>",
        "id": 213592590,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602870677
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> if the functions are marked inline and the selection is done while lowering is that a sufficient guarantee that it occurs in user code?</p>",
        "id": 213593054,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602870882
    },
    {
        "content": "<p>I don't know if inlineable functions are sufficient for efficient SIMD code in the accelerated case. That would probably suffice for the unaccelerated portable implementation though.</p>",
        "id": 213593287,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602870978
    },
    {
        "content": "<p>But yeah, having these be handled via lowering that a target can then override with its own lowering makes sense to me.</p>",
        "id": 213593424,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1602871035
    },
    {
        "content": "<p>This is one of those places where it'd be really nice to have a data-driven way to do the lowering, since writing out the code manually for MIR lowering of all the different things would be a royal pain.  Unless maybe it turned into a <code>compiler-builtins</code> call?  So we do a good job of not linking the universe when things from there are unused?</p>",
        "id": 213594796,
        "sender_full_name": "scottmcm",
        "timestamp": 1602871600
    },
    {
        "content": "<p>Teaching rustc about vectors it is, then.</p>",
        "id": 213599022,
        "sender_full_name": "Jubilee",
        "timestamp": 1602873843
    },
    {
        "content": "<p>I actually think all of the metadata is there from repr(simd) at least</p>",
        "id": 213599118,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602873887
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"312331\">Caleb Zulawski</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/Portable.20pure-Rust.20implementation/near/213557535\">said</a>:</p>\n<blockquote>\n<p>If something like function multiversioning is outside of the scope of this project group, I think supporting multiple SIMD backends is definitely outside the scope.  But I think I've made my position clear at this point haha.</p>\n</blockquote>\n<p>At this point it's a matter of removing the practical blockers to delivering our API, so we can get back to writing our API. If implementing function multiversioning is what's required to do that, then so be it. This is why I suggested removing <strong>all</strong> vector widths except 1 or 2.</p>",
        "id": 213599624,
        "sender_full_name": "Jubilee",
        "timestamp": 1602874168
    },
    {
        "content": "<p>Because we <em>will</em> need every single ounce of bandwidth we have to plow through all the reasons that no one has resolved this issue before.</p>",
        "id": 213600733,
        "sender_full_name": "Jubilee",
        "timestamp": 1602874728
    },
    {
        "content": "<p>I agree we need to solve it, I was concerned about moving forward with something like continuations, which I had technical concerns with, without even having a discussion on the implementation</p>",
        "id": 213601370,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602875096
    },
    {
        "content": "<p>I'm mostly indifferent to the collectively agreed upon solution, I just want to make sure this discussion occurs</p>",
        "id": 213601526,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602875174
    },
    {
        "content": "<p>I appreciate that you want to have a discussion, which is why I attempted to enumerate the alternatives, which included teaching rustc about vectors.</p>\n<p>I feel like I made a mistake by saying \"continuation\", because really, what my idea was <strong>about</strong> was an abstraction fence that would isolate us from both the detalis of how our implementation is selected and also isolate us from the details of the final codegen backend, while still being able to express as many things a possible inside stdsimd, not have to go to the compiler, and not have to have details of codegen backends live in our API. You raised a concern which was soluble via a mechanism to retry, so I tossed out the first thing that came to mind for doing so.</p>\n<p>Now, embedding vectors in the MIR satisfies me in some ways, because I believe in vectors as a basic computational concept and so I think they should have first-class representation in any serious language. However, people have expressed that making compiler commits can be daunting, and I agree, which is why we split out into a separate repo in the first place. I feel like having scalar lowerings live entirely inside rustc IS in fact a fine design, but will effectively \"split the party\" and require us to keep going to the compiler to adjust our API.</p>",
        "id": 213604455,
        "sender_full_name": "Jubilee",
        "timestamp": 1602876815
    },
    {
        "content": "<p>Which is why I expressed frustration a few times... I feel like I was already having to argue against my <strong>personal</strong> preference!</p>",
        "id": 213604803,
        "sender_full_name": "Jubilee",
        "timestamp": 1602876997
    },
    {
        "content": "<p>I'm ok with expanding compiler functionality as long as in the meantime we can continue with LLVM intrinsics.  I think if the selection done entirely within the compiler (which seems to me most philosophically correct) that also means anything we write with LLVM intrinsics should have a fairly trivial conversion to platform intrinsics</p>",
        "id": 213604886,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602877049
    },
    {
        "content": "<p>Though I'm ok with any solution that doesn't end up blocking library API development, really</p>",
        "id": 213604999,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602877096
    },
    {
        "content": "<p>This is a very long thread and so I'm not sure I've absorbed every nuance in catching up, but just to respond to some of the very recent potints:</p>\n<ul>\n<li>Having vector support happen within MIR <strong>sounds like</strong> the best long term solution (but all I really know about MIR is \"it's a layer that exists\").</li>\n<li>If vectors are in MIR, then MIRI can \"automatically\" support simd-using code, and it's generally much better for miri to be able to cover as much code as possible.</li>\n<li>The MIR can probably (?) lower to the appropriate codegen system (llvm, cranelift, whatever) through the normal well established channels.</li>\n<li>The public API then targets rustc intrinsics -&gt; becomes MIR -&gt; becomes codegen IR -&gt; becomes assembly</li>\n<li>It sounds like new functions will always <em>default</em> to fallback mode and then specific situations can opt-in to having a better version. This would be like trait specialization, but for assembly.</li>\n</ul>",
        "id": 213624998,
        "sender_full_name": "Lokathor",
        "timestamp": 1602891859
    },
    {
        "content": "<p>Oh, MIRI is a great point.  Hopefully it can get the MIR of compiler-builtins implementations, so they can be written in rust instead of directly in MIR?</p>\n<blockquote>\n<p>Though I'm ok with any solution that doesn't end up blocking library API development, really</p>\n</blockquote>\n<p>Arguably most (all?) of the API can be defined even if the optimized implementations can't be checked in immediately.</p>",
        "id": 213625714,
        "sender_full_name": "scottmcm",
        "timestamp": 1602892838
    }
]