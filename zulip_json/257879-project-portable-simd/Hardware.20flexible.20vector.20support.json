[
    {
        "content": "<p>not quite...RVV supports vectors having their length dynamically adjusted...our current api doesn't</p>",
        "id": 253478654,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631736273
    },
    {
        "content": "<p>What exactly do you mean by dynamic?</p>",
        "id": 253478732,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631736304
    },
    {
        "content": "<p>Runtime specified? Or just resized</p>",
        "id": 253478816,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631736332
    },
    {
        "content": "<p>runtime specified</p>",
        "id": 253478845,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631736344
    },
    {
        "content": "<p>That's not necessary.</p>",
        "id": 253478855,
        "sender_full_name": "Jubilee",
        "timestamp": 1631736347
    },
    {
        "content": "<p>Interesting. Yeah, that aspect is probably not portable.</p>",
        "id": 253478941,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631736363
    },
    {
        "content": "<p>SimpleV also supports that</p>",
        "id": 253478984,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631736379
    },
    {
        "content": "<p>Supporting runtime-specified vector size is not required and not the point of what I am talking about.</p>",
        "id": 253479014,
        "sender_full_name": "Jubilee",
        "timestamp": 1631736395
    },
    {
        "content": "<p>I thought that's kind of what you meant at first</p>",
        "id": 253479048,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631736412
    },
    {
        "content": "<p>No.</p>",
        "id": 253479062,
        "sender_full_name": "Jubilee",
        "timestamp": 1631736417
    },
    {
        "content": "<p>I mean support of <strong>hardware</strong> flexible vectors.</p>",
        "id": 253479100,
        "sender_full_name": "Jubilee",
        "timestamp": 1631736429
    },
    {
        "content": "<p>So runtime specified size, but fixed</p>",
        "id": 253479130,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631736446
    },
    {
        "content": "<p>Like SVE</p>",
        "id": 253479143,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631736454
    },
    {
        "content": "<p>Arm SVE only has dynamic length in the sense that the same program will run on cpus with different lengths, where the length is runtime constant</p>",
        "id": 253479175,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631736464
    },
    {
        "content": "<p>Lighting up the SIMD units should not require an adjustment to our programming model, even if there are some marginal inefficiencies.<br>\nI will continue this later, I do not have the time now.</p>",
        "id": 253479348,
        "sender_full_name": "Jubilee",
        "timestamp": 1631736524
    },
    {
        "content": "<p>non-RVV non-SimpleV can emulate dynamic vector lengths using masking</p>",
        "id": 253479352,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631736526
    },
    {
        "content": "<p>so it <em>is</em> portable</p>",
        "id": 253479425,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631736555
    },
    {
        "content": "<p>The only fundamental issue I see is that you must accept from the beginning that your vectors are either sized or unsized</p>",
        "id": 253479443,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631736563
    },
    {
        "content": "<p>you can have sized vectors where the operations use some dynamically selected smaller length</p>",
        "id": 253479610,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631736618
    },
    {
        "content": "<p>that's how SimpleV works</p>",
        "id": 253479633,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631736630
    },
    {
        "content": "<p>like an arrayvec</p>",
        "id": 253479660,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631736643
    },
    {
        "content": "<p>No.</p>",
        "id": 253479731,
        "sender_full_name": "Jubilee",
        "timestamp": 1631736675
    },
    {
        "content": "<p>I'll wait to hear Jubilees idea <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>",
        "id": 253479777,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631736695
    },
    {
        "content": "<p>I mean doing some MATH in a fucking prologue, JFC.</p>",
        "id": 253479788,
        "sender_full_name": "Jubilee",
        "timestamp": 1631736697
    },
    {
        "content": "<p>JFC??</p>",
        "id": 253479835,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631736715
    },
    {
        "content": "<p>idk what that means</p>",
        "id": 253479891,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631736725
    },
    {
        "content": "<p>Yes, you don't know. Again, later.</p>",
        "id": 253480020,
        "sender_full_name": "Jubilee",
        "timestamp": 1631736778
    },
    {
        "content": "<p>...Sorry, didn't mean to get snippy.</p>\n<p>So, the thing is that if someone is using u8x16 to vectorize what would otherwise be something like an operation on the data hiding in some <code>data: Vec&lt;u8&gt;</code> field, and let's say it is at least 1KiB and ignore the alignment details atm (they don't really matter on Arm as long as we have min 16 byte alignment, so let's pretend we have at least that, e.g. by it being actually a u8x16 vector, and I forget the RVV rules), so it would be obviously beneficial to use a wider vector if we could.</p>\n<p>afaict these allow us to grab the HW vector length at runtime, so we can load that into a GPR... the assembly might look vaguely like</p>\n<div class=\"codehilite\" data-code-language=\"GAS\"><pre><span></span><code><span class=\"nf\">call</span> <span class=\"no\">data.len</span><span class=\"p\">()</span>\n<span class=\"nf\">mov</span> <span class=\"no\">gpr0</span><span class=\"p\">,</span> <span class=\"no\">data.len</span><span class=\"p\">().</span><span class=\"no\">retval.0</span>\n<span class=\"nf\">arch_vlen_get</span> <span class=\"no\">gpr1</span> <span class=\"c1\"># bytes of HW vector len</span>\n<span class=\"nf\">mov</span> <span class=\"no\">gpr2</span><span class=\"p\">,</span> <span class=\"mi\">16</span> <span class=\"c1\"># core::simd const len</span>\n<span class=\"nf\">div</span> <span class=\"no\">gpr3</span><span class=\"p\">,</span> <span class=\"no\">gpr1</span><span class=\"err\">/</span><span class=\"no\">gpr2</span> <span class=\"c1\"># multiple to use</span>\n<span class=\"c1\"># we now have all the values needed</span>\n<span class=\"c1\"># to parameterize the ensuing loop</span>\n<span class=\"c1\"># we operate some unknown positive N</span>\n<span class=\"c1\"># iterations on the data field</span>\n</code></pre></div>\n<p>so, this is a <strong>very</strong> abstract version. SVE provides specialized assembly instructions that enables this kind of explicit looping vector predication much more efficiently.</p>",
        "id": 253498015,
        "sender_full_name": "Jubilee",
        "timestamp": 1631745029
    },
    {
        "content": "<p>No multiversioning required aside from the \"is SVE go?\" check at all. A single compilation should work.</p>",
        "id": 253498293,
        "sender_full_name": "Jubilee",
        "timestamp": 1631745190
    },
    {
        "content": "<p>So, I agree that's something a user can do if they want to, but is that really something we want to do?  For example it would be relying heavily on loop fusion</p>",
        "id": 253498448,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631745281
    },
    {
        "content": "<p>I think so, indeed I really haven't seen a good reason not to!</p>\n<p>I think providing a dynamic vector length API that allows more directly handling these abstractly long data structures would be a good idea.</p>",
        "id": 253498849,
        "sender_full_name": "Jubilee",
        "timestamp": 1631745521
    },
    {
        "content": "<p>However, I think aiming for having LLVM emit this kind of loop handling is a goal.</p>",
        "id": 253499157,
        "sender_full_name": "Jubilee",
        "timestamp": 1631745682
    },
    {
        "content": "<p>Well, IMO relying on loop fusion is perhaps a reason not to (in std::simd at least, a crate like this might be super useful)</p>",
        "id": 253499332,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631745775
    },
    {
        "content": "<p>I think the API would need to reflect performing things inside the loop</p>",
        "id": 253499426,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631745839
    },
    {
        "content": "<p>I don't see how anyone downstream will manage to make this happen because it involves coaxing LLVM to emit certain prologues.</p>",
        "id": 253499469,
        "sender_full_name": "Jubilee",
        "timestamp": 1631745843
    },
    {
        "content": "<p>Well, I mean doing the loops manually</p>",
        "id": 253499642,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631745948
    },
    {
        "content": "<p>Does LLVM have anything like this already?</p>",
        "id": 253499660,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631745960
    },
    {
        "content": "<p>I have been generally dissatisfied with both LLVM's and GCC's loop fusion optimizations</p>",
        "id": 253499753,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631745991
    },
    {
        "content": "<p>llvm has support for manual looping like described...</p>",
        "id": 253499995,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631746141
    },
    {
        "content": "<p>LLVM has a lot of loop metadata we can be emitting hints to, and explicitly has instructions that allow you to push fixed width vectors into a scalable vector.</p>",
        "id": 253500139,
        "sender_full_name": "Jubilee",
        "timestamp": 1631746222
    },
    {
        "content": "<p>so it's really more saying \"hello LLVM please take these fixed vectors and assemble them into scalable pieces danke schön.\"</p>",
        "id": 253500322,
        "sender_full_name": "Jubilee",
        "timestamp": 1631746333
    },
    {
        "content": "<p>and I just remembered I'm probably wrong about my previous statement that Arm SVE doesn't support dynamically selectable RVV-style vector lengths...icr, would have to check the docs for sure...i do remember that at least the SX Aurora gets faster if you tell it the length you want rather than relying on only masking .... icr if that's Arm SVE</p>",
        "id": 253500365,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631746367
    },
    {
        "content": "<p>SVE has vector length constraints but idk if it's an optimization to use it.</p>\n<p>not seeing anything about Arm: <a href=\"https://en.m.wikipedia.org/wiki/NEC_SX-Aurora_TSUBASA\">https://en.m.wikipedia.org/wiki/NEC_SX-Aurora_TSUBASA</a></p>",
        "id": 253500605,
        "sender_full_name": "Jubilee",
        "timestamp": 1631746524
    },
    {
        "content": "<p>llvm can take fixed-length vectors and generate rvv instructions from them, you do have to give it a guaranteed minimum supported length though</p>",
        "id": 253500608,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631746526
    },
    {
        "content": "<p>yes.</p>",
        "id": 253500722,
        "sender_full_name": "Jubilee",
        "timestamp": 1631746572
    },
    {
        "content": "<p>I think we should basically be Intel/Arm bigoted and say the minimum is 128 bits.</p>",
        "id": 253500778,
        "sender_full_name": "Jubilee",
        "timestamp": 1631746605
    },
    {
        "content": "<p>&lt;_&lt;</p>",
        "id": 253500830,
        "sender_full_name": "Jubilee",
        "timestamp": 1631746655
    },
    {
        "content": "<p>I think most other SIMD architectures have 128 bit vectors too</p>",
        "id": 253500847,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631746670
    },
    {
        "content": "<p>The less common ones</p>",
        "id": 253500858,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631746676
    },
    {
        "content": "<p>it actually will probably be target specific, but</p>",
        "id": 253500861,
        "sender_full_name": "Jubilee",
        "timestamp": 1631746677
    },
    {
        "content": "<p>llvm supports at the ir level all of fixed-length, scalable allocated inside fixed length (like ArrayVec), and scalable allocated inside scalable vectors...see the llvm.vp.* intrinsics</p>",
        "id": 253500863,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631746679
    },
    {
        "content": "<p>some isas only have 32 or 64-bit vectors, such as some versions of risc-v's P extension</p>",
        "id": 253500972,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631746742
    },
    {
        "content": "<p>intended for microcontrollers where rvv is too heavy</p>",
        "id": 253501004,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631746761
    },
    {
        "content": "<p>Something that I think may be a compromise between the two, what about support for unsized vectors?  With SVE this would be a standard SVE vector, on AVX (hopefully) we could get it to compile to a standard AVX vector (but an unsized type), and then a user could use either of these to implement flexible vectors however they would like</p>",
        "id": 253501519,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747024
    },
    {
        "content": "<p>That does not seem like less work.</p>",
        "id": 253501609,
        "sender_full_name": "Jubilee",
        "timestamp": 1631747080
    },
    {
        "content": "<p>I think we are getting a little confused here between scalable and flexible vectors</p>",
        "id": 253501631,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747094
    },
    {
        "content": "<p>I don't think scalable vectors have anything to do with flexible vectors</p>",
        "id": 253501641,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747106
    },
    {
        "content": "<p>Well, I'm not sure it's any more or less work.  clang already has support for SVE, we would need to extend <code>repr(simd)</code> or make a new repr to handle it</p>",
        "id": 253501759,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747168
    },
    {
        "content": "<p>hmm, i never noticed the difference between scalable/flexible and used them mostly interchangeably...</p>",
        "id": 253501762,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631747170
    },
    {
        "content": "<p>I really was not intending to draw a line between them and I haven't seen any material that has a coherent definition separating them.</p>",
        "id": 253501764,
        "sender_full_name": "Jubilee",
        "timestamp": 1631747173
    },
    {
        "content": "<p>well, let me avoid terminology for a second</p>",
        "id": 253501803,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747202
    },
    {
        "content": "<p>there are two independent things we can do with vectors:</p>\n<ul>\n<li>vectors that have size specified by hardware, but only determined at runtime</li>\n<li>vectors that have unlimited(ish) size, defined by the user</li>\n</ul>",
        "id": 253501885,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747270
    },
    {
        "content": "<p>if we focus entirely on the first bullet, I don't think we need loops/prologs/epilogs at all?</p>",
        "id": 253501956,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747298
    },
    {
        "content": "<p>all procedure calls have a prologue and epilogue.</p>",
        "id": 253501998,
        "sender_full_name": "Jubilee",
        "timestamp": 1631747329
    },
    {
        "content": "<p>let me clarify what I mean</p>",
        "id": 253502022,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747345
    },
    {
        "content": "<p>i think a good next step would to end up with an arrayvec-like vector -- that neatly avoids the unsized-stuff-on-stack problem while still benefiting from the SimpleV-style dynamic lengths</p>",
        "id": 253502048,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631747364
    },
    {
        "content": "<p>we can have struct <code>ScalableSimd</code> or whatever you want to call it, it would look nearly identical to what we currently have.  Calling <code>Add::add</code> on it would still result in just one instruction.  The only things that would be different is anything that touches memory (no <code>{from,to}_array</code>)</p>",
        "id": 253502204,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747436
    },
    {
        "content": "<p>I'm personally extremely hesitant to rely so heavily on the optimizer to the extent of generating loops for every fn call</p>",
        "id": 253502257,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747469
    },
    {
        "content": "<p>We are already relying on it performing inlining correctly.</p>",
        "id": 253502299,
        "sender_full_name": "Jubilee",
        "timestamp": 1631747496
    },
    {
        "content": "<p>llvm has <code>llvm.vp.*</code> intrinsics...no need for loop optimizations</p>",
        "id": 253502328,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631747513
    },
    {
        "content": "<p>and yes, I used a loop to introduce the idea but this is more about using simple math to address the problem.</p>",
        "id": 253502446,
        "sender_full_name": "Jubilee",
        "timestamp": 1631747565
    },
    {
        "content": "<p>The runtime value is a parameter we can work around. That's all. It doesn't need compile time multiversioning because it can be handled as intended: at runtime.</p>",
        "id": 253502674,
        "sender_full_name": "Jubilee",
        "timestamp": 1631747686
    },
    {
        "content": "<p>the issue with <code>ScalableSimd</code> is that there's two kinds...<code>ArrayVec</code> and truely unsized types</p>",
        "id": 253502677,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631747688
    },
    {
        "content": "<p>I think we should have the <code>ArrayVec</code> kind at first since it gives most the benefit without many compiler-level annoyances...owned unsized types can be tackled later</p>",
        "id": 253502859,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631747796
    },
    {
        "content": "<p>We can still have functions compile down to single instructions. The difference is that on AVX, we can't even emit a single instruction. It has to be multiversioned because vector length is a hard constant without parameterization, embedded in the function itself.</p>",
        "id": 253502909,
        "sender_full_name": "Jubilee",
        "timestamp": 1631747831
    },
    {
        "content": "<p>for the <code>ArrayVec</code> types, we generate code based on the compile-time-determined max vector length</p>",
        "id": 253502988,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631747882
    },
    {
        "content": "<p>I agree we are relying on inlining, but that's a significantly less complex thing than loop fusion</p>",
        "id": 253503036,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747903
    },
    {
        "content": "<p>so we can statically determine which AVX instructions to use without needing multiversioning</p>",
        "id": 253503064,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631747924
    },
    {
        "content": "<p>though multiversioning can still make it run faster, as expected</p>",
        "id": 253503104,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631747950
    },
    {
        "content": "<p>I'm confused--there is no way to create a portable binary that uses AVX without multiversioning</p>",
        "id": 253503107,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747954
    },
    {
        "content": "<p>Exactly.</p>",
        "id": 253503120,
        "sender_full_name": "Jubilee",
        "timestamp": 1631747966
    },
    {
        "content": "<p>Ignore all that, we can just say \"target features\"</p>",
        "id": 253503135,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747978
    },
    {
        "content": "<p>runtime or compile time specified, doesn't really matter</p>",
        "id": 253503146,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631747986
    },
    {
        "content": "<p>which is why bringing in the idea of using flexible vectors for AVX is irrelevant.</p>",
        "id": 253503191,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748002
    },
    {
        "content": "<p>there is---AVX is just the minimum required -- <code>-C target-features=+avx2</code></p>",
        "id": 253503223,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748013
    },
    {
        "content": "<p>Hmm maybe you misunderstood, I'm just saying that yes I agree you can implement any type of unsized vectors with fixed size vectors</p>",
        "id": 253503264,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748044
    },
    {
        "content": "<p>flexible vectors for AVX is relevant because we want to emulate them for portability</p>",
        "id": 253503337,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748065
    },
    {
        "content": "<p>No?</p>",
        "id": 253503342,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748066
    },
    {
        "content": "<p>I'm confused <span aria-label=\"confused\" class=\"emoji emoji-1f615\" role=\"img\" title=\"confused\">:confused:</span></p>",
        "id": 253503375,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748087
    },
    {
        "content": "<p>I don't understand what is being argued for</p>",
        "id": 253503388,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748096
    },
    {
        "content": "<p>I simply don't trust LLVM to do loop fusion correctly, if it did, well that's my only qualm</p>",
        "id": 253503478,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748129
    },
    {
        "content": "<p>it isn't about loop fusion.</p>",
        "id": 253503491,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748141
    },
    {
        "content": "<p>several separate things are being argued for...hence the confusion</p>",
        "id": 253503492,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748141
    },
    {
        "content": "<p>Okay let's back up</p>",
        "id": 253503513,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748155
    },
    {
        "content": "<p>Completely putting aside how it's implemented in codegen</p>",
        "id": 253503544,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748173
    },
    {
        "content": "<p>I have tried to focus on only one thing and I would appreciate it if we didn't bring up sidetracks.</p>",
        "id": 253503578,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748196
    },
    {
        "content": "<p>sorry</p>",
        "id": 253503594,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748206
    },
    {
        "content": "<p>Are we looking for an api that has something like:</p>\n<div class=\"codehilite\"><pre><span></span><code>impl FlexibleVector {\n    fn splat(value: T, len: usize) -&gt; { ... }\n}\n</code></pre></div>",
        "id": 253503627,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748231
    },
    {
        "content": "<p>or am I confused?</p>",
        "id": 253503633,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748236
    },
    {
        "content": "<p>No, we are not.</p>",
        "id": 253503682,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748246
    },
    {
        "content": "<p>I am not.</p>",
        "id": 253503691,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748250
    },
    {
        "content": "<p>Okay, can you give me an example?  In rust, not codegen</p>",
        "id": 253503709,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748262
    },
    {
        "content": "<p>Not yet. Someday, probably.</p>",
        "id": 253503710,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748263
    },
    {
        "content": "<p>i'm thinking of an api very much like arrayvec</p>",
        "id": 253503716,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748265
    },
    {
        "content": "<p>though that only covers one of the two flexible-vectors styles</p>",
        "id": 253503752,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748297
    },
    {
        "content": "<p>My point is that our existing,<br>\nconst sized vector programming<br>\ncan be compiled in a way to exploit hardware vector lanes fully, possibly by doing a bit of math occasionally.</p>",
        "id": 253503797,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748332
    },
    {
        "content": "<p>My point is exactly that nothing needs to change about the Rust.</p>",
        "id": 253503822,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748353
    },
    {
        "content": "<p>Hmm.</p>",
        "id": 253503879,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748370
    },
    {
        "content": "<p>Now, I expect this might not fully exploit the vector programming model SVE offers.</p>",
        "id": 253503906,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748390
    },
    {
        "content": "<p>So if you have <code>Simd&lt;f32, 1024&gt;::add</code>, doesn't that need to generate a loop because the vector might be as small as 128?</p>",
        "id": 253503941,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748423
    },
    {
        "content": "<p>That was already an issue. :D</p>",
        "id": 253503997,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748464
    },
    {
        "content": "<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">struct</span> <span class=\"nc\">SimdVec</span><span class=\"o\">&lt;</span><span class=\"n\">T</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"n\">MAX_LEN</span>: <span class=\"kt\">usize</span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">data</span>: <span class=\"p\">[</span><span class=\"n\">MaybeUninit</span><span class=\"o\">&lt;</span><span class=\"n\">T</span><span class=\"o\">&gt;</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">MAX_LEN</span><span class=\"p\">],</span><span class=\"w\"> </span><span class=\"c1\">// the vector's underlying storage, the part llvm sees as a vector</span>\n<span class=\"w\">    </span><span class=\"n\">len</span>: <span class=\"kt\">usize</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"c1\">// maybe passed in to methods instead of kept with data?</span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 253504010,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748477
    },
    {
        "content": "<p>Well, if you have fixed size vectors it doesn't create a loop!</p>",
        "id": 253504055,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748484
    },
    {
        "content": "<p>Please no sidetracks.</p>",
        "id": 253504064,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748490
    },
    {
        "content": "<p>Sure it does.</p>",
        "id": 253504073,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748496
    },
    {
        "content": "<p>Is it actually ever represented in LLVM as a loop?</p>",
        "id": 253504122,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748531
    },
    {
        "content": "<p>Yes, if the vector is bigger than the hardware can actually have, LLVM totally can compile it into a loop.</p>",
        "id": 253504132,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748538
    },
    {
        "content": "<p>currently a <code>f32x1024</code> creates a bunch of duplicate instructions, never a loop (iirc)</p>",
        "id": 253504147,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748545
    },
    {
        "content": "<p>Oh whatever. <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>",
        "id": 253504166,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748562
    },
    {
        "content": "<p>Yeah, I've never seen it create a loop.  I'm not saying it can't, but I think that falls out of an asm optimization, not lowering from IR</p>",
        "id": 253504180,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748570
    },
    {
        "content": "<p>I literally do not care about the difference atm.</p>",
        "id": 253504199,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748585
    },
    {
        "content": "<p>Okay but I do!! My point is that with a runtime factor you _must_ generate a loop, you cannot simply create duplicate instructions</p>",
        "id": 253504288,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748619
    },
    {
        "content": "<p>the optimal selection between the same sequence of repeating instructions and a loop depends on the arch details and codegen size.</p>",
        "id": 253504336,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748653
    },
    {
        "content": "<p>I agree with that--but that's not my point</p>",
        "id": 253504358,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748667
    },
    {
        "content": "<p>duplicate instructions work because llvm compiles dynamic lengths into masks (for x86), not loop counters</p>",
        "id": 253504364,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748670
    },
    {
        "content": "<p>that's cute.</p>",
        "id": 253504393,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748690
    },
    {
        "content": "<p>LLVM lowers into duplicate instructions, which may then be optimized into a loop (I've never seen it done, but I suppose it could)</p>",
        "id": 253504412,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748703
    },
    {
        "content": "<p>With a runtime factor, you must lower into a loop, and if you do that, you unavoidably run into loop fusion optimization</p>",
        "id": 253504475,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748734
    },
    {
        "content": "<p>I mentioned a loop because both SVE and RVV have arch-optimized predicated loop instructions.</p>",
        "id": 253504501,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748754
    },
    {
        "content": "<p>with a runtime factor, you <em>don't need</em> a loop, you can generate masks, which is what llvm does for non-flexible-vector-targets</p>",
        "id": 253504553,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748802
    },
    {
        "content": "<p>I am suggesting that with SVE (without multiversioning) there is absolutely no way to not lower into a loop with vectors over a certain size</p>",
        "id": 253504554,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748802
    },
    {
        "content": "<p>for SVE or RVV, idk what llvm does...it could just assert fail</p>",
        "id": 253504653,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748851
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"229517\">@Jacob Lifshay</span> I think you are focusing on smaller vectors, I am more concerned about larger vectors?</p>",
        "id": 253504664,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748858
    },
    {
        "content": "<p>i was focusing on targeting an arch that doesn't natively have dynamic lengths</p>",
        "id": 253504716,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748895
    },
    {
        "content": "<p>Yeah we aren't discussing that.</p>",
        "id": 253504752,
        "sender_full_name": "Jubilee",
        "timestamp": 1631748918
    },
    {
        "content": "<p>llvm assumes you'll use vectors small enough for overhead to be not absurd</p>",
        "id": 253504774,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631748931
    },
    {
        "content": "<p>Just to make sure we are on the same page <span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span>, do you see a way to do <code>Simd&lt;f32, 1024&gt;::add</code> without generating an actual test-index-and-jump loop?</p>",
        "id": 253504775,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748933
    },
    {
        "content": "<p>(with SVE)</p>",
        "id": 253504786,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631748942
    },
    {
        "content": "<p>for <code>Simd&lt;f32, 1024&gt;::add</code>, last I checked, llvm's rvv backend just crashes at compile-time if the native vectors aren't long enough</p>",
        "id": 253504976,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631749032
    },
    {
        "content": "<p>though I did check a slightly different op...</p>",
        "id": 253505098,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631749093
    },
    {
        "content": "<p>icr what</p>",
        "id": 253505110,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631749103
    },
    {
        "content": "<p>So,<br>\nI have not reviewed every single SVE instruction so I don't know,<br>\nbut I am gonna be honest with you,<br>\nNo one should be using vectors larger than a cache line, and we should not encourage users to use vectors that emit more than 64 bytes of code just to handle one of them.</p>",
        "id": 253505228,
        "sender_full_name": "Jubilee",
        "timestamp": 1631749193
    },
    {
        "content": "<p>It's mathematically insane considering the constraints the hardware is under BEFORE we enter SIMD into the mix.</p>",
        "id": 253505358,
        "sender_full_name": "Jubilee",
        "timestamp": 1631749266
    },
    {
        "content": "<p>Okay, lets say <code>Simd&lt;f32, 16&gt;</code> and keep it simple</p>",
        "id": 253505455,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631749328
    },
    {
        "content": "<p>Are we expecting it to generate 4 instructions and then mask the vector size down to 128?</p>",
        "id": 253505662,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631749444
    },
    {
        "content": "<p>I think you brought up a very good point re: what we should remain aware of! But it's a deeply degenerate case.</p>\n<p>And in the presence of a known size where there are no iterations, SVE code can fall back on Neon.</p>",
        "id": 253505741,
        "sender_full_name": "Jubilee",
        "timestamp": 1631749506
    },
    {
        "content": "<p>Okay, so in this case I think it's the same as running x86 without multiversioning--it would work but it's pretty lame compared to multiversioning for AVX-512</p>",
        "id": 253505894,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631749593
    },
    {
        "content": "<p>SVE2 could constrain vector length to 256 bits tho', I think, and use two instructions. I think that's the minimum?</p>\n<p>SVE2 is unavoidably specialized around parallelizing loop-shaped constructs.</p>",
        "id": 253505966,
        "sender_full_name": "Jubilee",
        "timestamp": 1631749668
    },
    {
        "content": "<p><code>Simd&lt;f32, 1024&gt;::add</code> on rvv with min hw vector len of 256-bits: <a href=\"https://gcc.godbolt.org/z/5b51Mh4xa\">https://gcc.godbolt.org/z/5b51Mh4xa</a></p>",
        "id": 253506055,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631749729
    },
    {
        "content": "<p>I think in this case I would argue that we shouldn't have to do anything special, LLVM should handle regular fixed size vectors optimally when you have SVE?</p>",
        "id": 253506057,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631749730
    },
    {
        "content": "<p>Correct.<br>\nI am merely saying, essentially,<br>\nthat telling people they GOTTA multiversion is likely incorrect.</p>",
        "id": 253506206,
        "sender_full_name": "Jubilee",
        "timestamp": 1631749840
    },
    {
        "content": "<p>for rvv, unless you tell llvm there's a min guaranteed hw vector len, fixed length vectors just generate scalar instructions and ignore rvv completely</p>",
        "id": 253506328,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631749926
    },
    {
        "content": "<p>lmao</p>",
        "id": 253506368,
        "sender_full_name": "Jubilee",
        "timestamp": 1631749954
    },
    {
        "content": "<p>So I tried enabling SVE, and it just generated 4 neon instructions</p>",
        "id": 253506381,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631749964
    },
    {
        "content": "<p>which I think is likely the more efficient way, anyway</p>",
        "id": 253506408,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631749983
    },
    {
        "content": "<p>so multiversioning on min supported vector len is a <em>very</em> good idea for rvv</p>",
        "id": 253506426,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631749989
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"312331\">@Caleb Zulawski</span> you probably need a min vector len thing for sve too</p>",
        "id": 253506563,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631750059
    },
    {
        "content": "<p>well I am ignoring scalar vs. vector-enabled multiversioning.</p>",
        "id": 253506574,
        "sender_full_name": "Jubilee",
        "timestamp": 1631750066
    },
    {
        "content": "<p>If you do that then you're effectively setting a target feature!</p>",
        "id": 253506606,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631750093
    },
    {
        "content": "<p>yeah LLVM can be really dumb.</p>",
        "id": 253506617,
        "sender_full_name": "Jubilee",
        "timestamp": 1631750102
    },
    {
        "content": "<p>my point was, without llvm knowing a min supported length, it ignores rvv completely</p>",
        "id": 253506644,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631750116
    },
    {
        "content": "<p>A recent change now requires you to pass two args to LLVM to enable SSE4.2</p>",
        "id": 253506669,
        "sender_full_name": "Jubilee",
        "timestamp": 1631750137
    },
    {
        "content": "<p>(except for explicitly scalable ir)</p>",
        "id": 253506680,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631750146
    },
    {
        "content": "<p>hopefully that won't make it to 14.0 release</p>",
        "id": 253506689,
        "sender_full_name": "Jubilee",
        "timestamp": 1631750152
    },
    {
        "content": "<p>I think without determining a minimum vector length (at compile time or multiversioned) it will never be more efficient to generate SVE/RVV</p>",
        "id": 253506761,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631750177
    },
    {
        "content": "<p>Caleb.</p>",
        "id": 253506805,
        "sender_full_name": "Jubilee",
        "timestamp": 1631750204
    },
    {
        "content": "<p>well, maybe for extremely long vectors it would be, but like you said, nothing reasonable</p>",
        "id": 253506808,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631750205
    },
    {
        "content": "<p>I am pretty sure what Jacob is saying is that you need two args to enable generating SVE code at all</p>",
        "id": 253506841,
        "sender_full_name": "Jubilee",
        "timestamp": 1631750235
    },
    {
        "content": "<p>that second argument is the minimum vector length!</p>",
        "id": 253506862,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631750251
    },
    {
        "content": "<p>which produces non-portable code.</p>",
        "id": 253506873,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631750260
    },
    {
        "content": "<p>...</p>",
        "id": 253506888,
        "sender_full_name": "Jubilee",
        "timestamp": 1631750269
    },
    {
        "content": "<p>idk, i'm just guessing llvm's sve backend is like it's rvv backend, they could be quite different!</p>",
        "id": 253506954,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631750287
    },
    {
        "content": "<p>sigh.</p>",
        "id": 253506989,
        "sender_full_name": "Jubilee",
        "timestamp": 1631750312
    },
    {
        "content": "<p>yeah, sorry, I'm easily distracted</p>",
        "id": 253507030,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631750342
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span> so I'm still not exactly sure what you are getting at.  If you don't want to multiversion, there's no reason to prefer SVE over NEON, since you are going to have 128 bit vectors max either way</p>",
        "id": 253507312,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631750516
    },
    {
        "content": "<p>now that i'm thinking of it, it could be the abi of passing vectors by value that's making sve get not used</p>",
        "id": 253507315,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631750518
    },
    {
        "content": "<p>which flag did you use to enable sve?</p>",
        "id": 253507634,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631750678
    },
    {
        "content": "<p><code>-march=armv8-a+sve</code></p>",
        "id": 253507662,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631750697
    },
    {
        "content": "<p>thx!</p>",
        "id": 253507676,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631750705
    },
    {
        "content": "<p>the micro case of the code it emits for a single vector add of a fat vector does not really matter because we are talking about programs which contain looping constructs. the design of the architecture revolves around reducing loops into predicates, controlling operations via <code>whilelt</code> and <code>whilelo</code>. of course if you pick something it isn't actually good at, i.e. improving performance in a minimal procedure, instead of a multistep procedure, it is bad. if there is no way for it to parallelize it, it doesn't.</p>\n<p>I really have no idea why you are so fixated on avoiding a jump.</p>",
        "id": 253509550,
        "sender_full_name": "Jubilee",
        "timestamp": 1631752085
    },
    {
        "content": "<p>you just defined loop fusion!!</p>",
        "id": 253509751,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631752265
    },
    {
        "content": "<p>In my experience, it is not good at optimizing it, that is my concern.</p>",
        "id": 253509767,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631752284
    },
    {
        "content": "<p>It is built into the architecture, Caleb.</p>",
        "id": 253509780,
        "sender_full_name": "Jubilee",
        "timestamp": 1631752298
    },
    {
        "content": "<p>If it were good at it, I would have no problem with it</p>",
        "id": 253509786,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631752301
    },
    {
        "content": "<p>It is built into the architecture, Caleb.</p>",
        "id": 253509798,
        "sender_full_name": "Jubilee",
        "timestamp": 1631752314
    },
    {
        "content": "<p>Fusing the loops generated by multiple LLVM intrinsics is not.</p>",
        "id": 253509860,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631752341
    },
    {
        "content": "<p>which is why if we emit... ARGH.<br>\nthis is what I am talking about.</p>\n<p>I don't have any more energy for this today because I rather feel like you are taking out your hostility to loop fusion, LLVM, and gcc on me.</p>",
        "id": 253509925,
        "sender_full_name": "Jubilee",
        "timestamp": 1631752401
    },
    {
        "content": "<p>I am not! I agree with you that, if it were able to merge those loops perfectly, the way to go</p>",
        "id": 253509957,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631752436
    },
    {
        "content": "<p>we know what is happening and can influence the way that rustc emits LLIR so that it knows to elevate to scalable vectors.</p>",
        "id": 253510053,
        "sender_full_name": "Jubilee",
        "timestamp": 1631752493
    },
    {
        "content": "<p>but since no one else sees the merit in doing that, because \"loop fusion in LLVM is doomed\", even though I am talking about potentially emitting an entirely different LLIR construct, I guess I won't bother.</p>",
        "id": 253510325,
        "sender_full_name": "Jubilee",
        "timestamp": 1631752694
    },
    {
        "content": "<p>are you suggesting that, in the final asm (not the llvm abstraction) it is not looping?</p>",
        "id": 253510553,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631752855
    },
    {
        "content": "<p>I'm also not saying it's doomed, I'm just suggesting that it likely won't work well in at least some circumstances</p>",
        "id": 253510576,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631752882
    },
    {
        "content": "<p>what does it even matter at this point since it's not happening.</p>",
        "id": 253510583,
        "sender_full_name": "Jubilee",
        "timestamp": 1631752890
    },
    {
        "content": "<p>yeah yeah I got it.</p>",
        "id": 253510591,
        "sender_full_name": "Jubilee",
        "timestamp": 1631752897
    },
    {
        "content": "<p>trying is a waste of time.</p>",
        "id": 253510606,
        "sender_full_name": "Jubilee",
        "timestamp": 1631752913
    },
    {
        "content": "<p>I'm looking at the LLVM lang ref</p>",
        "id": 253512031,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631753950
    },
    {
        "content": "<p>which intrinsic are you suggesting using?</p>",
        "id": 253512037,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631753957
    },
    {
        "content": "<p>why?</p>",
        "id": 253512715,
        "sender_full_name": "Jubilee",
        "timestamp": 1631754444
    },
    {
        "content": "<p>for using sve</p>",
        "id": 253512737,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631754470
    },
    {
        "content": "<p>no, I mean why continue?</p>",
        "id": 253512859,
        "sender_full_name": "Jubilee",
        "timestamp": 1631754558
    },
    {
        "content": "<p>I'm curious to see which specific intrinsic you were looking at</p>",
        "id": 253512977,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631754622
    },
    {
        "content": "<p>i'm suggesting llvm.vp.*</p>",
        "id": 253514494,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631755812
    },
    {
        "content": "<p>which shouldn't generate a loop--it usually generates 1 or a few instructions</p>",
        "id": 253514549,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631755860
    },
    {
        "content": "<p>maybe I'm confused but that seems to be the \"shrinking vector case\" which I don't think is what this conversation was supposed to be about?</p>",
        "id": 253514597,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631755910
    },
    {
        "content": "<p>though I'm also not sure I'm reading what those intrinsics do correctly</p>",
        "id": 253514618,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1631755922
    },
    {
        "content": "<p>well, the llvm.vp instructions cover predication, vector length, scalable/not, and storage in scalable/not</p>",
        "id": 253514715,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631756003
    },
    {
        "content": "<p>so, they basically cover everything</p>",
        "id": 253514730,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631756020
    },
    {
        "content": "<p>I helped with designing them, they're specifically designed to cover everything</p>",
        "id": 253514799,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631756060
    },
    {
        "content": "<p>(admittedly I didn't help a whole lot, mostly by just commenting on the email thread)</p>",
        "id": 253515321,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631756428
    },
    {
        "content": "<p>a sorta-good intro to the llvm.vp instructions: <a href=\"https://llvm.org/docs/LangRef.html#vector-predication-intrinsics\">https://llvm.org/docs/LangRef.html#vector-predication-intrinsics</a></p>",
        "id": 253515348,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631756457
    },
    {
        "content": "<p>maybe a better spot to look is an old rfc: <a href=\"https://reviews.llvm.org/D57504\">https://reviews.llvm.org/D57504</a></p>",
        "id": 253515824,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631756780
    },
    {
        "content": "<p>see also <a href=\"https://github.com/llvm/llvm-project/blob/main/llvm/docs/Proposals/VectorPredication.rst\">https://github.com/llvm/llvm-project/blob/main/llvm/docs/Proposals/VectorPredication.rst</a></p>",
        "id": 253516066,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1631756981
    }
]