[
    {
        "content": "<p>Hey everyone! I am super excited to try out the new stdsimd stuff in the Rust CV org for feature matching and search. <span class=\"user-mention\" data-user-id=\"224471\">@Lokathor</span>, I saw your comment on packed_simd, and I am super excited about this effort. While I am more focused currently on Rust CV, I can definitely speak to what features I am interested in as far as SIMD is concerned. I would like to point out that our most performance intensive tight loops run hamming distance calculations on 512-bit features to do brute-force nearest neighbor matching between sets of descriptors, so parallel XOR and popcount with a horizontal add (avoiding overflow) is fairly important to us. Other areas of interest are in creating image filters. Horizontal and vertical scharr filters using SIMD could speed up the akaze crate a lot, and that crate has other examples. If anyone is interested in downstream use cases, I can discuss that more. I will leave on my notifications, and thanks to all of you for making this possible. You all rock <span aria-label=\"rocket\" class=\"emoji emoji-1f680\" role=\"img\" title=\"rocket\">:rocket:</span>.</p>",
        "id": 210829840,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600753356
    },
    {
        "content": "<p>Taken under advisement.</p>",
        "id": 210830062,
        "sender_full_name": "Lokathor",
        "timestamp": 1600753705
    },
    {
        "content": "<p>However, it does feel fair to say that if the avx-512 support turns out to be any more complicated than \"call the 128 or 256 bit stuff but wider\" than it'll probably be a little farther out.</p>\n<p>It's hard just having a dev machine with avx-512 support to do the development on. Mostly it's available only for servers, so you can get it in CI if you look around but not so much for a local machine.</p>",
        "id": 210830167,
        "sender_full_name": "Lokathor",
        "timestamp": 1600753836
    },
    {
        "content": "<p>Also keep in mind that AVX-512 causes currently available Intel CPUs to drop their clocks significantly. So using it will slow down everything else currently running.</p>",
        "id": 210836729,
        "sender_full_name": "mati865",
        "timestamp": 1600760622
    },
    {
        "content": "<p>maybe.<br>\n<a href=\"https://travisdowns.github.io/blog/2020/08/19/icl-avx512-freq.html\">https://travisdowns.github.io/blog/2020/08/19/icl-avx512-freq.html</a><br>\n<a href=\"https://lemire.me/blog/2018/08/15/the-dangers-of-avx-512-throttling-a-3-impact/\">https://lemire.me/blog/2018/08/15/the-dangers-of-avx-512-throttling-a-3-impact/</a><br>\nWe will definitely want to be careful about lowering to those instructions, however, they definitely can be \"battery virus-y\" if used poorly.</p>",
        "id": 210837204,
        "sender_full_name": "Jubilee",
        "timestamp": 1600760981
    },
    {
        "content": "<p>there are use cases where they absolutely make a performance difference though (in a positive way)</p>",
        "id": 210885908,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600787979
    },
    {
        "content": "<p>although that may be at the expense of other applications on the system</p>",
        "id": 210886093,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600788035
    },
    {
        "content": "<p>clang/gcc/icc do not issue them for <code>skylake-avx512</code> without flags (<code>-mprefer-vector-width=512</code> or <code>-qopt-zmm-usage=high</code>). As Travis' blog shows, the issue is largely gone on Ice Lake (client; server unknown) and presumably compilers will follow (though clang and gcc trunk are currently still using 256-bit by default with <code>-march=icelake-client</code> et al).</p>",
        "id": 210890661,
        "sender_full_name": "Jed",
        "timestamp": 1600789912
    },
    {
        "content": "<p>I think if a user explicitly uses a 512-bit simd operation that it would be somewhat unexpected if it used 256-bit instructions</p>",
        "id": 210890833,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600789988
    },
    {
        "content": "<p>I can understand for autovectorization though, but if there is precedence it might be preferable to avoid avx-512</p>",
        "id": 210890928,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600790040
    },
    {
        "content": "<p>keep in mind though that some 512-bit instructions may not have the same issues</p>",
        "id": 210891001,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600790057
    },
    {
        "content": "<p>in particular, the ones I care about the most: xor and popcount</p>",
        "id": 210891027,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600790072
    },
    {
        "content": "<p>which does have a horizontal add, but that shouldn't be too power hungry</p>",
        "id": 210891081,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600790097
    },
    {
        "content": "<p>BMI-2, for instance, may have 512-bit instructions</p>",
        "id": 210891200,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600790148
    },
    {
        "content": "<p>The January post showed that even \"light instructions\" like <a href=\"https://travisdowns.github.io/blog/2020/01/17/avxfreq1.html#512-bit-integer-simd-avx-512\"><code>vpor</code></a> with <code>zmm</code> cause the frequency change on SKX.</p>",
        "id": 210891760,
        "sender_full_name": "Jed",
        "timestamp": 1600790357
    },
    {
        "content": "<p>Issue being that issuing a single <code>vpor</code> instruction results in a total of ~22 microseconds of stall (in addition to the 650 microseconds of lower frequency).</p>\n<p>I wonder if there is a bit finer grained way to indicate preferred vector width?</p>",
        "id": 210892433,
        "sender_full_name": "Jed",
        "timestamp": 1600790601
    },
    {
        "content": "<p>wow, I had no clue that such a simple bitwise operation could cause this</p>",
        "id": 210894166,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791317
    },
    {
        "content": "<p>I assumed that the heating was associated with instructions like multiplication</p>",
        "id": 210894202,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791336
    },
    {
        "content": "<p>nonetheless, there are workloads that run these things in tight loops where they perform very well, so being able to explicitly opt into these cases would be good</p>",
        "id": 210894330,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791388
    },
    {
        "content": "<p>but it sounds like it isnt as simple as \"use the widest register possible\"</p>",
        "id": 210894396,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791421
    },
    {
        "content": "<p>it seems like it should be, but I guess those few intel generations do make it more nebulous</p>",
        "id": 210894461,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791456
    },
    {
        "content": "<p>I will say that I am currently using 512 bit intrinsics in the <code>bitarray</code> crate to get high performance hamming distance</p>",
        "id": 210894647,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791529
    },
    {
        "content": "<p>llvm intrinsics specifically</p>",
        "id": 210894682,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791549
    },
    {
        "content": "<p>Yes, I agree. I wish it were as simple as thermal throttling, but the license change is a huge hit. We have scientific workloads where the wide instructions pay off, but only when the problem sizes are big enough (so it depends on run-time configuration whether it pays off, not that I'm asking for run-time configuration here).</p>",
        "id": 210894755,
        "sender_full_name": "Jed",
        "timestamp": 1600791585
    },
    {
        "content": "<p><a href=\"https://github.com/rust-cv/bitarray/blob/cf41a2edc69f326ce069d902d3a805f72f4038bb/src/lib.rs#L125\">https://github.com/rust-cv/bitarray/blob/cf41a2edc69f326ce069d902d3a805f72f4038bb/src/lib.rs#L125</a></p>",
        "id": 210894777,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791596
    },
    {
        "content": "<p>yeah, this is a huge pain, but it doesn't seem like mangling the API to work around this intel chip is the best thing</p>",
        "id": 210894912,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791647
    },
    {
        "content": "<p>maybe making it some kind of compiler flag could be more appropriate</p>",
        "id": 210894939,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791663
    },
    {
        "content": "<p>I have had a user report a significant performance drop when I tried to remove the llvm intrinsics</p>",
        "id": 210895030,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791703
    },
    {
        "content": "<p>I was aware of this fact, but they were impacted downstream</p>",
        "id": 210895056,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791718
    },
    {
        "content": "<p>now as you can see its off by default, but we have a feature to enable it</p>",
        "id": 210895118,
        "sender_full_name": "Geordon Worley",
        "timestamp": 1600791730
    },
    {
        "content": "<p>if you use a 512-bit type without 512-bit ops enabled it should lower to two 256-bit ops, so multi-versioning can probably handle much of this, though maybe not all.</p>",
        "id": 210899076,
        "sender_full_name": "Lokathor",
        "timestamp": 1600793508
    },
    {
        "content": "<p>Ultimately if a very particular assembly instruction is desired, there is still no replacement for actually using the <code>asm!</code> macro.<br>\nI believe part of the issue is that the SIMD instructions often prefer to be used frequently: it seems there's a transition where Intel actually \"lights up\" the vector registers bigger than 128 bit, and until then it uses the 128 bit registers only (executing wider ops with multiple uses of it). <a href=\"https://www.agner.org/optimize/blog/read.php?i=415#415\">https://www.agner.org/optimize/blog/read.php?i=415#415</a></p>",
        "id": 210934941,
        "sender_full_name": "Jubilee",
        "timestamp": 1600810927
    },
    {
        "content": "<p>Yeah, <code>power license level</code> is one related search term there, which might have been mentioned earlier in this thread.</p>",
        "id": 210958862,
        "sender_full_name": "Lokathor",
        "timestamp": 1600836020
    },
    {
        "content": "<p>and a lot of the details of that seems to be in board-configurable firmware so there's basically absolutely nothing that can be done there to detect the specifics going into it, so even runtime detection of whether or not you \"should\" use them Seems Hard. \"use AVX512 if you have a frequent, and we mean _frequent_ path and you're on Ice Lake\", otherwise...</p>",
        "id": 210989035,
        "sender_full_name": "Jubilee",
        "timestamp": 1600860789
    },
    {
        "content": "<p><a href=\"https://gist.github.com/rygorous/32bc3ea8301dba09358fd2c64e02d774\">https://gist.github.com/rygorous/32bc3ea8301dba09358fd2c64e02d774</a> oh wow.</p>",
        "id": 211031880,
        "sender_full_name": "Jubilee",
        "timestamp": 1600880413
    },
    {
        "content": "<p>\"yay\"</p>",
        "id": 211032521,
        "sender_full_name": "Lokathor",
        "timestamp": 1600880689
    },
    {
        "content": "<p>But that also matches up with everything I've ever heard previously</p>",
        "id": 211032570,
        "sender_full_name": "Lokathor",
        "timestamp": 1600880712
    },
    {
        "content": "<blockquote>\n<p>[In case you're wondering why: they literally need to give the voltage regulators time to adjust because if they start powering up the wide datapaths directly, the chip browns out. This is not theoretical, we had crashes from this when we got the new machines, because the Fucking Gamer BIOS of course defaults to turning this off, \"FULL TURBO FOR EVERYTHING ALL THE TIME!!!!\".]</p>\n</blockquote>\n<p>awesome.</p>",
        "id": 211033662,
        "sender_full_name": "Jubilee",
        "timestamp": 1600881190
    },
    {
        "content": "<p>reading more closely on the power licensing mechanics and wow, that's a long delay before it grants or releases.</p>",
        "id": 211435089,
        "sender_full_name": "Jubilee",
        "timestamp": 1601241682
    },
    {
        "content": "<p>As far as I understand though, the extra abilities introduced via <code>avx</code> and higher don't need extra power licensing as long as you use the 128-bit versions of said abilities.</p>",
        "id": 211442420,
        "sender_full_name": "Lokathor",
        "timestamp": 1601253399
    }
]