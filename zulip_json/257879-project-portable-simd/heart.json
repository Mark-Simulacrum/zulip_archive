[
    {
        "content": "<p>Just wanted to say.</p>\n<ol>\n<li>This work is consistently impressive to me.</li>\n<li>Congrats for making it into std on nightly.</li>\n</ol>\n<p>I've been implementing sorted array set operations (intersection, union, etc)<br>\nThe paper I referenced for intersection uses x86 PCMPISTRM instruction to do an all-against-all comparison of lanes in one instr</p>\n<p>Decided to try and write it with std::simd and writing the all-against-all cmp using equality, rotate by 1, or the mask, repeat<br>\nThe runtime is the same, and it's portable.</p>\n<p><span aria-label=\"heart\" class=\"emoji emoji-2764\" role=\"img\" title=\"heart\">:heart:</span> for you all.</p>",
        "id": 268941666,
        "sender_full_name": "Joel Pedraza",
        "timestamp": 1642834120
    },
    {
        "content": "<p>Given that PCMPISTRM was intended for string cmp, it only works for lane widths of 8 and 16. The authors of the the paper go out of their way to construct a hierarchical intersection mechanism for 32 bit ints.  Masking the high and lo 16 bits and using PCMPISTRM for cmp.  I wonder if they fell for the same trap that I did: assuming 1 inst will _obviously_  be faster than the 30 or so required to do the equivalent using more primitive instructions.</p>",
        "id": 268941887,
        "sender_full_name": "Joel Pedraza",
        "timestamp": 1642834449
    },
    {
        "content": "<p>A 1 to 30 ratio is a bit high, but it's true the latency for that instruction is (while not disastrous) a decent number of cycles.</p>",
        "id": 268942886,
        "sender_full_name": "Jubilee",
        "timestamp": 1642835669
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"281757\">Jubilee</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/heart/near/268942886\">said</a>:</p>\n<blockquote>\n<p>A 1 to 30 ratio is a bit high, but it's true the latency for that instruction is (while not disastrous) a decent number of cycles.</p>\n</blockquote>\n<p>Thats fair, I've only benchmarked on my local machine. It could be that it's more or less stubbed out and is much faster on better hardware.</p>",
        "id": 268944118,
        "sender_full_name": "Joel Pedraza",
        "timestamp": 1642837788
    },
    {
        "content": "<p>The authors also had to special case 0, in order for the instruction to not treat it like a NUL terminator. <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 268944335,
        "sender_full_name": "Joel Pedraza",
        "timestamp": 1642838098
    },
    {
        "content": "<p>If your local machine has AVX2 then that's probably about as good as it's gonna get.</p>",
        "id": 268945515,
        "sender_full_name": "Jubilee",
        "timestamp": 1642839815
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"469380\">Joel Pedraza</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/heart/near/268941887\">said</a>:</p>\n<blockquote>\n<p>I wonder if they fell for the same trap that I did: assuming 1 inst will _obviously_  be faster than the 30 or so required to do the equivalent using more primitive instructions.</p>\n</blockquote>\n<p>I made the same mistake.  &lt;<a href=\"https://users.rust-lang.org/t/converting-a-bgra-u8-to-rgb-u8-n-for-images/67938/14?u=scottmcm\">https://users.rust-lang.org/t/converting-a-bgra-u8-to-rgb-u8-n-for-images/67938/14?u=scottmcm</a>&gt; has a nice demo that the like 15 instructions it came up with to work around the lack of <code>vpshufb</code> turned out to still be super-fast.</p>\n<p>So kudos to LLVM's cost models!</p>",
        "id": 268948769,
        "sender_full_name": "scottmcm",
        "timestamp": 1642844617
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125270\">scottmcm</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/heart/near/268948769\">said</a>:</p>\n<blockquote>\n<p>(Edit: oh, PCMPISTRM is latency 10 on skylake!)</p>\n</blockquote>\n<p>Yeah I guess if you want to compare every lane in A to every lane in B you still need to obey physics. Bummer.</p>",
        "id": 268952431,
        "sender_full_name": "Joel Pedraza",
        "timestamp": 1642850139
    },
    {
        "content": "<p>lmao</p>",
        "id": 268967782,
        "sender_full_name": "Jubilee",
        "timestamp": 1642872024
    },
    {
        "content": "<p>Zen has lower latency I think but it's still like ~7 when I checked.</p>",
        "id": 268967816,
        "sender_full_name": "Jubilee",
        "timestamp": 1642872085
    },
    {
        "content": "<p>It's a similar story for the dot product instructions: it sounds nice to have \"one instruction\" that covers something that is commonly done, but then you find out it really was only a performance gain some time ago, and nowadays everyone just spams FMAs.</p>",
        "id": 268968010,
        "sender_full_name": "Jubilee",
        "timestamp": 1642872333
    },
    {
        "content": "<p>dot product instructions were pretty much never a perf gain, aside from a small amount of icache savings (due to the shorter instruction encoding compared to doing the dot product explicitly)</p>",
        "id": 268973291,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1642879452
    },
    {
        "content": "<p><code>pcmp*str*</code> can be a perf savings depending on the complexity of what you've programmed them to do. also, thye have pretty good throughput (but yeah, fairly shit latency on a lot of machines)</p>",
        "id": 268973304,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1642879494
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/heart/near/268973291\">said</a>:</p>\n<blockquote>\n<p>dot product instructions were pretty much never a perf gain, aside from a small amount of icache savings (due to the shorter instruction encoding compared to doing the dot product explicitly)</p>\n</blockquote>\n<p>I went through the instruction tables when I sized up that issue and IIRC they were a slight gain basically within 1 generation of their introduction and then it all went flat.</p>",
        "id": 268978009,
        "sender_full_name": "Jubilee",
        "timestamp": 1642884661
    },
    {
        "content": "<p>Basically \"since Haswell, nada.\"</p>",
        "id": 268978536,
        "sender_full_name": "Jubilee",
        "timestamp": 1642885381
    }
]