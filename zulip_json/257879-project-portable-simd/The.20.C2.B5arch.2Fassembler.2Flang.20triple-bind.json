[
    {
        "content": "<p>So, one of the thing that has become apparent is that we are in a triple bind between three \"opponents\":</p>\n<ol start=\"0\">\n<li>The Rust language itself, of course</li>\n<li>The assembler backend</li>\n<li>The instruction set architectures, including even</li>\n<li>(but it's 2 again) each µarch of an ISA, which may have different execution characteristics, which <strong>matter</strong> since we're trying to provide <strong>execution power</strong></li>\n</ol>",
        "id": 225065421,
        "sender_full_name": "Jubilee",
        "timestamp": 1612379412
    },
    {
        "content": "<p>We can't stress over every single piece of silicon in existence, but e.g. the divide between Intel and AMD implementations of the same x64 SIMD instructions really do matter a lot since those are quite different in execution characteristics, even to the point of supporting different sets of SIMD ISAs!</p>",
        "id": 225065673,
        "sender_full_name": "Jubilee",
        "timestamp": 1612379530
    },
    {
        "content": "<p>I mention this because we kind of vomited out listings of our various obstacles and ideas for dealing with them over the past few months, and I think it is valuable if we begin carefully enumerating not just what constraints we are under but also <strong>where those constraints come from</strong> and keeping in mind what currently can satisfy at least <strong>some</strong> of the constraints, in order to keep making headway.</p>",
        "id": 225066407,
        "sender_full_name": "Jubilee",
        "timestamp": 1612379846
    },
    {
        "content": "<p>This is sort of the obverse of the <a href=\"#narrow/stream/257879-project-portable-simd/topic/Using.20multiple.20feature.20gates/near/225063804\">using multiple feature gates thread</a>, which is about how to divide and conquer sets of obstacles: our sets of obstacles and the way we solve them are unlikely to be \"solve all of the µarch problems at once\" or even \"solve a subset of the µarch problems specifically\" but rather \"identify a problem from each obstacle and devise a solution that allows us to carve out those problems and address them separately\". But that means maintaining a relatively clear-eyed view of the sources of our obstacles per se, in and of themselves, or we'll confuse climbing one peak with the entire mountain range.</p>",
        "id": 225067320,
        "sender_full_name": "Jubilee",
        "timestamp": 1612380113
    },
    {
        "content": "<p>\"this should be a blogpost\" MAYBE</p>",
        "id": 225068866,
        "sender_full_name": "Jubilee",
        "timestamp": 1612380766
    },
    {
        "content": "<p>For instance, based on my understanding:<br>\nSupporting \"only\" SSE means we \"only\" have to support 128-bit vectors.<br>\nNEON introduces 64-bit vectors on the lower end.  AVX extends that to 256. AVX512 extends that to 512.<br>\nSVE extends that to potentially 2048(!)... in 128-bit increments.<br>\nAll of these are architecture-driven concerns.<br>\nConst generic types, arrays vs. tuples in repr(simd), etc. are language-driven.</p>\n<p>That SVE and AVX512 use bitmask predicates while NEON (and AVX?) use fullmasks is an architecture-driven concern.<br>\nHandling that w/ different mask types, opaqueness, traits, layouts, const generics or not, is language-driven.<br>\nA lot of the optimization concerns around them are between the assembler and the architecture.</p>",
        "id": 225077212,
        "sender_full_name": "Jubilee",
        "timestamp": 1612384468
    },
    {
        "content": "<p>I'm assuming that we're conveniently assuming x86 MMX doesn't exist...</p>",
        "id": 225078615,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1612385097
    },
    {
        "content": "<p>LA LA LA I CAN'T HEAR YOU</p>",
        "id": 225079089,
        "sender_full_name": "Jubilee",
        "timestamp": 1612385298
    },
    {
        "content": "<p>OK but seriously the architecture supporting insane instructions which just utterly explode even when you compile to them because they're really hard to use properly even if you're a compiler who can control the entire program is part of the problem, yes.</p>\n<p>Especially given that later revisions of that architecture... decoded those instructions slightly differently.</p>",
        "id": 225082271,
        "sender_full_name": "Jubilee",
        "timestamp": 1612386549
    },
    {
        "content": "<p>This thread is equal parts enticing and terrifying.</p>",
        "id": 225103550,
        "sender_full_name": "Miguel Raz Guzmán Macedo",
        "timestamp": 1612398238
    },
    {
        "content": "<p>I have not much to add except probably trying to talk to Sylvain Corlay who built the xsimd library for many of these shenanigans for C++, see here <a href=\"https://xsimd.readthedocs.io/en/latest/api/instr_macros.html\">https://xsimd.readthedocs.io/en/latest/api/instr_macros.html</a></p>",
        "id": 225103772,
        "sender_full_name": "Miguel Raz Guzmán Macedo",
        "timestamp": 1612398366
    },
    {
        "content": "<p>We're admittedly being <em>slightly</em> insane here and trying to get ahead of the game re: SVE, the likely-inevitable Intel AVX1024, etc.</p>",
        "id": 225104026,
        "sender_full_name": "Jubilee",
        "timestamp": 1612398595
    },
    {
        "content": "<p>Gotcha. I take it that besides some logical, shuffling, loading and masking ops, we only have basic arithmetic operations in <code>stdsimd</code> so far right?<br>\nIt's... a bit much to even keep track of how many different SIMD instructions there are.<br>\n(Lists appreciated.)</p>",
        "id": 225121127,
        "sender_full_name": "Miguel Raz Guzmán Macedo",
        "timestamp": 1612416852
    },
    {
        "content": "<p>At the moment we basically have arithmetic functions and some version of masking, and we need to implement other things. A lot of holdup has been \"wait how do we want to do masking exactly?\" since that has been sort of a thing on which a lot of API will depend. <br>\nAPI docs are available here <a href=\"https://rust-lang.github.io/stdsimd/core_simd/\">https://rust-lang.github.io/stdsimd/core_simd/</a><br>\nEvery vendor has their own list of SIMD intrinsic functions, which are specialized functions that compile to reasonably specific assembly instructions.<br>\nMost of Intel's Intrinsics: <a href=\"https://software.intel.com/sites/landingpage/IntrinsicsGuide/\">https://software.intel.com/sites/landingpage/IntrinsicsGuide/#</a><br>\nArm's Neon Intrinsics: <a href=\"https://developer.arm.com/architectures/instruction-sets/simd-isas/neon/intrinsics\">https://developer.arm.com/architectures/instruction-sets/simd-isas/neon/intrinsics</a></p>",
        "id": 225121399,
        "sender_full_name": "Jubilee",
        "timestamp": 1612417232
    },
    {
        "content": "<p>avx4096 or bust</p>",
        "id": 225126411,
        "sender_full_name": "Lokathor",
        "timestamp": 1612423300
    },
    {
        "content": "<p>see, the funny thing is that AVX1024 was actually threatened by Intel! ...9 years ago.</p>",
        "id": 225126478,
        "sender_full_name": "Jubilee",
        "timestamp": 1612423338
    },
    {
        "content": "<p>perhaps they will implement it right after they move on from the 14nm process.</p>",
        "id": 225126611,
        "sender_full_name": "Jubilee",
        "timestamp": 1612423496
    },
    {
        "content": "<p>Ah this is the kind of thing I am thinking of also, <a href=\"http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0349r0.pdf\">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0349r0.pdf</a></p>",
        "id": 225212666,
        "sender_full_name": "Jubilee",
        "timestamp": 1612468194
    }
]