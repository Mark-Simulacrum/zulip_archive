[
    {
        "content": "<p>Hi all, has there been any thought put into whether it'd be appropriate to provide out-of-the box algorithms on top of SIMD vector registers within <code>std::simd</code>?  Many of the algorithms in <code>Iterator</code> have equivalents on SIMD registers, and a native SIMD implementation can be more efficient than e.g. converting to an array and using the scalar equivalent.  To make this a bit more concrete, a specific algorithm that'd be generally useful is a vector <code>scan</code> or <code>prefix_sum</code> function, for example:</p>\n<div class=\"codehilite\"><pre><span></span><code>\n</code></pre></div>",
        "id": 272906448,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645594066
    },
    {
        "content": "<p>In particular I'm wondering about such algorithms that aren't expected to map directly to a single or a well known set of instructions.</p>",
        "id": 272906526,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645594146
    },
    {
        "content": "<p>(credit for the above algorithm goes to <a href=\"https://en.algorithmica.org/hpc/algorithms/prefix/\">https://en.algorithmica.org/hpc/algorithms/prefix/</a> , I just translated it to std::simd)</p>",
        "id": 272906565,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645594203
    },
    {
        "content": "<p>Another example is a sort function, perhaps bitonic</p>",
        "id": 272906978,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645594675
    },
    {
        "content": "<p>well...SimpleV has instructions for prefix sum (where the op can be fadd, fmul, add, mul, and, or, xor...really any 3-argument scalar openpower instruction).</p>",
        "id": 272907302,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645595020
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"229517\">@Jacob Lifshay</span> interesting, I'm not familiar with that, do you have a link?  Does it work similar to above?  I assume if the set of ops is closed they probably don't require the identity value to be specified</p>",
        "id": 272907517,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645595255
    },
    {
        "content": "<p>nah, the set of ops is every 3-argument scalar instruction in the OpenPower ISA -- not a closed set due to extensions.</p>",
        "id": 272908007,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645595840
    },
    {
        "content": "<p><a href=\"https://libre-soc.org/openpower/sv/\">https://libre-soc.org/openpower/sv/</a></p>",
        "id": 272908014,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645595845
    },
    {
        "content": "<p>another great algorithm could be some kind of sliding window - something that would make things like convolutions easier to write</p>",
        "id": 272908087,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645595922
    },
    {
        "content": "<p>it doesn't mention prefix-sum specifically, but it can be constructed by <code>sv.add r4.v, r3.v, r4.v</code>, which essentially translates to the loop:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"n\">VL</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">regs</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">regs</span><span class=\"p\">[</span><span class=\"mi\">3</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">regs</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"p\">];</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 272908212,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645596009
    },
    {
        "content": "<p>serious APL vibes</p>",
        "id": 272908420,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645596206
    },
    {
        "content": "<p>(In the best possible way, in case that wasn't clear :) )</p>",
        "id": 272908502,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645596312
    },
    {
        "content": "<p>:)</p>",
        "id": 272908509,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645596326
    },
    {
        "content": "<p>Yeah so I guess the identity value is implicit there, it's just whatevers in <code>regs[3]</code>.  I was trying to think of a way to not have to provide it for the example I gave above, but I think it's necessary.  It appears to totally optimize away in the cases I tested for e.g. a prefix_sum wrapper</p>",
        "id": 272908688,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645596504
    },
    {
        "content": "<p>err... how the heck do they make that fast?  That definition of the algorithm is entirely sequential, the reason the identity is necessary in my case is it's doing things non sequentially</p>",
        "id": 272908740,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645596563
    },
    {
        "content": "<p>hmm, i'd define prefix sum such that the first vector element is <code>regs[3]</code> and it just sums 0 times for the first element.</p>",
        "id": 272908828,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645596645
    },
    {
        "content": "<p>we can make prefix sum fast by recognizing the pattern and (when it doesn't change the result -- mostly only non-fp) converting to a tree-pattern</p>",
        "id": 272908874,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645596713
    },
    {
        "content": "<p>iirc we were thinking about adding a way to do the tree pattern for fp ops too but didn't get around to it yet.</p>",
        "id": 272908950,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645596762
    },
    {
        "content": "<p>(i'm one of the designers of SimpleV btw)</p>",
        "id": 272908965,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645596785
    },
    {
        "content": "<p>Yes I just noticed your name looking through the pages you linked :) .  This is a bit outside my domain so apologies for the probably basic questions.  I'm familiar with tree reductions and some of the fancier things from the parallel literature that comes out of the GPU camp, but that's a pretty different processing model than the CPU SIMD models I'm familiar with.  Is SimpleV more similar to GPUs with the ability to do many more memory accesses in parallel?</p>",
        "id": 272909085,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645596952
    },
    {
        "content": "<p>or it may be more accurate to think of it as the vector processor having threads or some kind of parallelism within it?  That's much more powerful than x86 simd</p>",
        "id": 272909182,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645597041
    },
    {
        "content": "<p>Ah, SIMD processors are more capable of tree reductions than they look.</p>",
        "id": 272909187,
        "sender_full_name": "Jubilee",
        "timestamp": 1645597050
    },
    {
        "content": "<p>are you referring to gather instructions, or something else?</p>",
        "id": 272909291,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645597153
    },
    {
        "content": "<p>Libre-SOC's cpu is designed to be a hybrid CPU/GPU, so it will be able to do many memory ops in parallel...that said, for the prefix sum op I mentioned, that happens entirely in cpu registers (of which it has 128 64-bit int and 128 64-bit fp registers)</p>",
        "id": 272909309,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645597183
    },
    {
        "content": "<p>In-register.<br>\nMore generally,<br>\nArm SVE and RISCV-V use the model of predicated vectors that AVX512 hints at,<br>\nand thus have a very different model than x86.</p>",
        "id": 272909372,
        "sender_full_name": "Jubilee",
        "timestamp": 1645597217
    },
    {
        "content": "<p>SimpleV (and Arm SVE and RISC-V V) are all vector processor instruction sets</p>",
        "id": 272909418,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645597276
    },
    {
        "content": "<p>SimpleV is more of the approach of \"just take everything, but vectorize it\", whereas most other ISAs have separately defined vector/simd instructions that are missing many ops</p>",
        "id": 272909506,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645597390
    },
    {
        "content": "<p>tbh,<br>\neverything since the Cray is still using packed registers in fact, afaict,<br>\nand that becomes more or less obvious between each.<br>\nThey just expose a different AL abstraction.</p>",
        "id": 272909584,
        "sender_full_name": "Jubilee",
        "timestamp": 1645597456
    },
    {
        "content": "<p>Is it fair to say that std::simd is an abstraction over packed registers?  I imagine packed registers are very much the lowest common denominator, since vector ISAs are a generalization?</p>",
        "id": 272909707,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645597595
    },
    {
        "content": "<p><em>handwobbles</em></p>",
        "id": 272909729,
        "sender_full_name": "Jubilee",
        "timestamp": 1645597633
    },
    {
        "content": "<p>hmm...i'm expecting std::simd to eventually provide a dynamically variable-length vector API, like what Arm SVE, RISC-V V, and SimpleV do...</p>",
        "id": 272909824,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645597726
    },
    {
        "content": "<p>If you have user-visible, fixed-length limits on the vector length (dynamically settable within that range or not), then the differences get to be pretty ambiguous.</p>",
        "id": 272909928,
        "sender_full_name": "Jubilee",
        "timestamp": 1645597814
    },
    {
        "content": "<p>i guess in summary we don't have an exact definition of what constitutes simd...I know it when i see it</p>",
        "id": 272909942,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645597837
    },
    {
        "content": "<p>well, Arm SVE has user visible non-settable length that varies between cpu designs...</p>",
        "id": 272909988,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645597899
    },
    {
        "content": "<p>Right.</p>",
        "id": 272910033,
        "sender_full_name": "Jubilee",
        "timestamp": 1645597929
    },
    {
        "content": "<p>One of the major differences touted between packed SWAR and vector processors is \"within-register\" reductions (because that actually <strong>isn't</strong> a straightforward \"SIMD\" instruction per se), but x86 has had that since ever.</p>",
        "id": 272910047,
        "sender_full_name": "Jubilee",
        "timestamp": 1645597961
    },
    {
        "content": "<p>RISC-V V and SimpleV have user-settable lengths</p>",
        "id": 272910050,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645597966
    },
    {
        "content": "<p>everything else can emulate length changes using predication</p>",
        "id": 272910066,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645598010
    },
    {
        "content": "<p>And there's nothing stopping Intel from publishing an SVE-like SIMD extension set tomorrow that does nothing to their actual hardware architecture but simply offers a different interface. :^)</p>",
        "id": 272910123,
        "sender_full_name": "Jubilee",
        "timestamp": 1645598049
    },
    {
        "content": "<p>length changes: (or be like early x86 SSE/MMX and just <del>cry</del> use scalar instructions)</p>",
        "id": 272910154,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645598112
    },
    {
        "content": "<p>This is very interesting ^.  One thing I just realized is that the original snippet I pasted is actually doing a tree reduction, but near the root of the tree it's shifting in the identity value in order to make the wide operation a no-op.  It could probably be re-implemented with masks or blending to not require an identity value.</p>",
        "id": 272910174,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645598139
    },
    {
        "content": "<p>simd tree reductions: <a href=\"https://github.com/rust-lang/portable-simd/issues/235\">https://github.com/rust-lang/portable-simd/issues/235</a></p>",
        "id": 272910272,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645598240
    },
    {
        "content": "<p>for SimpleV, I specifically wanted it to convert parts of a reduction tree to moves to handle elements that are predicated off</p>",
        "id": 272910351,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645598313
    },
    {
        "content": "<p>Yes perhaps the snippet isn't a reduction, but it is using a tree to implement the prefix scan in logn steps instead of n</p>",
        "id": 272910453,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645598411
    },
    {
        "content": "<p>n is the vector length here so it's not large, but it is still a net win</p>",
        "id": 272910466,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645598450
    },
    {
        "content": "<p>tree prefix sum: <a href=\"https://en.wikipedia.org/wiki/Prefix_sum#Parallel_algorithms\">https://en.wikipedia.org/wiki/Prefix_sum#Parallel_algorithms</a></p>",
        "id": 272910670,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645598762
    },
    {
        "content": "<p>yes, I believe the snippet is equivalent to Algorithm 1 in that link</p>",
        "id": 272910819,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645598914
    },
    {
        "content": "<p>So Simple-V is going to translate a vector add instruction into that kind of tree prefix sum?  That seems magical</p>",
        "id": 272910851,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645598972
    },
    {
        "content": "<p>:)</p>",
        "id": 272910914,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645599013
    },
    {
        "content": "<p>Here's a better version of the snippet that uses masking instead of requiring an identity:</p>\n<div class=\"codehilite\"><pre><span></span><code>fn scan&lt;T, const LANES: usize, Op&gt;(mut values: Simd&lt;T, LANES&gt;, mut op: Op) -&gt; Simd&lt;T, LANES&gt;\nwhere\n    T: SimdElement + Default + std::fmt::Debug,\n    LaneCount&lt;LANES&gt;: SupportedLaneCount,\n    Op: FnMut(Simd&lt;T, LANES&gt;, Simd&lt;T, LANES&gt;) -&gt; Simd&lt;T, LANES&gt;,\n{\n    let mut mask = [true; LANES];\n    unroll! {\n        for IDX in [1, 2, 4, 8, 16, 32] {\n            if IDX &lt; LANES {\n                mask[..IDX].fill(false);\n                values = Mask::from(mask).select(\n                    op(\n                        values,\n                        values.rotate_lanes_right::&lt;IDX&gt;(),\n                    ),\n                    values,\n                )\n            }\n        }\n    }\n\n    values\n}\n</code></pre></div>",
        "id": 272911024,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645599149
    },
    {
        "content": "<p>currently, SimpleV guarantees results equivalent to the serial prefix sum. we may add a prefix-sum guaranteed to match a specific tree's results. for both of those, a cpu can implement it however it sees fit, as long as the answer matches exactly.</p>",
        "id": 272911028,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645599151
    },
    {
        "content": "<p>according to MCA that snippet is actually more efficient on icelake when LANES=32 compared to the native vector size of 16. Perhaps a good example of what y'all were talking about above</p>",
        "id": 272911475,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645599656
    },
    {
        "content": "<p>or perhaps just a good example of the power of logarithms</p>",
        "id": 272911495,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645599686
    },
    {
        "content": "<p>probably because of pipelining in the fadd units</p>",
        "id": 272911510,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645599715
    },
    {
        "content": "<p>err well it's not really logarithmic above 16 lines</p>",
        "id": 272911511,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645599719
    },
    {
        "content": "<p>yeah</p>",
        "id": 272911513,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645599721
    },
    {
        "content": "<p>Toward the original question - are algorithms like this in scope of std::simd?  Would such a patch be accepted?</p>",
        "id": 272911976,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645600204
    },
    {
        "content": "<p>imho prefix sum should be in std::simd because some cpus provide instructions for it. as for generic scan, i'm a little more iffy on that because, in my mind, std::simd is supposed to be a thin abstraction over a generic vector/simd instruction set</p>",
        "id": 272912137,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645600425
    },
    {
        "content": "<p>i'll probably leave generic scan up to everyone else to decide</p>",
        "id": 272912234,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1645600520
    },
    {
        "content": "<p>Makes sense.  FWIW I'd probably reject such a patch at this point if I were in the maintainers shoes, but thought I'd offer it up in case there is appetite for this sort of thing.  There can always be an itertools-alike to house such things</p>",
        "id": 272912472,
        "sender_full_name": "Dan Burkert",
        "timestamp": 1645600769
    }
]