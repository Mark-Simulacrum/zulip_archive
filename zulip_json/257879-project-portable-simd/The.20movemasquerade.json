[
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/What.20core.3A.3Aarch.20users.20need.20from.20std.3A.3Asimd/near/212501034\">said</a>:</p>\n<blockquote>\n<p>My point was more: a lot of code will end up using one or two weirder instructions that LLVM doesnt offer a portable equivalent. Say: <code>_mm_movemask_ps</code>¹ (this is not weird as in rarely used at all, it's just semantically a bit odd).</p>\n<p>It's often pretty easy (trivial for movemask) to implement a portable equivalent to this, so we should support it even though it's not like LLVM will automatically implement the portable versions for us.</p>\n</blockquote>\n<p>not to detract from your point, but LLVM has portable intrinsics for masked load/store (IIRC same thing as <code>movemask</code>):<br>\n<a href=\"https://llvm.org/docs/LangRef.html#masked-vector-load-and-store-intrinsics\">https://llvm.org/docs/LangRef.html#masked-vector-load-and-store-intrinsics</a></p>",
        "id": 212502576,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602030244
    },
    {
        "content": "<p>movemask isn't masked load/store (as i mentioned, intel is bad at names), it's \"get me a integer where bit N is set if lane N of the mask is on\" (well, it only actually looks at the LSB of the mask lane , but yah)</p>",
        "id": 212502664,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602030357
    },
    {
        "content": "<p>(I think it's sign bit, not LSB)</p>",
        "id": 212503992,
        "sender_full_name": "Lokathor",
        "timestamp": 1602031860
    },
    {
        "content": "<p>oh, possibly, it only looks at one of the bits either way.</p>",
        "id": 212504007,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602031890
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/What.20core.3A.3Aarch.20users.20need.20from.20std.3A.3Asimd/near/212502664\">said</a>:</p>\n<blockquote>\n<p>movemask isn't masked load/store (as i mentioned, intel is bad at names), it's \"get me a integer where bit N is set if lane N of the mask is on\" (well, it only actually looks at the LSB of the mask lane , but yah)</p>\n</blockquote>\n<p>Oh, you mean (with MSB instead of LSB as <span class=\"user-mention\" data-user-id=\"224471\">@Lokathor</span> mentioned):</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">x</span>: <span class=\"nc\">i8x16</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"o\">..</span><span class=\"p\">.;</span><span class=\"w\"></span>\n<span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">bits</span>: <span class=\"nc\">m1x16</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">x</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">splat</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">);</span><span class=\"w\"></span>\n<span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">result</span>: <span class=\"kt\">u16</span> <span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">bits</span><span class=\"p\">.</span><span class=\"n\">to_int</span><span class=\"p\">();</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 212510099,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602039028
    },
    {
        "content": "<p>i think avx512 actually has masks that aren't 512 bits, so... dunno how we wanna handle that whole thing</p>",
        "id": 212510177,
        "sender_full_name": "Lokathor",
        "timestamp": 1602039140
    },
    {
        "content": "<p>I vote for <code>m1x64</code> for a 64-lane 1-bit-per-lane mask.</p>",
        "id": 212511036,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602040349
    },
    {
        "content": "<p>avx512 is not the only one that uses 1-bit per lane masks: RISC-V V, Libre-SOC's SimpleV, and probably more do as well.</p>",
        "id": 212511100,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602040459
    },
    {
        "content": "<p>AMDGPU too.</p>",
        "id": 212511105,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602040477
    },
    {
        "content": "<p>i guess things like <code>impl From&lt;m8x16&gt; for m1x16</code> would be a sane place to use movemask intrinsics. anyway, that wasn't <em>really</em> my point.</p>\n<p>not really sure if you'd ever use a m1xN mask is besides just to turn it into an integer tho</p>",
        "id": 212511122,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602040512
    },
    {
        "content": "<p>Single bit masks would also be useful for detecting overflow, as that's what the llvm function uses</p>",
        "id": 212511204,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602040620
    },
    {
        "content": "<p>I should also note that \"AVX512\" is not \"AVX512\"... there is AVX512F and then all the additional extension featuresets on top of it.</p>",
        "id": 212511952,
        "sender_full_name": "Jubilee",
        "timestamp": 1602041762
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/What.20core.3A.3Aarch.20users.20need.20from.20std.3A.3Asimd/near/212511122\">said</a>:</p>\n<blockquote>\n<p>not really sure if you'd ever use a m1xN mask is besides just to turn it into an integer tho</p>\n</blockquote>\n<p>maybe not on code designed for x86 without avx512, but other architectures use m1xL masks instead of mNxL masks since it's more power-efficient. At least RISC-V V and SimpleV do that.</p>",
        "id": 212511991,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602041774
    },
    {
        "content": "<p>Hm, this is a different topic.</p>",
        "id": 212512004,
        "sender_full_name": "Jubilee",
        "timestamp": 1602041813
    },
    {
        "content": "<p>AVX512 is a nice shorthand for AVX512F and all the other instructions that use <code>zmm</code> registers</p>",
        "id": 212512011,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602041848
    },
    {
        "content": "<p>Here we go.</p>",
        "id": 212512057,
        "sender_full_name": "Jubilee",
        "timestamp": 1602041892
    },
    {
        "content": "<p>This is what I was referring to with 1-bit masks being used for overflow: <a href=\"https://llvm.org/docs/LangRef.html#llvm-sadd-with-overflow-intrinsics\">https://llvm.org/docs/LangRef.html#llvm-sadd-with-overflow-intrinsics</a></p>\n<p>I think I'd be ok with adding them if it's not only used for a single thing</p>",
        "id": 212512069,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602041935
    },
    {
        "content": "<p>Yeah, it is.</p>",
        "id": 212512071,
        "sender_full_name": "Jubilee",
        "timestamp": 1602041939
    },
    {
        "content": "<p>It may make sense to provide ops that work with both lane-width-masks and m1xN masks with the understanding that one will be faster than the other depending on the architecture, and the other will likely do a narrowing or widening op</p>",
        "id": 212512148,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602042050
    },
    {
        "content": "<p>It may also not make sense to do this, I haven't actually looked at RISC-V's SIMD or any other arch that actually uses them</p>",
        "id": 212512160,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602042090
    },
    {
        "content": "<p>the common cases for movemask is basically e.g. <code>_mm_movemask_ps(_mm_cmpeq_ps(a, b))</code>. this gives you a 4-bit value that tells you which lanes were equal. often you just do something like test the result for <code>0b1111</code> or <code>0</code>, but you can get <a href=\"https://github.com/thomcc/bad3d/blob/master/t3m/src/simd.rs#L359-L366\">more clever</a>.</p>\n<p>i guess for avx512foo the return value would be potentially a 64 bit integer? i'm a little confused and suspect i may have explained something poorly at some point</p>",
        "id": 212512233,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602042215
    },
    {
        "content": "<p>I just felt like I should note that complication re: AVX512 just in case anyone got too comfortable with treating them all as a single set, since it matters for discussing intrinsics and such that aren't literally in AVX512F.</p>",
        "id": 212512284,
        "sender_full_name": "Jubilee",
        "timestamp": 1602042275
    },
    {
        "content": "<p>note that the _mm_cmpeq operation returns a e.g. m32x4 there</p>",
        "id": 212512287,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602042280
    },
    {
        "content": "<blockquote>\n<p>It may make sense to provide ops that work with both lane-width-masks and m1xN masks with the understanding that one will be faster than the other depending on the architecture</p>\n</blockquote>\n<p>the 1bit mask is strictly an output for the x86 stuff i'm aware of. i mean, you could reverse the operation, but it would have to be done manually.</p>\n<p>so that makes sense iff another target uses 1bit masks for input (is this true?)</p>",
        "id": 212512444,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602042513
    },
    {
        "content": "<p>The plan for SimpleV is that comparing <code>Tx64</code> values would return a 64-bit value in an integer register -- similar to AVX512F's compares, except that they store the result in the <code>kN</code> mask registers.</p>",
        "id": 212512449,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602042521
    },
    {
        "content": "<p>SimpleV and AVX512 do use 1-bit masks for predicated execution.</p>",
        "id": 212512462,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602042588
    },
    {
        "content": "<p>and before AVX512 it seems to map to movemask.  I wonder if NEON has any comparable instruction(s)</p>",
        "id": 212512518,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602042630
    },
    {
        "content": "<blockquote>\n<p>I wonder if NEON has any comparable instruction(s)</p>\n</blockquote>\n<p><a href=\"https://github.com/DLTcollab/sse2neon\">https://github.com/DLTcollab/sse2neon</a> is usually how i answer this question</p>",
        "id": 212512529,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602042657
    },
    {
        "content": "<p><a href=\"https://github.com/DLTcollab/sse2neon/blob/master/sse2neon.h#L2056\">https://github.com/DLTcollab/sse2neon/blob/master/sse2neon.h#L2056</a></p>\n<blockquote>\n<p>NEON does not provide this method</p>\n</blockquote>",
        "id": 212512557,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602042713
    },
    {
        "content": "<p>this is an extremely powerful repo thank you.</p>",
        "id": 212512632,
        "sender_full_name": "Jubilee",
        "timestamp": 1602042833
    },
    {
        "content": "<p>it's tricky to think what good more broad API for this is. most cases (aside from weirdos like me using it as an index) is to answer \"which lanes between these two vectors pass the given test\" efficiently</p>",
        "id": 212512633,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602042837
    },
    {
        "content": "<p>It's radiating some intensely (cursed | blessed) energy.</p>",
        "id": 212512684,
        "sender_full_name": "Jubilee",
        "timestamp": 1602042864
    },
    {
        "content": "<p>I'm curious what llvm produces for <code>fcmp</code> etc on NEON</p>",
        "id": 212512685,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602042866
    },
    {
        "content": "<p>(the LLVM instruction <code>fcmp</code>, I mean)</p>",
        "id": 212512689,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602042878
    },
    {
        "content": "<p>I would _hope_ that movemask is a specific case of <code>icmp</code></p>",
        "id": 212512706,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602042948
    },
    {
        "content": "<blockquote>\n<p>I would _hope_ that movemask is a specific case of icmp</p>\n</blockquote>\n<p>yeah, i still think i haven't explained what movemask does well enough. it's not the actual comparison, it's the <code>mLxN</code> =&gt; <code>m1xN</code> function you use so that you can easily look at the result of the comparison</p>",
        "id": 212512812,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602043129
    },
    {
        "content": "<p>i'm pretty confident that you couldn't implement it as a icmp</p>",
        "id": 212512816,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602043142
    },
    {
        "content": "<p>e.g. <code>fn m32x4::all_zero(self) -&gt; bool</code> would be <code>_mm_movemask_ps(transmute(self)) == 0</code><br>\nand <code>fn m32x4::all_ones(self) -&gt; bool</code> would be <code>_mm_movemask_ps(transmute(self)) == 0b1111</code></p>",
        "id": 212512894,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602043231
    },
    {
        "content": "<p>outside of overly clever code, it's purely a thing you use for inspecting a <code>mKxN</code> that came from a comparison</p>",
        "id": 212512991,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602043335
    },
    {
        "content": "<p>(sorry if we <em>are</em> on the same page on this and i'm overexplaining, it just didn't feel that way)</p>",
        "id": 212513011,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602043381
    },
    {
        "content": "<p>maybe I'm just tired, but I think <code>icmp lt &lt;i32 x 4&gt; 0 x</code>should generate movemask if the compiler is smart?</p>",
        "id": 212513169,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602043515
    },
    {
        "content": "<p>oh, maybe. i guess that would return &lt;i1 x 4&gt; ? i'd expect llvm to possibly try to avoid the movemask since it is another instruction on top of the compare, and you don't always need it. my understanding of something like &lt;i1 x 4&gt; is that it's allowed to use more space than 1 bit per lane?</p>",
        "id": 212513372,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602043695
    },
    {
        "content": "<p>similar to how bool is i1 and is actually 8 bits. but perhaps it works differently for vectors</p>",
        "id": 212513394,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602043727
    },
    {
        "content": "<p>as part of legalization/instruction selection/something else for x86, <code>&lt;i1 x 4&gt;</code> would be expanded to <code>&lt;i32 x 4&gt;</code>.</p>",
        "id": 212513414,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602043760
    },
    {
        "content": "<p>Well here it's a constant 0,so I think it would produce it. On another arch it will probably just do a compare</p>",
        "id": 212513426,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602043786
    },
    {
        "content": "<p>or <code>&lt;i64 x 4&gt;</code> -- whatever matches the lane width of the thing it's used with.</p>",
        "id": 212513471,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602043807
    },
    {
        "content": "<p>Are you sure that llvm does that, and not just rustc?  I figured rustc is sign extending the mask (which the compiler optimizes out)</p>",
        "id": 212513483,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602043845
    },
    {
        "content": "<p>the important part is that LLVM's layout for <code>&lt;i1 x 8&gt;</code> is not the same as <code>i8</code>.</p>",
        "id": 212513506,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602043896
    },
    {
        "content": "<p>so it doesn't ever convert it to a single integer.</p>",
        "id": 212513510,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602043910
    },
    {
        "content": "<p>What is the layout?</p>",
        "id": 212513512,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602043922
    },
    {
        "content": "<p>yeah. if you actually do need to produce an i8 thats when llvm would have to emit a movemask. but that pretty much might be limited to \"when the user uses a movemask intrinsic\"</p>",
        "id": 212513554,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602043945
    },
    {
        "content": "<p>I guess the alignment of i1 is a byte?</p>",
        "id": 212513555,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602043950
    },
    {
        "content": "<p>i'd hope that if <code>fcmp</code> on a vector produces <code>&lt;i1 x N&gt;</code> then it would be valid to represent <code>&lt;i1 x N&gt;</code> as just the result of the comparison operation. but i guess i can see why that might not be possible.</p>",
        "id": 212513589,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602044026
    },
    {
        "content": "<p>I think it doesn't really have a defined layout, it just gets expanded to <code>&lt;i32 x 4&gt;</code> if used to mask another <code>&lt;i32 x 4&gt;</code></p>",
        "id": 212513594,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602044030
    },
    {
        "content": "<p>Right, but I'm guessing if we explicitly pack it into an m1xN it may optimize correctly</p>",
        "id": 212513651,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602044088
    },
    {
        "content": "<p>At least I'd like to see</p>",
        "id": 212513657,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602044096
    },
    {
        "content": "<p>what I expect if you tried to use a <code>m1xN</code> on x86 is LLVM would expand it to <code>m32xN</code> or whatever other lane size we use it with. The actual representation in memory is probably something like <code>m8xN</code></p>",
        "id": 212513772,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602044197
    },
    {
        "content": "<p>i doubt it would use a movemask since the actual semantics of that instruction are that it only operates on the MSB of each lane. so you'd have to be careful to ensure your explicit packing behaved that way. we can know all bits are the same in a land in a <code>mLxN</code> because of type-level guarantees but idk if llvm can know</p>",
        "id": 212513867,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602044304
    },
    {
        "content": "<p>I think what <code>packed_simd</code> did was just say \"there's a truthy value here\" and the rest is unspecified.</p>\n<p>We might have to have a bit of a concession against simplicity and either use two mask types or make mask value content way more vague.</p>",
        "id": 212513976,
        "sender_full_name": "Lokathor",
        "timestamp": 1602044492
    },
    {
        "content": "<p>i think the packed simd approach is fine, i also think there should be a way to get it as a 1-bit-per-lane mask (which would use movemask on x86 or a fallback elsewhere) but that's in the category of \"apis only worth exposing only because it's very efficient on some platform\".</p>",
        "id": 212514034,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602044587
    },
    {
        "content": "<p>actually \"a truthy value\" might be too vague — it is sometimes very useful to be able to actually use the comparison result, err, as a mask. i assume that's why we named them mask vectors (and not bool vectors) anyway.</p>",
        "id": 212514088,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602044683
    },
    {
        "content": "<p><span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span> I am so confused.</p>",
        "id": 212514111,
        "sender_full_name": "Jubilee",
        "timestamp": 1602044753
    },
    {
        "content": "<p>So the problem is we can't just use movemask, whatever we do needs to be just LLVM intrinsics to ensure that everything codegens ok</p>",
        "id": 212514113,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602044758
    },
    {
        "content": "<p><em>currently</em> the code in the stdsimd repo is all sorts of masks of specific widths. we should avoid building too much more on top of masks until the mask situation is clarified, which also means we can't implement comparisons and blends, which mostly means we can't implement most stuff.</p>\n<p>So i guess this is accidentally a major blocking point.</p>\n<p>What I personally want a mask to do, as a user, is be a \"yes / no\" per lane, and you can combine them lanewise like a bool, and then when you have the lane mask you want you use it to blend between two code paths.</p>\n<p>are there additional requirements on the <em>purpose</em> of having a mask? or is that the basic idea regardless of the size/details of the mask types?</p>",
        "id": 212514182,
        "sender_full_name": "Lokathor",
        "timestamp": 1602044867
    },
    {
        "content": "<p>I agree, I think that's all I generally want it to do as well</p>",
        "id": 212514251,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602044963
    },
    {
        "content": "<p>yes, that's correct. I also think there should be something like</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">impl</span><span class=\"w\"> </span><span class=\"n\">m32x4</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"sd\">/// Returns a 4-bit value containing a 1 for ever occupied lane in this mask</span>\n<span class=\"w\">    </span><span class=\"k\">pub</span><span class=\"w\"> </span><span class=\"k\">fn</span> <span class=\"nf\">to_int</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"w\"> </span>-&gt; <span class=\"kt\">u8</span> <span class=\"p\">{</span><span class=\"w\"> </span><span class=\"cm\">/*... use movemask on x86, fallback elsewhere ...*/</span><span class=\"w\"> </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>\n\n<p>for each mask type</p>\n<p>i brought this up in the other topic as an example of an API which you probably wouldn't add except for the fact that it's extremely efficient on one of the platforms, and isn't <em>too</em> bad on the others. I think it fits here, but it's hardly important enough to impact the whole design (even though it's ubiquitous in actual SSE code).</p>",
        "id": 212514378,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602045166
    },
    {
        "content": "<p>i've always been told that movemask is actually quite inefficient and can quickly stall the simd pipeline, avoid it and such</p>",
        "id": 212514391,
        "sender_full_name": "Lokathor",
        "timestamp": 1602045205
    },
    {
        "content": "<p>Turns out I was wrong about <code>m1xN</code> on x86_64, the in-memory representation is <code>uN</code>:<br>\n<a href=\"https://gcc.godbolt.org/z/994v1b\">https://gcc.godbolt.org/z/994v1b</a></p>",
        "id": 212514394,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602045214
    },
    {
        "content": "<p>The problem is you can't, say, do that for m32x8, because that would be AVX which you don't necessarily have the target feature for</p>",
        "id": 212514402,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602045234
    },
    {
        "content": "<p>That's good news</p>",
        "id": 212514450,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602045268
    },
    {
        "content": "<blockquote>\n<p>i've always been told that movemask is actually quite inefficient and can quickly stall the simd pipeline, avoid it and such</p>\n</blockquote>\n<p>i mean it has a data dep on the mask used as input but its still only 1 or 2 cycles pretty much everywhere. it's better to avoid since generally if you use it you're about to branch though</p>",
        "id": 212514451,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602045268
    },
    {
        "content": "<p>I say we _try_ implementing 1-bit masks and the associated comparisons etc and if it codegens as expected then it's up to the user to pick the one they want</p>",
        "id": 212514469,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602045325
    },
    {
        "content": "<p>Yeah, so one minor constraint is that when you have N lane vectors, you need an N lane mask type, so at the wider types we'd need like a u64 as the mask output to bit pack all the lanes in.</p>",
        "id": 212514472,
        "sender_full_name": "Lokathor",
        "timestamp": 1602045331
    },
    {
        "content": "<p>it's also always better to use the comparison result to select directly if possible, it's just that only applies to algorithms where that's relevant</p>",
        "id": 212514473,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602045335
    },
    {
        "content": "<p><del>is there a way we can get away with not having an explicit movemask API at all and just make the operations that it describes implicitly happen</del></p>",
        "id": 212514597,
        "sender_full_name": "Jubilee",
        "timestamp": 1602045573
    },
    {
        "content": "<p>uhhhhh, honestly, probably</p>",
        "id": 212514605,
        "sender_full_name": "Lokathor",
        "timestamp": 1602045602
    },
    {
        "content": "<p>Yeah I think so too haha. A comparison api should be sufficient</p>",
        "id": 212514657,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602045659
    },
    {
        "content": "<blockquote>\n<p>I say we _try_ implementing 1-bit masks and the associated comparisons etc and if it codegens as expected then it's up to the user to pick the one they want</p>\n</blockquote>\n<p>err, why? i'm pretty sure <code>simd_{eq,lt,gt,...}</code> functions return a wider mask directly. converting to a 1 bit per lane mask eagerly seems bad because:</p>\n<ol>\n<li>on platforms without a movemask equivalent it's wasteful since you use other operations to test the mask values</li>\n<li>you have to expand the one bit mask into a wider mask if it gets used for, well, masking, and IDK if any arch can do this efficiently</li>\n</ol>",
        "id": 212514660,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602045669
    },
    {
        "content": "<p>okay so,<br>\npretend I am a very small overexcited child that has somehow wound up on a standards committee,<br>\nI grasp what masking is for abstractly, but what exactly is <code>_mm_movemask_ps</code> specifically for?</p>",
        "id": 212514663,
        "sender_full_name": "Jubilee",
        "timestamp": 1602045677
    },
    {
        "content": "<p>inspecting the result of the a comparison operation</p>",
        "id": 212514673,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602045709
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"209168\">@Thom Chiovoloni</span> I'm suggesting using the llvm intrinsics, not the rustc intrinsics</p>",
        "id": 212514674,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602045714
    },
    {
        "content": "<p>So movemask_ps converts <code>__m128</code> (think <code>f32x4</code>) that stores a truthy value in each lane into an <code>i32</code> with the lowest 4 bits set to 0 or 1, and all other bits 0. This lets you easily inspect the mask register in a more normal way because now it's just an i32</p>",
        "id": 212514723,
        "sender_full_name": "Lokathor",
        "timestamp": 1602045754
    },
    {
        "content": "<p>Is it <code>eq</code> or <code>cmp</code>?<br>\n<code>eq</code> is only 1 bit, so it shouldn't be?<br>\nahhhh</p>",
        "id": 212514729,
        "sender_full_name": "Jubilee",
        "timestamp": 1602045777
    },
    {
        "content": "<p>I think we're maybe a little too focused on movemask specifically. AVX512 has a whole suite of comparisons on 1-bit masks, right?</p>",
        "id": 212514730,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602045781
    },
    {
        "content": "<p>Movemask is just one particular instruction that can be used for that API for SSE and AVX</p>",
        "id": 212514741,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602045819
    },
    {
        "content": "<p>yes i was told that avx512 has entirely special registers for masks that need their own handling.</p>",
        "id": 212514743,
        "sender_full_name": "Lokathor",
        "timestamp": 1602045820
    },
    {
        "content": "<p>okay, so <code>_mm_movemask_ps</code> is in fact 1 bit per lane,<br>\nare there any APIs which expose masks which aren't 1 bit per lane?</p>",
        "id": 212514788,
        "sender_full_name": "Jubilee",
        "timestamp": 1602045843
    },
    {
        "content": "<p>Comparisons?</p>",
        "id": 212514791,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602045873
    },
    {
        "content": "<p>the standard \"mask\" values you get from comparisons are the exact same size as the types you're comparing. The movemask operation collapses that from x bits per lane to 1 bit per lane.</p>",
        "id": 212514796,
        "sender_full_name": "Lokathor",
        "timestamp": 1602045892
    },
    {
        "content": "<p>Everything else in SSE, AVX, NEON</p>",
        "id": 212514797,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602045894
    },
    {
        "content": "<p>almost every vector comparison API in hardware returns a vector of the same size with all-bits-set in any lanes where the comparison passed, and no-bits-set where it failed</p>",
        "id": 212514800,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602045904
    },
    {
        "content": "<p>Movemask and AVX512 are special here, but maybe not so special looking at RISC-V</p>",
        "id": 212514809,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602045931
    },
    {
        "content": "<p>Okay, so <em>abstractly</em>,<br>\nas in pure information theory level,<br>\nis it ever not 1 bit per lane?</p>",
        "id": 212514815,
        "sender_full_name": "Jubilee",
        "timestamp": 1602045942
    },
    {
        "content": "<p>No</p>",
        "id": 212514818,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602045951
    },
    {
        "content": "<p>always true or false per lane</p>",
        "id": 212514823,
        "sender_full_name": "Lokathor",
        "timestamp": 1602045956
    },
    {
        "content": "<p><strong>Cool.</strong></p>",
        "id": 212514824,
        "sender_full_name": "Jubilee",
        "timestamp": 1602045956
    },
    {
        "content": "<p>Then our type is Mask x Width, as I understand it.</p>",
        "id": 212514870,
        "sender_full_name": "Jubilee",
        "timestamp": 1602045984
    },
    {
        "content": "<p>this is super useful for a lot of things (selects and such), but different hardware has different strategies for answering questions like \"did all lanes pass the comparison\".</p>\n<p>for x86 you do this with movemask<br>\nfor neon you do something like check fi the minimum value in the mask vector is all-bits-set</p>",
        "id": 212514877,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602046000
    },
    {
        "content": "<p><em>sorta</em> (@ jub)</p>",
        "id": 212514879,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046001
    },
    {
        "content": "<p>I think we can't hide away the mask width become some architectures support both</p>",
        "id": 212514890,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046060
    },
    {
        "content": "<p>yeah that's the heart of it.</p>",
        "id": 212514893,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046080
    },
    {
        "content": "<p>And you may want to transmute it, I guess</p>",
        "id": 212514932,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046091
    },
    {
        "content": "<p>I am not sure we cannot if we provide transformation functions for the different arch mask types.</p>",
        "id": 212514940,
        "sender_full_name": "Jubilee",
        "timestamp": 1602046114
    },
    {
        "content": "<p>Particularly transmuting 1 bit masks to integers for table lookups</p>",
        "id": 212514941,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046115
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span> some mask values are, in hardware, &gt;1 bits per lane, and some are actually in hardware 1 bit per lane, and we can't paper over that difference. we probably need to expose both systems, horrible as that might be.</p>",
        "id": 212514944,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046127
    },
    {
        "content": "<p>\"Do not transmute this, plz.\"</p>",
        "id": 212514949,
        "sender_full_name": "Jubilee",
        "timestamp": 1602046140
    },
    {
        "content": "<p>hmmmmmmmm.</p>",
        "id": 212514953,
        "sender_full_name": "Jubilee",
        "timestamp": 1602046151
    },
    {
        "content": "<p>I actually don't think it's particularly awful</p>",
        "id": 212514955,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046157
    },
    {
        "content": "<p>You can then just use cfg or whatever to select which you prefer</p>",
        "id": 212514961,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046184
    },
    {
        "content": "<p>Same as number of lanes</p>",
        "id": 212514963,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046200
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"312331\">Caleb Zulawski</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212514402\">said</a>:</p>\n<blockquote>\n<p>The problem is you can't, say, do that for m32x8, because that would be AVX which you don't necessarily have the target feature for</p>\n</blockquote>\n<p>LLVM seems to work fine when you tell it to not use AVX:<br>\n<a href=\"https://gcc.godbolt.org/z/WTEdT4\">https://gcc.godbolt.org/z/WTEdT4</a></p>",
        "id": 212515013,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602046232
    },
    {
        "content": "<p>(I would hope some SIMD traits make it easier to write generic)</p>",
        "id": 212515016,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046238
    },
    {
        "content": "<p>particularly, since we're promising that <code>core::simd</code> is easily interacting with <code>core::arch</code>, we need to be fairly concrete about the types because people need to concretely know what <code>core::arch</code> thing they line up with on a particular arch (and the answer might be \"nothing on this particular arch quite matches that <code>core::simd</code> type, don't think about it too hard\")</p>\n<p>eg, f32x8 has no 100% mapping for neon, so we tell you to use [vf32x4;2] maybe</p>",
        "id": 212515026,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046254
    },
    {
        "content": "<p>anyway i brought up movemask explicitly because its a bit of a wonky api.</p>\n<p>my point was that that's honestly fine, it doesn't have to be a major part of the comparison/masking API, just one extra function on mask types that's exposed. this follows the logic of (from <span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span>'s comment in the other thread).</p>\n<blockquote>\n<p>if something is fast in one vector instruction set, it's worth exposing, even if other instruction sets have to write it out as a series of instructions.</p>\n</blockquote>\n<p>which imo is worth doing, at least for the cases where it's not too burdensome</p>",
        "id": 212515042,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602046294
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"229517\">@Jacob Lifshay</span> that's how I think it should be done, I meant we can't explicitly use the naskmove instruction</p>",
        "id": 212515051,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046311
    },
    {
        "content": "<p>I'm also very happy that icmp codegens correctly in that case</p>",
        "id": 212515108,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046377
    },
    {
        "content": "<p>It's promising that the API should \"just work\"</p>",
        "id": 212515120,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046405
    },
    {
        "content": "<p>So, <em>resolved</em> (?) that mask types shal be convertable to integers via a method on the type.</p>\n<p>question: can we say the output type is always u64? or do we usually want u32 and then u64 as the output type only when there's actually 64 lanes?</p>",
        "id": 212515128,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046431
    },
    {
        "content": "<p>Though, if you want to see some truly awful code: <a href=\"https://gcc.godbolt.org/z/14xc3a\">https://gcc.godbolt.org/z/14xc3a</a></p>",
        "id": 212515168,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602046445
    },
    {
        "content": "<p>Do we really just want them convertible? I would think we specifically want to duplicate the mask api for both lane-width and 1-bit masks, unless I'm misunderstanding</p>",
        "id": 212515188,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046513
    },
    {
        "content": "<p>Rust offers all sorts of conversions that aren't bit-level transmutes.</p>",
        "id": 212515203,
        "sender_full_name": "Jubilee",
        "timestamp": 1602046551
    },
    {
        "content": "<p>well, you're just converting it to a normal int, not a special second mask type.</p>",
        "id": 212515243,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046576
    },
    {
        "content": "<p>So, what happens when one architecture stores the bits where lane 0 corresponds to the MSB and other architectures has lane 0 correspond to the LSB?</p>",
        "id": 212515254,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602046605
    },
    {
        "content": "<p>Sorry, what I meant was that some architectures support a whole variety of 1-bit mask operations, so we need to support those too I think</p>",
        "id": 212515259,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046614
    },
    {
        "content": "<p>I am thinking I would <strong>like</strong> to solve this with a single somewhat abstract type that offers hardware-level transformation functions and maybe attributes, here, so that when it's not needed to go to <code>std::arch</code>, you don't have to worry about what type it is at all, and LLVM just does whatever seems correct, and maybe you decorate some things with an extra attribute to make sure they use the \"right\" mask type.</p>",
        "id": 212515263,
        "sender_full_name": "Jubilee",
        "timestamp": 1602046620
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"229517\">@Jacob Lifshay</span> the \"spec\" for this would be that bit 0 is lane 0, bit 1 is lane 1, etc, whatever that means happens on the local arch.</p>",
        "id": 212515276,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046667
    },
    {
        "content": "<p>I don't understand how it can be a single type if AVX512 has operations that would work with both say m1x8 and m32x8</p>",
        "id": 212515326,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046721
    },
    {
        "content": "<p>they don't work with both types, i think</p>",
        "id": 212515340,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046749
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span>  That type could be target calling convention specific to avoid unnecessary <code>pmovmskb</code> on x86 or the probably even worse code needed to convert from an int back to a full vector</p>",
        "id": 212515341,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602046757
    },
    {
        "content": "<p>All I mean is it's a user's decision which to use in that case</p>",
        "id": 212515346,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046776
    },
    {
        "content": "<p>So I don't think we should attempt to hide away the mask width, there are reasons to use both</p>",
        "id": 212515406,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046811
    },
    {
        "content": "<p>from what i saw of avx512 they weren't flexible on mask type</p>",
        "id": 212515422,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046838
    },
    {
        "content": "<p>like, a given op used a given mask type, not \"whatever type of mask you want\"</p>",
        "id": 212515427,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046847
    },
    {
        "content": "<p>eg: <code>void _mm512_2intersect_epi32 (__m512i a, __m512i b, __mmask16* k1, __mmask16* k2)</code></p>",
        "id": 212515433,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046854
    },
    {
        "content": "<p>It's not hiding the mask width, it's just ignoring it when it isn't relevant. <span aria-label=\"shrug\" class=\"emoji emoji-1f937\" role=\"img\" title=\"shrug\">:shrug:</span></p>",
        "id": 212515441,
        "sender_full_name": "Jubilee",
        "timestamp": 1602046864
    },
    {
        "content": "<p>fine details are sadly always relevent</p>",
        "id": 212515453,
        "sender_full_name": "Lokathor",
        "timestamp": 1602046894
    },
    {
        "content": "<p>that is why we could allow programmers to add the amount of salience that they personally need.</p>",
        "id": 212515460,
        "sender_full_name": "Jubilee",
        "timestamp": 1602046915
    },
    {
        "content": "<p>Right, but there are choices such as _mm_cmp_ps and _mm_cmp_mask_ps</p>",
        "id": 212515509,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046955
    },
    {
        "content": "<p>Not sure if I got those names right</p>",
        "id": 212515511,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046962
    },
    {
        "content": "<p>AVX512 adds the packed comparisons in addition to the original wide mask comparisons</p>",
        "id": 212515525,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602046987
    },
    {
        "content": "<p>well, following LLVM's precedent, I vote for <code>m1xN</code> as the default representation when not being passed as function parameters or return values or being stored in memory. LLVM is most likely to optimize that type correctly, since it's what it uses internally.</p>",
        "id": 212515529,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602046993
    },
    {
        "content": "<p>That's also a possibility</p>",
        "id": 212515554,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602047036
    },
    {
        "content": "<p>\"when not being passed as function parameters or return values\" is an odd way to put it.</p>",
        "id": 212515555,
        "sender_full_name": "Lokathor",
        "timestamp": 1602047036
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"229517\">@Jacob Lifshay</span> what does LLVM do if you want to use the comparison result as a mask in a further operation?</p>",
        "id": 212515557,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047040
    },
    {
        "content": "<p>also what is the actual binary representation of m1xN ? is it 1-bit-per-lane? because that truly seems like the worst of all worlds. (disasterous to have to splat out if you need a mask, forces movemask or movemask-equivalent everywhere even when you don't need 1 bit per lane)</p>",
        "id": 212515634,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047111
    },
    {
        "content": "<p>i genuinely think the design we have now, and that packed_simd uses, is pretty good? it's heading in the right direction anyway.</p>",
        "id": 212515650,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047138
    },
    {
        "content": "<p>Remember that it's just a type in llvm, it doesn't necessarily correspond to actual memory layout</p>",
        "id": 212515716,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602047194
    },
    {
        "content": "<p>yeah, but if we're going to say \"m1xN is the default representation\", that <em>is</em> a representation</p>",
        "id": 212515732,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047219
    },
    {
        "content": "<p>or else i don't know what that statement means</p>",
        "id": 212515744,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047229
    },
    {
        "content": "<p>That's true</p>",
        "id": 212515749,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602047238
    },
    {
        "content": "<p>I think Jacob may have meant API / logical representation.</p>",
        "id": 212515759,
        "sender_full_name": "Jubilee",
        "timestamp": 1602047253
    },
    {
        "content": "<p>Part of the reason I don't think we should try to go too hard on layout here is precisely because this is not the first time Rust has a highly unspecified layout.</p>",
        "id": 212515769,
        "sender_full_name": "Jubilee",
        "timestamp": 1602047270
    },
    {
        "content": "<p>yeah but there's <em>much</em> gnashing of teeth in the unsafe community every time things are less specified</p>",
        "id": 212515821,
        "sender_full_name": "Lokathor",
        "timestamp": 1602047307
    },
    {
        "content": "<p>Is there any reason we can't have both parts of the api? For example <code>eq</code> and <code>eq_packed</code>, or whatever we want to call it</p>",
        "id": 212515827,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602047314
    },
    {
        "content": "<p>There is, and sometimes you have to deal.</p>",
        "id": 212515835,
        "sender_full_name": "Jubilee",
        "timestamp": 1602047331
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"312331\">@Caleb Zulawski</span> You are going to get someone who gets them backwards every day.</p>",
        "id": 212515843,
        "sender_full_name": "Jubilee",
        "timestamp": 1602047352
    },
    {
        "content": "<p>i like caleb's plan</p>",
        "id": 212515849,
        "sender_full_name": "Lokathor",
        "timestamp": 1602047362
    },
    {
        "content": "<p>I agree it's slightly confusing, but it looks like intel already uses both, and other architectures aren't consistent</p>",
        "id": 212515865,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602047397
    },
    {
        "content": "<p>ALSO, thom's plan: unpacked masks that simply also have a method to pack them down</p>",
        "id": 212515908,
        "sender_full_name": "Lokathor",
        "timestamp": 1602047407
    },
    {
        "content": "<p>...I think trying to specify this at this moment is a mistake.</p>",
        "id": 212515920,
        "sender_full_name": "Jubilee",
        "timestamp": 1602047435
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span> genuinely unsure if an API that's largely for helping people write explicitly optimized/tuned code is the right place to be super handwavy about data layout tbh</p>",
        "id": 212515923,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047438
    },
    {
        "content": "<p>I was not proposing being handwavey.</p>",
        "id": 212515940,
        "sender_full_name": "Jubilee",
        "timestamp": 1602047467
    },
    {
        "content": "<p>well, promising nothing then</p>",
        "id": 212515946,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047482
    },
    {
        "content": "<p>I was not proposing that either, just no one read what I said.</p>",
        "id": 212515956,
        "sender_full_name": "Jubilee",
        "timestamp": 1602047499
    },
    {
        "content": "<p>I think considering the packed masks are specifically useful for indexing tables and the wide masks are specifically useful for transmuting both are probably necessary</p>",
        "id": 212515964,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602047511
    },
    {
        "content": "<blockquote>\n<p>sometimes you have to deal.</p>\n</blockquote>\n<p>i was responding to this</p>",
        "id": 212515970,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047517
    },
    {
        "content": "<p>If you try to offer two types on the assumption that will be enough that will break if another architecture does not use either of them, and now you need 3.</p>",
        "id": 212516046,
        "sender_full_name": "Jubilee",
        "timestamp": 1602047581
    },
    {
        "content": "<p>wide masks are also useful for stuff like selecting lanes between two vectors and stuff. you use them all the time if you're trying to avoid branching in simd code.</p>",
        "id": 212516049,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047585
    },
    {
        "content": "<p>I would at least support an initial implementation to experiment with until we have a good reason to change it to something else</p>",
        "id": 212516053,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602047587
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212515557\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"229517\">Jacob Lifshay</span> what does LLVM do if you want to use the comparison result as a mask in a further operation?</p>\n</blockquote>\n<p><a href=\"https://gcc.godbolt.org/z/s3r8hs\">https://gcc.godbolt.org/z/s3r8hs</a></p>",
        "id": 212516065,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602047614
    },
    {
        "content": "<p>Well, okay, mask values that are <code>maskBxL</code> for B bit elements and L count lanes. This <em>works</em> and we're very sure that it works because it's been used quite a bit, and it's simple to understand. <strong>Do we agree on this much?</strong></p>\n<p>From there: <em>additional</em> ways to have a SIMD mask seem to me like they should be alternate ways without tainting the simplicity of the basic mask</p>",
        "id": 212516067,
        "sender_full_name": "Lokathor",
        "timestamp": 1602047618
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span> isn't that kind of the goal though? Support things that are generally available on many but not all architectures, and polyfill the rest</p>",
        "id": 212516075,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602047634
    },
    {
        "content": "<p>It is not handwavey to suggest a more abstract type that can be forced to solidify into a specific repr using provided transmutation functions.</p>",
        "id": 212516125,
        "sender_full_name": "Jubilee",
        "timestamp": 1602047660
    },
    {
        "content": "<p>I have material things to pack, so I should suppose I should get to that.</p>",
        "id": 212516129,
        "sender_full_name": "Jubilee",
        "timestamp": 1602047664
    },
    {
        "content": "<p>i've had a Tim Rogers video paused for 30 minutes now</p>",
        "id": 212516134,
        "sender_full_name": "Lokathor",
        "timestamp": 1602047683
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"229517\">Jacob Lifshay</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212516065\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212515557\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"229517\">Jacob Lifshay</span> what does LLVM do if you want to use the comparison result as a mask in a further operation?</p>\n</blockquote>\n<p><a href=\"https://gcc.godbolt.org/z/s3r8hs\">https://gcc.godbolt.org/z/s3r8hs</a></p>\n</blockquote>\n<p>wow yikes, that's kinda what i was afraid of tbh</p>",
        "id": 212516144,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047709
    },
    {
        "content": "<p>hence why I recommended it only be used for values inside functions, not for passing between functions or storing in memory</p>",
        "id": 212516168,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602047762
    },
    {
        "content": "<p>and convinces me that the use logic that \"LLVM is most likely to optimize that type correctly, since it's what it uses internally.\" isn't really correct</p>",
        "id": 212516206,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047770
    },
    {
        "content": "<p>at least on x86</p>",
        "id": 212516209,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602047773
    },
    {
        "content": "<p>yeah i mean values inside functions don't have a representation so i have no opinion on that</p>",
        "id": 212516217,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047788
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212516206\">said</a>:</p>\n<blockquote>\n<p>and convinces me that the use logic that \"LLVM is most likely to optimize that type correctly, since it's what it uses internally.\" isn't really correct</p>\n</blockquote>\n<p>Hey, look at the return type of the <code>icmp</code> LLVM IR instruction: it's <code>&lt;16 x i1&gt;</code>. LLVM only supports <code>&lt;i1 x N&gt;</code> vectors as compare results and for the mask argument of the <code>select</code> instruction.</p>",
        "id": 212516238,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602047857
    },
    {
        "content": "<p>I don't even know what a value \"in\" a function but \"not passed between\" a function means, since you can only have a value from a literal or as the output of another function, so that other function passed it up to you</p>",
        "id": 212516239,
        "sender_full_name": "Lokathor",
        "timestamp": 1602047858
    },
    {
        "content": "<p>like, whatever rustc wants to tell LLVM is fine by me, and the <code>f_sse_inlined</code> code says \"telling it i1 vector\" is more or less optimal so long as stuff stays inlined.</p>",
        "id": 212516240,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047861
    },
    {
        "content": "<p>PS: I can't wait to have the next grand thread on how to handle immediate operations &lt;3</p>",
        "id": 212516298,
        "sender_full_name": "Lokathor",
        "timestamp": 1602047947
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"229517\">@Jacob Lifshay</span> right the yikes is at the non-inlined version. the inlined version is basically ideal, but the non-inlined version is more or less exactly what i was worried about</p>",
        "id": 212516301,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602047954
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212516239\">said</a>:</p>\n<blockquote>\n<p>I don't even know what a value \"in\" a function but \"not passed between\" a function means, since you can only have a value from a literal or as the output of another function, so that other function passed it up to you</p>\n</blockquote>\n<p>it means we add conversions at function boundaries and hope LLVM removes them when inlining.</p>",
        "id": 212516368,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602048023
    },
    {
        "content": "<p>Could you give a small example?</p>",
        "id": 212516469,
        "sender_full_name": "Lokathor",
        "timestamp": 1602048142
    },
    {
        "content": "<p>Okay, let me say one last thing on this:<br>\nPart of my reasoning is that if we have two type-incompatible mask width types then this <strong>badly</strong> hurts library support with a concern that they should not actually have to worry about, because now whenever the library... heck, whenever <em>we</em>... generate a mask type, then we have to decide which type comes back, which may not actually be optimized for a given architecture. However, a compiler in an application context can... what Jacob said.</p>",
        "id": 212516486,
        "sender_full_name": "Jubilee",
        "timestamp": 1602048180
    },
    {
        "content": "<p>anyway, given that overwhelmingly existing APIs represent comparison results the same (as masks of the same width) it's hard for me to see why we wouldn't assume that new APIs offering the same functionality would either do the same thing or have  a relatively cheap conversion.</p>\n<p>the examples i've seen for different things, e.g. avx512, were really different APIs no?</p>",
        "id": 212516510,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602048236
    },
    {
        "content": "<p>A compiler can theoretically recognize that they should have been using a given mask type all along.</p>",
        "id": 212516511,
        "sender_full_name": "Jubilee",
        "timestamp": 1602048237
    },
    {
        "content": "<p>Well, I think that <em>part of</em> that is solved by having the wide masks bit pack to normal integers. Once you rip the info \"from simd world\" and just have a normal integer, then that's fine. That's not actually a whole other set of types we're dealing with. You can do whatever the heck you like with a <code>u32</code>, go nuts.</p>",
        "id": 212516582,
        "sender_full_name": "Lokathor",
        "timestamp": 1602048301
    },
    {
        "content": "<blockquote>\n<p>Part of my reasoning is that if we have two type-incompatible mask width types</p>\n</blockquote>\n<p>do you consider the current API (e.g. <code>m32x4</code> and friends) to be this?</p>",
        "id": 212516588,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602048305
    },
    {
        "content": "<p>to be clear i would rather not have any support for e.g. <code>movemask</code> than have it require its own set of types. i think it's mostly relevant when porting algorithms, and can just be a inherent method that returns an integer.</p>",
        "id": 212516649,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602048380
    },
    {
        "content": "<p>Yeah, \"compress this to an integer\" seems like a totally reasonable method.</p>",
        "id": 212516685,
        "sender_full_name": "Lokathor",
        "timestamp": 1602048455
    },
    {
        "content": "<p>with or without hardware support</p>",
        "id": 212516692,
        "sender_full_name": "Lokathor",
        "timestamp": 1602048465
    },
    {
        "content": "<p>ideally the only time you use it is if you're porting code that expects hardware support or if your algorithm genuinely needs this operation and you can accept a less efficient operation when the hw support isn't there</p>",
        "id": 212516764,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602048550
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212516469\">said</a>:</p>\n<blockquote>\n<p>Could you give a small example?</p>\n</blockquote>\n<p><a href=\"https://gcc.godbolt.org/z/5Wxhhd\">https://gcc.godbolt.org/z/5Wxhhd</a></p>\n<p>I don't think it's possible to tell LLVM that a particular <code>&lt;16 x i8&gt;</code> is really <code>m8x16</code>, so it has to use a second compare instruction after the call.</p>",
        "id": 212516817,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602048628
    },
    {
        "content": "<p>ha, sorry, i meant could you show some rust code of what you meant.</p>",
        "id": 212516828,
        "sender_full_name": "Lokathor",
        "timestamp": 1602048676
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212516828\">said</a>:</p>\n<blockquote>\n<p>ha, sorry, i meant could you show some rust code of what you meant.</p>\n</blockquote>\n<p>Oh:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">pub</span><span class=\"w\"> </span><span class=\"k\">fn</span> <span class=\"nf\">f</span><span class=\"p\">(</span><span class=\"n\">a</span>: <span class=\"nc\">u8x16</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">b</span>: <span class=\"nc\">u8x16</span><span class=\"p\">)</span><span class=\"w\"> </span>-&gt; <span class=\"nc\">maskx16</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"c1\">// note maskx16 doesn't say which kind of mask it is</span>\n<span class=\"w\">    </span><span class=\"c1\">// it's architecture specific with conversions to m1x16 and m8x16</span>\n<span class=\"w\">    </span><span class=\"k\">return</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"w\"> </span><span class=\"o\">&lt;</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 212516905,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602048840
    },
    {
        "content": "<p>it's mostly not visible from rust</p>",
        "id": 212516953,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602048901
    },
    {
        "content": "<p>hmm, so one complication feels like you might have, a number of mask values from more than one way</p>",
        "id": 212517128,
        "sender_full_name": "Lokathor",
        "timestamp": 1602049136
    },
    {
        "content": "<p>we could also just define <code>m8x16</code> to be either <code>&lt;16 x i1&gt;</code> or <code>&lt;16 x i8&gt;</code> depending on the architecture and define a <code>fullmask8x16</code> when the user explicitly wants <code>&lt;16 x i8&gt;</code></p>",
        "id": 212517150,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602049163
    },
    {
        "content": "<p>yeah so i think m1x16 is just <code>u16</code> honestly. but more importantly i think the LLVM examples kinda show that we do need to care about the width of the lanes</p>",
        "id": 212517151,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602049164
    },
    {
        "content": "<p>that is, say maskx4, that might be from f32x4 (128-bit) or f64x4 (256-bit), and it feels weird that you can't see the size there if you're going to use it as a blend. like blending f32x4 from a mask generated via a comparison between f64x4 sounds.... strange.</p>",
        "id": 212517212,
        "sender_full_name": "Lokathor",
        "timestamp": 1602049224
    },
    {
        "content": "<p>like, if i came across <a href=\"https://gcc.godbolt.org/z/7xoxab\">https://gcc.godbolt.org/z/7xoxab</a> (which is a simple case — real code would likely have way more), it would would make me never want to use the API</p>",
        "id": 212517231,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602049265
    },
    {
        "content": "<p>i mean the f_sse function to be clear, the f_sse_inlined function is essentially optimal</p>",
        "id": 212517239,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602049295
    },
    {
        "content": "<p>i dont' really read intel asm, but that sure does look bad</p>",
        "id": 212517293,
        "sender_full_name": "Lokathor",
        "timestamp": 1602049341
    },
    {
        "content": "<p>theres a toggle for asm syntax style behind the gear.</p>",
        "id": 212517301,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602049368
    },
    {
        "content": "<p>no sorry, i mean that the only assembly i know is for arm</p>",
        "id": 212517308,
        "sender_full_name": "Lokathor",
        "timestamp": 1602049385
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212517212\">said</a>:</p>\n<blockquote>\n<p>that is, say maskx4, that might be from f32x4 (128-bit) or f64x4 (256-bit), and it feels weird that you can't see the size there if you're going to use it as a blend. like blending f32x4 from a mask generated via a comparison between f64x4 sounds.... strange.</p>\n</blockquote>\n<p>That should be totally possible, it's what you get when vectorizing:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">a</span>: <span class=\"nc\">f64x4</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">b</span>: <span class=\"nc\">f32x4</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">c</span>: <span class=\"nc\">f32x4</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"k\">mut</span><span class=\"w\"> </span><span class=\"n\">d</span>: <span class=\"nc\">f32x4</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"nb\">Default</span>::<span class=\"n\">default</span><span class=\"p\">();</span><span class=\"w\"></span>\n<span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"mi\">4</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">d</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"n\">a</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"mf\">0.0</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"p\">}</span><span class=\"w\"> </span><span class=\"k\">else</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"> </span><span class=\"n\">c</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span><span class=\"w\"> </span><span class=\"p\">};</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 212517313,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602049399
    },
    {
        "content": "<p>it should be possible, i agree, but not something we want to have easily happen on accident, which i feel could happen</p>",
        "id": 212517362,
        "sender_full_name": "Lokathor",
        "timestamp": 1602049454
    },
    {
        "content": "<p>hence why I like:<br>\n<span class=\"user-mention silent\" data-user-id=\"229517\">Jacob Lifshay</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212517150\">said</a>:</p>\n<blockquote>\n<p>we could also just define <code>m8x16</code> to be either <code>&lt;16 x i1&gt;</code> or <code>&lt;16 x i8&gt;</code> depending on the architecture and define a <code>fullmask8x16</code> when the user explicitly wants <code>&lt;16 x i8&gt;</code></p>\n</blockquote>",
        "id": 212517385,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602049518
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224471\">@Lokathor</span> <a href=\"https://gcc.godbolt.org/z/xE1WWW\">https://gcc.godbolt.org/z/xE1WWW</a></p>",
        "id": 212517474,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602049676
    },
    {
        "content": "<p>cool.</p>",
        "id": 212517532,
        "sender_full_name": "Jubilee",
        "timestamp": 1602049744
    },
    {
        "content": "<p>e.g. it's even worse on neon — note that f_sse_inlined does the same as f_sse and cmp_f.</p>",
        "id": 212517535,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602049759
    },
    {
        "content": "<p>I was wondering if godbolt could be persuaded to generate ARM code.</p>",
        "id": 212517536,
        "sender_full_name": "Jubilee",
        "timestamp": 1602049760
    },
    {
        "content": "<p>it can but you probably will have to do stuff like pass in --help and --version as args inside the godbolt window to figure out how. also the attributes <a href=\"https://github.com/rust-lang/rust/issues/1\">#1</a> thing needs modifying for each arch (e.g. llvm ir continues to be non-portable)</p>",
        "id": 212517606,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602049864
    },
    {
        "content": "<p>hey i can almost read aarch64! (normally i use armv4t code, gba and all that)</p>",
        "id": 212517674,
        "sender_full_name": "Lokathor",
        "timestamp": 1602049966
    },
    {
        "content": "<p>lol</p>",
        "id": 212517677,
        "sender_full_name": "Jubilee",
        "timestamp": 1602049982
    },
    {
        "content": "<p>i mean, no vectors there so.</p>",
        "id": 212517681,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602049989
    },
    {
        "content": "<p>go team Raspi</p>",
        "id": 212517686,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050002
    },
    {
        "content": "<p>i actually posted most of this thread from a raspi4 (though now i'm on the laptop)</p>",
        "id": 212517745,
        "sender_full_name": "Lokathor",
        "timestamp": 1602050059
    },
    {
        "content": "<p>anyway this is very convincing to me that it's worth it to have e.g. <code>m32x8</code> and <code>m16x8</code> be just different types. using a mask here already helps defend us from guaranteeing the specific binary values (unlike if we had comparisons return <code>u32x8</code> and such).</p>",
        "id": 212517748,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050063
    },
    {
        "content": "<p>nice.</p>",
        "id": 212517749,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050065
    },
    {
        "content": "<p>although i think the name \"mask\" does stronly imply a... specific binary representaion</p>",
        "id": 212517771,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050111
    },
    {
        "content": "<p>that's true, I do not want to guarantee binary values because some arch is gonna be a joker</p>",
        "id": 212517773,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050112
    },
    {
        "content": "<p>it seems unlikely that producing a mask from a comparison won't be cheap on any hypothetical arch, since that's such a common thing</p>",
        "id": 212517836,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050174
    },
    {
        "content": "<p>and say a mask for u8x16 or w/e is not [Bits[M; 8]; 8]</p>",
        "id": 212517841,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050187
    },
    {
        "content": "<p>but actually [Bits[0,0,0,0,0,0,0,M]; 8]</p>",
        "id": 212517856,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050218
    },
    {
        "content": "<p>that's still very cheap to convert. waaaaaaaaaaaaaaaaaaaaay cheaper than that mess i linked with the i1 vec</p>",
        "id": 212517876,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050263
    },
    {
        "content": "<p>(its cheap to convert because converting it is equivalent to a signed int negate)</p>",
        "id": 212517929,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050321
    },
    {
        "content": "<p>oh yes.</p>",
        "id": 212517933,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050330
    },
    {
        "content": "<p>but also <a href=\"https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#sec-mask-register-layout\">https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#sec-mask-register-layout</a></p>",
        "id": 212517956,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050371
    },
    {
        "content": "<p>so it's compares more or less automatically have a builtin movemask</p>",
        "id": 212518032,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050458
    },
    {
        "content": "<p>ah, you can use the mask register to expand cheaply by directly using its mask for a bit negate on 0</p>",
        "id": 212518102,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050558
    },
    {
        "content": "<p>if i'm reading right that would work</p>",
        "id": 212518106,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050570
    },
    {
        "content": "<p>ish, it goes into a vector register.</p>",
        "id": 212518109,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050573
    },
    {
        "content": "<p>yeah.</p>",
        "id": 212518110,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050582
    },
    {
        "content": "<p>And \"it goes into a vector register\" means it isn't just a scalar value!</p>",
        "id": 212518142,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050631
    },
    {
        "content": "<p>that seems fine so long as you can just use it as a mask for another instruction directly</p>",
        "id": 212518190,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050671
    },
    {
        "content": "<p>yes, it's actually quite peculiar to RISCV-V how mask works.</p>",
        "id": 212518196,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050691
    },
    {
        "content": "<p>honestly riscv's option seems like the most flexible, and could cheaply emulate any of the things we choose</p>",
        "id": 212518199,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050694
    },
    {
        "content": "<p><a href=\"https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#vector-masking\">https://github.com/riscv/riscv-v-spec/blob/master/v-spec.adoc#vector-masking</a></p>",
        "id": 212518215,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050721
    },
    {
        "content": "<p>yeah i saw that</p>",
        "id": 212518219,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050730
    },
    {
        "content": "<p>nod.</p>",
        "id": 212518220,
        "sender_full_name": "Jubilee",
        "timestamp": 1602050736
    },
    {
        "content": "<p>doing it like that would slightly pessimize riscv for cases where everything isn't inlined (since you can't just directly use that mask elsewhere), but it seems like it would not be nearly as devastating as the alternative on x86/arm/honestly probably everywhere else</p>",
        "id": 212518380,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602050917
    },
    {
        "content": "<p>honestly for masking risv's approach is clearly the best (very clean and almost any conversion of the data is extremely cheap)... (but i still think working with non-statically sized vectors sounds awful lol)</p>",
        "id": 212518672,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602051285
    },
    {
        "content": "<p>anyway i think the real downside of the current mask design is not because it's likely some future arch will come up with a new way of doing things that is hard to convert to it. the issue is clearly that it's a shitload of types:</p>\n<ul>\n<li>\"scalar\" mask values (basially a <code>OnlyZeroOrMax$Int</code> type. IMO these should probably not be exposed) <code>mask8</code>, <code>mask16</code>, <code>mask32</code>, <code>mask64</code>, <code>mask128</code>, <code>masksize</code> .</li>\n<li>many vector mask values: <code>mask8x8</code>, <code>mask8x16</code>, <code>mask8x32</code>, <code>mask8x64</code>, <code>mask16x4</code>, <code>mask16x8</code>, <code>mask16x16</code>, <code>mask16x32</code>, <code>mask32x2</code>, <code>mask32x4</code>, <code>mask32x8</code>, <code>mask32x16</code>, <code>mask64x2</code>, <code>mask64x4</code>, <code>mask64x8</code>, <code>mask128x4</code>, <code>mask128x2</code>, <code>masksizex2</code>, <code>masksizex4</code>, <code>masksizex8</code></li>\n</ul>",
        "id": 212519417,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602052141
    },
    {
        "content": "<p>uh whats the timeline on min_const_generics again?</p>",
        "id": 212519442,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602052183
    },
    {
        "content": "<p>\"by the end of the year\"</p>",
        "id": 212519519,
        "sender_full_name": "Lokathor",
        "timestamp": 1602052241
    },
    {
        "content": "<p>something's going to be stabilized-ish in 2020, smaller features will be stabilized in 2021 (so, we can count on them being even stronger, though in an ill-defined way, by the time we stabilize anything)</p>",
        "id": 212519531,
        "sender_full_name": "Jubilee",
        "timestamp": 1602052269
    },
    {
        "content": "<p>some of the work currently happening is literally just hacking the const generic feature into a million smaller features.</p>",
        "id": 212519545,
        "sender_full_name": "Jubilee",
        "timestamp": 1602052290
    },
    {
        "content": "<p>is there a way we can leverage it for the sizes of vectors?</p>",
        "id": 212519603,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602052327
    },
    {
        "content": "<p>I do believe so, in fact, but we will have to sit down and talk to them and maybe help them a bit with hacking the compiler.</p>",
        "id": 212519624,
        "sender_full_name": "Jubilee",
        "timestamp": 1602052364
    },
    {
        "content": "<p>re: packing masks into an explicit uint, what are the reasons to not target usize exactly?</p>",
        "id": 212519649,
        "sender_full_name": "Jubilee",
        "timestamp": 1602052403
    },
    {
        "content": "<p>can you elaborate?</p>",
        "id": 212519663,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602052421
    },
    {
        "content": "<p>uhm, that was raised a while back.</p>",
        "id": 212519667,
        "sender_full_name": "Jubilee",
        "timestamp": 1602052431
    },
    {
        "content": "<p>\"should it be a u32 or u64?\"<br>\n\"why not usize, exactly?\"</p>",
        "id": 212519717,
        "sender_full_name": "Jubilee",
        "timestamp": 1602052449
    },
    {
        "content": "<p>do you mean my example where i had <code>mask32x4</code> return u8? that would be fine to have it return <code>usize</code> instead</p>",
        "id": 212519720,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602052457
    },
    {
        "content": "<p>eh, just as a generic question sortof!</p>",
        "id": 212519737,
        "sender_full_name": "Jubilee",
        "timestamp": 1602052478
    },
    {
        "content": "<p>I guess \"because it is hypothetically possible to have a 32-bit platform with 512-bit vectors\"</p>",
        "id": 212519764,
        "sender_full_name": "Jubilee",
        "timestamp": 1602052511
    },
    {
        "content": "<p>or a 64-bit platform with 1024-bit vectors that supports u8s</p>",
        "id": 212519844,
        "sender_full_name": "Jubilee",
        "timestamp": 1602052575
    },
    {
        "content": "<p>yes, <code>mask8x64</code> (for 512bit SIMD) needs to pack into u64 and cant use usize. but i think the mask vector types don't really need to agree on the packed type, it can just be an inherent method and not a trait. that avoids issues if someone adds 1024-bit vectors in the future</p>",
        "id": 212519858,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602052592
    },
    {
        "content": "<p>right.</p>",
        "id": 212519862,
        "sender_full_name": "Jubilee",
        "timestamp": 1602052603
    },
    {
        "content": "<p>(in case it's unclear at all, the <code>mask8</code>, <code>mask16</code>, <code>mask32</code>, <code>mask64</code>, <code>mask128</code>, and <code>masksize</code> are the lanes of the mask vec, and not the bitpacked mask)</p>",
        "id": 212519900,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602052669
    },
    {
        "content": "<p>so i think the desire to const generics impacts every part of the API and not just masking, and it doesnt really impact masking in a different way than it impacts other stuff</p>",
        "id": 212519987,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602052768
    },
    {
        "content": "<p>assuming we remove or at least dont publically expose the maskvec lane types we then have 20 mask vector types, which is the same number of vector types that we have for {signed,unsigned} ints (seprately, e.g. 20 signed vec types and 20 unsigned vec types).</p>",
        "id": 212520171,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602052990
    },
    {
        "content": "<p>const generics would make that 6 each which probably doesn't super meaningfully change the nature of the API, just the size of it.</p>",
        "id": 212520253,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602053093
    },
    {
        "content": "<p>If you mean we could genericize over lane widths? yeah, 2, 4, 8, 16, 32, 64</p>",
        "id": 212520853,
        "sender_full_name": "Jubilee",
        "timestamp": 1602053876
    },
    {
        "content": "<p>yeah, but i kinda suspect repr(simd) might get mad about weird sizes</p>",
        "id": 212520910,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602053924
    },
    {
        "content": "<p>and i think min const generics dont let you limit things like that? maybe?</p>",
        "id": 212520933,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602053943
    },
    {
        "content": "<p>in practice most of the power of our API will be locked behind <a href=\"https://github.com/rust-lang/compiler-team/issues/340\">https://github.com/rust-lang/compiler-team/issues/340</a></p>",
        "id": 212520969,
        "sender_full_name": "Jubilee",
        "timestamp": 1602053992
    },
    {
        "content": "<p>i think with current design direction, in the future we'd probably still be able to do <code>pub type f32x4 = SimdF32&lt;4&gt;</code> or even <code>pub type f32x4 = Simd&lt;f32, 4&gt;;</code>, and i vaguely remember that waiting for const generics is part of why packed_simd stalled</p>",
        "id": 212521173,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602054175
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"216206\">lcnr</span> <a href=\"#narrow/stream/146212-t-compiler.2Fconst-eval/topic/Do.20the.20const.20SIMD-shuffle.3F/near/207927943\">said</a>:</p>\n<blockquote>\n<p>you can then write <code>fn simd_stuff&lt;const N: usize&gt;() where [u8;  BOUND - N]</code> which fails to compile if <code>N</code> is greater than <code>BOUND</code></p>\n<p>I personally expect us to still be able to add these bounds to methods we want to stabilize even if they can only be satisfied by using concrete values. That would forbid users on stable from writing <code>simd_stuff::&lt;CONST_PARAM&gt;</code> at the start</p>\n</blockquote>",
        "id": 212521193,
        "sender_full_name": "Jubilee",
        "timestamp": 1602054193
    },
    {
        "content": "<p>also having it not be generic might help push people towards chosing a realistic size for their architecture. maybe. (i can dream)</p>",
        "id": 212521266,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602054246
    },
    {
        "content": "<p>...why would they introduce arch-specific concerns when writing arch-generic code?</p>",
        "id": 212521291,
        "sender_full_name": "Jubilee",
        "timestamp": 1602054277
    },
    {
        "content": "<p>i mean, they're gonna have a bad time if they use SimdVec&lt;u8, 13&gt;</p>",
        "id": 212521317,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602054313
    },
    {
        "content": "<p>const wf lets us ban non-n^2 length vectors</p>",
        "id": 212521337,
        "sender_full_name": "Jubilee",
        "timestamp": 1602054342
    },
    {
        "content": "<p>okay, they still should probably pick 128bit (or sometimes 256) if they care about perf, and imo if you don't care about perf you're prob better served by just writing the obvious scalar code</p>",
        "id": 212521439,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602054463
    },
    {
        "content": "<p>yeah <code>packed_simd</code> did the const generics thing. It.. makes the api harder to understand. We've got our initial charter as being against the idea of repeating that path.</p>",
        "id": 212521541,
        "sender_full_name": "Lokathor",
        "timestamp": 1602054574
    },
    {
        "content": "<p>It's not impossible to change that but.. we'd need a pretty sturdy justification i think.</p>",
        "id": 212521592,
        "sender_full_name": "Lokathor",
        "timestamp": 1602054604
    },
    {
        "content": "<p>sold</p>",
        "id": 212521609,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602054622
    },
    {
        "content": "<p>We don't want to make everything const generic but there will be cases where we do intend to use it.<br>\nAnd with all due respect, there are reasons to explicitly communicate that an algorithm is vectorizable in a way that opens the door for significant performance gains without needing to worry about the specific architecture size.</p>",
        "id": 212521614,
        "sender_full_name": "Jubilee",
        "timestamp": 1602054627
    },
    {
        "content": "<p>LLVM can fail to vectorize \"obvious\" vectors. Implicit vectorization is not a programming model. \"This is mostly vectorizable if the architecture supports it\" is a valid thing to want to communicate.</p>",
        "id": 212521668,
        "sender_full_name": "Jubilee",
        "timestamp": 1602054709
    },
    {
        "content": "<p>yeah that's plausible, i also think there are cases where it's reasonable to reach for a simd type even if it's not actively hot code (probably is convenient for mathy stuff). that said i'd consider code where you're worrying about if llvm is vectorizing stuff to be code where you care about the perf</p>",
        "id": 212521731,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602054749
    },
    {
        "content": "<p>Mostly I think, const generics helps save on code writing time in some cases, but we've got sufficiently few cases and we've got macro_rules! so i think we can already generate the specific cases we want to handle quickly enough.</p>",
        "id": 212521763,
        "sender_full_name": "Lokathor",
        "timestamp": 1602054794
    },
    {
        "content": "<p>Intel CPUs can literally execute 512 bit vector instructions as 128 bit vectors until AVX512 turns on. :^)</p>",
        "id": 212521766,
        "sender_full_name": "Jubilee",
        "timestamp": 1602054796
    },
    {
        "content": "<p>4k vectors :3</p>",
        "id": 212521791,
        "sender_full_name": "Lokathor",
        "timestamp": 1602054832
    },
    {
        "content": "<p>noticing \"this is vectorizable at a performance gain of at least x5, I should probably use <code>core::simd</code>\" is not the same as caring about every last % of performance</p>",
        "id": 212521837,
        "sender_full_name": "Jubilee",
        "timestamp": 1602054852
    },
    {
        "content": "<p>i mean, there's real non-obvious performance cost to the wider vectors. anyway this is not a hill i want to die on, people can use the api however they want</p>",
        "id": 212521843,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602054859
    },
    {
        "content": "<p>The dilemma is in fact that people will use the API however they want and not how we imagine they will, yes.</p>",
        "id": 212521872,
        "sender_full_name": "Jubilee",
        "timestamp": 1602054895
    },
    {
        "content": "<p>I guess the thing to remember is that people can always use a thing wrong, we just need to make it easy enough to use right and provide help when they shout on reddit</p>",
        "id": 212521897,
        "sender_full_name": "Lokathor",
        "timestamp": 1602054923
    },
    {
        "content": "<p>and e.g. someone is almost certainly to implement a language against our API and then we <strong>really</strong> won't know how the API is being used because it's being used by proxy by users who may not even be aware they're using it. :^)</p>",
        "id": 212522036,
        "sender_full_name": "Jubilee",
        "timestamp": 1602055060
    },
    {
        "content": "<p>i mean i do genuinely think scalar code is easier to read than vector code 9 times out of 10, and that most people should reach for 128bit vectors if they don't specifically know better, but these are mostly personal opinions and certainly not things i want to encode in the API. (i was mostly thinking/worried about users using SimdVec&lt;T, N&gt; for strange Ns, when they really want [T; N]. but i didn't realize that we had the ability to limit the values N can take. anyway,  if const generics are out this isn't a concern really)</p>",
        "id": 212522352,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602055322
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"281757\">Jubilee</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212521337\">said</a>:</p>\n<blockquote>\n<p>const wf lets us ban non-n^2 length vectors</p>\n</blockquote>\n<p>I think we should plan on vector lengths not being required to be a power of 2, maybe not right away, but at least when RISC-V V and/or SimpleV support is added, since RISC-V V supports arbitrary vector lengths by setting the Vector Length register to whatever length you want. SimpleV additionally supports using e.g. 7 consecutive 64-bit registers to store a <code>f32x14</code> or 13 registers to store a <code>i8x49</code> where the last register has some unused bytes.</p>",
        "id": 212522416,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602055398
    },
    {
        "content": "<p>That sounds... less portable though</p>",
        "id": 212522655,
        "sender_full_name": "Lokathor",
        "timestamp": 1602055568
    },
    {
        "content": "<p>that value changes at runtime though no? or is the idea that you'd set compile code that uses f32x14, but first sets the register to a value that lets that run well</p>",
        "id": 212522669,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602055583
    },
    {
        "content": "<p>erm... </p>\n<p>the bits in a RISCV-V vector register must be 2^n though, no?</p>",
        "id": 212522726,
        "sender_full_name": "Jubilee",
        "timestamp": 1602055662
    },
    {
        "content": "<p>anyway i find the combination of it not working out amazingly for packed_simd, and \"We've got our initial charter as being against the idea of repeating that path.\" fairly compelling. someone in the future can always rfc replacing the current types with type aliases anyway.</p>",
        "id": 212522899,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602055801
    },
    {
        "content": "<p>sounds like: physically a single register is \"2^n bits\", but you can combo registers and also ignore some of the bytes, so overall it's just \"8*n bits\" because you can put the byte bound anywhere you want</p>",
        "id": 212522936,
        "sender_full_name": "Lokathor",
        "timestamp": 1602055804
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212522669\">said</a>:</p>\n<blockquote>\n<p>that value changes at runtime though no? or is the idea that you'd set compile code that uses f32x14, but first sets the register to a value that lets that run well</p>\n</blockquote>\n<p>RISC-V V is mostly designed for the case where the value changes at runtime, every CPU has a different hardware limit on vector length.<br>\nSimpleV is designed to work well with both fixed-length and variable vectors, every CPU is required to support lengths up to 64. Lengths greater than 64 won't work due to predicate masks being just a u64 in an integer register.</p>",
        "id": 212523049,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602055883
    },
    {
        "content": "<p>64 bytes?</p>",
        "id": 212523083,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602055907
    },
    {
        "content": "<p>i mean we cover powers of two up to 64 bytes.</p>",
        "id": 212523281,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602056004
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212522936\">said</a>:</p>\n<blockquote>\n<p>sounds like: physically a single register is \"2^n bits\", but you can combo registers and also ignore some of the bytes, so overall it's just \"8*n bits\" because you can put the byte bound anywhere you want</p>\n</blockquote>\n<p>That's how SimpleV works. all registers are 64 bits, vectors are where the bytes that make up consecutive registers are reinterpreted as <code>f32x13</code> or whatever.</p>",
        "id": 212523420,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602056106
    },
    {
        "content": "<p>i think we should worry about that after doing fixed power of 2 sizes, since it's not like they're disasterous anywhere</p>",
        "id": 212523645,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602056285
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212523083\">said</a>:</p>\n<blockquote>\n<p>64 bytes?</p>\n</blockquote>\n<p>64 lanes in a vector since you need 1 predicate bit per lane. you can have up to <code>&lt;64 x u64&gt;</code> or, using the subvectors functionality, up to 128 underlying 64 bit registers since there are only 128 registers for fp and 128 for integers.</p>",
        "id": 212523819,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602056426
    },
    {
        "content": "<p>back to the masks, if we find having 20 mask types problematic, we might be able to get away with just making them a wrapper like <code>Mask&lt;u32x4&gt;</code> instead of <code>mask32x4</code>.  I don't actually know that this would be worth while, but it's an option i just thought of</p>",
        "id": 212523910,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602056491
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212523645\">said</a>:</p>\n<blockquote>\n<p>i think we should worry about that after doing fixed power of 2 sizes, since it's not like they're disasterous anywhere</p>\n</blockquote>\n<p>sounds good, as long as we're not guaranteeing that we'll only ever provide powers of 2 lengths.</p>",
        "id": 212523997,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602056545
    },
    {
        "content": "<p>re: <code>Mask&lt;uNxK&gt;</code> actually it's probably fine to keep it as is for now, making it a wrapper sounds annoying (probably requires specialization, or at least some heavy weight trait shenanigans.</p>",
        "id": 212524143,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602056657
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212523910\">said</a>:</p>\n<blockquote>\n<p>back to the masks, if we find having 20 mask types problematic, we might be able to get away with just making them a wrapper like <code>Mask&lt;u32x4&gt;</code> instead of <code>mask32x4</code>.  I don't actually know that this would be worth while, but it's an option i just thought of</p>\n</blockquote>\n<p>I think that would be unnecessarily messy, since <code>Mask&lt;u32x4&gt;</code>, <code>Mask&lt;i32x4&gt;</code>, and <code>Mask&lt;f32x4&gt;</code> would all be different types, right?</p>",
        "id": 212524161,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602056677
    },
    {
        "content": "<p>i was thinking it would always be a unsigned int type but honestly it's a half-baked thought that only reduces the number of types in the API and not the complexity</p>",
        "id": 212524207,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602056730
    },
    {
        "content": "<p>and honestly the only reason i care at all is that i think we'll be the part of stdlib that defines by far more types than any other, which isn't ideal</p>",
        "id": 212524330,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602056820
    },
    {
        "content": "<p>Hm, no.<br>\nLMUL has only 2^N values.<br>\nSEW has only 2^N values.<br>\nVLEN and ELEN are also 2^N values.<br>\nHow do you specify a non-2^N vector length in RISCV-V?</p>",
        "id": 212524348,
        "sender_full_name": "Jubilee",
        "timestamp": 1602056832
    },
    {
        "content": "<p>setting VL to a non-power-of-2</p>",
        "id": 212524374,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602056863
    },
    {
        "content": "<p>what happens if that register changes while you have vectors out</p>",
        "id": 212524441,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602056897
    },
    {
        "content": "<p>you aren't allowed</p>",
        "id": 212524460,
        "sender_full_name": "Jubilee",
        "timestamp": 1602056919
    },
    {
        "content": "<blockquote>\n<p>Thread contexts with active vector state cannot be migrated during execution between harts that have any difference in VLEN or ELEN parameters.</p>\n</blockquote>",
        "id": 212524505,
        "sender_full_name": "Jubilee",
        "timestamp": 1602056969
    },
    {
        "content": "<p>same kinda thing as if you set the stack pointer to a different value, the compiler keeps track of it and if you change it behind it's back you get UB.</p>",
        "id": 212524530,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602056991
    },
    {
        "content": "<p>IIRC you can totally change VL without needing to reset the vector state. the stuff past VL just becomes unused.</p>",
        "id": 212524657,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602057079
    },
    {
        "content": "<p>right that kinda thing is along the lines of \"you can assume well-behaved rust code will never touch this register unless it's doign some very hairy platform-specific code\" which may not be something the portable simd api needs to worry about</p>",
        "id": 212524671,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602057093
    },
    {
        "content": "<p>well behaved rust code totally changes the stack pointer all the time ... when the compiler expects it to. same thing with VL.</p>",
        "id": 212524777,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602057174
    },
    {
        "content": "<p>so the compiler would track this?</p>",
        "id": 212524810,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602057204
    },
    {
        "content": "<p>yup</p>",
        "id": 212524821,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602057212
    },
    {
        "content": "<p>i mean, llvm has a bad track record for tracking control register values</p>",
        "id": 212524833,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602057221
    },
    {
        "content": "<p>depends on the register.</p>",
        "id": 212524903,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602057255
    },
    {
        "content": "<p>anyway, i feel like this is super in the weeds.</p>",
        "id": 212524970,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602057308
    },
    {
        "content": "<p>some work great, such as the stack pointer or x86 zero flag. others, not so much.</p>",
        "id": 212525011,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602057344
    },
    {
        "content": "<p>this feels somewhat equivalent to the fpenv since it's also supposed to use this knowledge for codegen.</p>\n<p>anyway. tldr seems to be: the current mask design is probably mostly fine.</p>\n<ul>\n<li>\n<p>trying to unify masks of the same lane count (as some fully opaque bool or mask vector) isn't viable since llvm does a very bad job here unless it can inline everything. it also seems every current arch we can find either produces these kinds of mask from a comparisons, or turn a comparison result into a mask in 1 or 2 cheap instructions.</p>\n</li>\n<li>\n<p>also, since it's in the title movemask isn't important enough to warrant anything beyond an inherent method the mask types, and it's probably not worth explicitly representing 1-bit mask vectors expect as integers.</p>\n</li>\n</ul>\n<p>that said this sounds suspiciously like the set of things i felt going in, so perhaps i'm projecting.</p>",
        "id": 212525833,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602057951
    },
    {
        "content": "<p>GPU languages seem to use mostly uints in their lane masking code.</p>",
        "id": 212526932,
        "sender_full_name": "Jubilee",
        "timestamp": 1602058685
    },
    {
        "content": "<p>Went to bed so just catching up--i agree that movemask itself it's necessarily important that but AVX512 still has an enormous packed mask API</p>",
        "id": 212563657,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602079817
    },
    {
        "content": "<p>I would like to at least experiment with packed masks (and see if it codegens as expected), unless it seems like a waste of time I can submit a PR so we can get a feeling of what our API might look like</p>",
        "id": 212563952,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602079956
    },
    {
        "content": "<p>Worst case we scrap the PR and start from what we've learned</p>",
        "id": 212564051,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602080005
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"312331\">@Caleb Zulawski</span> by packed mask you mean one-bit-per-lane? either way the AVX512 mask API seems pretty different than the other mask stuff, so IDK if it needs to be handled the same.</p>",
        "id": 212564423,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602080163
    },
    {
        "content": "<p>i mean it's a different kind of api and if it also uses a different mask layout then... that says to me it probably shouldn't be the same</p>",
        "id": 212564493,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602080195
    },
    {
        "content": "<p>Yeah, 1 bit per lane.  Actually, a huge amount of SSE and AVX APIs were ported to using the 1-bit masks in AVX512 so the APIs can be nearly identical</p>",
        "id": 212564722,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602080293
    },
    {
        "content": "<p>ugh</p>",
        "id": 212564810,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602080335
    },
    {
        "content": "<p>And my understanding is as long as the type is repr(simd) it should work</p>",
        "id": 212564825,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602080342
    },
    {
        "content": "<p>At least as far as function calls are concerned</p>",
        "id": 212564934,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602080386
    },
    {
        "content": "<p>i'm not 100% sure i follow, would this be only for 1-bit masks?</p>",
        "id": 212564941,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602080390
    },
    {
        "content": "<p>Would what be?</p>",
        "id": 212565040,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602080421
    },
    {
        "content": "<p>I'm suggesting for now providing both types of masks (with conversions between the two) and some subset of operations that utilize them</p>",
        "id": 212565313,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602080544
    },
    {
        "content": "<p>And at least with a PR we have something tangible to critique</p>",
        "id": 212565451,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602080599
    },
    {
        "content": "<p>I mean my main issue here is that it's only going to be efficient on avx512 and will double the API surface for the mask code, and make it confusing for users to decide what to use.</p>",
        "id": 212565964,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602080818
    },
    {
        "content": "<p>It sounds to me that there is an efficient (for some ops) implementation that uses movemask, and for some architectures such as RISC-V the wide masks are inefficient and the narrow masks should be preferred</p>",
        "id": 212566162,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602080896
    },
    {
        "content": "<p>yeah riscv has support for that too. the issue sin't the movemask so much as that the fallback code has to undo a movemask to implement any masking operation... which is not efficient</p>",
        "id": 212566290,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602080970
    },
    {
        "content": "<p>I also think it's shortsighted to discount AVX512 when in a few years it will probably be the dominant vector instruction set. If anything this indicates to me that the narrow masks may be more heavily adopted as time goes on</p>",
        "id": 212566407,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602081009
    },
    {
        "content": "<p>you think it will/ i've really seen no indication that avx512 is going to come to consumer machines.</p>",
        "id": 212566613,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602081096
    },
    {
        "content": "<p>It's already available on some consumer CPUs</p>",
        "id": 212566789,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602081171
    },
    {
        "content": "<p>I've used either a skylake or cannon lake i5 that supports it, as well as a mac pro with I believe an i9 that supports it</p>",
        "id": 212567058,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602081292
    },
    {
        "content": "<p>I know, but are there plans for that to increase? i also think you're overestimating how long it takes for new instructions to be something people actually want to use</p>\n<p>that said, the biggest reason i'm discounting it is also that it doesn't seem to offer a meaningful improvement to the API, just largely another version of it</p>",
        "id": 212567072,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602081299
    },
    {
        "content": "<p>i9 macs don't support it unless that's changed very recently</p>",
        "id": 212567118,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602081320
    },
    {
        "content": "<p>Maybe it's xeon then</p>",
        "id": 212567150,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602081333
    },
    {
        "content": "<p>i also think that rather than add new types for 1 bit masks you can probably just use unsigned integers (or int vectors? not sure the api shape).</p>",
        "id": 212567319,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602081404
    },
    {
        "content": "<p>Yeah that was what I was imagining. The narrow masks likely have a different API</p>",
        "id": 212567374,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602081427
    },
    {
        "content": "<p>I agree that it's a significant addition to the API but I'm worried that not supporting it rules out AVX512 and RISC-V (admittedly not the most common use cases, for now at least)</p>",
        "id": 212567656,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602081563
    },
    {
        "content": "<p>it's a significant addition and it feels <em>very</em> much like the kind of API where someone unfamiliar with simd code would assume it's the main/correct way for dealing with what's conceptually bool vector, and the downside of \"operations are O(lanes) unless you have a very high target_feature configured or are targetting riscv\" just feels like a huge footgun</p>",
        "id": 212568057,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602081731
    },
    {
        "content": "<p>and for riscv vectors AFAICT it's still very efficient to turn the bit masks to/from the wider mask vectors that are much more common</p>",
        "id": 212568263,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602081840
    },
    {
        "content": "<p>is that true for the avx512 bit masks? e.g. can they \"undo\" a movemask efficiently?</p>",
        "id": 212568454,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602081917
    },
    {
        "content": "<p>Honestly not sure, but I don't think the normal usage would be to do that.</p>",
        "id": 212568865,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602082052
    },
    {
        "content": "<p>I just checked, say you are only using 128 bit vectors. With AVX a blendv has double the latency and half the throughput of an AVX512 masked blend on the same vector</p>",
        "id": 212569072,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602082115
    },
    {
        "content": "<p>There really does seem to be a significant performance benefit of using them when they are available. I agree it's possible to accidentally use the wrong type of mask, but it's already possible to generate suboptimal code if you're not somewhat aware of what you're doing</p>",
        "id": 212569240,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602082199
    },
    {
        "content": "<p>I also imagine in many cases the compiler will be smart enough to optimize the narrow masks to wide masks when they remain in register, since that's LLVM's representation in the first place</p>",
        "id": 212569840,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602082392
    },
    {
        "content": "<p>right no, but if they can cheaply go back and forth, IMO they should just use the same api as everything else rather than add a duplicate version of the API that runs more slowly for most targets.</p>\n<p>this way, for people on AVX512: in the case that stuff's inlined, it's very that LLVM will be able to \"see through\" something cheap like that, and in the case that stuff is <em>not</em> inlined, you have an extra few instructions of overhead. I strongly doubt it can do this for the operation of manually undoing a movemask — and especially not in the case where it's tied to the algo at all</p>",
        "id": 212569966,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602082438
    },
    {
        "content": "<p>Wide masks to narrow masks I'm not so sure, since they are normal vector registers and support more operations</p>",
        "id": 212569973,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602082440
    },
    {
        "content": "<p>wide to narrow is easier than narrow to wide i think. i think wide to narrow is O(log(lanes)) and narrow to wide is O(lanes) for most ISAs</p>",
        "id": 212570161,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602082509
    },
    {
        "content": "<p>I meant that it's harder to verify that you didn't do something to a wide mask to make it no longer a mask.  Narrow masks don't have that problem</p>",
        "id": 212570307,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602082570
    },
    {
        "content": "<p>also it's worth noting that LLVM does abysmally for &lt;bool x N&gt; which seems strictly easier to me than the &lt;bit x N&gt; case</p>",
        "id": 212570330,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602082581
    },
    {
        "content": "<p>Isn't that because bool is specifically defined as 8 bits but utilizing only the LSB? i1 is not defined that way</p>",
        "id": 212570416,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602082635
    },
    {
        "content": "<p>yeah, but you aren't really relying on the compiler to know that. it's encoded in the type system (hence the mask vecs being their own types and no unsigned int vecs)</p>",
        "id": 212570417,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602082635
    },
    {
        "content": "<p>the code i'm referring to was i1.</p>",
        "id": 212570475,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602082661
    },
    {
        "content": "<p>Do you have it on godbolt?</p>",
        "id": 212570611,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602082711
    },
    {
        "content": "<p><a href=\"https://gcc.godbolt.org/z/7xoxab\">https://gcc.godbolt.org/z/7xoxab</a> / <a href=\"https://gcc.godbolt.org/z/xE1WWW\">https://gcc.godbolt.org/z/xE1WWW</a></p>",
        "id": 212570641,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602082719
    },
    {
        "content": "<p>(ignore fn names) the arm is more obviously terrible since you see that:</p>\n<ul>\n<li>cmp_f has to do extra work to pack up the mask</li>\n<li>f_sse then has to unpack it which is nontrivial</li>\n</ul>",
        "id": 212570897,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602082802
    },
    {
        "content": "<p>Right-but on SSE you wouldn't want to use narrow masks in the first place</p>",
        "id": 212571293,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602082918
    },
    {
        "content": "<p>i strongly suspect if we provide narrow mask APIs people will use them not realizing they're only efficient on avx512/riscv</p>",
        "id": 212571449,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602082967
    },
    {
        "content": "<p>i mean, i think there's a very strong case to be made that a narrow mask API is a better api — it's a lot simpler and more obvious. it's just aslo... way less efficient on most hardware.</p>",
        "id": 212571591,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602083033
    },
    {
        "content": "<p>it just feels like a bad outcome if we have two versions of most apis</p>\n<ul>\n<li>one that's simpler but is a performance footgun until AVX512/riscv become widespread</li>\n<li>one that is more complex (all those mask types) but will produce essentially optimal code for nearly every ISA, and only be slighly worse than optimal on AVX512/riscv</li>\n</ul>",
        "id": 212572006,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602083184
    },
    {
        "content": "<p>i mean i said this last night but, if i were porting code to use the simd API, and i expected <code>f_sse_inlined</code> but got <code>f_sse</code> (from the examples above), i'd probably just assume it was an inefficient API and go back to intrinsics</p>",
        "id": 212572395,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602083359
    },
    {
        "content": "<p>i also think it's worht noting that in reality the majority of users are going to be compiling for stock x86_64/i686 targets for a long time, especially on rust, which means SSE/SSE2.</p>",
        "id": 212573403,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602083651
    },
    {
        "content": "<p>ugh idk we probably should have some way of doing this but it both sucks because of that stuff and just in general it feels very bad to add two API surfaces that do the same thing.</p>",
        "id": 212573543,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602083700
    },
    {
        "content": "<p>you said that avx512 re-exposes a bunch of other stuff to work with 1-bit masks, what about just not exposing that part, and only exposing the new functionality</p>",
        "id": 212573646,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602083749
    },
    {
        "content": "<p>I'm concerned about making too many assumptions for the user.  When you're talking about the level of performance of SIMD you pretty much have to look at generated assembly</p>",
        "id": 212573647,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602083749
    },
    {
        "content": "<p>which part of what i said is an unreasonable assumption?</p>",
        "id": 212573804,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602083804
    },
    {
        "content": "<p>I think someone who is writing SIMD to improve performance but not testing for features beyond SSE2 is probably already on the wrong track for most problems</p>",
        "id": 212573811,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602083807
    },
    {
        "content": "<p>i definitely disagree about that, but i also think this is what you have to expect if you provide a portable API</p>",
        "id": 212574012,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602083880
    },
    {
        "content": "<p>i mean: runtime feature checking is a pain, for rust the decision to enable features at compile time is often out of the hands of the person writing SIMD code.</p>",
        "id": 212574351,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602084000
    },
    {
        "content": "<p>If you're working with say f64 and you only use SSE2 you're probably going to be surprised when your SIMD ends up slower</p>",
        "id": 212574409,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602084006
    },
    {
        "content": "<p>Unless of course you have zero shuffles etc</p>",
        "id": 212574593,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602084083
    },
    {
        "content": "<p>sure. and to be clear i'm not saying we can't do better than SSE2 — i hope this ultimately does something to improve runtime feature checking too.</p>",
        "id": 212574612,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602084094
    },
    {
        "content": "<p>Not trying to plug <code>multiversion</code> really, but runtime detection is trivial with something like that</p>",
        "id": 212574781,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602084143
    },
    {
        "content": "<p>yeah, but with multiversion, IIUC if you use an api like this everybody who isn't using AVX512 gets a much slower result. whereas if you used the wider vectors, it would improve much more smoothly as the API availibility increased.</p>",
        "id": 212574974,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602084224
    },
    {
        "content": "<p>You would select algorithms based on instruction set</p>",
        "id": 212575172,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602084283
    },
    {
        "content": "<p>You'll have the exact same problem if you only use 128 bit vectors on wider architectures</p>",
        "id": 212575235,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602084307
    },
    {
        "content": "<p>Or even 64 bit vectors!</p>",
        "id": 212575263,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602084316
    },
    {
        "content": "<p>summarizing the problems i have here</p>\n<ul>\n<li>it duplicates a huge amount of api surface</li>\n<li>the api is appealingly simple in comparison to the one that maps better to hardware, and so i suspect it would be confusing and easy to use accidentally</li>\n<li>it's very hard to shim efficiently and will make a lot of surrounding code slower</li>\n<li>so you fall off huge performance cliff if you aren't on avx512 (which is extremely rare still)</li>\n</ul>",
        "id": 212575528,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602084417
    },
    {
        "content": "<p>i think those problems are decidedly different than choosing to use 128 bit vectors</p>",
        "id": 212575623,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602084460
    },
    {
        "content": "<p>What makes the api simpler? I'm suggesting having nearly identical APIs for both</p>",
        "id": 212575645,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602084475
    },
    {
        "content": "<p>it mostly looks simpler since users are more familiar with \"<code>u64</code> acting as a bitmask\" than they are with <code>mask8x32</code> or w/e</p>",
        "id": 212575807,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602084523
    },
    {
        "content": "<p>Well to them it would just be mask1x32 and mask8x32</p>",
        "id": 212575879,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602084555
    },
    {
        "content": "<p>Also given the choice between <code>eq</code> and <code>eq_packed</code> I think <code>eq</code> is more likely to be seen as general purpose</p>",
        "id": 212576024,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602084608
    },
    {
        "content": "<p>We could even provide the packed API as a trait so you explicitly need to opt into it</p>",
        "id": 212576110,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602084644
    },
    {
        "content": "<p>i mean, those would probably help address several of my concerns, but i'm genuinely worried about the \"duplicates a huge amount of api surface\" part making it harder to get this ultimately accepted (i am worried about this regardless of the outcome here...)</p>",
        "id": 212576446,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602084767
    },
    {
        "content": "<p>that said if it's done in a way to avoid the potential for perf footgun, i dont care as much</p>",
        "id": 212576573,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602084819
    },
    {
        "content": "<p>As far as stabilization goes, it doesn't need to all be stabilized at once</p>",
        "id": 212576697,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602084861
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"312331\">@Caleb Zulawski</span> I have no idea when I am supposed to use each though.</p>",
        "id": 212585144,
        "sender_full_name": "Jubilee",
        "timestamp": 1602088462
    },
    {
        "content": "<p>One note about using <code>u64</code> or even <code>u128</code> as a lane mask -- RISC-V V supports much more than 128 lanes.<br>\nAnother note about RISC-V V: IIRC it doesn't guarantee any more than 128-bit vectors last time I checked.</p>",
        "id": 212585235,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602088513
    },
    {
        "content": "<p>Like, you can explain it to me five times, and I get that there are specific instructions, but I am trying to write portable SIMD. Injecting a non-portable concern into my code means that now my code compiles like trash on some architectures and not others, and I don't necessarily know which ones. Yielding these architecture-specific types into non-architecture-specific code is deciding to make the API less portable, and I don't see this actually changing no matter what convolutions are done with the code.</p>",
        "id": 212585396,
        "sender_full_name": "Jubilee",
        "timestamp": 1602088588
    },
    {
        "content": "<p>This is exactly the problem we are supposed to be solving. Deciding to do so by punting to the programmer to know which architectures they should use which type on is simply not what we should be doing.</p>",
        "id": 212585515,
        "sender_full_name": "Jubilee",
        "timestamp": 1602088672
    },
    {
        "content": "<p>yes, that's why i'm not a huge fan of adding a duplicate api that's like an existing one except is much slower everywhere but when compiled with avx512</p>",
        "id": 212585605,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602088698
    },
    {
        "content": "<p>It cuts both ways though.</p>",
        "id": 212585643,
        "sender_full_name": "Jubilee",
        "timestamp": 1602088722
    },
    {
        "content": "<p>Shouldn't we remove integer division and 64-bit vectors for the same reason?</p>",
        "id": 212585664,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602088733
    },
    {
        "content": "<p>i mean its only very slightly faster on avx512</p>",
        "id": 212585679,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602088742
    },
    {
        "content": "<p>Arm is also extremely limited on immediate shuffles as well</p>",
        "id": 212585693,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602088750
    },
    {
        "content": "<p>Sure, let's do it.</p>",
        "id": 212585757,
        "sender_full_name": "Jubilee",
        "timestamp": 1602088797
    },
    {
        "content": "<p>i also very much don't think it follows that when desiginign the API we should not consider the performance of these things across a vareity of targets</p>",
        "id": 212585811,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602088809
    },
    {
        "content": "<p>Though to rebut:<br>\nDivision is a logical operation, if someone needs the logical operation of division they need it regardless of what the arch support specifically is.<br>\n<strong>This is not the same</strong> as masking having an implementation-specific type, where the ultimate logical operation is the same but the hardware implementation details -- the things we're supposed to be abstracting over -- differ.</p>",
        "id": 212586000,
        "sender_full_name": "Jubilee",
        "timestamp": 1602088928
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"312331\">@Caleb Zulawski</span> it's tradeoffs. in this case you gain a small amount of performance on niche hardware, and in exchange you greatly increase the API surface, provide very little that couldn't already be done at close to the same performance, and add performance footguns for everybody else. i really don't think these concerns apply to the cases you keep listing.</p>",
        "id": 212586006,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602088933
    },
    {
        "content": "<p>Another example, neon doesn't have a copysign equivalent afaik</p>",
        "id": 212586136,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602089012
    },
    {
        "content": "<p>Again, if someone needs logical copysign they need it regardless of the arch support.</p>",
        "id": 212586167,
        "sender_full_name": "Jubilee",
        "timestamp": 1602089032
    },
    {
        "content": "<p>copysign is done with bitops</p>",
        "id": 212586226,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602089048
    },
    {
        "content": "<p>Also it's just an &amp; or maybe a XOR...</p>",
        "id": 212586228,
        "sender_full_name": "Jubilee",
        "timestamp": 1602089051
    },
    {
        "content": "<p>I wouldn't say that's an accurate characterization, it's potentially double the performance for all masked ops</p>",
        "id": 212586262,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602089073
    },
    {
        "content": "<p>Also nearly all server hardware has AVX512 now I believe</p>",
        "id": 212586313,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602089096
    },
    {
        "content": "<p>it's way worse than double the cost on everything else though</p>",
        "id": 212586334,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602089106
    },
    {
        "content": "<p>All Intel server hardware.</p>",
        "id": 212586340,
        "sender_full_name": "Jubilee",
        "timestamp": 1602089108
    },
    {
        "content": "<p>That was sold recently.</p>",
        "id": 212586362,
        "sender_full_name": "Jubilee",
        "timestamp": 1602089120
    },
    {
        "content": "<p>We're only pessimizing the performance if we hardcode a specific type size, just saying.</p>",
        "id": 212586398,
        "sender_full_name": "Jubilee",
        "timestamp": 1602089145
    },
    {
        "content": "<p>What do you mean?</p>",
        "id": 212586516,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602089181
    },
    {
        "content": "<p>also double the cost for mask ops is like 1 or two instrucitons each way that i highly suspect (when things are inlined) that LLVM will easily see through. when things aren't inlined or other stuff gets in the way yeah, you add a little bit of overhead.</p>",
        "id": 212586578,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602089219
    },
    {
        "content": "<p>dynamically sized types are things?</p>\n<p>As Lokathor said a whiiile back, it's confusing to do blending operations with things that aren't bitmasks. However, we need our mask types to operate the same way in our API regardless of their actual hardware implementation. If a vector implementation doesn't have or prefer bitmasks, then we still need masks to behave the same way in our API regardless of whether they are uints as they are in GPUs or RISCV or movemask, or the Neon/x86 bitmasks, or whatever else someone comes up with.</p>",
        "id": 212586901,
        "sender_full_name": "Jubilee",
        "timestamp": 1602089370
    },
    {
        "content": "<p>Given that it <strong>is</strong> so contentious and performance-sensitive, what I would be really happy with is if we found a way to expose the ability to mask lanes without exposing the actual type at all, frankly.</p>",
        "id": 212587255,
        "sender_full_name": "Jubilee",
        "timestamp": 1602089522
    },
    {
        "content": "<p>i'm pretty surprised it's this contentious</p>",
        "id": 212587472,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602089633
    },
    {
        "content": "<p>idk how you could not expose some sort of comparison result though. i guess you could return an impl trait voldermort type but i think that would make everybody annoyed.</p>",
        "id": 212587638,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602089706
    },
    {
        "content": "<p>(if you meant not exposing the width of the simd lane — i don't think it's possible. if it were this wouldn't be an issue, since the \"no lane width\" type is morally equivalent to a 1-bit-per-lane type)</p>",
        "id": 212587729,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602089759
    },
    {
        "content": "<p>i also just think the number of people who will jump through the hoops to get their code running on AVX512 via either multiversion or compiling with -Ctarget-foo flags is a very small number of people. realistically it's not great but i think most people will use this exactly how they use anything from the stdlib now, which is to say they'll compile it with default settings (and get SSE2)</p>",
        "id": 212588014,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602089885
    },
    {
        "content": "<p>Until someone makes it easy to compile to various arch features.</p>",
        "id": 212588104,
        "sender_full_name": "Jubilee",
        "timestamp": 1602089941
    },
    {
        "content": "<p>if the library here is designed well presumably we could auto-multiversion for you by just recompile the same source code with higher target features (or something like this).</p>",
        "id": 212588119,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602089947
    },
    {
        "content": "<p>That's exactly what the multiversion crate does</p>",
        "id": 212588203,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602089995
    },
    {
        "content": "<p>Exactly.</p>",
        "id": 212588270,
        "sender_full_name": "Jubilee",
        "timestamp": 1602090007
    },
    {
        "content": "<p>That is, as we say in the biz,<br>\nmerely an engineering problem.</p>",
        "id": 212588341,
        "sender_full_name": "Jubilee",
        "timestamp": 1602090033
    },
    {
        "content": "<p>okay, i thought it was, but you later said you needed to use a different algorithm for different arches. which is basically the problem i have with the 1bit mask — its only a good idea if you know the arch you're targeting.</p>",
        "id": 212588417,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602090075
    },
    {
        "content": "<p>Also honestly I don't think I've seen any SIMD code written in the last 10 years that didn't do runtime feature detection</p>",
        "id": 212588492,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602090112
    },
    {
        "content": "<p>Not to say people don't and won't, but I don't think that's a good argument for excluding newer architectures</p>",
        "id": 212588585,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602090137
    },
    {
        "content": "<p>Teaching people how to use SIMD Masks is not, however, so trivial a problem, and if you're arguing for an expansion of specific typesin the code, because it's performance sensitive and they have to use it correctly and they have to only use certain types on certain arches...</p>",
        "id": 212588698,
        "sender_full_name": "Jubilee",
        "timestamp": 1602090184
    },
    {
        "content": "<p>uh<br>\nI'm going to be frank I don't know how to teach people to do that.</p>",
        "id": 212588801,
        "sender_full_name": "Jubilee",
        "timestamp": 1602090234
    },
    {
        "content": "<p>Also people work with Voldemort types all the time. :P</p>",
        "id": 212589006,
        "sender_full_name": "Jubilee",
        "timestamp": 1602090320
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"229517\">Jacob Lifshay</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212517150\">said</a>:</p>\n<blockquote>\n<p>we could also just define <code>m8x16</code> to be either <code>&lt;16 x i1&gt;</code> or <code>&lt;16 x i8&gt;</code> depending on the architecture and define a <code>fullmask8x16</code> when the user explicitly wants <code>&lt;16 x i8&gt;</code></p>\n</blockquote>\n<p>I still think this is probably the best solution to handling masks for fixed-width SIMD</p>",
        "id": 212589036,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602090328
    },
    {
        "content": "<p>i think having 2 sets of mask types would be bad. i also think having the types layout radically change depending on architecture would be pretty bad, and from what i've seen LLVM doesn't really do a great job with <code>&lt;N x i1&gt;</code> code...</p>",
        "id": 212589260,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602090423
    },
    {
        "content": "<p>Fwiw if you dont know anything about SIMD I think you will still run into some problems with performance anyway. I imagine that the overlap of people who write branch free code but don't know SIMD is already very low</p>",
        "id": 212589369,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602090480
    },
    {
        "content": "<p>I don't think so?</p>",
        "id": 212589437,
        "sender_full_name": "Jubilee",
        "timestamp": 1602090498
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212589260\">said</a>:</p>\n<blockquote>\n<p>i think having 2 sets of mask types would be bad. i also think having the types layout radically change depending on architecture would be pretty bad, and from what i've seen LLVM doesn't really do a great job with <code>&lt;N x i1&gt;</code> code...</p>\n</blockquote>\n<p>From what I can see, it only does a bad job with <code>&lt;16 x i1&gt;</code> types on architectures that use <code>&lt;16 x i8&gt;</code> masks, it should be fine on architectures that natively support <code>&lt;16 x i1&gt;</code> as their preferred mask format.</p>",
        "id": 212589609,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602090601
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"312331\">@Caleb Zulawski</span> That's a frankly elitist assumption that is unfounded. Entire programming languages are noted to contribute to trivially more parallelizable code because of stream fusion, and some people learned and program exclusively in those languages, and one of the notable contribution backgrounds to Rust is from those languages.</p>",
        "id": 212589937,
        "sender_full_name": "Jubilee",
        "timestamp": 1602090733
    },
    {
        "content": "<p>Well, <code>usize</code> radically changes between different architectures, but it hasn't caused many problems...</p>",
        "id": 212590019,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602090786
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span> I didn't mean to imply that there aren't people who do it, but I am still pretty sure that the vast majority of branch free code is in the context of SIMD</p>",
        "id": 212590227,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602090873
    },
    {
        "content": "<p>But the average rust user is going to be probably familiar with branching code, especially with the prevalence of <code>match</code> etc</p>",
        "id": 212590338,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602090922
    },
    {
        "content": "<p>i think the disagreement here is: i am okay trading fairly small amounts of performance on a few ISAs (even if they're the \"newer\" ones) if it means the API is simpler, and most code still has zero-cost operations. </p>\n<p>i genuinely think this is unavoidable in a portable api in some cases. i don't think there's a hard and fast rule for it, but... if something will double the size of an already complex part of the API it <em>reallllly</em> has to justify itself IMO</p>",
        "id": 212590477,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602090971
    },
    {
        "content": "<p>I think this was mentioned in a different thread, but it's a disagreement over whether _all_ of portable SIMD's code should be mostly optimal, vs should it be  capable of producing valid code on all platforms and optimal on each depending on algorithm</p>",
        "id": 212590738,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602091093
    },
    {
        "content": "<p>\"but I am still pretty sure that the vast majority of branch free code is in the context of SIMD\" that's plainly false, there are fields that want to write branch free code with or without SIMD parallelization.</p>",
        "id": 212590877,
        "sender_full_name": "Jubilee",
        "timestamp": 1602091170
    },
    {
        "content": "<p>( e.g. cryptography. )<br>\nand there are vector processor targeting languages which, er, do not concern themselves with this level of API detail.</p>",
        "id": 212591029,
        "sender_full_name": "Jubilee",
        "timestamp": 1602091245
    },
    {
        "content": "<p>True, it's relevant for timing attacks etc but I think that's relatively niche too</p>",
        "id": 212591086,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602091276
    },
    {
        "content": "<p>That is uh, not how cryptographers view it.</p>",
        "id": 212591117,
        "sender_full_name": "Jubilee",
        "timestamp": 1602091296
    },
    {
        "content": "<p>I think the real elephant in the room is WebGL shader authors who do write explicit masking ops but are pretty OK with having it be a fairly abstract operation.</p>",
        "id": 212591258,
        "sender_full_name": "Jubilee",
        "timestamp": 1602091359
    },
    {
        "content": "<p>I'm just looking at it from the point of view of the average rust developer. The average rust developer isn't going to know cryptography or SIMD. Some certainly will but I really doubt the average developer does, and we should be supporting average developers too</p>",
        "id": 212591283,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602091376
    },
    {
        "content": "<p>And even with portable SIMD it's still very easy to write very poor vectorized code if you're not aware of the quirks</p>",
        "id": 212591412,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602091440
    },
    {
        "content": "<p>Could we please not think about \"average\" developers? Because there are no \"average developers\". There are different groups with different needs, you can extract an LCD but the modal developer is going to have a fairly large amount of specialized skills.</p>",
        "id": 212591460,
        "sender_full_name": "Jubilee",
        "timestamp": 1602091446
    },
    {
        "content": "<p>this sounds snarky and i mean it respectfully: i don't know how you can think that adding a new separate family of simd masking types would help a developer with a no-more-than-typical level of familiarity with simd</p>",
        "id": 212591618,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602091526
    },
    {
        "content": "<p>I didn't mean average in a derogatory sense, I meant if you split all rust developers into groups of those familiar and unfamiliar with SIMD most will be in the latter group</p>",
        "id": 212591656,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602091550
    },
    {
        "content": "<p>Because it's definitely not a common focus</p>",
        "id": 212591739,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602091571
    },
    {
        "content": "<p>i think to act in that groups best interest we probably want to avoid duplicate funtionality in the api where possible, since that always confusing at all/most levels of familiarity (imo anyway)</p>",
        "id": 212591908,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602091656
    },
    {
        "content": "<p>My point isn't that it helps them, it definitely doesn't, my point is that some level of familiarity is going to be necessary to use portable SIMD regardless of how we end up handling masks, and it's probably more of an issue of education (a portable SIMD mdbook?) than API, in my opinion</p>",
        "id": 212592013,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602091697
    },
    {
        "content": "<p>The two are not separate, actually.</p>",
        "id": 212592033,
        "sender_full_name": "Jubilee",
        "timestamp": 1602091713
    },
    {
        "content": "<p>And are you going to write the entire section on masking and answer all the questions about it for the next 3 years?</p>",
        "id": 212592114,
        "sender_full_name": "Jubilee",
        "timestamp": 1602091748
    },
    {
        "content": "<p>Haha, maybe</p>",
        "id": 212592191,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602091784
    },
    {
        "content": "<p>I speak from experience from having directly mentored many, many people: That is not a trivial act. You are going to have to discard your notions of \"average Rust developers\"... even \"average levels of SIMD familiarity\"... really quickly.</p>",
        "id": 212592582,
        "sender_full_name": "Jubilee",
        "timestamp": 1602091937
    },
    {
        "content": "<p>like, there's basically a spectrum of possible designs of stdsimd, and we're coming at it with different opinions on where we want it to be.</p>\n<ol>\n<li>at one end is bacially: safe_arch but portable (expose everything, polyfill, broadly don't worry about coherency but do try to make the pieces rusty if possible)</li>\n<li>the other end is something more like wasm simd  (when in doubt, don't expose it, keep things simple even if limited)</li>\n</ol>\n<p>(and there's certainly more axes about what things we'd be willing to trade off on and such)</p>\n<p>I'm in the middle, but towrds the safe_arch side. i think exposing functionality is generally better, but it has to be weighed against a bunch of other metrics like complexity, understandability, performance, etc.</p>",
        "id": 212593247,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602092232
    },
    {
        "content": "<p>but i think theres a problem we have in that there's basically no agreement at all about this, which is a pretty core piece of the mission statement.</p>",
        "id": 212593309,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602092265
    },
    {
        "content": "<p>and thats why even a small thing like masking has caused so much controversy</p>",
        "id": 212593378,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602092287
    },
    {
        "content": "<p>Yeah, I think that's the core of the problem</p>",
        "id": 212593557,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602092392
    },
    {
        "content": "<p>I feel like I am being painted into the \"WASM SIMD\" corner, so I will say simply: I am not arguing for that.<br>\nI am arguing for what was in the announcement post we agreed on:<br>\n<a href=\"https://blog.rust-lang.org/inside-rust/2020/09/29/Portable-SIMD-PG.html\">https://blog.rust-lang.org/inside-rust/2020/09/29/Portable-SIMD-PG.html</a></p>\n<blockquote>\n<p>The portable SIMD API will enable writing SIMD code just once using a high-level API. By explicitly communicating your intent to the compiler, it's better able to generate the best possible final code. This is still only a best-effort process. If your target doesn't support a desired operation in SIMD, the compiler will fall back to using scalar code, processing one lane at a time. The details of what's available depend on the build target.</p>\n</blockquote>",
        "id": 212593690,
        "sender_full_name": "Jubilee",
        "timestamp": 1602092438
    },
    {
        "content": "<p>yeah sorry <span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span>, i suspect you're closer to the 2nd side than I am and I don't feel like i did a good job explaining your poitn</p>",
        "id": 212593708,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602092447
    },
    {
        "content": "<blockquote>\n<p>We will cover as many use cases as we can, but it might still be appropriate for you to use std::arch directly. For that reason the std::simd types will also be easily convertable to std::arch types where needed.</p>\n</blockquote>\n<p>conversion, not 1 = 1</p>",
        "id": 212593810,
        "sender_full_name": "Jubilee",
        "timestamp": 1602092514
    },
    {
        "content": "<p>and easy, not always and forever 0-cost for all possible conversions</p>",
        "id": 212593925,
        "sender_full_name": "Jubilee",
        "timestamp": 1602092553
    },
    {
        "content": "<p>To be fair, to me that means it would be perfectly appropriate (but certainly not required) to support narrow masks and on unsupported platforms allow it to fall back to scalar code</p>",
        "id": 212593935,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602092560
    },
    {
        "content": "<p>I'm not sure it's definitive in either direction</p>",
        "id": 212594009,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602092602
    },
    {
        "content": "<p>i think that statement is pretty vague unfortunately. or, fundamentally i kind of feel like it's unrealistic to push everything here into the compiler</p>",
        "id": 212594030,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602092615
    },
    {
        "content": "<p>From \"high-level\", I discern that my first concern is making sure that the API is higher-level than specific vendor intrinsics, which is why I'm wary of the approach that seems to argue for things mostly in the context of vendor intrinsics.</p>",
        "id": 212594165,
        "sender_full_name": "Jubilee",
        "timestamp": 1602092685
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212591618\">said</a>:</p>\n<blockquote>\n<p>this sounds snarky and i mean it respectfully: i don't know how you can think that adding a new separate family of simd masking types would help a developer with a no-more-than-typical level of familiarity with simd</p>\n</blockquote>\n<p>So, would you be happier with just the <code>m8x16</code> type that is either <code>&lt;16 x i8&gt;</code> or <code>&lt;16 x i1&gt;</code> depending on the particular architecture, without the <code>fullmask8x16</code> type? I think that's probably the core part of my proposal.</p>",
        "id": 212594241,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602092727
    },
    {
        "content": "<p>I believe there are higher-level patterns that can be relied on, and Jacob has been pretty astute in identifying how those can be sliced between arches, probably because they have the most, er, implementation side experience with hardware.</p>",
        "id": 212594346,
        "sender_full_name": "Jubilee",
        "timestamp": 1602092770
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"229517\">@Jacob Lifshay</span> i'm certainly more comfortable with it. especially if it is based on the arch, since i think handling levels of feature support would complicate things a lot.</p>",
        "id": 212594552,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602092871
    },
    {
        "content": "<p>I'm not sure you can simply divide it by architecture since Intel (like it or not, a major piece of market share) supports both paradigms</p>",
        "id": 212594569,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602092877
    },
    {
        "content": "<p>I mean so does AMD, and if anything I am a partisan for them.</p>",
        "id": 212594690,
        "sender_full_name": "Jubilee",
        "timestamp": 1602092924
    },
    {
        "content": "<p>I just meant intel since they designed the extension, but yeah really x86-64 as a whole</p>",
        "id": 212594746,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602092953
    },
    {
        "content": "<p>It further complicates things that if you're reaching for performance you'll want a different mask than if you're aiming for compatibility</p>",
        "id": 212594869,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602093005
    },
    {
        "content": "<p>As far as I see it, a slightly more opaque API on the mask end is mostly useful <em>as a lever to</em> achieve better performance overall.</p>",
        "id": 212595026,
        "sender_full_name": "Jubilee",
        "timestamp": 1602093095
    },
    {
        "content": "<p>I also don't think we can just swap masks on different architectures because wide masks can be transmuted to integer vectors and can be referenced as slices, and narrow vectors can't</p>",
        "id": 212595108,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602093129
    },
    {
        "content": "<p>I wouldn't be opposed to something like a mask trait and functions return <code>impl Mask</code>, but I still think you should have access to explicitly wide and narrow masks as well</p>",
        "id": 212595231,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602093204
    },
    {
        "content": "<p>My brain just offered this extremely cursed thought, so you all get to share in it:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">use</span><span class=\"w\"> </span><span class=\"n\">std</span>::<span class=\"n\">arch</span>::<span class=\"n\">x86_64</span>::<span class=\"n\">MaskExt</span><span class=\"p\">;</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 212595896,
        "sender_full_name": "Jubilee",
        "timestamp": 1602093538
    },
    {
        "content": "<p>I believe that, as usual with these things, we actually agree more than we disagree, but we are having trouble expressing the finer points of our agreements which are probably more important than the finer points of our disagreements.</p>",
        "id": 212597365,
        "sender_full_name": "Jubilee",
        "timestamp": 1602094220
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"312331\">Caleb Zulawski</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212595108\">said</a>:</p>\n<blockquote>\n<p>I also don't think we can just swap masks on different architectures because wide masks can be transmuted to integer vectors and can be referenced as slices, and narrow vectors can't</p>\n</blockquote>\n<p>Can't we just say <code>m8x16</code> has platform-specific layout and provide methods to convert from/to wide masks (<code>u8x16</code> or some mask-specific type) as well as narrow masks (either <code>u16</code> or some mask-specific type)?</p>",
        "id": 212599217,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602095128
    },
    {
        "content": "<p>or even unspecified layout</p>",
        "id": 212599254,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602095152
    },
    {
        "content": "<p>allowing us to use narrow masks with AVX512F and wide masks with AVX2 (assuming the compiler wants to implement that)</p>",
        "id": 212599440,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602095229
    },
    {
        "content": "<p>i mean you can bring the result of one mask operation elsewhere so idk how different layouts for those would work</p>",
        "id": 212599520,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602095275
    },
    {
        "content": "<p>unless they're different types</p>",
        "id": 212599564,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602095283
    },
    {
        "content": "<p>where it switches the layout based on the enabled features</p>",
        "id": 212599588,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602095296
    },
    {
        "content": "<p>i'm fine with it being arch specific though honestly</p>",
        "id": 212599595,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602095299
    },
    {
        "content": "<p>you mean enabled at compile time?</p>",
        "id": 212599833,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602095410
    },
    {
        "content": "<p>we'd want to have some logic for picking the in-memory layout based only on the global feature set, not the per-function features though, otherwise we end up with a problem</p>",
        "id": 212599838,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602095411
    },
    {
        "content": "<p>There's no way to change layout depending on target feature</p>",
        "id": 212599885,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602095439
    },
    {
        "content": "<p>compiler can be extended to add that? it knows the target features when calculating layout</p>",
        "id": 212599959,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602095484
    },
    {
        "content": "<p>And I think it's unlikely we can add that support either, most features like that have been deferred until rust has a hypothetical effects system</p>",
        "id": 212599981,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602095501
    },
    {
        "content": "<p>global features, that is</p>",
        "id": 212599992,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602095508
    },
    {
        "content": "<p>I don't think global feature set would work because core/std is delivered compiled</p>",
        "id": 212600101,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602095549
    },
    {
        "content": "<p>yeah according to  <a href=\"https://rust-lang.github.io/rfcs/2045-target-feature.html\">https://rust-lang.github.io/rfcs/2045-target-feature.html</a> the <code>cfg</code> value varies depending on which features have been enabled</p>\n<blockquote>\n<p>In a function annotated with #[target_feature(enable = \"feature_name\")] the macro cfg!(target_feature = \"feature_name\") expands to true if the generated code for the function uses the feature</p>\n</blockquote>",
        "id": 212600146,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602095572
    },
    {
        "content": "<p>That never actually made it to implementation</p>",
        "id": 212600202,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602095598
    },
    {
        "content": "<p>okay that makes a lot more sense</p>",
        "id": 212600233,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602095615
    },
    {
        "content": "<p>that said it could in the future maybe idk</p>",
        "id": 212600264,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602095635
    },
    {
        "content": "<p>There is no way to detect the current target features, and likely no way in the near future unfortunately</p>",
        "id": 212600311,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602095643
    },
    {
        "content": "<p>Would definitely solve a lot of headaches but I get why it's so hard to implement</p>",
        "id": 212600403,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602095690
    },
    {
        "content": "<p>not from rust source code, but the compiler knows -- it calculates the layout in the same process after all</p>",
        "id": 212600411,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602095697
    },
    {
        "content": "<p>It doesn't know what function you have been inlined into afaik</p>",
        "id": 212600489,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602095735
    },
    {
        "content": "<p>target_feature's design is pretty annoying tbh but it very much beats the situation in c/c++ where you have to compile everything separately and pray</p>",
        "id": 212600638,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602095792
    },
    {
        "content": "<p>if that doesn't work, we could just have it use the same in-memory layout for the arch and in the function ABI lowering convert vectors passed by value to the appropriate ABI -- just like the ABI of <code>f32x16</code> changes in C compilers if you enable/disable AVX512f</p>",
        "id": 212600800,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602095857
    },
    {
        "content": "<p>Actually I think it's nearly identical to target attributes in gcc and clang</p>",
        "id": 212600816,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602095866
    },
    {
        "content": "<p>I think at that point I would just prefer a completely opaque type and not support AVX512</p>",
        "id": 212601024,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602095940
    },
    {
        "content": "<p>so two notes: you can change the layout of a struct based on compile time features.</p>",
        "id": 212603419,
        "sender_full_name": "Lokathor",
        "timestamp": 1602097079
    },
    {
        "content": "<p>and two: i've yet to see <em>any</em> argument against having wide masks available everywhere and optional narrow masks as an extension you sometimes use</p>",
        "id": 212603568,
        "sender_full_name": "Lokathor",
        "timestamp": 1602097127
    },
    {
        "content": "<p>bigger api/more complex surface mostly.</p>",
        "id": 212605207,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602097786
    },
    {
        "content": "<p>but yes i was okay with this so long as it's not confusing which is the extension and which is the main api you're expected to work with.</p>",
        "id": 212605395,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602097856
    },
    {
        "content": "<p>but only people who delve into the extra layer care. this would be comparable to std::fs or whatever having unix and windows extensions. i just ignore those modules because i don't care to get into it.</p>",
        "id": 212605424,
        "sender_full_name": "Lokathor",
        "timestamp": 1602097879
    },
    {
        "content": "<p>it being like std::fs::unix implies it's not portable and we do kinda already have the nonportable simd api</p>",
        "id": 212605562,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602097936
    },
    {
        "content": "<p>uh, partly. it might be better to say that with enough PRs we will some day have avx512 coverage (and the simpleV arch stuff as well, again, \"someday\").</p>",
        "id": 212606197,
        "sender_full_name": "Lokathor",
        "timestamp": 1602098218
    },
    {
        "content": "<p>oh right avx512 isnt there</p>",
        "id": 212606289,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602098256
    },
    {
        "content": "<p>so i propose that we continue with wide masks, and then as an extension we can also support narrow masks, possibly to be stabilized separately because just generally the narrow mask targets are pretty experimentqal</p>",
        "id": 212606341,
        "sender_full_name": "Lokathor",
        "timestamp": 1602098276
    },
    {
        "content": "<p>fwiw RISCV-V is not SimpleV for note.<br>\nand GPUs aren't really experimental?</p>",
        "id": 212606414,
        "sender_full_name": "Jubilee",
        "timestamp": 1602098293
    },
    {
        "content": "<p>honestly at this point my will to have an opinion on masking has eroded so it sounds fine.</p>",
        "id": 212606418,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602098295
    },
    {
        "content": "<p>&lt;_&lt;;</p>",
        "id": 212606431,
        "sender_full_name": "Jubilee",
        "timestamp": 1602098302
    },
    {
        "content": "<p>aaaa.<br>\nI don't think we should be making hard decisions atm.</p>",
        "id": 212606488,
        "sender_full_name": "Jubilee",
        "timestamp": 1602098329
    },
    {
        "content": "<p>GPUs aren't experimental, but mixing code across GPUs, avx512, and simplev (or whatever it's called) <em>is experimental</em>, and so that's why we'd put it on hold</p>",
        "id": 212606548,
        "sender_full_name": "Lokathor",
        "timestamp": 1602098361
    },
    {
        "content": "<p>That's True.</p>",
        "id": 212606591,
        "sender_full_name": "Jubilee",
        "timestamp": 1602098375
    },
    {
        "content": "<p>(anyway sorry if i contributed to any bad vibes in this discussion, i feel like i might have unintentionally)</p>",
        "id": 212606604,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602098387
    },
    {
        "content": "<p>right, the best part about putting things on hold is that it's not a hard decision. you can always just take a thing off hold later</p>",
        "id": 212606606,
        "sender_full_name": "Lokathor",
        "timestamp": 1602098388
    },
    {
        "content": "<p>I basically am just mentally moving my internal estimate of where our \"stabilize masks\" date will be out to closer to our \"stabilize floats\" date, which is after our \"stabilize uints/sints\" date.</p>",
        "id": 212606786,
        "sender_full_name": "Jubilee",
        "timestamp": 1602098461
    },
    {
        "content": "<p>by stabilize you mean like, decide on? (i dont really think we should land something like on stable with gaps quite that big)</p>",
        "id": 212607090,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602098613
    },
    {
        "content": "<p>I think we can stabilize wide masks and delay narrow masks as long as we come to a conclusion that they are definitely different things, even if we don't decide how narrow masks are handled</p>",
        "id": 212607212,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602098669
    },
    {
        "content": "<p>...hrm.<br>\nI do not know how to communicate, I feel like.</p>",
        "id": 212607256,
        "sender_full_name": "Jubilee",
        "timestamp": 1602098704
    },
    {
        "content": "<p>sorry i think i got it</p>",
        "id": 212607283,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602098722
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212606341\">said</a>:</p>\n<blockquote>\n<p>so i propose that we continue with wide masks, and then as an extension we can also support narrow masks, possibly to be stabilized separately because just generally the narrow mask targets are pretty experimentqal</p>\n</blockquote>\n<p>I think it's fine to start out only with types that look like wide masks, but on targets such as RISC-V V those types should instead be narrow masks inside, since narrow masks are waay more efficient on RISC-V V and similar to the extent that I don't think bitwise logical ops are supported on float vectors without converting to a narrow mask first or converting the float vector to an integer vector, both of which can cost extra cycles.</p>\n<p>This wouldn't mean much at the API level for now other than transmutation between mask types and other vectors is not defined to always work, you just have to use conversions instead. The other difference is mostly just documentation.</p>",
        "id": 212615626,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602102852
    },
    {
        "content": "<p>Shouldn't you just prefer to use the narrow masks in that situation then? Rather than type trickery</p>",
        "id": 212617765,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602104059
    },
    {
        "content": "<p>yeah, if a device has no floating point unit and you have to do software floats instead, but <em>also</em> you could do fixed point, we'd just offer fixed point and leave the decision of when to swap over to the user. we wouldn't make normal floats magically change to fixed point in the background on you.</p>",
        "id": 212619200,
        "sender_full_name": "Lokathor",
        "timestamp": 1602104779
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"312331\">Caleb Zulawski</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212617765\">said</a>:</p>\n<blockquote>\n<p>Shouldn't you just prefer to use the narrow masks in that situation then? Rather than type trickery</p>\n</blockquote>\n<p>no, because you'd want your code to be portable between SSE2 and similar and RISC-V V.</p>",
        "id": 212635646,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602116574
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212619200\">said</a>:</p>\n<blockquote>\n<p>yeah, if a device has no floating point unit and you have to do software floats instead, but <em>also</em> you could do fixed point, we'd just offer fixed point and leave the decision of when to swap over to the user. we wouldn't make normal floats magically change to fixed point in the background on you.</p>\n</blockquote>\n<p>There's an important difference between your example and what I'm proposing: in your example the operations produce fundamentally different results, in what i'm proposing the results are exactly the same, only the representation is different.</p>",
        "id": 212635806,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602116726
    },
    {
        "content": "<p>I think you could abstract a subset of features in common with narrow and wide masks and use the same code on all architectures (with a trait)</p>",
        "id": 212635828,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602116758
    },
    {
        "content": "<p>But in many cases you want to have a known layout of the mask so you can transmute/convert it i think</p>",
        "id": 212635881,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602116789
    },
    {
        "content": "<p>some numbers can be represented in fp but not fixed point and vis versa. however, the two kinds of masks are 1:1 isomorphic.</p>",
        "id": 212635908,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602116830
    },
    {
        "content": "<p>I imagine there are even times with RISC-V you may want your comparison results to have lane width so you can transmute them to integers</p>",
        "id": 212636009,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602116951
    },
    {
        "content": "<p>Or to floats</p>",
        "id": 212636012,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602116955
    },
    {
        "content": "<p>Just as with other architectures it is sometimes useful to convert the narrow masks to a single integer</p>",
        "id": 212636079,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602117009
    },
    {
        "content": "<p>thinking a bit more another issue with e.g. <code>m16x8</code> changing its layout to <code>&lt;i1 x 8&gt;</code> on riscv is that it would be pretty reasonable for user code to assume <code>m16x8</code> is a type which has a well defined and reliable layout, given that it looks a ton like <code>i16x8</code>/<code>u16x8</code> which are this way... eg.. I'm worried about unsafe code doing things and then being unsound on riscv</p>",
        "id": 212636115,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602117071
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"312331\">Caleb Zulawski</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212635881\">said</a>:</p>\n<blockquote>\n<p>But in many cases you want to have a known layout of the mask so you can transmute/convert it i think</p>\n</blockquote>\n<p>then what you do is call the conversion function provided by <code>stdsimd</code> that converts from <code>m8x16</code> to <code>u8x16</code> if you want wide masks and to <code>u16</code> or some other type if you want narrow masks. This is kinda like <code>OsString</code> is internally UTF-8 (actually WTF-8) but on windows platforms can be converted to windows standard UTF-16 (mostly -- actually a nearly arbitrary sequence of u16)</p>",
        "id": 212636126,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602117098
    },
    {
        "content": "<p>Right, but if you are 90% there the loss of support for AVX512 at that point seems arbitrary</p>",
        "id": 212636229,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602117228
    },
    {
        "content": "<p>When this is definitely solved by a mask trait and conditionally compiled functions that use <code>impl Mask</code></p>",
        "id": 212636301,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602117268
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212636115\">said</a>:</p>\n<blockquote>\n<p>thinking a bit more another issue with e.g. <code>m16x8</code> changing its layout to <code>&lt;i1 x 8&gt;</code> on riscv is that it would be pretty reasonable for user code to assume <code>m16x8</code> is a type which has a well defined and reliable layout, given that it looks a ton like <code>i16x8</code>/<code>u16x8</code> which are this way... eg.. I'm worried about unsafe code doing things and then being unsound on riscv</p>\n</blockquote>\n<p>we can add lints to catch bad transmutes (suggesting conversion to the provided <code>convert</code> functions) and explicitly state that they have unspecified layout in the docs</p>",
        "id": 212636303,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602117272
    },
    {
        "content": "<p>we can also pick a different naming scheme if you think that might help, but I think the default mask type should be whatever <code>m8x16</code> and friends is renamed to</p>",
        "id": 212636352,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602117349
    },
    {
        "content": "<p>if we're going to do something fairly atypical like <code>impl Mask</code> i suspect we should try to quickly get to a point where the library can be used to write sample code (even if lots of other stuff is still subject to change), to flush out issues with te design. this is probably a good idea regardless...</p>",
        "id": 212636440,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602117403
    },
    {
        "content": "<p>You could even provide both wide and narrow masks as separate extension traits and purely use <code>impl Mask</code> as the default--in that case we don't favor a single implementation</p>",
        "id": 212636462,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602117438
    },
    {
        "content": "<p>honestly i'm pretty skeptical of a design which fundamentally from being able to store a mask in a struct or w/e because it's an impl Trait</p>",
        "id": 212636535,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602117498
    },
    {
        "content": "<p>or in an array, etc.</p>",
        "id": 212636545,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602117515
    },
    {
        "content": "<p>What I'm proposing is that you can have access to each type if you choose, with the implications of each, but by default it's purely an opaque type and you don't necessarily know which you have</p>",
        "id": 212636581,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602117563
    },
    {
        "content": "<p>Instead of a trait it could be an opaque type with unspecified layout, since that would solve some of the current limitations of impl trait</p>",
        "id": 212636680,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602117640
    },
    {
        "content": "<p>what about providing 3 types to cover all the special cases: <code>mask8x16</code>, <code>widemask8x16</code>, and <code>bitmaskx16</code>? obviously the names could use some help :)</p>",
        "id": 212636692,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602117650
    },
    {
        "content": "<p>that's a very large api surface area...</p>",
        "id": 212636736,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602117707
    },
    {
        "content": "<p>Yeah that may actually work, I think that's a balance of the suggestions you and <span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span> proposed with an opaque type, and the extension trait version I'm a fan of</p>",
        "id": 212636740,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602117712
    },
    {
        "content": "<p>Yeah, it is large, but I think the wide and bitmasks can be relegated to extension traits to make them easy to ignore until you need them</p>",
        "id": 212636805,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602117750
    },
    {
        "content": "<p>i would very strongly prefer to avoid any more unspecified layout types</p>",
        "id": 212636809,
        "sender_full_name": "Lokathor",
        "timestamp": 1602117759
    },
    {
        "content": "<p>How do you feel about impl trait instead?</p>",
        "id": 212636838,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602117798
    },
    {
        "content": "<p>yeah i don't want it to be unspecified. i also don't want masking to be over half of the api surface but i guess i liek a bunch of concrete types slightly more than i like it being a <code>impl Trait</code></p>",
        "id": 212636901,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602117862
    },
    {
        "content": "<p>what about defining the generic mask type to be a repr(transparent) wrapper around one of the other mask types? it would have a associated type with the wrapped mask type. we could also potentially have cfg flags for which kind of masks is default, kinda like the cfg flags for which atomic widths are supported</p>",
        "id": 212636994,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602117992
    },
    {
        "content": "<p>That would make it very easy to write code that compiles on some architectures but not others</p>",
        "id": 212637070,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602118100
    },
    {
        "content": "<p>if i'm being totally honest, it feels like an unreasonable amount of complexity to throw at the problem</p>",
        "id": 212637071,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602118105
    },
    {
        "content": "<p>(... eh, i should stop for a bit, this is just driving me crazy)</p>",
        "id": 212637091,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602118155
    },
    {
        "content": "<p>SIMD is messy</p>",
        "id": 212637108,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602118197
    },
    {
        "content": "<p>The impl trait solution would actually only duplicate the API (which is extra complexity, yes, but not too bad).  You could make a mask trait, which abstracts over masks, and a mask extension trait that provides the API over normal vectors</p>",
        "id": 212637286,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602118372
    },
    {
        "content": "<p>my concern for impl trait is mostly ergonomics. it's also pretty uncommon to find in stdlib apis.</p>",
        "id": 212637318,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602118404
    },
    {
        "content": "<p>Then you can copy the extension trait methods as inherent methods that return impl Mask</p>",
        "id": 212637329,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602118417
    },
    {
        "content": "<p>I agree it's not the best ergonomics</p>",
        "id": 212637368,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602118443
    },
    {
        "content": "<p>At least not on stable yet</p>",
        "id": 212637387,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602118461
    },
    {
        "content": "<p>You could use an opaque type that implements the mask trait as well but that doesn't seem as elegant</p>",
        "id": 212637425,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602118522
    },
    {
        "content": "<p>i feel like the design of masking is threatening to become one of the largest and most complex apis in the whole stdlib, which feels like a failure to me, and bodes poorly for the project. <em>sigh</em></p>",
        "id": 212637427,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602118524
    },
    {
        "content": "<p>I don't actually think masks have too many functions, fortunately.</p>",
        "id": 212637437,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602118557
    },
    {
        "content": "<p>Comparisons, blends</p>",
        "id": 212637485,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602118573
    },
    {
        "content": "<p>Masked loads and stores</p>",
        "id": 212637490,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602118584
    },
    {
        "content": "<p>yeah i mean, i feel like we're still not even close to on the same page about whether this should be something like \"safe_arch but portable\" or something higher level. i definitely feel like the design now is leaning towards</p>\n<ul>\n<li>be safe_arch but portable</li>\n<li>try to distract from this fact by adding more complexity on top</li>\n</ul>\n<p>which just feels like the worst possible option. anyway, i'm out for a bit.</p>",
        "id": 212637630,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602118782
    },
    {
        "content": "<p>I think that problem is unique to masks since they're handled so fundamentally differently by different instruction sets</p>",
        "id": 212637962,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602119128
    },
    {
        "content": "<p>But I agree that we haven't really settled that completely</p>",
        "id": 212638018,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602119170
    },
    {
        "content": "<p>Though I'm not sure \"safe_arch but portable\" is the right way to look at it, target-feature 1.1 handles the safe portion of that (or should, at least)</p>",
        "id": 212638091,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602119269
    },
    {
        "content": "<p>sorta. safe_arch provides reference based apis in some sports so the pointer using functions are kept valid</p>",
        "id": 212638180,
        "sender_full_name": "Lokathor",
        "timestamp": 1602119368
    },
    {
        "content": "<p>Yeah, that's definitely something to handle here</p>",
        "id": 212638185,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602119394
    },
    {
        "content": "<p>I think I'm going to re-state my position even though it has essentially not changed since last time: We proceed with wide masks as default, and narrow masks are available as a set of extensions that you can access if you know it will help you on a specific platform.</p>",
        "id": 212638280,
        "sender_full_name": "Lokathor",
        "timestamp": 1602119491
    },
    {
        "content": "<p>That is the simplest, most future-compatible plan, which also serves the most users as best as possible.</p>",
        "id": 212638356,
        "sender_full_name": "Lokathor",
        "timestamp": 1602119564
    },
    {
        "content": "<p>Yeah I guess I should clarify what I meant:</p>\n<p>safe_arch exposes a safe version of the entire API of every intel ISA. That is to say, if an operation exists and can possibly be exposed safely, it is, even if it's weird, redundant, and etc.</p>\n<p>The reason I make this comparison is: Exposing multiple families of mask types because some ISAs handle one more efficiently than the other very much feels like this. </p>\n<p>Now, we do have the option of saying: \"okay, anything any simd ISA can do, we should have a portable version we expose.\" This is basiclaly what <span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span>  was suggesting earlier. I'm actually not even opposed to that if it's the explicit design decision, and i don't think safe_arch is a bad library. I think the result will be a large and complex API, but it also would be undeniably useful for a lot of stuff.</p>\n<p>Now, I won't lie and say it would be my choice for what the best thing to do here is — it's also very different from the charter that I saw earlier. IMO a <em>good</em> API needs to be willing to cut functionality in order to keep things simple even if it means not every case can be optimally handled.</p>\n<p>That said, perhaps this group just can't come to agreements here, and other design are worth considering.</p>",
        "id": 212638792,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602120112
    },
    {
        "content": "<p>Just as a quick footnote before I do go:</p>\n<blockquote>\n<p>I think that problem is unique to masks since they're handled so fundamentally differently by different instruction sets</p>\n</blockquote>\n<p>It's just an example of a case where we can't provide a single operation that's optimal everywhere. Whenever this happens we will have the choice to weigh the various tradeoffs and make a choice for one over the others, or expose multiple similar operations (increasing API complexity).</p>\n<p>I think this kind of thing is basically <em>everywhere</em> in this problem domain, and is not at all unique to masks (even if masks are worse because the duplication requires a large family of types instead of just like, two functions).</p>\n<p>Our discussion here kinda makes me feel like a decision to cut will be frequently a big uphill fight, which is just exhausting (although perhaps it will depend on which ISAs are pessimized)...</p>\n<p>(Anyway, I'm genuinely not opposed to just deciding up front to expose it all — that's honestly simpler in a lot of ways...)</p>",
        "id": 212639187,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602120607
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212638356\">said</a>:</p>\n<blockquote>\n<p>That is the simplest, most future-compatible plan, which also serves the most users as best as possible.</p>\n</blockquote>\n<p>simple it may be, but I'd argue it's not the best one for the future: recently I've seen various SIMD instruction sets moving to narrower masks, as part of enabling predicated execution and reducing power usage: AVX512 (1 bit per lane), ARM SVE (1 bit per byte), RISC-V V (1 bit per lane), SimpleV (1 bit per lane). the only recently designed SIMD instruction set that i've seen that doesn't use narrower masks is RISC-V P which is designed for embedded processors and probably integer only. All the other SIMD instruction sets I'm aware of were designed more than 10 years ago or are small extensions of existing SIMD instruction sets.</p>",
        "id": 212639400,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602120937
    },
    {
        "content": "<p>there's also the NEC SX-Aurora which is also 1 bit per lane</p>",
        "id": 212640016,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602121632
    },
    {
        "content": "<p>I wouldn't overcalibrate on this dispute, I think it's just a consequence of everyone kind of bumbling in with the assumption that everyone else was on exactly the same page and then realizing \"oh wait, we are actually on pretty different footing in many places\", it just took an issue with this amount of nuance for these differences to be fully exposed. I also think there's differences in perceived difficulties for various approaches, and a need to discuss things with other teams, and we will eventually sort things out.</p>\n<p>We just have to keep talking and eventually Aumann's agreement theorem will kick in.</p>",
        "id": 212725721,
        "sender_full_name": "Jubilee",
        "timestamp": 1602179179
    },
    {
        "content": "<p>I choose to act irrationally. All masks must be 3 bits</p>",
        "id": 212725820,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602179243
    },
    {
        "content": "<p>lol</p>",
        "id": 212725842,
        "sender_full_name": "Jubilee",
        "timestamp": 1602179258
    },
    {
        "content": "<p>as long as you <a href=\"https://www.youtube.com/watch?v=wbOTkDn49qI\">https://www.youtube.com/watch?v=wbOTkDn49qI</a></p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"wbOTkDn49qI\" href=\"https://www.youtube.com/watch?v=wbOTkDn49qI\"><img src=\"https://i.ytimg.com/vi/wbOTkDn49qI/default.jpg\"></a></div>",
        "id": 212725932,
        "sender_full_name": "Jubilee",
        "timestamp": 1602179285
    },
    {
        "content": "<p>&lt;ignore this sent to wrong topic&gt;</p>",
        "id": 212731921,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602182105
    },
    {
        "content": "<p>FWIW I said before about the charter</p>\n<blockquote>\n<p>i kind of feel like it's unrealistic to push everything here into the compiler</p>\n</blockquote>\n<p>I take this back. I hadn't realized that ultimately the implementation strategy it describes is very close to what <code>packed_simd</code> currently does, so yeah.</p>\n<p>I still think it's kinda vague (and it comes very close to invoking a sufficiently smart compiler\")... but I can firm details up by reviewing packed_simd's implementation strategy.</p>\n<p>This doesn't answer any questions around masking, but I'm less terrified of the thought of having 1000 more of these threads as we go through every piece of SIMD functionality.</p>",
        "id": 212736151,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602184300
    },
    {
        "content": "<p>I believe we will have gradually less of these as more information diffuses, but we're going to have, mm, probably three more before we have enough information diffusion to get all the hidden assumptions into the open and then start taking them down. One of them might be more acrimonious than this one! That one will be fun (not).</p>\n<p><del>And it's true that a lot of stuff requires a \"sufficiently smart compiler\" but really it's 2020, if your compiler isn't serving you breakfast in bed you need to be upping your expectations.</del></p>",
        "id": 212794818,
        "sender_full_name": "Jubilee",
        "timestamp": 1602231140
    },
    {
        "content": "<p>...huh, simd_select truncates to i1xN? <a href=\"https://github.com/rust-lang/rust/commit/9a44448a252a94bf6b99388cab82aa9cd4595207#diff-811abed36cfd18fc1f7a6af984e0fd39R1170\">https://github.com/rust-lang/rust/commit/9a44448a252a94bf6b99388cab82aa9cd4595207#diff-811abed36cfd18fc1f7a6af984e0fd39R1170</a></p>",
        "id": 212878889,
        "sender_full_name": "Jubilee",
        "timestamp": 1602279802
    },
    {
        "content": "<p>the issue with i1xN was only when llvm could not see where it was coming from. e.g. if it came from something that failed to get inlined it would cause terrible code, otherwise it was fine.</p>",
        "id": 212879005,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602279886
    },
    {
        "content": "<p>nod.</p>",
        "id": 212879023,
        "sender_full_name": "Jubilee",
        "timestamp": 1602279901
    },
    {
        "content": "<p>That this is already the implicit mask vector does suggest that either the LLVM repr is less of a problem than expected or we have Deeper Problems.</p>",
        "id": 212879128,
        "sender_full_name": "Jubilee",
        "timestamp": 1602279967
    },
    {
        "content": "<p>it seemed like when reading/wriing to memory or returning across function boundaries it turnd &lt;i1 x N&gt; into a concrete representation (possibly [bool; N]) and then had to undo that on the other side. e.g. the &lt;i1 x N&gt; is only good if its actually allowed to be represented that way</p>",
        "id": 212879337,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602280099
    },
    {
        "content": "<p>that is: <a href=\"https://gcc.godbolt.org/z/3YjbW3\">https://gcc.godbolt.org/z/3YjbW3</a></p>\n<ul>\n<li>on line 3 the function returns the &lt;i1 x N&gt;</li>\n<li>on line 8 the the returned value is given to a call</li>\n</ul>\n<p>this is an optimization bounary because llvm doesnt know on line 3 what the caller will need, and so on line 8 it ends up having to do a crapload of work.</p>\n<p>conversely, if llvm does know what the caller needs, it can keep things in the optimal format, which is why f_sse_inlined does great.</p>",
        "id": 212879824,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602280471
    },
    {
        "content": "<p>as i see it, the problem is we can't ensure that &lt;i1 x N&gt; values have ambiguous representations forever and then just use the optimal thing everywhere — llvm would need to do whole program optimization for that sort of thing. </p>\n<p>in practice, functions that dont get inlined, and values that are loaded from memory are probably going to have that problem.</p>",
        "id": 212879940,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602280573
    },
    {
        "content": "<p>yeah, in general we need to make our worst case as good as possible, not the other way around.</p>",
        "id": 212880000,
        "sender_full_name": "Lokathor",
        "timestamp": 1602280635
    },
    {
        "content": "<p>we could try and file an llvm bug about this but it seems very unsurprising that this is the way this works.</p>",
        "id": 212880016,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602280651
    },
    {
        "content": "<p>FWIW in the past couple days i pretty much decided i'd be fine with the 3 mask types design. or at least, we can try it for a while and go from there, and take a look later after more of the api is there to bounce against</p>",
        "id": 212880246,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602280815
    },
    {
        "content": "<p>i think 2 types (bitmasks and wide masks) would probably be better though since they do enable different sets of algorithms, even if there is overlap.</p>\n<p>the 3rd type (the more limited/representation-unspecified type which uses the fast thing for your target) seems more problematic to me still</p>",
        "id": 212880666,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602281174
    },
    {
        "content": "<p>Other than the number of types, the API is actually uncomplex</p>",
        "id": 212881049,
        "sender_full_name": "Lokathor",
        "timestamp": 1602281586
    },
    {
        "content": "<p>I wonder--what are the chances some other form of mask becomes common in the future, if we already have 2?</p>",
        "id": 212881174,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602281706
    },
    {
        "content": "<p>Not that I can think of any other way to possibly do it but who knows</p>",
        "id": 212881175,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602281706
    },
    {
        "content": "<p>and after looking through packed_simd and thinking both: \"wow this is a lot\" and \"yep seems like we'll certainly want a lot of this\", the number of mask types doesn't bother me as much. i also think it's plausible that moving forward will either reduce or increase our concerns around what llvm does when it can't inline mask code, and a good way to know is to go forward</p>",
        "id": 212881223,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602281754
    },
    {
        "content": "<p>oh i wanted to ask <span class=\"user-mention\" data-user-id=\"312331\">@Caleb Zulawski</span>, the avx512 mask instructions, do those trigger the frequency transition you get from some avx512 ops?</p>",
        "id": 212881439,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602281948
    },
    {
        "content": "<p>On full 512 bit vectors yes</p>",
        "id": 212881571,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602282042
    },
    {
        "content": "<p>On smaller vectors I don't believe so (though of course AVX has its own frequency drop)</p>",
        "id": 212881603,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602282074
    },
    {
        "content": "<p>I should note that the exact details of the transition and the overhead vary based on CPU</p>",
        "id": 212888796,
        "sender_full_name": "Jubilee",
        "timestamp": 1602288045
    },
    {
        "content": "<p>yeah i'm not more worried about it now than i was before. in practice it does make \"use wider vectors\" sometimes dodgy but with an api like we have here going back and forth to experiment should be roughly trivial. it has always worried me a little about 512 tho, but that's not to say that worry impacts the api design at all</p>",
        "id": 212889265,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1602288220
    },
    {
        "content": "<p>With avx512 going wider can be worth it despite the frequency change if you're doing a lot of masking since it's essentially free. Straight math doesn't see as much of a benefit</p>",
        "id": 212889547,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602288525
    },
    {
        "content": "<p>(I assume the compiler will be smart enough to merge mask and math ops from std::simd)</p>",
        "id": 212889605,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1602288590
    },
    {
        "content": "<p>as long as we don't promise specific instructions we can continue tweaking performance concerns based on AVX512 and such well into 2030.</p>",
        "id": 212894397,
        "sender_full_name": "Jubilee",
        "timestamp": 1602296226
    },
    {
        "content": "<p>but in 2031 avx512 will be cancalled and everyone will have to move on with life.</p>",
        "id": 212897928,
        "sender_full_name": "Lokathor",
        "timestamp": 1602302787
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/257879-project-portable-simd/topic/The.20movemasquerade/near/212880246\">said</a>:</p>\n<blockquote>\n<p>FWIW in the past couple days i pretty much decided i'd be fine with the 3 mask types design. or at least, we can try it for a while and go from there, and take a look later after more of the api is there to bounce against</p>\n</blockquote>\n<p>:)</p>\n<p>One additional benefit of the 3 mask type design is it allows platforms that default to even weirder mask types to use that for the representation-unspecified mask type, instead of having to use one or the other of the already defined mask types.</p>",
        "id": 212946366,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1602386656
    },
    {
        "content": "<p>To bring back this discussion, I've opened a review on an initial design that supports multiple mask types: <a href=\"https://github.com/rust-lang/stdsimd/pull/44\">https://github.com/rust-lang/stdsimd/pull/44</a></p>",
        "id": 214894644,
        "sender_full_name": "Caleb Zulawski",
        "timestamp": 1603917628
    },
    {
        "content": "<p>Nominated for our next sync up <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 215190209,
        "sender_full_name": "Ashley Mannix",
        "timestamp": 1604148491
    }
]