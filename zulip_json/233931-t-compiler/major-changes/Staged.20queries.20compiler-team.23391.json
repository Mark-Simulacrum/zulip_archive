[
    {
        "content": "<p>Creating the topic manually as it didn't happen automatically.</p>",
        "id": 220720924,
        "sender_full_name": "bjorn3",
        "timestamp": 1608662520
    },
    {
        "content": "<blockquote>\n<p>Nothing to AST,</p>\n</blockquote>\n<p>I don't think it will ever be possible to use queries for macro expansion/name resolution due to it being a fixpoint algorithm. For parsing I don't think it is really beneficial either.</p>\n<blockquote>\n<p>AST to HIR,</p>\n</blockquote>\n<p>Same as for parsing I think.</p>\n<blockquote>\n<p>HIR to MIR,<br>\nMIR to LLVM bitcode.</p>\n</blockquote>\n<p>Do you have any estimate about how much queries require HIR and can eagerly be invoked without having to wait till codegen?</p>",
        "id": 220721261,
        "sender_full_name": "bjorn3",
        "timestamp": 1608662760
    },
    {
        "content": "<p>TBH, the stages were indicative. I don't know anything about what happens before lowering.</p>",
        "id": 220724346,
        "sender_full_name": "cjgillot",
        "timestamp": 1608664633
    },
    {
        "content": "<p>I don't have stats, and I am not sure of how we should count. Quite a few queries are eagerly invoked in order to produce metadata. Among them: a lot of typing information + promoted &amp; optimized MIR.</p>",
        "id": 220724552,
        "sender_full_name": "cjgillot",
        "timestamp": 1608664768
    },
    {
        "content": "<p>As a first step, I would like to create the split at MIR creation, so that everything that happens on MIR (borrow check &amp; optimisations) happens without the HIR.</p>",
        "id": 220724745,
        "sender_full_name": "cjgillot",
        "timestamp": 1608664881
    },
    {
        "content": "<p>And thanks for creating the topic :)</p>",
        "id": 220724792,
        "sender_full_name": "cjgillot",
        "timestamp": 1608664918
    },
    {
        "content": "<p>cc <span class=\"user-group-mention\" data-user-group-id=\"3282\">@wg-incr-comp</span></p>",
        "id": 220725374,
        "sender_full_name": "cjgillot",
        "timestamp": 1608665286
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"248906\">cjgillot</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Staged.20queries.20compiler-team.23391/near/220724346\">said</a>:</p>\n<blockquote>\n<p>TBH, the stages were indicative. I don't know anything about what happens before lowering.</p>\n</blockquote>\n<p>FYI, we tried to write <a href=\"https://rustc-dev-guide.rust-lang.org/overview.html#what-the-compiler-does-to-your-code\">a list of the different steps of compilation</a> in the rustc-dev-guide, but it's still got TODOs in unfortunate places</p>",
        "id": 220725836,
        "sender_full_name": "LÃ©o Lanteri Thauvin",
        "timestamp": 1608665576
    },
    {
        "content": "<p>I like the idea in principle, but I'm too big of a noob to comment on specifics. <span aria-label=\"big smile\" class=\"emoji emoji-1f604\" role=\"img\" title=\"big smile\">:big_smile:</span></p>\n<p>I've had similar ideas while thinking of ways to reduce memory usage. In general, I think the idea of splitting compilation into a small set of well-defined stages, so that we can prune unnecessary data as we go along, could be profitable.</p>\n<p>I kind of assumed that traditional compiler design used a more staged approach in this vein, and wondered if the query system intentionally avoided that approach to enable more flexibility. In any case, I assume there's a flexibility tradeoff here. Ideally, there are some very clear stages where we know we will never need any data that we've pruned at previous stage boundaries. Then flexibility wouldn't really be a concern.</p>\n<p>Pruning could also be applicable beyond the query system. E.g. maybe it's possible to prune no-longer-useful interned / arena'd data. It's beyond the scope of the proposal, but it would be worth thinking about in advance, in case any mechanisms can be shared.</p>",
        "id": 220726522,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1608666005
    },
    {
        "content": "<p>the issue with a staged approach is it breaks incremental, it means you need to recalculate all the data even if you don't use it</p>",
        "id": 220726612,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1608666096
    },
    {
        "content": "<p>has anyone tried doing <code>drop(queries.hir().steal());</code> and seeing if that 'just works'?</p>",
        "id": 220726636,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1608666117
    },
    {
        "content": "<p>I guess you need somewhere to call it <em>from</em></p>",
        "id": 220726839,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1608666242
    },
    {
        "content": "<p>dropping the hir before codegen would require us to force all needed queries before then <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> I think changing <code>tcx.hir</code> to return <code>Steal</code> and then dropping it after mir building/analysis would be quite insightful and not too difficult hopefully</p>",
        "id": 220731121,
        "sender_full_name": "lcnr",
        "timestamp": 1608669102
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"232545\">Joshua Nelson</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Staged.20queries.20compiler-team.23391/near/220726612\">said</a>:</p>\n<blockquote>\n<p>the issue with a staged approach is it breaks incremental, it means you need to recalculate all the data even if you don't use it</p>\n</blockquote>\n<p>I am not so sure of that. By calling <code>ensure</code> on the output queries, we can avoid loading the data from the cache if its not used by later stages. Anyway, a lot of information is already forced for metadata output. I will aim at not forcing more queries manually.</p>",
        "id": 220737514,
        "sender_full_name": "cjgillot",
        "timestamp": 1608673647
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"216206\">lcnr</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Staged.20queries.20compiler-team.23391/near/220731121\">said</a>:</p>\n<blockquote>\n<p>dropping the hir before codegen would require us to force all needed queries before then <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> I think changing <code>tcx.hir</code> to return <code>Steal</code> and then dropping it after mir building/analysis would be quite insightful and not too difficult hopefully</p>\n</blockquote>\n<p>I tried to. I wanted to drop the HIR after all MIR is built. The trouble is that HIR data is appears in  a lot of queries. Furthermore, the <code>'tcx</code> lifetime is the one of the HIR (more precisely, of the arena which is declared in rustc_interface). Dropping this arena without having dangling pointers everywhere would require to drop a lot of query results.</p>\n<p>About the point where the call to <code>steal</code> is done, it should be after having forced all the MIR to be built.</p>\n<p>In summary, we get to this proposal.</p>",
        "id": 220737806,
        "sender_full_name": "cjgillot",
        "timestamp": 1608673865
    },
    {
        "content": "<p>I thinl it should at least be possible to drop (or make empty) the hir::Crate without dropping the arena backing certain parts of the hir that can be borrowed.</p>",
        "id": 220738157,
        "sender_full_name": "bjorn3",
        "timestamp": 1608674142
    },
    {
        "content": "<p>I'll have to read the backscroll, but I am mildly dubious of this -- part of our goal with the query system was to allow particular things to be compiled without forcing all things to be compiled</p>",
        "id": 226005049,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1613056512
    },
    {
        "content": "<p>Is there some place where ongoing design discussion is happening? (wg-incr-comp, maybe?)</p>",
        "id": 226005170,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1613056553
    },
    {
        "content": "<p>I mgiht be interested in joining some discussions on this topic</p>",
        "id": 226005180,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1613056558
    },
    {
        "content": "<p>There is no real discussion place about this. However, I am available in this thread.</p>",
        "id": 226023885,
        "sender_full_name": "cjgillot",
        "timestamp": 1613063268
    },
    {
        "content": "<p>My initial consideration is the following: a few queries are forced for all definitions, to emit metadata. As a consequence, I wonder whether embedding this systematic forcing into the query system would allow \"checkpoints\" where we can clear the caches.</p>",
        "id": 226025296,
        "sender_full_name": "cjgillot",
        "timestamp": 1613063730
    },
    {
        "content": "<p>For longer-term design, I started an incr-comp roadmap thread here, with an unsorted brain dump<br>\n<a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/Roadmap.20and.20projects.20for.20incr-comp\">https://rust-lang.zulipchat.com/#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/Roadmap.20and.20projects.20for.20incr-comp</a></p>",
        "id": 226025477,
        "sender_full_name": "cjgillot",
        "timestamp": 1613063812
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116009\">nikomatsakis</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Staged.20queries.20compiler-team.23391/near/226005170\">said</a>:</p>\n<blockquote>\n<p>Is there some place where ongoing design discussion is happening? (wg-incr-comp, maybe?)</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span>  I am currently revising the WG list on the <a href=\"https://rust-lang.github.io/compiler-team/\">compiler team page</a> and just just noticed that @_<em>wg-incr-comp</em> has no page in that directory but has a Zulip presence under <a class=\"stream\" data-stream-id=\"241847\" href=\"/#narrow/stream/241847-t-compiler.2Fwg-incr-comp\">#t-compiler/wg-incr-comp</a> and regular checkins at the compiler team meetings.<br>\nSo, worth adding some content for @_<em>wg-incr-comp</em> there, too?</p>",
        "id": 226032082,
        "sender_full_name": "apiraino",
        "timestamp": 1613066410
    },
    {
        "content": "<p>This was probably our (wg-incr-comp) fault. We can add a page there.</p>",
        "id": 226035181,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1613067709
    },
    {
        "content": "<p>Yes</p>",
        "id": 226192021,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1613161763
    },
    {
        "content": "<p>the list needs to be revisited</p>",
        "id": 226192036,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1613161769
    },
    {
        "content": "<p>perhaps the mechanism for maintaining it, too =)</p>",
        "id": 226192053,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1613161776
    },
    {
        "content": "<p>I feel like maybe it'd be better to move that list to the team repo</p>",
        "id": 226192064,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1613161785
    },
    {
        "content": "<p>Would it be possible to drop a hir::Body once the corresponding mir::Body is generated?</p>",
        "id": 226231697,
        "sender_full_name": "bjorn3",
        "timestamp": 1613200598
    },
    {
        "content": "<p>if we wrap all <code>hir::Body</code>s in a <code>Steal</code>, this would work quite easily I would think</p>",
        "id": 226242096,
        "sender_full_name": "oli",
        "timestamp": 1613218015
    },
    {
        "content": "<p>Just a passing thought -- I'm wondering if we could avoid keeping all past queries in memory, e.g., with some kind of speculation/prediction/whatever</p>",
        "id": 232771159,
        "sender_full_name": "simulacrum",
        "timestamp": 1617289234
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> in other words, determine what a good cache eviction strategy might be, and then impose an optional limit on the size of the query cache?</p>",
        "id": 233307604,
        "sender_full_name": "pnkfelix",
        "timestamp": 1617711225
    },
    {
        "content": "<p>yeah, we'd need to be careful around diagnostics/side-effects, but otherwise yes :)</p>",
        "id": 233307678,
        "sender_full_name": "simulacrum",
        "timestamp": 1617711255
    },
    {
        "content": "<p>in theory you might even always want it, if you have sufficient fast cpu that fitting the query cache, in, say l3 is better for you</p>",
        "id": 233307729,
        "sender_full_name": "simulacrum",
        "timestamp": 1617711288
    },
    {
        "content": "<p>maybe. Might depend on how much RAM you have, right?</p>",
        "id": 233307841,
        "sender_full_name": "pnkfelix",
        "timestamp": 1617711343
    },
    {
        "content": "<p>(iâm assuming this stuff will always tend to exhaust the L1/L2/L3 cache, at leastâ¦)</p>",
        "id": 233307961,
        "sender_full_name": "pnkfelix",
        "timestamp": 1617711391
    },
    {
        "content": "<p>yeah, maybe -- well, more so the RAM vs CPU speed; it might be faster in some cases to recompute the query, I guess, though it definitely depends on the query</p>",
        "id": 233308296,
        "sender_full_name": "simulacrum",
        "timestamp": 1617711593
    },
    {
        "content": "<p>I know we had some which were like basically a hash table lookup, caching that in a hash table is 100% pointless and wasteful</p>",
        "id": 233308369,
        "sender_full_name": "simulacrum",
        "timestamp": 1617711610
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Staged.20queries.20compiler-team.23391/near/233308369\">said</a>:</p>\n<blockquote>\n<p>I know we had some which were like basically a hash table lookup, caching that in a hash table is 100% pointless and wasteful</p>\n</blockquote>\n<p>Hmm. My first reaction was <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span>. My second reaction was âwait, thatâs a different problem from cache eviction though, right? I.e., identifying cases that should never be cached at all?â My third reaction is now: âI guess there may be a spectrum here: Things that shoud never be cached, to things that may be useful to evict, and presumably there are things that, once computed, should never be evictedâ¦\"</p>",
        "id": 233312466,
        "sender_full_name": "pnkfelix",
        "timestamp": 1617713543
    },
    {
        "content": "<p>yeah, there's likely a spectrum. for some things a cache may make sense, but perhaps we do a bunch of queries on one thing and then never again. I don't know if we have hit rate metrics in a more granular (i.e. not overall hit rate, but per-element) way</p>",
        "id": 233313842,
        "sender_full_name": "simulacrum",
        "timestamp": 1617714046
    },
    {
        "content": "<p>a per-element hit rate sounds like a good thing to capture. The evolution of the hit rate over time might also be useful.</p>",
        "id": 233321289,
        "sender_full_name": "pnkfelix",
        "timestamp": 1617716879
    },
    {
        "content": "<p>I guess there are actually two problems this proposal can address: (1) how to release memory for query results we do not need any more, and (2) how to convert between different representations of the crate.</p>\n<p>On point 1, there can be many other answers. For instance, having a more systematic use of <code>Steal</code> along with caching just after the query computation (instead of at the end of compilations); having recomputable queries like <span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span>  suggests... For now, the query system does not allow to recompute its results. Allowing that should be doable, but certainly very subtle to do efficiently (most notably: how to ensure the results are exactly the same without going through the full query code path?).</p>\n<p>Point 2 is only interesting in the perspective of end-to-end queries. The most prominent issue here is iterating all LocalDefIds when queries can create new LocalDefIds. Having a staged query system could allow progress on incremental front-end (macro expansion and incremental parsing, if anybody actually wants make those incremental), while allowing for time to design and join everything cleanly.</p>",
        "id": 233359045,
        "sender_full_name": "cjgillot",
        "timestamp": 1617730449
    }
]