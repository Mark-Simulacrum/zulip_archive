[
    {
        "content": "<p>A new proposal has been announced <a href=\"https://github.com/rust-lang/compiler-team/issues/278\" title=\"https://github.com/rust-lang/compiler-team/issues/278\">#278</a>. It will be brought up at the next meeting.</p>",
        "id": 195224015,
        "sender_full_name": "triagebot",
        "timestamp": 1587751198
    },
    {
        "content": "<p>I do have a few questions from a detailed reading of your proposal, the PR and the related issues:</p>",
        "id": 195842947,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1588255359
    },
    {
        "content": "<ul>\n<li>Since the llvm-profdata tool is tied to the LLVM version, how do we expect users to obtain that tool? Will they be required to build our LLVM fork or will the tool be available via rustup? I think, as this is an unstable compiler flag, pretty much any answer is fine but we should have some plan for stabilizing this flag.</li>\n</ul>",
        "id": 195842974,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1588255368
    },
    {
        "content": "<ul>\n<li>Introducing so many calls to the __incr_cov function will create a lot of additional control flow edges (and a lot more MIR). It seems like this could lead to a lot of additional work done during compile time. Does clang take a similar approach? What impact does that typically have on their compilation time? How is the compilation performance of the existing prototype you have? Do you have any thoughts about whether this hits an \"acceptable\" bar for compiler performance?</li>\n</ul>",
        "id": 195842995,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1588255380
    },
    {
        "content": "<ul>\n<li>Like many others on the PR and linked issues, my initial thought was that this would be a MIR pass. Having used poor quality tools in the past, I certainly agree with @bob-wilson's points regarding the quality of the code coverage reporting being critical to this feature. Still, my gut says that this should be done at least at the HIR level. I think I'm worried that by basing this pass on the AST, it will break much more frequently as the AST is changed than if it was based on a lower-level construct like the HIR. Do you have thoughts about what could be done to minimize regressions in the code coverage due to changes in the AST, for example, when adding new syntax?</li>\n</ul>",
        "id": 195843016,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1588255389
    },
    {
        "content": "<ul>\n<li>It sounds like you implemented two prototypes, one based on MIR transforms and one on the AST approach. Did you find issues regarding the quality of code coverage information generated from the MIR pass that the AST approach fixed? Or was the primary issue the implementation complexity that you mentioned above?</li>\n</ul>",
        "id": 195843028,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1588255396
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195842974\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195842974\">said</a>:</p>\n<blockquote>\n<ul>\n<li>Since the llvm-profdata tool is tied to the LLVM version, how do we expect users to obtain that tool? Will they be required to build our LLVM fork or will the tool be available via rustup? I think, as this is an unstable compiler flag, pretty much any answer is fine but we should have some plan for stabilizing this flag.</li>\n</ul>\n</blockquote>\n<p>I think it's sufficient, at least initially, to assume the first significant users will integrate the llvm-profdata and llvm-cov tools into their own toolchains. This is what the Fuchsia team will be doing once coverage is available. Downloading and/or compiling the additional tools, and scripting commands with the project-appropriate flags gives each project owner the most flexibility.</p>\n<p>For any end-user that is savvy enough to want to integrate coverage analysis into even small projects, the <a href=\"https://clang.llvm.org/docs/SourceBasedCodeCoverage.html\" title=\"https://clang.llvm.org/docs/SourceBasedCodeCoverage.html\">clang example tutorial</a> I referenced in the MCP is fairly straightforward to run, and is easily scriptable.</p>\n<p>I can also imagine future efforts, if someone is motivated to do so, to integrated the Rust coverage features into IDEs (VSCode, etc.) and CI tools (Travis, etc.).</p>",
        "id": 195845167,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588256267
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195842995\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195842995\">said</a>:</p>\n<blockquote>\n<ul>\n<li>Introducing so many calls to the __incr_cov function will create a lot of additional control flow edges (and a lot more MIR). It seems like this could lead to a lot of additional work done during compile time. Does clang take a similar approach? What impact does that typically have on their compilation time? How is the compilation performance of the existing prototype you have? Do you have any thoughts about whether this hits an \"acceptable\" bar for compiler performance?</li>\n</ul>\n</blockquote>\n<p>It's too early to tell what the performance impact is or what kind of optimizations can be done. (This touches a little on your third bullet as well, so I'll say more on that point in a separate response.)</p>\n<p>My prototyping, thus far, is focused on injecting coverage counters, computing the associated coverage regions, and running the resulting program to confirm the results match expectations, so I've done feasibility prototyping, but nothing significant enough to assess performance, yet. I certainly care about performance, and I continue to look into low-hanging-fruit opportunities where available. But other optimizations will have to be done in phases, as mentioned in the MCP, once the base capability is known to work.</p>\n<p>Also, since coverage injection will almost certainly be opt-in, and only done very occasionally, the bar for \"acceptable\" performance is not going to be nearly the same as compiling without that instrumentation. I do expect the impact to be linear to the number of existing branches in the source.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"296362\">Bob Wilson</span> can speak more authoritatively to the clang approach (ref: <a href=\"https://clang.llvm.org/doxygen/CoverageMappingGen_8cpp_source.html\" title=\"https://clang.llvm.org/doxygen/CoverageMappingGen_8cpp_source.html\">https://clang.llvm.org/doxygen/CoverageMappingGen_8cpp_source.html</a>) but my take is that clang is processing the AST and injecting the counters from there. I don't think clang has a direct analogy to the Rust HIR representation, but the clang coverage pass might be considered as happening at a level similar to the AST-&gt;HIR lowering pass in <code>rustc_ast_lowering</code>. Both walk the AST in a similar way.</p>",
        "id": 195850784,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588258557
    },
    {
        "content": "<p>A problem with drawing an analogy to clang is that clang's AST isn't really an AST (it has a lot more HIR-like information hanging off it)</p>",
        "id": 195854114,
        "sender_full_name": "tmandry",
        "timestamp": 1588259681
    },
    {
        "content": "<p>clang also has no MIR equivalent that I know of</p>",
        "id": 195854263,
        "sender_full_name": "tmandry",
        "timestamp": 1588259727
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"296355\">Rich Kadel</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195845167\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195845167\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195842974\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195842974\">said</a>:</p>\n<blockquote>\n<ul>\n<li>Since the llvm-profdata tool is tied to the LLVM version, how do we expect users to obtain that tool? Will they be required to build our LLVM fork or will the tool be available via rustup? I think, as this is an unstable compiler flag, pretty much any answer is fine but we should have some plan for stabilizing this flag.</li>\n</ul>\n</blockquote>\n<p>I think it's sufficient, at least initially, to assume the first significant users will integrate the llvm-profdata and llvm-cov tools into their own toolchains. This is what the Fuchsia team will be doing once coverage is available. Downloading and/or compiling the additional tools, and scripting commands with the project-appropriate flags gives each project owner the most flexibility.</p>\n<p>For any end-user that is savvy enough to want to integrate coverage analysis into even small projects, the <a href=\"https://clang.llvm.org/docs/SourceBasedCodeCoverage.html\" title=\"https://clang.llvm.org/docs/SourceBasedCodeCoverage.html\">clang example tutorial</a> I referenced in the MCP is fairly straightforward to run, and is easily scriptable.</p>\n<p>I can also imagine future efforts, if someone is motivated to do so, to integrated the Rust coverage features into IDEs (VSCode, etc.) and CI tools (Travis, etc.).</p>\n</blockquote>\n<p>Sounds great! Thanks</p>",
        "id": 195857262,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1588260913
    },
    {
        "content": "<blockquote>\n<p>Compiler performance impact</p>\n</blockquote>\n<p>That makes sense. I agree the threshold is probably significantly higher given that this opt-in for people who want the feature and it should have absolutely no impact otherwise. </p>\n<p>I would caution about optimizations on AST/HIR in the future, AFAIK, we have none of those currently or any plans to implement them. Doing any optimizations in <code>rustc</code> was pretty heavily gated on the MIR effort because it just wasn't practical before that point.</p>",
        "id": 195858079,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1588261228
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195843016\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195843016\">said</a>:</p>\n<blockquote>\n<ul>\n<li>Like many others on the PR and linked issues, my initial thought was that this would be a MIR pass. Having used poor quality tools in the past, I certainly agree with @bob-wilson's points regarding the quality of the code coverage reporting being critical to this feature. Still, my gut says that this should be done at least at the HIR level. I think I'm worried that by basing this pass on the AST, it will break much more frequently as the AST is changed than if it was based on a lower-level construct like the HIR. Do you have thoughts about what could be done to minimize regressions in the code coverage due to changes in the AST, for example, when adding new syntax?</li>\n</ul>\n</blockquote>\n<p>Yes! I discussed three alternatives in the MCP, and I'm open to influence here. You make a good point about the stability of the AST vs. HIR, an I'm open to influence here. I do see value in an HIR-level approach.</p>\n<p>My chief concern is that I need to understand the representation well enough to accurately identify the coverage regions within the original source code, and accurately inject the right counter instructions in the right places. At least with the AST, it's obvious. </p>\n<p>I'm already investigating how I can do this within the HIR, and I'd like to do it there if I can ramp up quickly enough, but I also have working code built on the AST. It may or may not be a reasonable cost-benefit tradeoff, for the <strong>initial</strong> implementation, but if not, it shouldn't be hard to move the coverage-injected nodes to the HIR in a follow-on optimization pass. (The question, then, would be, once there's a proven implementation, would someone then say they can bypass the HIR altogether and just migrate coverage injection directly to a MIR pass? And if that's the case, then spending time trying to move working AST code to HIR might be a waste of time anyway ;-) ...</p>\n<p>All this said, I'm not ignoring the feedback here and I am investigating those alternatives.</p>",
        "id": 195858195,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588261277
    },
    {
        "content": "<p>Yeah, I didn't mean to imply that you were ignoring the feedback. The entire value proposition of this feature is that it closely matches the end-user's mental model of the language semantics, not an underlying thing like MIR. So I fully agree with you and <span class=\"user-mention\" data-user-id=\"296362\">@Bob Wilson</span> there!</p>",
        "id": 195858644,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1588261467
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195858079\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195858079\">said</a>:</p>\n<blockquote>\n<p>I would caution about optimizations on AST/HIR in the future, AFAIK, we have none of those currently or any plans to implement them. Doing any optimizations in <code>rustc</code> was pretty heavily gated on the MIR effort because it just wasn't practical before that point.</p>\n</blockquote>\n<p>Understood. I think my use of the word optimization here refers only to optimizing the implementation of coverage injection, for example, moving coverage injection from earlier passes to later passes, or even simple things like improving how the hash argument is computed.</p>",
        "id": 195858673,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588261483
    },
    {
        "content": "<p>I'm just wanting to try to find a way to have our cake and eat it too. <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span></p>",
        "id": 195858676,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1588261486
    },
    {
        "content": "<p>one question I also had -- to what extent do we expect this to be stable? I presume if e.g. rustc 1.50 decided to refactor how things internally were represented and that meant that coverage for some things vanished (e.g. end brace of a for loop or some such) people wouldn't be too concerned?</p>",
        "id": 195858998,
        "sender_full_name": "simulacrum",
        "timestamp": 1588261620
    },
    {
        "content": "<p>The effect of that would be degraded behavior, but not breaking anything per se</p>",
        "id": 195859680,
        "sender_full_name": "tmandry",
        "timestamp": 1588261893
    },
    {
        "content": "<p>That's one argument I can see in favor of doing it in a later stage like MIR; fewer edge cases to worry about or that can break.</p>",
        "id": 195859785,
        "sender_full_name": "tmandry",
        "timestamp": 1588261928
    },
    {
        "content": "<p>Another argument is that it might make it easier to use performance counter info directly in MIR optimizations one day, though I'm not 100% clear on exactly how that would work.</p>",
        "id": 195860160,
        "sender_full_name": "tmandry",
        "timestamp": 1588262094
    },
    {
        "content": "<p>we could e.g. annotate likely/unlikely branches based on perf counters ourselves, though it's probably better to leave that to llvm I imagine</p>",
        "id": 195860554,
        "sender_full_name": "simulacrum",
        "timestamp": 1588262231
    },
    {
        "content": "<p>maybe with e.g. cranelift which doesn't have native support for pgo though that would make more sense</p>",
        "id": 195860622,
        "sender_full_name": "simulacrum",
        "timestamp": 1588262255
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195843028\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195843028\">said</a>:</p>\n<blockquote>\n<ul>\n<li>It sounds like you implemented two prototypes, one based on MIR transforms and one on the AST approach. Did you find issues regarding the quality of code coverage information generated from the MIR pass that the AST approach fixed? Or was the primary issue the implementation complexity that you mentioned above?</li>\n</ul>\n</blockquote>\n<p>To be more clear, I did start an early prototype by injecting coverage in <code>rustc_ast_lowering</code> functions, but as I started working out how to ensure proper coverage for the less simple cases (like lazy booleans, for example), I felt I had more control and visibility by implementing coverage by walking the AST before any HIR code transformations. (Still considering the HIR though, as discussed in my earlier reply.)</p>\n<p>I did not code up any prototype on the MIR <em>directly</em> but I used -Zunpretty=mir to get a look at the difference between the uninstrumented MIR and an instrumented MIR (after I had injected counter code), and from that I decided the MIR might be a bridge too far, for me, from a complexity standpoint.</p>",
        "id": 195861306,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588262512
    },
    {
        "content": "<p>I recently implemented code coverage support for embedded Rust based on the existing -Zprofile GCOV profiling support: <a href=\"https://github.com/Amanieu/minicov/\" title=\"https://github.com/Amanieu/minicov/\">https://github.com/Amanieu/minicov/</a></p>\n<p>It basically works by using a custom implementation of the profiling runtime which simply serializes the counters and metadata to a <code>Vec&lt;u8&gt;</code>. This data can then be sent back to the dev system and \"replayed\", which creates the .gcda files as if the program was run locally.</p>\n<p>Would such an approach also be possible for new profiling system considering the constraints of embedded systems (<code>#[no_std]</code> and no libc but you can use liballoc)? It seems to me that the new profiling system would produce much more accurate profiling information than the existing GCOV-based system which is injected in an LLVM pass.</p>",
        "id": 195862364,
        "sender_full_name": "Amanieu",
        "timestamp": 1588262889
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"143274\">@Amanieu</span> Possibly, but the actual implementation of maintaining the counters is all in LLVM</p>",
        "id": 195862740,
        "sender_full_name": "tmandry",
        "timestamp": 1588263068
    },
    {
        "content": "<p>On a related note (to the discussion with Wesley on AST vs HIR), I'd like to look into the possible benefits of mirroring what is done in <a href=\"https://github.com/rust-lang/rust/blob/master/src/librustc_ast_lowering/expr.rs#L1300\" title=\"https://github.com/rust-lang/rust/blob/master/src/librustc_ast_lowering/expr.rs#L1300\"><code>expr_drop_temps...()</code> in <code>rustc_ast_lowering/expr.rs</code></a>. It appears to inject a custom HIR node <code>hir::ExprKind::DropTemps(expr)</code> that (according to the docs):</p>\n<div class=\"codehilite\"><pre><span></span><code>    /// ... has the same effect as wrapping `expr` in\n    /// `{ let _t = $expr; _t }` but should provide better compile-time performance.\n</code></pre></div>\n\n\n<p>This is very reminiscent of the unwrapped implementation of my notional inlined <code>__incr_cov()</code> implementation. (Aside: I am not comfortable that the inlining will work as expected so my plan is to implement the functionality unwrapped, without introducing an intermediate function call.) So assuming the following <code>match</code> is part of a coverage region that needs a counter:</p>\n<div class=\"codehilite\"><pre><span></span><code>    match some_expr { ...\n</code></pre></div>\n\n\n<p>Injecting the LLVM intrinsic counter function would look something like:</p>\n<div class=\"codehilite\"><pre><span></span><code>    match { let _t = some_expr; llvm_instrprof_increment(...); _t } {\n</code></pre></div>\n\n\n<p>I'm interested to get feedback from someone familiar with the DropTemps implementation and ultimate code injection if a similar strategy can be used for the coverage counter injection, and if that would also give us some \"better compile time performance\".</p>",
        "id": 195864923,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588264064
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"296355\">Rich Kadel</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195861306\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195861306\">said</a>:</p>\n<blockquote>\n<p>I did not code up any prototype on the MIR <em>directly</em> but I used -Zunpretty=mir to get a look at the difference between the uninstrumented MIR and an instrumented MIR (after I had injected counter code), and from that I decided the MIR might be a bridge too far, for me, from a complexity standpoint.</p>\n</blockquote>\n<p>So a benefit of MIR is that every possible branch is encoded directly in the representation (it's a basic block), and that includes things not obvious from the AST, like panic/unwind branches. The question in my mind is whether there's a tradeoff between instrumenting this \"invisible code\" and having full fidelity on covering the source code. I think full fidelity on the source is <em>most</em> important, but having coverage on all generated code is important too for PGO.</p>\n<p>MIR's SourceInfo maps every statement and terminator back to the source code from which it came, and directly after HIR -&gt; MIR construction I would expect that to be quite high fidelity. <span class=\"user-mention\" data-user-id=\"119009\">@eddyb</span> also seems to think this is the way to go.</p>",
        "id": 195865407,
        "sender_full_name": "tmandry",
        "timestamp": 1588264282
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span> so the decision was based on what you would've had to add in MIR, i.e. the calls? not anything about what information MIR had for you to be able to decide <em>where</em> to instrument?</p>",
        "id": 195865588,
        "sender_full_name": "eddyb",
        "timestamp": 1588264365
    },
    {
        "content": "<p>because this is something that confused me</p>",
        "id": 195865622,
        "sender_full_name": "eddyb",
        "timestamp": 1588264387
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span> anything you inject early-on will produce messy MIR - that doesn't mean that doing it at the MIR level would require all of that mess</p>",
        "id": 195865676,
        "sender_full_name": "eddyb",
        "timestamp": 1588264415
    },
    {
        "content": "<p>in fact, it's probably much better to try to avoid it in the first place</p>",
        "id": 195865703,
        "sender_full_name": "eddyb",
        "timestamp": 1588264427
    },
    {
        "content": "<p>for example, if you introduce a new MIR statement, you can avoid calls altogether</p>",
        "id": 195865741,
        "sender_full_name": "eddyb",
        "timestamp": 1588264441
    },
    {
        "content": "<p>I think <span class=\"user-mention\" data-user-id=\"296362\">@Bob Wilson</span> (hopefully that's the right person) had looked into this before and decided not to do it in MIR, but I'm not sure what their reasoning was.</p>",
        "id": 195865792,
        "sender_full_name": "tmandry",
        "timestamp": 1588264446
    },
    {
        "content": "<p>MIR calls are terminators because they may unwind</p>",
        "id": 195865809,
        "sender_full_name": "eddyb",
        "timestamp": 1588264453
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116883\">@tmandry</span> oh okay. still, this confusion/question applies to anyone who doesn't want to do something on/with/etc. MIR</p>",
        "id": 195865855,
        "sender_full_name": "eddyb",
        "timestamp": 1588264478
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195865676\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195865676\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"296355\">Rich Kadel</span> anything you inject early-on will produce messy MIR - that doesn't mean that doing it at the MIR level would require all of that mess</p>\n</blockquote>\n<p>Yes, I do understand that.</p>",
        "id": 195865864,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588264482
    },
    {
        "content": "<p>okay reading more of the backlog, <code>DropTemps</code> is basically a noop for almost everything except one part of the compiler</p>",
        "id": 195866120,
        "sender_full_name": "eddyb",
        "timestamp": 1588264588
    },
    {
        "content": "<p>But I look at the MIR and see a bunch of new <code>let</code> statements with auto generated names, etc. etc. and it's just hard to trace back to how to ensure that generating code at that level will give me the result I expect when looking at the source. It's mostly my lack of being able to grok the MIR.</p>",
        "id": 195866198,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588264625
    },
    {
        "content": "<p>if you want to go that route (<code>DropTemps</code>-like) you could add a \"post-instrument\" expression, that evaluates the original expression and then immediately afterwards does the instrumentation</p>",
        "id": 195866383,
        "sender_full_name": "eddyb",
        "timestamp": 1588264704
    },
    {
        "content": "<p>/me dreams about a vscode extension or something that lets you mouse over a MIR statement and see the SourceInfo associated with it as a highlight in your editor</p>",
        "id": 195866478,
        "sender_full_name": "tmandry",
        "timestamp": 1588264750
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span> okay but shouldn't that (groking MIR) be a necessary step before you decide how to implement this?</p>",
        "id": 195866533,
        "sender_full_name": "eddyb",
        "timestamp": 1588264778
    },
    {
        "content": "<p>it's also unclear to me, from the <code>match</code> example, what it is achieved, since there's no way to record which arm matched</p>",
        "id": 195866787,
        "sender_full_name": "eddyb",
        "timestamp": 1588264870
    },
    {
        "content": "<p>I don't see that as a significant requirement. (I agree I have to understand how it works at some level, but not necessarily how it remaps the control flow.) A Rust programmer doesn't have to grok MIR to write Rust.</p>",
        "id": 195866800,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588264875
    },
    {
        "content": "<p>I mean for implementing this feature, not using it</p>",
        "id": 195866847,
        "sender_full_name": "eddyb",
        "timestamp": 1588264903
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195866787\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195866787\">said</a>:</p>\n<blockquote>\n<p>it's also unclear to me, from the <code>match</code> example, what it is achieved, since there's no way to record which arm matched</p>\n</blockquote>\n<p>The example is not counting the arms. Its counting the code leading up to the execution of the pattern match, including any code inside the match expression (with the possibility that an insanely complex match expression could include an early return).</p>",
        "id": 195867008,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588264965
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195866533\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195866533\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"296355\">Rich Kadel</span> okay but shouldn't that (groking MIR) be a necessary step before you decide how to implement this?</p>\n</blockquote>\n<p>Meta-point: I mean, that's part of what a design review is for. Taking a stab at a design based on limited information is perfectly acceptable, but knowing all the relevant details before adopting a final design is (also) a good idea.</p>",
        "id": 195867045,
        "sender_full_name": "tmandry",
        "timestamp": 1588264984
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span> okay, what's the granularity then? expressions nest arbitrarily, do you want to instrument at every point in the expression tree? or is it coarser than that?</p>",
        "id": 195867150,
        "sender_full_name": "eddyb",
        "timestamp": 1588265035
    },
    {
        "content": "<p>having spent time looking into this before, I don't see how you can efficiently instrument code without using a control-flow graph</p>",
        "id": 195867265,
        "sender_full_name": "eddyb",
        "timestamp": 1588265067
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195867150\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195867150\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"296355\">Rich Kadel</span> okay, what's the granularity then? expressions nest arbitrarily, do you want to instrument at every point in the expression tree? or is it coarser than that?</p>\n</blockquote>\n<p>Every coded branch.</p>",
        "id": 195867325,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588265090
    },
    {
        "content": "<p>so you want to find all of the control-flow edges in the AST?</p>",
        "id": 195867388,
        "sender_full_name": "eddyb",
        "timestamp": 1588265123
    },
    {
        "content": "<p>If you instrument right before every MIR <code>SwitchInt</code>, <code>Call</code>, <code>Drop</code> and <code>Assert</code> terminator, you will get every possible branch. If you want to ignore unwinds, you only need to instrument <code>SwitchInt</code>.</p>",
        "id": 195867670,
        "sender_full_name": "bjorn3",
        "timestamp": 1588265220
    },
    {
        "content": "<p>we used to have code that did that (extract a CFG from an AST). we've recently removed it after a successful transition to MIR borrowck</p>",
        "id": 195867672,
        "sender_full_name": "eddyb",
        "timestamp": 1588265220
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span> okay let me ask a more useful question: say you know all the points that are relevant to control-flow: how do you represent all of the code in between, for coverage purposes?</p>",
        "id": 195868219,
        "sender_full_name": "eddyb",
        "timestamp": 1588265362
    },
    {
        "content": "<p>based on the answer to this, the solution may even be implementable all the way down in codegen, even after MIR optimizations have run</p>",
        "id": 195868304,
        "sender_full_name": "eddyb",
        "timestamp": 1588265400
    },
    {
        "content": "<p>with the pre-existing information (which mainly exists for debuginfo)</p>",
        "id": 195868426,
        "sender_full_name": "eddyb",
        "timestamp": 1588265432
    },
    {
        "content": "<p>IIRC, the LLVM format is more fine-grained than lines, and uses some sort of (nested?) range system, but it's been two years since I've looked at it</p>",
        "id": 195868673,
        "sender_full_name": "eddyb",
        "timestamp": 1588265524
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195866847\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195866847\">said</a>:</p>\n<blockquote>\n<p>I mean for implementing this feature, not using it</p>\n</blockquote>\n<p>That's what I mean too. But I think you are arguing for injecting coverage without caring about what the input source looked like, with the (probably reasonable) assumption that using a downstream representation will be \"more efficient\" (as you put it), and that's fair. You are much more experienced with this than I am.</p>\n<p>All I can say is, I believe I can identify coverage regions and inject coverage counters based on AST nodes without needing to know much more than what Rust source looks like.</p>\n<p>I certainly don't want to argue with you over details you are much more familiar with than I am. Just trying to be practical, given my current knowledge.</p>",
        "id": 195868783,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588265570
    },
    {
        "content": "<p>I'm arguing for something that we'd want to maintain long-term, <em>without loss of precision</em></p>",
        "id": 195869028,
        "sender_full_name": "eddyb",
        "timestamp": 1588265653
    },
    {
        "content": "<p>and I want to understand what parts of source code you care about, that the MIR doesn't already represent accurately</p>",
        "id": 195869153,
        "sender_full_name": "eddyb",
        "timestamp": 1588265704
    },
    {
        "content": "<p>after all, our debuginfo is emitted from MIR, <em>and in a lossy way</em>. that is, MIR has more information than DWARF can encode</p>",
        "id": 195869205,
        "sender_full_name": "eddyb",
        "timestamp": 1588265727
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span> anyway to the best of my knowledge there is no advantage to doing the injection at any point before HIR -&gt; MIR</p>",
        "id": 195869526,
        "sender_full_name": "eddyb",
        "timestamp": 1588265843
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195868219\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195868219\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"296355\">Rich Kadel</span> okay let me ask a more useful question: say you know all the points that are relevant to control-flow: how do you represent all of the code in between, for coverage purposes?</p>\n</blockquote>\n<p>I can try an example</p>",
        "id": 195869541,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588265850
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195869526\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195869526\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"296355\">Rich Kadel</span> anyway to the best of my knowledge there is no advantage to doing the injection at any point before HIR -&gt; MIR</p>\n</blockquote>\n<p>What do you mean by \"advantage\", just so I'm clear?</p>",
        "id": 195869698,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588265900
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195869153\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195869153\">said</a>:</p>\n<blockquote>\n<p>and I want to understand what parts of source code you care about, that the MIR doesn't already represent accurately</p>\n</blockquote>\n<p>I think this is the point that's unclear right now. We don't know if there's any loss of fidelity in the MIR representation, and it would take some work to find out. The most important thing is full fidelity, so from that standpoint I can see why AST or HIR feel safest. But your earlier point about this producing messy MIR with a lot of unwind branches is well taken (by me).. that will impact compiler performance quite a lot.</p>",
        "id": 195869722,
        "sender_full_name": "tmandry",
        "timestamp": 1588265908
    },
    {
        "content": "<p>not only will it impact performance, it risks impacting <em>semantics</em></p>",
        "id": 195869782,
        "sender_full_name": "eddyb",
        "timestamp": 1588265930
    },
    {
        "content": "<p>which is far scarier than code coverage not being 100% accurate</p>",
        "id": 195869816,
        "sender_full_name": "eddyb",
        "timestamp": 1588265943
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195869782\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195869782\">said</a>:</p>\n<blockquote>\n<p>not only will it impact performance, it risks impacting <em>semantics</em></p>\n</blockquote>\n<p>I don't believe the injection I have in mind will impact semantics at all, btw</p>",
        "id": 195869859,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588265957
    },
    {
        "content": "<p>you're changing the HIR which goes into type-checking, there are enough subtleties that it's hard to say just from looking at it</p>",
        "id": 195870019,
        "sender_full_name": "eddyb",
        "timestamp": 1588266007
    },
    {
        "content": "<p>the only thing I am aware of that is almost guaranteed to not impact semantics is adding non-<code>let</code> statements</p>",
        "id": 195870108,
        "sender_full_name": "eddyb",
        "timestamp": 1588266043
    },
    {
        "content": "<p>in that it translates to adding a sub-CFG of MIR that doesn't change the CFG around it</p>",
        "id": 195870206,
        "sender_full_name": "eddyb",
        "timestamp": 1588266081
    },
    {
        "content": "<p>well, a statement that doesn't mention any local variables, that is</p>",
        "id": 195870257,
        "sender_full_name": "eddyb",
        "timestamp": 1588266102
    },
    {
        "content": "<p>it's equivalent to having a new built-in MIR statement, and can't influence typeck of the code around it either</p>",
        "id": 195870344,
        "sender_full_name": "eddyb",
        "timestamp": 1588266133
    },
    {
        "content": "<p>anyway, AST -&gt; HIR is \"lossy except for diagnostics\", in that we actually preserve enough information, despite desugaring the structure, to know what kind of AST shape some HIR came from</p>",
        "id": 195870412,
        "sender_full_name": "eddyb",
        "timestamp": 1588266174
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"119009\">@eddyb</span> you type too fast and I don't have time to respond :-)</p>",
        "id": 195870491,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588266222
    },
    {
        "content": "<p>time is money :P</p>",
        "id": 195870609,
        "sender_full_name": "eddyb",
        "timestamp": 1588266269
    },
    {
        "content": "<p>so while you can inject in AST -&gt; HIR, you can also do it as HIR -&gt; HIR (except for HIR transformations not existing), which means you can do it in HIR -&gt; MIR</p>",
        "id": 195870644,
        "sender_full_name": "eddyb",
        "timestamp": 1588266293
    },
    {
        "content": "<p>doing it as late as possible using the same information source means there is less friction/interference with other parts of the compiler</p>",
        "id": 195870754,
        "sender_full_name": "eddyb",
        "timestamp": 1588266340
    },
    {
        "content": "<p>I get that and am on board generally speaking.</p>",
        "id": 195870848,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588266375
    },
    {
        "content": "<p>then the only question about MIR specifically is whether MIR -&gt; MIR is lossier compared to HIR -&gt; MIR</p>",
        "id": 195870852,
        "sender_full_name": "eddyb",
        "timestamp": 1588266376
    },
    {
        "content": "<p>but if it starts off in HIR -&gt; MIR then it's much easier to move later to MIR -&gt; MIR, even if there are reasons to believe we can't do it in MIR -&gt; MIR from the start, or just because we don't want to bother</p>",
        "id": 195870992,
        "sender_full_name": "eddyb",
        "timestamp": 1588266441
    },
    {
        "content": "<p>and to avoid constructing true calls, you can add a new <code>StatementKind</code></p>",
        "id": 195871141,
        "sender_full_name": "eddyb",
        "timestamp": 1588266503
    },
    {
        "content": "<p>Perhaps I can add something useful here.  I was working on this very issue back towards the end of last year, but events rather swamped over me and I've not been able to return to it.  I'm delighted to see <span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span> picking it up and taking it forward.  On the issue of when to instrument, I had preferred instrumenting the MIR for all the reasons that are being articulated here now—but...</p>",
        "id": 195871148,
        "sender_full_name": "eggyal",
        "timestamp": 1588266506
    },
    {
        "content": "<p>The LLVM instrumentation leans toward having calculated regions wherever possible, and only making instrumentation calls where the count cannot be imputed from other counters.  I found it impossible to reliably formulate the necessary flow graph from the MIR, and saw this as something far easier to construct with the HIR.</p>",
        "id": 195871499,
        "sender_full_name": "eggyal",
        "timestamp": 1588266672
    },
    {
        "content": "<p>(note that HIR -&gt; MIR is <em>not</em> MIR instrumentation, but HIR instrumentation, just emitting the instrumentation calls in MIR instead of trying to fit them into HIR)</p>",
        "id": 195871550,
        "sender_full_name": "eddyb",
        "timestamp": 1588266703
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249694\">@eggyal</span> hmm I would've used linear sequences of basic blocks that are connected by<code>Call</code> terminators, but that's just an optimization over using basic blocks</p>",
        "id": 195871691,
        "sender_full_name": "eddyb",
        "timestamp": 1588266770
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"119009\">@eddyb</span> But that doesn't help you decide when a linear sequence has no other entry points?</p>",
        "id": 195871786,
        "sender_full_name": "eggyal",
        "timestamp": 1588266825
    },
    {
        "content": "<p>unless you mean considering each basic block's counter a variable in a system of equations and trying to reduce the base number of variables</p>",
        "id": 195871792,
        "sender_full_name": "eddyb",
        "timestamp": 1588266829
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249694\">@eggyal</span> what do you mean, that's just a property of the CFG</p>",
        "id": 195871861,
        "sender_full_name": "eddyb",
        "timestamp": 1588266849
    },
    {
        "content": "<p>you either compute that by doing a full traversal or just use the <code>predecessors</code> cache if you want</p>",
        "id": 195871958,
        "sender_full_name": "eddyb",
        "timestamp": 1588266914
    },
    {
        "content": "<p>if you do a full traversal you can just record the number of ingoing edges (i.e. predecessors) of each basic block and then you only treat it as not needing its own counter if it has exactly one ingoing edge that's e.g. not conditional</p>",
        "id": 195872475,
        "sender_full_name": "eddyb",
        "timestamp": 1588267173
    },
    {
        "content": "<p>you can do all sorts of things on a CFG</p>",
        "id": 195872522,
        "sender_full_name": "eddyb",
        "timestamp": 1588267200
    },
    {
        "content": "<p>what I'd rather be worried about with MIR -&gt; MIR is whether code affected by counters is describable given the MIR</p>",
        "id": 195872628,
        "sender_full_name": "eddyb",
        "timestamp": 1588267242
    },
    {
        "content": "<p>Hm.  I don't recall seeing a <code>predecessors</code> cache—so that may well have made a big difference!  I also struggled mapping some blocks back to source code regions, though that was early on in my exploration and I can't immediately recall what the issues were.  Reading back over the comments at the time, I also see <a href=\"https://github.com/rust-lang/rust/issues/34701#issuecomment-548578062\" title=\"https://github.com/rust-lang/rust/issues/34701#issuecomment-548578062\">@**Bob Wilson**'s comment</a></p>\n<blockquote>\n<p>Consider \"if let condition\" followed by a blank line vs. \"match condition\" followed by a blank line. What execution count should be displayed for that blank line? For the \"if\", Clang shows the \"then\" count. The corresponding behavior for the \"match\" (or a match lowered from \"if let\") would be to show the count for the first arm of the match. That just seems wrong to me.</p>\n</blockquote>\n<p>These sorts of gap regions are difficult to identify and locate from the MIR.</p>",
        "id": 195872648,
        "sender_full_name": "eggyal",
        "timestamp": 1588267256
    },
    {
        "content": "<p>Wow, there's a lot of discussion here today and I've only got a few minutes this morning to respond. I can follow up later with more detailed responses.</p>\n<ul>\n<li>The compile time and runtime overhead for both Swift and Clang is relatively low, but it depends on the input. I don't remember specific numbers, but it was good enough that we briefly considered enabling it by default in Xcode Debug builds (but eventually decided against that because of larger overheads for some projects).</li>\n<li>Swift is a better comparison than Clang because the coverage data structures have to be plumbed through the SIL level before getting to LLVM IR.</li>\n<li>This discussion has been focused on how to inject the LLVM intrinsic calls for instrumentation. In my experience, that is the easy part. Generating the coverage map is more complicated. It might be helpful to start with that and work backward to some of the other aspects of this. I'm still not entirely clear on how the coverage map will be correlated with the instrumentation counters.</li>\n<li>I stand by my earlier statement that the coverage map should be generated from the AST, but I'm increasingly skeptical about inserting the LLVM intrinsic calls into the AST. My suggestion to Rich was to build a side table mapping AST nodes to counters, lower that through HIR, and then insert the intrinsic calls during the HIR-to-MIR lowering. This is basically what Swift does. One nice thing about Rich's proposal to modify the AST is that it keeps the coverage code in one place (at least to some extent) instead of scattering bits across different parts of the compiler. He is still optimistic that he can get it to work at the AST, but it seems much more manageable at the MIR level.</li>\n<li>The Clang design for instrumentation-based PGO intentionally tracks source-visible branches. The intent is that compiler-generated control flow should be annotated with branch probabilities by the compiler. For coverage, there is no point in instrumenting branches that are not visible in the source, and I don't think that should be done here.</li>\n</ul>",
        "id": 195872674,
        "sender_full_name": "Bob Wilson",
        "timestamp": 1588267269
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249694\">@eggyal</span> okay yeah this is the interesting parts to me (mapping the source code)</p>",
        "id": 195872718,
        "sender_full_name": "eddyb",
        "timestamp": 1588267294
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296362\">@Bob Wilson</span> sorry, I tried to stay out of it but <span class=\"user-mention\" data-user-id=\"116883\">@tmandry</span> pinged me</p>",
        "id": 195872749,
        "sender_full_name": "eddyb",
        "timestamp": 1588267311
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296362\">@Bob Wilson</span> I can clear up something right away: this is unnecessary: \"side table mapping AST nodes to counters, lower that through HIR, and then insert the intrinsic calls during the HIR-to-MIR lowering\"</p>",
        "id": 195872838,
        "sender_full_name": "eddyb",
        "timestamp": 1588267348
    },
    {
        "content": "<p>the HIR contains enough information that you don't need to know the AST it came from</p>",
        "id": 195872883,
        "sender_full_name": "eddyb",
        "timestamp": 1588267372
    },
    {
        "content": "<p>this mostly exists for diagnostics, which need to be accurate even when the actual constructs were desugared</p>",
        "id": 195872939,
        "sender_full_name": "eddyb",
        "timestamp": 1588267401
    },
    {
        "content": "<p>also, <code>rustc</code>'s <code>Span</code>s record a macro backtrace, and HIR desugaring is also encoded in that, so you can probably do a bunch more things that not even heavy diagnostics logic does yet :P</p>",
        "id": 195873135,
        "sender_full_name": "eddyb",
        "timestamp": 1588267483
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249694\">@eggyal</span> I don't understand the quoted example. is the blank line inside the condition expression part of the syntax or after the <code>{</code>?</p>",
        "id": 195873343,
        "sender_full_name": "eddyb",
        "timestamp": 1588267571
    },
    {
        "content": "<p>are we talking about a blank line that's outside of a <code>match</code> arm but inside the <code>{...}</code> that enclose the match arms?</p>",
        "id": 195873545,
        "sender_full_name": "eddyb",
        "timestamp": 1588267665
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195872883\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195872883\">said</a>:</p>\n<blockquote>\n<p>the HIR contains enough information that you don't need to know the AST it came from</p>\n</blockquote>\n<p>I'm not that familiar with it, but I'm not convinced. The coverage map generated from the AST needs to refer to counter indices. The counter indices are associated with different AST nodes and the details on how to inject the instrumentation may depend on the type of the AST node. How can you get that counter index from HIR and what kind of node it came from (e.g., a \"match\" lowered from an  AST \"if\" should probably be instrumented differently than a source-level \"match\")?</p>",
        "id": 195873574,
        "sender_full_name": "Bob Wilson",
        "timestamp": 1588267680
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249694\">@eggyal</span> keep in mind you have this problem all the way throughout the AST -&gt; HIR -&gt; MIR pipeline (you always have to work with <code>Span</code>s that don't necessarily touch)</p>",
        "id": 195873577,
        "sender_full_name": "eddyb",
        "timestamp": 1588267681
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296362\">@Bob Wilson</span> isn't <code>rustc</code>'s job to invent those counters?</p>",
        "id": 195873694,
        "sender_full_name": "eddyb",
        "timestamp": 1588267728
    },
    {
        "content": "<p>why would AST and HIR be different? other than the desugaring, which I just pointed out you can observe that it happened</p>",
        "id": 195873780,
        "sender_full_name": "eddyb",
        "timestamp": 1588267767
    },
    {
        "content": "<p>you can tell apart <code>if-let</code> from <code>match</code> on HIR</p>",
        "id": 195873795,
        "sender_full_name": "eddyb",
        "timestamp": 1588267777
    },
    {
        "content": "<p>again, mostly for diagnostics reasons</p>",
        "id": 195873811,
        "sender_full_name": "eddyb",
        "timestamp": 1588267784
    },
    {
        "content": "<p>anyway I agree that figuring out the coverage map is the most important part of this</p>",
        "id": 195873939,
        "sender_full_name": "eddyb",
        "timestamp": 1588267849
    },
    {
        "content": "<p>HIR/MIR has no(conditional branches that aren't visible in the source with two notable exceptions I guess: the pattern-matching on <code>Iterator::next</code>'s result in <code>for</code> loop, and the pattern-matching <code>?</code> does. but MIR can tell they came from a desugaring, last I checked</p>",
        "id": 195874223,
        "sender_full_name": "eddyb",
        "timestamp": 1588267997
    },
    {
        "content": "<p>HIR -&gt; MIR introduces some checks for e.g. array indexing and checked arithmetic, but those use the <code>Assert</code> terminator, not conditional control-flow</p>",
        "id": 195874262,
        "sender_full_name": "eddyb",
        "timestamp": 1588268022
    },
    {
        "content": "<p>Naively to me, it does seem like you can instrument every branch regardless of what the source looked like (modulo optimizing away unnecessary counters like <span class=\"user-mention\" data-user-id=\"249694\">@eggyal</span> was talking about), and care about what the source looked like only when building a map between counters and source code. If means multiple \"hidden\" branches map back to the exact same code, that's okay; that additional information could still be useful for optimization purposes.</p>",
        "id": 195874437,
        "sender_full_name": "tmandry",
        "timestamp": 1588268111
    },
    {
        "content": "<p>also, rather than gaps, I'd be more concerned about overlaps</p>",
        "id": 195874490,
        "sender_full_name": "eddyb",
        "timestamp": 1588268152
    },
    {
        "content": "<p>how do you build a coverage map out of an expression tree where each expression has a range in the source?</p>",
        "id": 195874581,
        "sender_full_name": "eddyb",
        "timestamp": 1588268182
    },
    {
        "content": "<p>what's the algorithm? how does it behave when the naive assumption that the ranges are trivially nested, breaks down?</p>",
        "id": 195874712,
        "sender_full_name": "eddyb",
        "timestamp": 1588268235
    },
    {
        "content": "<p>how do you handle all of the ways in which macro expansion can create spans?</p>",
        "id": 195874765,
        "sender_full_name": "eddyb",
        "timestamp": 1588268258
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195874712\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195874712\">said</a>:</p>\n<blockquote>\n<p>what's the algorithm? how does it behave when the naive assumption that the ranges are trivially nested, breaks down?</p>\n</blockquote>\n<p>It's worth reading <a href=\"http://llvm.org/docs/CoverageMappingFormat.html#mapping-region\" title=\"http://llvm.org/docs/CoverageMappingFormat.html#mapping-region\">http://llvm.org/docs/CoverageMappingFormat.html#mapping-region</a></p>",
        "id": 195874867,
        "sender_full_name": "eggyal",
        "timestamp": 1588268283
    },
    {
        "content": "<p>and I have, two years ago :)</p>",
        "id": 195874883,
        "sender_full_name": "eddyb",
        "timestamp": 1588268295
    },
    {
        "content": "<p>my question is how do you produce that <em>from Rust ASTs</em></p>",
        "id": 195874894,
        "sender_full_name": "eddyb",
        "timestamp": 1588268305
    },
    {
        "content": "<p>the best way to handle gaps, IMO, is to consider anything that's not a sub-range, as always executing if the parent expression executes. this means that various bits of syntax, punctuation, etc., are automatically included, and the only parts that can vary dynamically are exactly what's not guaranteed to also execute</p>",
        "id": 195875166,
        "sender_full_name": "eddyb",
        "timestamp": 1588268436
    },
    {
        "content": "<p>AFAIK the format allows this and many other approaches, but you still have to pick a way to turn expression spans into that format</p>",
        "id": 195875285,
        "sender_full_name": "eddyb",
        "timestamp": 1588268494
    },
    {
        "content": "<p>My feeling is the discussion on where to include whitespace, comments, and punctuation are very minor issues and maybe not worth too much discussion at this stage of the proposal.</p>",
        "id": 195875522,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588268588
    },
    {
        "content": "<p>the nice thing about a sufficiently capable algorithm  is that it will likely be correct when throwing MIR spans at it willy nilly</p>",
        "id": 195875525,
        "sender_full_name": "eddyb",
        "timestamp": 1588268590
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span> a correct implementation wrt those is likely going to be most of the effort</p>",
        "id": 195875572,
        "sender_full_name": "eddyb",
        "timestamp": 1588268624
    },
    {
        "content": "<p>anyway when I agreed to offer <span class=\"user-mention\" data-user-id=\"116883\">@tmandry</span> my emails from two years ago I didn't agree to repeat the whole experience again</p>",
        "id": 195875724,
        "sender_full_name": "eddyb",
        "timestamp": 1588268691
    },
    {
        "content": "<p>my main piece of advice is that there shouldn't be any loss of information between the AST observed by AST -&gt; HIR and the HIR observed by HIR -&gt; MIR and injecting in the latter is less likely to be a problem long-term</p>",
        "id": 195875812,
        "sender_full_name": "eddyb",
        "timestamp": 1588268746
    },
    {
        "content": "<p>HIR -&gt; MIR vs MIR -&gt; MIR is a more advanced matter of syntactically shallow vs semantic approaches, and what the actual goals are</p>",
        "id": 195875977,
        "sender_full_name": "eddyb",
        "timestamp": 1588268823
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195875724\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195875724\">said</a>:</p>\n<blockquote>\n<p>anyway when I agreed to offer <span class=\"user-mention silent\" data-user-id=\"116883\">tmandry</span> my emails from two years ago I didn't agree to repeat the whole experience again</p>\n</blockquote>\n<p>Apologies if I've cause some churn here. Was not aware of these emails, but I can get them from <span class=\"user-mention\" data-user-id=\"116883\">@tmandry</span> </p>\n<p>Thanks for the great feedback.</p>",
        "id": 195875989,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588268832
    },
    {
        "content": "<p>ah I thought tmandry already discussed it</p>",
        "id": 195876016,
        "sender_full_name": "eddyb",
        "timestamp": 1588268846
    },
    {
        "content": "<p>anyway I will try to stay out of the way of this. I cannot be 100% objective due to the stuff from a couple years ago</p>",
        "id": 195876133,
        "sender_full_name": "eddyb",
        "timestamp": 1588268885
    },
    {
        "content": "<p>most of the information is in what I said above and those emails, although they might be outdated by now</p>",
        "id": 195876176,
        "sender_full_name": "eddyb",
        "timestamp": 1588268914
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"133247\">@bjorn3</span>, <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> and the rest of <span class=\"user-group-mention\" data-user-group-id=\"1162\">@WG-mir-opt</span> should be able to help</p>",
        "id": 195876222,
        "sender_full_name": "eddyb",
        "timestamp": 1588268942
    },
    {
        "content": "<p>with either HIR -&gt; MIR or MIR -&gt; MIR</p>",
        "id": 195876260,
        "sender_full_name": "eddyb",
        "timestamp": 1588268958
    },
    {
        "content": "<p>good luck, have fun, stay safe, etc.</p>",
        "id": 195876333,
        "sender_full_name": "eddyb",
        "timestamp": 1588268993
    },
    {
        "content": "<p>Thank you! You as well.</p>",
        "id": 195876682,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588269147
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 195887451,
        "sender_full_name": "tmandry",
        "timestamp": 1588273916
    },
    {
        "content": "<p>It sounds like there is some history about this topic that I'm not aware of.... Anyway, I generally agree with @eddyb, but I still think building the coverage map from ASTs would be more maintainable, since doing it from HIR would need to be updated to account for any changes in the desugaring over time. If you produce the coverage map from the AST, it shouldn't be hard to pass it through HIR -- it's mostly self-contained except for the mapping to counter numbers, and I think that mapping could be translated to describe the HIR without much difficulty. Inserting instrumentation during HIR-&gt;MIR lowering would also be my recommendation. <span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span>, you don't really need to understand MIR very well to do that, since the analysis of the control flow would be done earlier.</p>",
        "id": 195903383,
        "sender_full_name": "Bob Wilson",
        "timestamp": 1588281751
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span> You wrote in the GitHub PR and issue that you're now planning to implement this as a MIR -&gt; MIR pass based on feedback here. From what I see here, the clear feedback is that the instrumentation should be inserted in MIR, but there was at least as many recommendations to do that in HIR -&gt; MIR lowering, with the coverage map computed from the AST or HIR. What led you to settle on MIR -&gt; MIR? Specifically, how do you intend to build the coverage map from MIR? I saw a few comments suggesting that is should be doable, but it still sounds difficult to me.</p>",
        "id": 196254406,
        "sender_full_name": "Bob Wilson",
        "timestamp": 1588636894
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296362\">@Bob Wilson</span> I did a walkthrough of the MIR with <span class=\"user-mention\" data-user-id=\"116883\">@tmandry</span> on Friday and I can see in the CFG and data structures how the MIR branches <em>should</em> map back to the AST nodes; and from there, I expect to be able to map back to the coverage regions. This still has to be proven of course, but MIR-&gt;MIR was cleary @eddyb 's preferred approach, and based on his experience, and <span class=\"user-mention\" data-user-id=\"116883\">@tmandry</span> 's recommendations (which I believe were influenced by the discussion in this thread), it's worth prioritizing an attempt at MIR-&gt;MIR. If I run into any unexpected complications, I'll document them and can discuss the pros and cons of alternatives from there.</p>",
        "id": 196255224,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588637514
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195876222\" title=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/195876222\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"133247\">bjorn3</span>, <span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> and the rest of <span class=\"user-group-mention\" data-user-group-id=\"1162\">@WG-mir-opt</span> should be able to help</p>\n</blockquote>\n<p><span class=\"user-group-mention\" data-user-group-id=\"1162\">@WG-mir-opt</span> Please take a look at my revisions to the <a href=\"https://github.com/rust-lang/compiler-team/issues/278\" title=\"https://github.com/rust-lang/compiler-team/issues/278\">Rust coverage MCP submission</a>. (I tried to tag this group by @mention but github does not allow me to; hence this ping.)  Thanks!</p>",
        "id": 196256019,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1588638206
    },
    {
        "content": "<p>Thanks for the ping <span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span>! I'm going to spend some time this evening going over the revised proposal and the rest of the thread here.</p>",
        "id": 196310930,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1588687175
    },
    {
        "content": "<p><span class=\"user-group-mention\" data-user-group-id=\"492\">@T-compiler</span>: Proposal <a href=\"https://github.com/rust-lang/compiler-team/issues/278#issuecomment-624722653\" title=\"https://github.com/rust-lang/compiler-team/issues/278#issuecomment-624722653\">#278</a> has been seconded, and will be approved in 10 days if no objections are raised.</p>",
        "id": 196652538,
        "sender_full_name": "triagebot",
        "timestamp": 1588779360
    },
    {
        "content": "<p><span class=\"user-group-mention\" data-user-group-id=\"492\">@T-compiler</span>: Proposal <a href=\"https://github.com/rust-lang/compiler-team/issues/278#issuecomment-624722653\">#278</a> was accepted/approved, with note from <span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> on May 21. Thanks!</p>",
        "id": 198372848,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1590092935
    },
    {
        "content": "<p><span class=\"user-group-mention\" data-user-group-id=\"492\">@T-compiler</span> - I'd like to give the broader compiler team an opportunity to take a look at and potentially weigh in on a suggested change to how I represent coverage counter metadata injected into MIR.</p>\n<p>I currently encode metadata as Rust intrinsic functions and args (Operands), most of which inform the codegen process (e.g., to generate the coverage map data section), but not always generating an actual LLVM intrinsic call.</p>\n<p>The use of existing MIR Call Terminators and arguments allows me to implement the coverage instrumentation purely through MIR manipulation, but it's a bit \"hacky\" using \"fake\" function calls, and encoding and decoding <code>Operand</code>s just to pass data from the MIR phase to the codegen phase.  (This was a known tradeoff of the current approach.)</p>\n<p>I recently noticed that the current approach also results in some less than optimal LLVM IR output, adding some unnecessary BasicBlocks and <code>br</code>anches, and worse, moving those blocks around so the LLVM IR is not as sequential as it would be otherwise (making it less \"readable\", for those that care to read it).</p>\n<p>I see an opportunity to not only improve the LLVM IR generation, but also significantly improve some of the MIR and codegen aspects of this implementation.</p>\n<p>I suggest changing the implementation from using \"Call\" terminators to<br>\nusing a custom <code>StatementKind</code>. This would have several benefits:</p>\n<ol>\n<li>One problem with using a Call <code>Terminator</code> is a <code>Terminator</code> requires its own<br>\n   BasicBlock, but as it turns out, LLVM's <code>instrprof.increment</code> intrinsic is converted<br>\n   into a set of inline statements that don't actually perform a function call and don't<br>\n   need to unwind or branch. However, the existence of the BasicBlock in the Rust MIR CFG<br>\n   results the generation of an additional BasicBlock label, and an unnecessary <code>br</code>anch,<br>\n   from the statement just after the increment statements to the label for the next<br>\n   block, even though the first statement of the next block is sequentionally next<br>\n   anyway. Here's an LLVM IR snippet to demonstrate this. The example function has no<br>\n   statements:</li>\n</ol>\n<h1>No instrumentation:</h1>\n<div class=\"codehilite\"><pre><span></span><code>     <span class=\"p\">{</span>\n       <span class=\"nl\">start:</span>\n       <span class=\"k\">ret</span> <span class=\"k\">void</span>\n     <span class=\"p\">}</span>\n</code></pre></div>\n\n\n<h1>Current instrumentation with required new block:</h1>\n<div class=\"codehilite\"><pre><span></span><code>     <span class=\"p\">{</span>\n       <span class=\"nl\">start:</span>\n       <span class=\"nv\">%pgocount</span> <span class=\"p\">=</span> <span class=\"k\">load</span> <span class=\"k\">i64</span><span class=\"p\">,</span> <span class=\"k\">i64</span><span class=\"p\">*</span> <span class=\"k\">getelementptr</span> <span class=\"k\">inbounds</span> <span class=\"p\">([</span><span class=\"m\">1</span> <span class=\"k\">x</span> <span class=\"k\">i64</span><span class=\"p\">],</span>  <span class=\"p\">[</span><span class=\"m\">1</span> <span class=\"k\">x</span> <span class=\"k\">i64</span><span class=\"p\">]*</span> <span class=\"vg\">@__profc_testfunc</span><span class=\"p\">,</span> <span class=\"k\">i64</span> <span class=\"m\">0</span><span class=\"p\">,</span> <span class=\"k\">i64</span> <span class=\"m\">0</span><span class=\"p\">)</span>\n       <span class=\"nv nv-Anonymous\">%0</span> <span class=\"p\">=</span> <span class=\"k\">add</span> <span class=\"k\">i64</span> <span class=\"nv\">%pgocount</span><span class=\"p\">,</span> <span class=\"m\">1</span>\n       <span class=\"k\">store</span> <span class=\"k\">i64</span> <span class=\"nv nv-Anonymous\">%0</span><span class=\"p\">,</span> <span class=\"k\">i64</span><span class=\"p\">*</span> <span class=\"k\">getelementptr</span> <span class=\"k\">inbounds</span> <span class=\"p\">([</span><span class=\"m\">1</span> <span class=\"k\">x</span> <span class=\"k\">i64</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"m\">1</span> <span class=\"k\">x</span> <span class=\"k\">i64</span><span class=\"p\">]*</span> <span class=\"vg\">@__profc_testfunc</span><span class=\"p\">,</span> <span class=\"k\">i64</span> <span class=\"m\">0</span><span class=\"p\">,</span> <span class=\"k\">i64</span> <span class=\"m\">0</span><span class=\"p\">)</span>\n       <span class=\"k\">br</span> <span class=\"k\">label</span> <span class=\"nv\">%bb1</span>          <span class=\"c\">; unnecessary</span>\n\n       <span class=\"nl\">bb1:</span>                   <span class=\"c\">; unnecessary</span>\n       <span class=\"k\">ret</span> <span class=\"k\">void</span>\n     <span class=\"p\">}</span>\n</code></pre></div>\n\n\n<h1>Expected instrumentation, possible with custom coverage <code>StatementKind</code></h1>\n<div class=\"codehilite\"><pre><span></span><code>     <span class=\"p\">{</span>\n       <span class=\"nl\">start:</span>\n       <span class=\"nv\">%pgocount</span> <span class=\"p\">=</span> <span class=\"k\">load</span> <span class=\"k\">i64</span><span class=\"p\">,</span> <span class=\"k\">i64</span><span class=\"p\">*</span> <span class=\"k\">getelementptr</span> <span class=\"k\">inbounds</span> <span class=\"p\">([</span><span class=\"m\">1</span> <span class=\"k\">x</span> <span class=\"k\">i64</span><span class=\"p\">],</span>  <span class=\"p\">[</span><span class=\"m\">1</span> <span class=\"k\">x</span> <span class=\"k\">i64</span><span class=\"p\">]*</span> <span class=\"vg\">@__profc_testfunc</span><span class=\"p\">,</span> <span class=\"k\">i64</span> <span class=\"m\">0</span><span class=\"p\">,</span> <span class=\"k\">i64</span> <span class=\"m\">0</span><span class=\"p\">)</span>\n       <span class=\"nv nv-Anonymous\">%0</span> <span class=\"p\">=</span> <span class=\"k\">add</span> <span class=\"k\">i64</span> <span class=\"nv\">%pgocount</span><span class=\"p\">,</span> <span class=\"m\">1</span>\n       <span class=\"k\">store</span> <span class=\"k\">i64</span> <span class=\"nv nv-Anonymous\">%0</span><span class=\"p\">,</span> <span class=\"k\">i64</span><span class=\"p\">*</span> <span class=\"k\">getelementptr</span> <span class=\"k\">inbounds</span> <span class=\"p\">([</span><span class=\"m\">1</span> <span class=\"k\">x</span> <span class=\"k\">i64</span><span class=\"p\">],</span> <span class=\"p\">[</span><span class=\"m\">1</span> <span class=\"k\">x</span> <span class=\"k\">i64</span><span class=\"p\">]*</span> <span class=\"vg\">@__profc_testfunc</span><span class=\"p\">,</span> <span class=\"k\">i64</span> <span class=\"m\">0</span><span class=\"p\">,</span> <span class=\"k\">i64</span> <span class=\"m\">0</span><span class=\"p\">)</span>\n       <span class=\"k\">ret</span> <span class=\"k\">void</span>\n     <span class=\"p\">}</span>\n</code></pre></div>\n\n\n<ol start=\"2\">\n<li>\n<p>Also, to inject the new BasicBlock requires adding the block to the end of the vector<br>\n   of BasicBlocks, and then, since the new block has to be inserted BEFORE another block,<br>\n   the \"next\" BasicBlockData has to be swapped with the new intrinsic Call terminator<br>\n   BasicBlockData, which results in LLVM IR that jumps around more than it would<br>\n   otherwise. (What was the first block in a Function moves to the last block in the<br>\n   function, and shows up last in LLVM IR, with a <code>br</code>anch to that last block after<br>\n   incrementing the intrinsic. A custom <code>StatementKind</code> would avoid all of this.</p>\n</li>\n<li>\n<p>A custom statement should allow us to embed metadata in the new StatementKind(s)<br>\n   without requiring me to encode them as <code>Operand</code>s, for which the translations can be<br>\n   somewhat obscure. Currently, the <code>Operand</code> types require very specific <code>Ty</code>pe<br>\n   metadata that was really hard to get right, just to make the intrinsics look like<br>\n   normal Rust function calls, even though they are never actually used that way.</p>\n</li>\n<li>\n<p>The filename <code>str</code> generates an <code>Allocation</code> for the string content, and even though<br>\n   this const operand is _only_ used pre-codegen, this unused alloc still gets injected<br>\n   into LLVM IR. This entire issue can be avoided with a custom <code>StatementKind</code>.</p>\n</li>\n<li>\n<p>The temporary objects and corresponding <code>StorageLive</code> and <code>StorageDead</code> <code>StatementKinds</code>,<br>\n   required by the <code>Call</code> as a return result (though empty), can be removed.</p>\n</li>\n<li>\n<p>All of the essentially \"fake\" coverage intrinsic function declarations, and the<br>\n   associated \"lang items\" can be removed.</p>\n</li>\n<li>\n<p>The special handling of these calls during code generation can be migrated to more<br>\n   isolated and coverage-specific handlers of the coverage <code>StatementKind</code>(s), which would<br>\n   make the rest of the intrinsic codegen handling less confusing.</p>\n</li>\n</ol>\n<p>All of these changes will probably result in a simpler and smaller overall<br>\nimplementation.</p>\n<p>(Attn to primary reviewers: <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> <span class=\"user-mention\" data-user-id=\"116883\">@tmandry</span> )</p>",
        "id": 206731748,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1597256630
    },
    {
        "content": "<p>Given that the eventual goal is to add an intrinsic to every branch, I think adding another <code>StatementKind</code> makes sense given the likely performance impact and the complexity of the IR that we'd get otherwise.</p>",
        "id": 206733352,
        "sender_full_name": "tmandry",
        "timestamp": 1597257475
    },
    {
        "content": "<p>That said, there of course is a cost of adding a new case to everything that consumes MIR</p>",
        "id": 206733530,
        "sender_full_name": "tmandry",
        "timestamp": 1597257574
    },
    {
        "content": "<p>I wonder if other intrinsics would also benefit from being modeled as statements</p>",
        "id": 206734028,
        "sender_full_name": "tmandry",
        "timestamp": 1597257823
    },
    {
        "content": "<p>Maybe. I'm not sure they would all have similar benefits, but other intrinsics in <code>rustc_codegen_ssa::mir::block</code> that don't get passed to <code>codegen_intrinsic_call()</code> include <code>transmute</code>, <code>drop_in_place</code>, <code>caller_location</code>, and (I think) <code>simd_shuffle</code>, <code>assert_inhabited</code>, <code>assert_zero_valid</code>, and <code>assert_uninit_valid</code>. These all handle codegen a bit differently, and I don't see a lot of similarity to how coverage injection is done.</p>",
        "id": 206739499,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1597260591
    },
    {
        "content": "<p>IMO I think it would be hard to come up with a one-size-fits-all solution. If we can limit this discussion to the original topic, I think it will be easier to get through; and if there's agreement to move forward, it could be a model for other intrinsics to follow in the future.</p>",
        "id": 206739653,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1597260664
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> I noted your thumbs-up, and I'm not seeing any objections to the suggested approach. Unless you think we should wait longer, I may start working on this tomorrow. Let me know if you disagree. Thanks!</p>",
        "id": 206882549,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1597360296
    },
    {
        "content": "<p>No objections here. I do wonder though if adding new MIR StatementKinds needs to go through an MCP.</p>\n<p>I can see a few ways we could go:</p>\n<ul>\n<li>\n<p>We add a StatementKind specifically for code coverage</p>\n<ul>\n<li>Pros: Has pretty obvious semantics, probably the simplest solution for this problem, might be reusable for other code coverage techs </li>\n<li>Cons: Not really scalable in the long run for each intrinsic</li>\n</ul>\n</li>\n<li>\n<p>We add a StatementKind for intrinsics</p>\n<ul>\n<li>Pros: Would scale better, might solve the unused allocation issue for string data.</li>\n<li>Cons: There might not be enough commonality between intrinsics for this to make sense. We're getting along ok as it is now so this might be overkill. </li>\n</ul>\n</li>\n<li>\n<p>We add a StatementKind for calls which cannot unwind</p>\n<ul>\n<li>Pros: Would be conceptually similar to how we inject the performance counter now, there might be compilation time wins since we can more eagerly remove unwind branches.  </li>\n<li>Cons: To do this completely would probably be a larger change than the other two but if this is the direction we choose to go, we could start by just doing this for the code coverage intrinsic and leave the rest of the work to be done later. (I would be interested in helping with that effort)</li>\n</ul>\n</li>\n</ul>",
        "id": 206889745,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597368007
    },
    {
        "content": "<p>I'm leaning toward the first option, but since there are essentially three variants of coverage intrinsics right now (increment, expression, and unreachable) I think I would implement it as a StatementKind variant with sub-variants anyway. If (perhaps deciding during code review) we decide it makes sense to make this more general purpose, we can add more sub-variants for any of those other intrinsics that make sense.</p>",
        "id": 206890440,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1597368879
    },
    {
        "content": "<p>That would limit the impact of adding new subvariants to a much smaller code footprint, compared with adding more StatementKinds</p>",
        "id": 206890481,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1597368936
    },
    {
        "content": "<p>As for going through another MCP, obviously I can't make that call, but I don't see why this would not be considered just a design decision under the existing, approved MCP. There wasn't anything in the MCP that contradicts this approach. (We even considered it in the beginning. At least, I remember Tyler suggesting using a Statement instead of inserting a block, so he gets the credit for that good idea ;-)</p>\n<p>Perhaps let's see what the PR looks like, and if it feels \"major\", consider either looping in others for review, or consider an MCP if there are broader impacts we don't forsee.</p>",
        "id": 206890835,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1597369388
    },
    {
        "content": "<p>I'm fine with starting the work now and seeing what it looks like. There are large number of consumers of MIR in the compiler ecosystem so adding new types of statements might be disruptive enough that it requires it's own MCP. I will reach out to some folks and see what they think. If that is the case, having a PR with the suggested design would probably make it go faster so that would still be helpful.</p>",
        "id": 206979224,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597437598
    },
    {
        "content": "<p>The PR is complete and ready for review: <a href=\"https://github.com/rust-lang/rust/pull/75563\">https://github.com/rust-lang/rust/pull/75563</a></p>",
        "id": 207040804,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1597527931
    },
    {
        "content": "<p>I'm really happy with the results, both in terms of the rustc implementation code itself (significantly reduced SLOC and complexity), and much smaller impact on the generated MIR and LLVM IR. See for example the <a href=\"https://github.com/rust-lang/rust/blob/7166355861bc959cac468091da13bba8c17bc33d/src/test/mir-opt/instrument_coverage.main.InstrumentCoverage.diff\">cleaner mir-opt diff</a>, vs. <a href=\"https://github.com/rust-lang/rust/blob/master/src/test/mir-opt/instrument_coverage.main.InstrumentCoverage.diff\">the prior implementation</a>. And the unwanted <code>alloc</code> in the LLVM IR (for the non-codegenned filename string operand) is taken care of now too.</p>",
        "id": 207055387,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1597554131
    },
    {
        "content": "<p>I realized a couple of additional advantages (in addition to the <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/206731748\">original 7 advantages I expected</a>):</p>\n<ul>\n<li>Diff-based tests of both MIR and LLVM are much less brittle because the lines changed have a direct relationship with the enabled coverage instrumentation feature. This will make a huge difference when I add more tests to cover different branching scenarios (if-else, match, lazy boolean, loops) because unlike the prior implementation, I don't have to move entire blocks around.</li>\n<li>Since I'm not limited to primitive data types supported by Operand, I was able to take advantage of semantically-enforced <code>newtype_index!</code> types throughout the implementation, from injection to codegen to the coverage map generation. The implementation has better consistency across the board, and should be much more maintainable.</li>\n</ul>",
        "id": 207168686,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1597683590
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/233931-t-compiler.2Fmajor-changes/topic/Implement.20LLVM-compatible.20source-based.20cod.20compiler-team.23278/near/206889745\">said</a>:</p>\n<blockquote>\n<p>...<br>\nI can see a few ways we could go:</p>\n<ul>\n<li>We add a <code>StatementKind</code> specifically for code coverage<br>\n...</li>\n</ul>\n</blockquote>\n<p>The PR currently calls it <code>StatementKind::Coverage</code> and has one variant value of type <code>Coverage</code>.</p>\n<p>If we want to make this a little more generic, I'd like to suggest: <code>StatementKind::Injected</code>, taking an <code>InjectedKind</code> enum value. <code>Coverage</code> can then be a <code>kind</code> of <code>Injected</code> statement. </p>\n<p>The semantics of an \"Injected\" statement would be, the statement is injected during compilation (it does not exist at the source level), meaning it can be ignored or removed without affecting the semantics of the original source code.</p>\n<p>I think it's reasonable to expect an <code>Injected</code> statement does not return a value, and does not unwind.</p>\n<p>I haven't looked into whether these semantics support any of the other non-codegenned intrinsics, but the <code>Injected</code> variant could be used with other, future instrumentation features (maybe similar to LLVM sanitizers).</p>\n<p>This lines up with the PR feedback from <span class=\"user-mention\" data-user-id=\"120791\">@RalfJ</span> regarding how Miri should handle <code>Coverage</code>.</p>",
        "id": 207208336,
        "sender_full_name": "Rich Kadel",
        "timestamp": 1597706521
    },
    {
        "content": "<p>I put up a PR for a blog post announcing this feature: <a href=\"https://github.com/rust-lang/blog.rust-lang.org/pull/725\">https://github.com/rust-lang/blog.rust-lang.org/pull/725</a></p>",
        "id": 216420217,
        "sender_full_name": "tmandry",
        "timestamp": 1605147220
    },
    {
        "content": "<p>FYI: <a href=\"#narrow/stream/257328-clippy/topic/Clippy.20code.20coverage/near/216439076\">Clippy code coverage</a></p>",
        "id": 216439271,
        "sender_full_name": "flip1995",
        "timestamp": 1605169663
    },
    {
        "content": "<p>One question: Is it possible to exlude deps when creating or showing the coverage report?</p>",
        "id": 216439358,
        "sender_full_name": "flip1995",
        "timestamp": 1605169731
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"264664\">@flip1995</span> I think you can compile the deps without <code>-Zinstrument-coverage</code>, though it might require cargo support</p>",
        "id": 216524120,
        "sender_full_name": "tmandry",
        "timestamp": 1605213238
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span> do you know how that would interact with e.g. generic functions from other crates that are monomorphized when compiling with <code>-Zinstrument-coverage</code>?</p>",
        "id": 216524285,
        "sender_full_name": "tmandry",
        "timestamp": 1605213283
    },
    {
        "content": "<p>Hi all -- i'm having trouble finding the <code>llvm-cov</code> binary.  according to the docs, it should be next to <code>llvm-profdata</code>, but i'm not finding it</p>",
        "id": 216661041,
        "sender_full_name": "Andrew Chin (eminence)",
        "timestamp": 1605295911
    },
    {
        "content": "<p>ooh, i see.  i need <a href=\"https://github.com/rust-lang/rust/issues/78947\">#78947</a>.  ok, nevermind!  sorry for the noise</p>",
        "id": 216661504,
        "sender_full_name": "Andrew Chin (eminence)",
        "timestamp": 1605295999
    },
    {
        "content": "<p>I had the same issue about <code>llvm-cov</code>. Maybe it's worth extending <a href=\"https://doc.rust-lang.org/nightly/unstable-book/compiler-flags/source-based-code-coverage.html\">https://doc.rust-lang.org/nightly/unstable-book/compiler-flags/source-based-code-coverage.html</a> to mention how to install <code>llvm-cov</code> with <code>rustup</code>, and where to find the binary?</p>",
        "id": 217006052,
        "sender_full_name": "Thomas McGuire",
        "timestamp": 1605622067
    },
    {
        "content": "<p>Also, for anyone else reading this, in the hope it helps: When installing <code>llvm-tools-preview</code> with <code>rustup</code> for nightly, make sure to remove <code>miri</code> first, as it is not contained in the version of today (<a href=\"https://rust-lang.github.io/rustup-components-history/\">https://rust-lang.github.io/rustup-components-history/</a>), and <code>rustup</code> will skip versions with missing components (<a href=\"https://github.com/rust-lang/blog.rust-lang.org/pull/725#discussion_r523181457\">https://github.com/rust-lang/blog.rust-lang.org/pull/725#discussion_r523181457</a>).</p>",
        "id": 217007716,
        "sender_full_name": "Thomas McGuire",
        "timestamp": 1605622818
    },
    {
        "content": "<p>After solving the <code>llvm-cov</code> issue, it seems to work nicely so far. Good job! <span aria-label=\"thumbs up\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"thumbs up\">:thumbs_up:</span></p>",
        "id": 217012778,
        "sender_full_name": "Thomas McGuire",
        "timestamp": 1605624927
    },
    {
        "content": "<p>Hi, I am having trouble with the generated prof data, it is not empty but it reports 0% coverage. More details about what I do:</p>\n<ul>\n<li>use toolchain <code>nightly-2020-11-16</code> via <code>rust-toolchain</code> file</li>\n<li>run <code>RUSTFLAGS=\"-Zinstrument-coverage\" cargo test</code></li>\n<li>run <code>llvm-profdata-10 merge -sparse default.profraw -o default.profdata</code></li>\n<li>run <code>llvm-cov-10 export target/debug/deps/&lt;crate&gt;-&lt;checksum&gt; -instr-profile=default.profdata --format=lcov &gt;| lcov.txt</code></li>\n<li>and finally run <code>lcov --summary lcov.txt</code> which prints</li>\n</ul>\n<div class=\"codehilite\"><pre><span></span><code>Reading tracefile lcov.txt\nSummary coverage rate:\n  lines......: 0.0% (0 of 13741 lines)\n  functions..: 0.0% (0 of 1122 functions)\n  branches...: no data found\n</code></pre></div>\n<p>I cannot figure out what is my mistake.</p>",
        "id": 217068437,
        "sender_full_name": "Arnaud de Bossoreille",
        "timestamp": 1605650074
    },
    {
        "content": "<p>I managed to go further the doc tests overwrote the raw data after the test executable. I'll try to play with <code>LLVM_PROFILE_FILE</code>.</p>",
        "id": 217072865,
        "sender_full_name": "Arnaud de Bossoreille",
        "timestamp": 1605652502
    }
]