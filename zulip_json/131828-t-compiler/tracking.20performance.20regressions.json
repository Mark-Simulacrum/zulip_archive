[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> <span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span> Pong. I would suggest that whether we continue to track a regression depends on how severe we consider it. \"We generate one extra instruction\" isn't necessarily a bug worth tracking. \"We fail to vectorize something we vectorized before\", on the other hand, is severe enough to be worth tracking.</p>",
        "id": 198350490,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590081996
    },
    {
        "content": "<p>In this case, I don't think the code size issue alone is critical, but generating panic handlers when we didn't before seems problematic.</p>",
        "id": 198350609,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590082062
    },
    {
        "content": "<p>And I suggested reporting it because I wondered if fixing it might be as simple as an <code>#[inline]</code> hint in the right place (and then appropriate testing to make sure that doesn't cause unexpected problems / perf issues).</p>",
        "id": 198350739,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590082119
    },
    {
        "content": "<p>This topic was moved here from <a class=\"stream-topic\" data-stream-id=\"238009\" href=\"/#narrow/stream/238009-t-compiler.2Fmeetings/topic/.5Bweekly.20meeting.5D.202020-05-21.20.2354818\">#t-compiler/meetings &gt; [weekly meeting] 2020-05-21 #54818</a> by <span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span></p>",
        "id": 198355563,
        "sender_full_name": "Notification Bot",
        "timestamp": 1590084468
    },
    {
        "content": "<p>pulled this over here</p>",
        "id": 198355608,
        "sender_full_name": "simulacrum",
        "timestamp": 1590084482
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> One of the problems we have is that \"doesn't cause unexpected problems\" isn't actually something we can really say too well, unfortunately -- we just don't have a good suite of test cases. For example, <code>#[inline]</code> in panic code can be an optimization if it means it vanishes but <em>definitely</em> hurts compile times for all users of that method (or callers?) as we start to codegen it into downstream crates, which can be quite painful.</p>",
        "id": 198355801,
        "sender_full_name": "simulacrum",
        "timestamp": 1590084572
    },
    {
        "content": "<p>Sure, there are tradeoffs between compilation performance and runtime performance.</p>",
        "id": 198361662,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590087587
    },
    {
        "content": "<p>That's the kind of thing I'd <em>hope</em> could be tied to <code>--release</code>.</p>",
        "id": 198361687,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590087598
    },
    {
        "content": "<p>I do think there may be room for --release-but-no-really-i-can-wait</p>",
        "id": 198361833,
        "sender_full_name": "simulacrum",
        "timestamp": 1590087641
    },
    {
        "content": "<p>But in any case, what I'm thinking of by \"doesn't cause unexpected problems\" would be a rust-timer run.</p>",
        "id": 198361854,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590087650
    },
    {
        "content": "<p>yeah, that's what we'd usually do</p>",
        "id": 198361876,
        "sender_full_name": "simulacrum",
        "timestamp": 1590087658
    },
    {
        "content": "<p>Adding the <code>#[inline]</code> and running rust-timer seems worthwhile.</p>",
        "id": 198361887,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590087661
    },
    {
        "content": "<p>We could then evaluate the tradeoff.</p>",
        "id": 198361927,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590087677
    },
    {
        "content": "<p>I do think it makes sense to try a rust-timer run here and see how it goes</p>",
        "id": 198361932,
        "sender_full_name": "simulacrum",
        "timestamp": 1590087681
    },
    {
        "content": "<p>(presuming there's an inline or whatever that can be added)</p>",
        "id": 198361947,
        "sender_full_name": "simulacrum",
        "timestamp": 1590087691
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/tracking.20performance.20regressions/near/198361833\">said</a>:</p>\n<blockquote>\n<p>I do think there may be room for --release-but-no-really-i-can-wait</p>\n</blockquote>\n<p>Perhaps, yes. Among other things, that could also turn on LTO.</p>",
        "id": 198361982,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590087710
    },
    {
        "content": "<p>We'd probably want to start by adding a new optimization level to rustc. But I don't know how much this is on-topic for <em>this</em> particular issue.</p>",
        "id": 198362087,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590087743
    },
    {
        "content": "<p>Yes for this particular case I would agree that trying to fix it seems reasonable</p>",
        "id": 198362331,
        "sender_full_name": "simulacrum",
        "timestamp": 1590087862
    },
    {
        "content": "<p>but I think if there's not an easy fix (e.g. inline annotations) then there's not much to do</p>",
        "id": 198362359,
        "sender_full_name": "simulacrum",
        "timestamp": 1590087876
    },
    {
        "content": "<p>I do <em>absolutely</em> agree that we can't track every last \"why does new rustc generate three more instructions here\" regression, and we should focus on the ones that have an impact.</p>",
        "id": 198362432,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590087923
    },
    {
        "content": "<p>There's definitely a (fuzzy) line somewhere for what we should track.</p>",
        "id": 198362459,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590087941
    },
    {
        "content": "<p>On a different note...I wonder how difficult it would be to have a fully automated regression-bisect bot? For instance, \"here's a test case, it's a failure if the compiled output {includes this instruction, doesn't include this instruction, calls this function, has more than X instructions, ...}\". @ some github bot, get back a commit hash and a diff of compiled output for the test case.</p>",
        "id": 198362770,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590088089
    },
    {
        "content": "<p>Once you add support to <code>cargo bisect-rustc</code>, adding support to my bisect bot should just be a matter of parsing the instruction for it and passing it to <code>cargo bisect-rustc</code>.</p>",
        "id": 198363129,
        "sender_full_name": "bjorn3",
        "timestamp": 1590088263
    },
    {
        "content": "<p>do we expect a lot of these regressions to be in rustc rather than the one PR updating LLVM to the most recent version ?</p>",
        "id": 198363801,
        "sender_full_name": "lqd",
        "timestamp": 1590088581
    },
    {
        "content": "<p>it's mostly std or llvm, these days, but as we have more mir opts that'll probably change</p>",
        "id": 198363878,
        "sender_full_name": "simulacrum",
        "timestamp": 1590088627
    },
    {
        "content": "<p>right</p>",
        "id": 198363894,
        "sender_full_name": "lqd",
        "timestamp": 1590088640
    },
    {
        "content": "<p>codegen changes in std happen more often than the others, very true</p>",
        "id": 198364019,
        "sender_full_name": "lqd",
        "timestamp": 1590088697
    },
    {
        "content": "<p>I guess lolbench could also have a role to play in this conversation</p>",
        "id": 198364223,
        "sender_full_name": "lqd",
        "timestamp": 1590088811
    },
    {
        "content": "<p>(although its regressions had a per-nightly granularity IIRC rather than per-commit; and here the actual code regressing would be known to the bisector, rather than some performance counters stats)</p>",
        "id": 198364762,
        "sender_full_name": "lqd",
        "timestamp": 1590089117
    },
    {
        "content": "<p>lolbench iirc takes forever to run</p>",
        "id": 198365532,
        "sender_full_name": "simulacrum",
        "timestamp": 1590089483
    },
    {
        "content": "<p>like, days</p>",
        "id": 198365535,
        "sender_full_name": "simulacrum",
        "timestamp": 1590089486
    },
    {
        "content": "<p>yeah, part of the reason why it couldn't per-commit iirc</p>",
        "id": 198365572,
        "sender_full_name": "lqd",
        "timestamp": 1590089510
    },
    {
        "content": "<p>(maybe with enough sponsored hardware + pinning benches to the same host it could be speedier :)</p>",
        "id": 198365728,
        "sender_full_name": "lqd",
        "timestamp": 1590089586
    },
    {
        "content": "<p>perhaps :)</p>",
        "id": 198366138,
        "sender_full_name": "simulacrum",
        "timestamp": 1590089765
    }
]