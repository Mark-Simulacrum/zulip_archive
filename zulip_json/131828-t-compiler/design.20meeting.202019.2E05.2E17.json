[
    {
        "content": "<p>Hi <span class=\"user-group-mention\" data-user-group-id=\"897\">@T-compiler/meeting</span> ! We're going to be having our first ever design meeting here in <strong>5 minutes</strong>. The topic of discussion is moving to a parallel rustc. Big thanks <span aria-label=\"heart\" class=\"emoji emoji-2764\" role=\"img\" title=\"heart\">:heart:</span> to <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> and <span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span> for working hard on gathering data over the last week or so.</p>",
        "id": 165902147,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101375
    },
    {
        "content": "<p>You can <a href=\"https://hackmd.io/s/B1NAo-m3V\" target=\"_blank\" title=\"https://hackmd.io/s/B1NAo-m3V\">view the \"measurements hackmd file\" here</a></p>",
        "id": 165902196,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101418
    },
    {
        "content": "<p>( cc <span class=\"user-mention\" data-user-id=\"116015\">@Alex Crichton</span> and <span class=\"user-mention\" data-user-id=\"220056\">@lwshang</span> )</p>",
        "id": 165902294,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101482
    },
    {
        "content": "<p>Hmm I realize it'd be nice to have the \"absolute perf differences\" too; <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> there isn't some \"quick-n-dirty\" way to dump the data into a spreadsheet, is there?</p>",
        "id": 165902569,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101688
    },
    {
        "content": "<p>(Is the data available in json form?)</p>",
        "id": 165902636,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101732
    },
    {
        "content": "<p>Shall we start?</p>",
        "id": 165902752,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101845
    },
    {
        "content": "<p>(Is <span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span> here?)</p>",
        "id": 165902761,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101858
    },
    {
        "content": "<p>I didn't see them \"wave\" in the meeting announcement :)</p>",
        "id": 165902785,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101881
    },
    {
        "content": "<p>Did they confirm availability for this slot?</p>",
        "id": 165902815,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558101906
    },
    {
        "content": "<p>They were here when we settled on the time</p>",
        "id": 165902822,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101914
    },
    {
        "content": "<p>But in any case we might as well get started</p>",
        "id": 165902829,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101922
    },
    {
        "content": "<p>I'm here =P</p>",
        "id": 165902848,
        "sender_full_name": "Zoxc",
        "timestamp": 1558101951
    },
    {
        "content": "<p>ah for some reason Zulip wasn't updating for me, I'm not sure what you mean by absolute perf differences</p>",
        "id": 165902860,
        "sender_full_name": "simulacrum",
        "timestamp": 1558101962
    },
    {
        "content": "<p>each \"row\" on perf is expandable if you click the black triangle on the left</p>",
        "id": 165902901,
        "sender_full_name": "simulacrum",
        "timestamp": 1558101980
    },
    {
        "content": "<p>What I meant is seeing not just \"20% slower\" but \"slower by 0.2s\" or whatever</p>",
        "id": 165902905,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101981
    },
    {
        "content": "<p>yeah, the data is there, I just have to do the math myself :)</p>",
        "id": 165902912,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558101990
    },
    {
        "content": "<p>I will see if I can hack something together</p>",
        "id": 165902927,
        "sender_full_name": "simulacrum",
        "timestamp": 1558102005
    },
    {
        "content": "<p>Anyway, the context is that some time back <span class=\"user-mention\" data-user-id=\"124287\">@mw</span>, <span class=\"user-mention\" data-user-id=\"116015\">@Alex Crichton</span> and I drew up <a href=\"https://gist.github.com/nikomatsakis/4263d4f55ff290c7c46993035dbeb091\" target=\"_blank\" title=\"https://gist.github.com/nikomatsakis/4263d4f55ff290c7c46993035dbeb091\">this rough plan</a> to talk about trying to deploy parallel rustc.</p>",
        "id": 165902942,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102021
    },
    {
        "content": "<p>The idea was to deploy in 3 phases, but basically the most important is the first one: enabling parallel compilation (meaning, the use of locks etc) but making it <strong>opt-in</strong>.</p>",
        "id": 165902998,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102075
    },
    {
        "content": "<p>This is a \"rough patch\" because, if you're not using parallelism for whatever reason, you don't get to recoup the perf benefits.</p>",
        "id": 165903057,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102096
    },
    {
        "content": "<p>At the time, I think we were shooting for performance that said no \"major regressions\", which we defined as:</p>\n<blockquote>\n<p>A <strong>major regression</strong> is a regression in compilation time that is both &gt;5% and greater than 1 second.</p>\n</blockquote>",
        "id": 165903076,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102131
    },
    {
        "content": "<p>That may or may not be achievable :)</p>",
        "id": 165903105,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102146
    },
    {
        "content": "<p>So <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> (in the <a href=\"https://hackmd.io/s/B1NAo-m3V\" target=\"_blank\" title=\"https://hackmd.io/s/B1NAo-m3V\">parallel measurements doc</a>) has a bunch of useful links to various measurements</p>",
        "id": 165903134,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102185
    },
    {
        "content": "<p>(are there more whole-crate-graph numbers on the way?)</p>",
        "id": 165903234,
        "sender_full_name": "mw",
        "timestamp": 1558102262
    },
    {
        "content": "<p>Anyway, the point of this meeting I would say is to:</p>\n<ul>\n<li>Decide what criteria we want to deploy the plan</li>\n<li>This includes perf measurements</li>\n<li>But probably talking over other concerns. I've heard two but there may be more:<br>\n    - Maintenance -- the design is not, I think, that broadly documented or understood. That's also sort of par for the course in rustc. Do we want to try to change that? Before/after we deploy? :) What will happen when bugs come up?<br>\n    - This will make perf profiling more complex (raised by <span class=\"user-mention\" data-user-id=\"120989\">@nnethercote</span>) because instruction measurements are less correlated to overall perf (but note we already have parallel llvm enabled)</li>\n</ul>",
        "id": 165903268,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102291
    },
    {
        "content": "<p>it's somewhat slow to collect them (same as with regular perf) -- if we have specific requests I can kick those off but we probably won't have them by meeting</p>",
        "id": 165903270,
        "sender_full_name": "simulacrum",
        "timestamp": 1558102294
    },
    {
        "content": "<p>Should we start by reviewing the measurements?</p>",
        "id": 165903349,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102336
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> cargo with <code>-t4 -j4</code> would be interesting</p>",
        "id": 165903353,
        "sender_full_name": "mw",
        "timestamp": 1558102343
    },
    {
        "content": "<p>The perf.r-l.o section has:</p>\n<p>Wall time, single crate:</p>\n<ul>\n<li><a href=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-8&amp;stat=wall-time\" target=\"_blank\" title=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-8&amp;stat=wall-time\">single vs. -Zthreads=8</a> - 40-60% speedup on average; no significant performance hits</li>\n<li><a href=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-4&amp;stat=wall-time\" target=\"_blank\" title=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-4&amp;stat=wall-time\">single vs. -Zthreads=4</a> - 35-50% speedup on average; no significant performance hits</li>\n<li><a href=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-2&amp;stat=wall-time\" target=\"_blank\" title=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-2&amp;stat=wall-time\">single vs. -Zthreads=2</a> - 20-30% speedup on average; no significant performance hits (most tiny, i.e., &lt;1 second)</li>\n<li><a href=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-1&amp;stat=wall-time\" target=\"_blank\" title=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-1&amp;stat=wall-time\">single vs. -Zthreads=1</a> - 10%-20% slowdown (i.e., overhead of parallelism)</li>\n</ul>",
        "id": 165903373,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102365
    },
    {
        "content": "<p>I'm curious about the final line, this is why I was asking about absolute measurements</p>",
        "id": 165903384,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102377
    },
    {
        "content": "<p>e.g., helloworld-check is 36% slower but it's like 0.6 to 0.7 :)</p>",
        "id": 165903415,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102407
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> <code>-tX-j1</code> means that rustc will never be allowed to use more than one thread (which is useful for measuring overhead but doesn't allow measuring speedups)</p>",
        "id": 165903427,
        "sender_full_name": "mw",
        "timestamp": 1558102416
    },
    {
        "content": "<p>(Oh, I am also remembering now... back when we were talking about NLL performance, someone -- who was it? -- was citing bits of research  about how much slowdown there is before things become noticeable)</p>",
        "id": 165903445,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102431
    },
    {
        "content": "<p>I want to say scottmcm</p>",
        "id": 165903503,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102444
    },
    {
        "content": "<p>okay spreadsheet with absolute data is up but no formulas run yet</p>",
        "id": 165903616,
        "sender_full_name": "simulacrum",
        "timestamp": 1558102525
    },
    {
        "content": "<p>see link in document</p>",
        "id": 165903644,
        "sender_full_name": "simulacrum",
        "timestamp": 1558102543
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> <a href=\"https://github.com/rust-lang-nursery/rustc-perf/issues/192#issuecomment-394611567\" target=\"_blank\" title=\"https://github.com/rust-lang-nursery/rustc-perf/issues/192#issuecomment-394611567\">https://github.com/rust-lang-nursery/rustc-perf/issues/192#issuecomment-394611567</a></p>",
        "id": 165903647,
        "sender_full_name": "mw",
        "timestamp": 1558102544
    },
    {
        "content": "<p><code>packed-simd</code> takes a 20% perf hit and it isn't small.</p>",
        "id": 165903648,
        "sender_full_name": "Zoxc",
        "timestamp": 1558102544
    },
    {
        "content": "<p>oh, nice</p>",
        "id": 165903650,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102544
    },
    {
        "content": "<p>(sorry woke up recently, but I\"m now following here!)</p>",
        "id": 165903806,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1558102671
    },
    {
        "content": "<blockquote>\n<p><code>packed-simd</code> takes a 20% perf hit and it isn't small.</p>\n</blockquote>\n<p>yeah, that's one of the few I've found so far</p>",
        "id": 165903926,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102755
    },
    {
        "content": "<p>packed-simd doesn't take as big a hit in the <a href=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-1&amp;stat=wall-time\" target=\"_blank\" title=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-1&amp;stat=wall-time\">single vs. -Zthreads=1</a> data, FWIW</p>",
        "id": 165903942,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558102769
    },
    {
        "content": "<p>the hit depends also on opt, debug, check</p>",
        "id": 165903958,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102788
    },
    {
        "content": "<blockquote>\n<p>(Oh, I am also remembering now... back when we were talking about NLL performance, someone -- who was it? -- was citing bits of research  about how much slowdown there is before things become noticeable)</p>\n</blockquote>\n<p>It's probably from the book \"Usability Engineering\" which has:</p>\n<ul>\n<li>0.1 seconds — Operations that are completed in 100ms or fewer will feel instantaneous to the user.</li>\n<li>1 second — Operations that take 1 second to finish are generally OK, but the user will feel the pause.</li>\n<li>10 seconds — If an operation takes 10 seconds or more to complete, you’ll struggle to maintain the user’s attention.</li>\n</ul>",
        "id": 165903959,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1558102789
    },
    {
        "content": "<p>which is another way that might be useful to slice the data</p>",
        "id": 165903968,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102793
    },
    {
        "content": "<p>(I guess we have no idea why packed-simd in particular takes a hit?)</p>",
        "id": 165904118,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558102903
    },
    {
        "content": "<p>a lot of the big percentages on the <a href=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-1&amp;stat=wall-time\" target=\"_blank\" title=\"https://perf.rust-lang.org/compare.html?start=single-threaded&amp;end=parallel-rustc-1&amp;stat=wall-time\">single vs. -Zthreads=1</a> data seems like it originates from regressions solely in \"patched incremental\" ... does that sound plausible&gt;?</p>",
        "id": 165904188,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558102932
    },
    {
        "content": "<p>(any ideas as to why \"patched incremental\" in particular would take a signficant hit?)</p>",
        "id": 165904211,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558102961
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span>  Yes. Incremental is lock heavy. <a href=\"https://github.com/rust-lang/rust/pull/60035\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/pull/60035\">https://github.com/rust-lang/rust/pull/60035</a> helps with that</p>",
        "id": 165904245,
        "sender_full_name": "Zoxc",
        "timestamp": 1558102988
    },
    {
        "content": "<p>it might involve more locking than the other workloads</p>",
        "id": 165904246,
        "sender_full_name": "mw",
        "timestamp": 1558102988
    },
    {
        "content": "<p>(perhaps also because those are already starting off as small numbers overall, and so the percentages get exagerrated)</p>",
        "id": 165904263,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558103002
    },
    {
        "content": "<p>(ah my hypothesis is wrong anyway; there are tests where the \"clean\" build was the one with the big perf hit, and not their \"patched incremental\"  variants)</p>",
        "id": 165904384,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558103083
    },
    {
        "content": "<p>that may partially depend on whether the incremental case is hitting the happy path -- i.e., being actually incremental</p>",
        "id": 165904415,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103118
    },
    {
        "content": "<p>(which may cause more locks to be hit)</p>",
        "id": 165904436,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103147
    },
    {
        "content": "<p>I think the incremental cases can allow for more of a hit because they don't aggregate up so much</p>",
        "id": 165904443,
        "sender_full_name": "mw",
        "timestamp": 1558103154
    },
    {
        "content": "<p>but I'm not sure if that's accurate from how incremental is implemented</p>",
        "id": 165904446,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103160
    },
    {
        "content": "<p>i.e. you are usually only re-compiling the leaf crates incrementally</p>",
        "id": 165904498,
        "sender_full_name": "mw",
        "timestamp": 1558103173
    },
    {
        "content": "<p>I think the perf.rlo numbers look OK, with a few outliers (must of them synthetic tests)</p>",
        "id": 165904564,
        "sender_full_name": "mw",
        "timestamp": 1558103248
    },
    {
        "content": "<p>true -- it is worth noting that all of perf data is \"leaf\" compilations (i.e., single-crate)</p>",
        "id": 165904572,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103261
    },
    {
        "content": "<p>I'd be more interested in the whole-crate-graph scenarios</p>",
        "id": 165904576,
        "sender_full_name": "mw",
        "timestamp": 1558103266
    },
    {
        "content": "<p>the things that are \"major regressions\" from what I can tell:</p>\n<ul>\n<li>packed-simd-debug (baseline-incremental, clean) </li>\n<li>packed-simd-opt (clean)</li>\n<li>script-servo-debug (patch/incremental)</li>\n<li>ctfe-stress-2-check</li>\n</ul>",
        "id": 165904635,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103293
    },
    {
        "content": "<p>whereas at least in the rustc whole-crate-graph (i.e., x.py build --stage 0) we see significantly worse performance with multi-threaded as total runtime</p>",
        "id": 165904638,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103298
    },
    {
        "content": "<blockquote>\n<p>I think the perf.rlo numbers look OK, with a few outliers (must of them synthetic tests)</p>\n</blockquote>\n<p>I tend to agree with this</p>",
        "id": 165904644,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103299
    },
    {
        "content": "<p>This is the sort of testing though that we wanted to make a call on internals for right? (whole crate graph testing)</p>",
        "id": 165904648,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1558103305
    },
    {
        "content": "<p>(notably, script-servo-debug starts to have perf improvements of 17% with even 2 cores)</p>",
        "id": 165904721,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103378
    },
    {
        "content": "<p>I'm personally suspecting that the rustc case is fairly representative of many crate graphs -- and that we gain more from coarse parallelism than from fine grained parallelism, at least in the --release case</p>",
        "id": 165904726,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103386
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116015\">@Alex Crichton</span> we wanted to have some numbers for this meeting already</p>",
        "id": 165904732,
        "sender_full_name": "mw",
        "timestamp": 1558103388
    },
    {
        "content": "<p>I may also be misunderstanding the purpose of the mtg here, but is this trying to provide data that we shouldn't turn on parallel -j1 nightlies because the overhead in singlethreaded mode is too high?</p>",
        "id": 165904824,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1558103428
    },
    {
        "content": "<p>we're trying to decide whether to kick off the plan, basically, yes</p>",
        "id": 165904847,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103452
    },
    {
        "content": "<p>I have to say that the rustc numbers are a bit scary</p>",
        "id": 165904865,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103464
    },
    {
        "content": "<p>well it also sounds like <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> is seeing evidence that there is negative return in a very important use case</p>",
        "id": 165904878,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558103473
    },
    {
        "content": "<p>the cargo-tX-j1 results (that seem to be gone again) were rather interesting actually</p>",
        "id": 165904891,
        "sender_full_name": "mw",
        "timestamp": 1558103491
    },
    {
        "content": "<p>in what way?</p>",
        "id": 165904902,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103507
    },
    {
        "content": "<p>they showed no wall-time regression</p>",
        "id": 165904916,
        "sender_full_name": "mw",
        "timestamp": 1558103522
    },
    {
        "content": "<p>although the single-threaded compiler was not tested, I think</p>",
        "id": 165904967,
        "sender_full_name": "mw",
        "timestamp": 1558103539
    },
    {
        "content": "<p>so, nevermind :/</p>",
        "id": 165904976,
        "sender_full_name": "mw",
        "timestamp": 1558103549
    },
    {
        "content": "<p>yeah, I didn't get a chance to run that</p>",
        "id": 165904979,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103551
    },
    {
        "content": "<p>it's really just showing -t1-j1</p>",
        "id": 165904987,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103559
    },
    {
        "content": "<p>at least the jobserver seems to work :)</p>",
        "id": 165904992,
        "sender_full_name": "mw",
        "timestamp": 1558103566
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> : what was the invocation used to gather the rustc-stage0 numbers?</p>",
        "id": 165904999,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558103573
    },
    {
        "content": "<p><code>x.py build --stage 0 </code> with <code>rustc =</code> set to the parallel compiler in bootstrap</p>",
        "id": 165905033,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103605
    },
    {
        "content": "<blockquote>\n<p>at least the jobserver seems to work :)</p>\n</blockquote>\n<p>i.e., doesn't crash? :)</p>",
        "id": 165905109,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103646
    },
    {
        "content": "<p>huh, do the <code>rustc stage 0 compilation</code> look really bad?</p>",
        "id": 165905120,
        "sender_full_name": "mw",
        "timestamp": 1558103661
    },
    {
        "content": "<p>or what did you mean by that?</p>",
        "id": 165905123,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103663
    },
    {
        "content": "<p>it's worth noting that the parallel compiler there is a beta-versioned parallel compiler (i.e., not the most recent possible parallel compiler)</p>",
        "id": 165905128,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103666
    },
    {
        "content": "<p>which is probably not great in hindsight :/</p>",
        "id": 165905139,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103677
    },
    {
        "content": "<p>i.e., doing the stage0 build?</p>",
        "id": 165905140,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103678
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span> : <a href=\"https://hackmd.io/s/B1NAo-m3V#Whole-crate-graph-data-%E2%80%93-from-Mark%E2%80%99s-computer-8-core-16-thread\" target=\"_blank\" title=\"https://hackmd.io/s/B1NAo-m3V#Whole-crate-graph-data-%E2%80%93-from-Mark%E2%80%99s-computer-8-core-16-thread\">https://hackmd.io/s/B1NAo-m3V#Whole-crate-graph-data-%E2%80%93-from-Mark%E2%80%99s-computer-8-core-16-thread</a></p>",
        "id": 165905141,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558103684
    },
    {
        "content": "<p>(if i understand correctly)</p>",
        "id": 165905160,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558103703
    },
    {
        "content": "<p>Here's some numbers I got from rustc compilation <a href=\"https://github.com/rust-lang/rust/pull/59530#issuecomment-481557551\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/pull/59530#issuecomment-481557551\">https://github.com/rust-lang/rust/pull/59530#issuecomment-481557551</a></p>",
        "id": 165905179,
        "sender_full_name": "Zoxc",
        "timestamp": 1558103720
    },
    {
        "content": "<p>hm, is that after x.py clean?</p>",
        "id": 165905197,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103749
    },
    {
        "content": "<blockquote>\n<blockquote>\n<p>at least the jobserver seems to work :)</p>\n</blockquote>\n<p>i.e., doesn't crash? :)</p>\n</blockquote>\n<p>it keeps the time constant, which suggest that now more threads are used than the jobserver allows</p>",
        "id": 165905201,
        "sender_full_name": "mw",
        "timestamp": 1558103753
    },
    {
        "content": "<p>I wonder why <span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span>'s numbers seem so different. I guess it makes sense for us to do a bit more testing here.</p>",
        "id": 165905265,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103793
    },
    {
        "content": "<p>Especially considering those are <code>stage1</code> numbers</p>",
        "id": 165905282,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1558103819
    },
    {
        "content": "<p>yeah I am sitting here wondering if there's something goofy with <code>--stage 0</code> ?</p>",
        "id": 165905304,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558103836
    },
    {
        "content": "<p>So, it seems safe to say:</p>\n<ul>\n<li>perf looks quite good</li>\n<li>rustc and whole-crate-graph numbers are a bit murkier</li>\n</ul>",
        "id": 165905319,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103861
    },
    {
        "content": "<p>Well, so it's worth noting that this is a) a beta compiler essentially (just compiled with --enable-parallel-compiler)</p>",
        "id": 165905321,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103864
    },
    {
        "content": "<p>I'm also not sure how <span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span> collected data</p>",
        "id": 165905360,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103882
    },
    {
        "content": "<p>Didn't we like <em>just</em> branch a beta -- or aren't we about to?</p>",
        "id": 165905387,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103897
    },
    {
        "content": "<p>maybe we need to start sharing benchmarking scripts? just to keep everyone in sync?</p>",
        "id": 165905389,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558103898
    },
    {
        "content": "<p><code>RUSTFLAGS=\"-Zthreads=4\" perf stat -o multi-threaded-t4-j16 -ddd --repeat=10 --pre \"./x.py clean\" -- ./x.py build -j16 --stage 0</code></p>",
        "id": 165905407,
        "sender_full_name": "simulacrum",
        "timestamp": 1558103919
    },
    {
        "content": "<p>I'm wondering if we should spend a bit of time looking beyond the perf measurements -- it seems like we want to do more measurements on rustc at minimum.</p>",
        "id": 165905412,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103921
    },
    {
        "content": "<p>I think we should not focus on rustc too much</p>",
        "id": 165905436,
        "sender_full_name": "mw",
        "timestamp": 1558103947
    },
    {
        "content": "<p>it's always been a weird special case</p>",
        "id": 165905444,
        "sender_full_name": "mw",
        "timestamp": 1558103958
    },
    {
        "content": "<p>I feel like it's kind of one that important to <em>us</em> in a number of ways =)</p>",
        "id": 165905467,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558103985
    },
    {
        "content": "<p>okay, but we should select another large crate graph then</p>",
        "id": 165905470,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558103987
    },
    {
        "content": "<ul>\n<li>servo</li>\n<li>cranelift</li>\n<li>ripgrep</li>\n</ul>",
        "id": 165905479,
        "sender_full_name": "mw",
        "timestamp": 1558103998
    },
    {
        "content": "<p>from the document</p>",
        "id": 165905531,
        "sender_full_name": "mw",
        "timestamp": 1558104008
    },
    {
        "content": "<p>But definitely <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span> to gathering more crate graph numbers</p>",
        "id": 165905533,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104010
    },
    {
        "content": "<p>I can try to get us numbers on all three of those this weekend; unfortunately it takes a lot of time :/</p>",
        "id": 165905553,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104024
    },
    {
        "content": "<p>Yeah :/ I'm game to run some scripts too</p>",
        "id": 165905581,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104045
    },
    {
        "content": "<p>but regardless - I think we should maybe discuss the next few items on the agenda</p>",
        "id": 165905587,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104048
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> I infer it takes a lot of time in part because you are exploring multiple dimensions, varying both thread-count and job-count, yes?</p>",
        "id": 165905594,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104056
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span> yes, and running each build at least 3-4 times to get the +/- down lower)</p>",
        "id": 165905612,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104075
    },
    {
        "content": "<p>as you can see in the current data multi-threaded builds even with 10 runs are still +/- 8% or so</p>",
        "id": 165905631,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104096
    },
    {
        "content": "<p>(I'm not sure if I have much in the way of suggestions as to how to address that combinatoric blowup, but it seems worth trying to reduce in some way...)</p>",
        "id": 165905644,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104113
    },
    {
        "content": "<p>( I feel like we are mostly interested in the 1 thread and maybe like 4 thread case )</p>",
        "id": 165905719,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104140
    },
    {
        "content": "<p>or 2 thread, something like that</p>",
        "id": 165905725,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104146
    },
    {
        "content": "<p>It would certainly reduce the blowup if we do 1, 2, 4 threads / -j{4,8,16} perhaps?</p>",
        "id": 165905745,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104172
    },
    {
        "content": "<p>not sure on the <code>-j</code> bit</p>",
        "id": 165905748,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104176
    },
    {
        "content": "<p>yes, but I do think its interesting to have comparisons against increasing the job-count while keeping thread count fixed</p>",
        "id": 165905758,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104183
    },
    {
        "content": "<p>which seems to be what <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> was doing</p>",
        "id": 165905779,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104201
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span>echo 0 | sudo tee /proc/sys/kernel/nmi_watchdog\nfor cargo_threads in 2 3 4 6 8 16; do\nfor rust_threads in 1 2 3 4 6 8 16 ; do\nRUSTC=/home/mark/.rustup/toolchains/6f087ac1c17723a84fd45f445c9887dbff61f8c0/bin/rustc RUSTFLAGS=&quot;-Zthreads=$rust_threads&quot; perf stat -o &quot;/home/mark/perf-results/cargo-multi-threaded-t$rust_threads-j$cargo_threads&quot; -ddd --repeat=4 --pre &quot;cargo clean&quot; cargo build --release -j$cargo_threads\ndone\ndone\necho 1 | sudo tee /proc/sys/kernel/nmi_watchdog\n</pre></div>",
        "id": 165905795,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104221
    },
    {
        "content": "<p>If you're varying the job count, use 1 CGU to avoid LLVM threads affecting the result</p>",
        "id": 165905861,
        "sender_full_name": "Zoxc",
        "timestamp": 1558104246
    },
    {
        "content": "<p>okay. my most immediate suggestion: don't do N x M</p>",
        "id": 165905863,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104248
    },
    {
        "content": "<p>at least, not for now</p>",
        "id": 165905873,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104257
    },
    {
        "content": "<p>do instead 2 x N + 2 x M</p>",
        "id": 165905878,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104263
    },
    {
        "content": "<p>(does that make sense?)</p>",
        "id": 165905892,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104271
    },
    {
        "content": "<p>anyway, the other item was documentation and maintenance</p>",
        "id": 165905894,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104274
    },
    {
        "content": "<p>let's break the measurement stuff out into a separate topic</p>",
        "id": 165905903,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104280
    },
    {
        "content": "<p>I guess the real question, ultimately, is when bug reports come, do we feel like we're gonna' be able to fix them :)</p>",
        "id": 165905926,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104304
    },
    {
        "content": "<p>only if we can replicate them</p>",
        "id": 165905952,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104327
    },
    {
        "content": "<p>I feel like there are a fair number of moving parts in the system -- I don't understand it that well, but off the top of my head:</p>\n<ul>\n<li>how is interning working</li>\n<li>query results, what is locking strategy (that's actually maybe simple-ish?)</li>\n<li>what other bits of shared state are replicated in non-trivial ways?</li>\n<li>tcx splitting and interning?</li>\n</ul>",
        "id": 165905977,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104352
    },
    {
        "content": "<p>should we try to document them? for sure some of these things (<em>cough</em> interning) are only barely documented today, though the <span class=\"user-group-mention\" data-user-group-id=\"1380\">@WG-learning</span> group is sort of working on trying to improve that :)</p>",
        "id": 165906093,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104418
    },
    {
        "content": "<p>Interning is pretty much unchanged</p>",
        "id": 165906119,
        "sender_full_name": "Zoxc",
        "timestamp": 1558104432
    },
    {
        "content": "<p>did we basically just put locks around the central hashmaps?</p>",
        "id": 165906136,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104454
    },
    {
        "content": "<p>Yes</p>",
        "id": 165906146,
        "sender_full_name": "Zoxc",
        "timestamp": 1558104459
    },
    {
        "content": "<p>that's an interesting piece of information in itself :)</p>",
        "id": 165906148,
        "sender_full_name": "mw",
        "timestamp": 1558104463
    },
    {
        "content": "<p>Basically RefCell -&gt; Mutex</p>",
        "id": 165906214,
        "sender_full_name": "Zoxc",
        "timestamp": 1558104485
    },
    {
        "content": "<p>I remember that when we decided to merge this stuff there was a fairly \"long tail\" of random bits of mutexes and the like</p>",
        "id": 165906258,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104536
    },
    {
        "content": "<p>I think my feeling is that it'd be great to try and document the design, perhaps together with the impl of queries -- <span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span> what are the last few bugs you fixed :)</p>",
        "id": 165906290,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104572
    },
    {
        "content": "<p>Anything here is an interesting piece of information, especially an ELI5-style  overview would be nice.<br>\nAll e.g. I know about parallel rustc is that some Rc/Cell become Arc/Mutex and something becomes parallel.</p>",
        "id": 165906294,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1558104575
    },
    {
        "content": "<p>ELI5?</p>",
        "id": 165906301,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104585
    },
    {
        "content": "<p>(I ask about bugs because i'm trying to pull out what are some of the trickier things that may not jump immediately to mind...)</p>",
        "id": 165906358,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104605
    },
    {
        "content": "<p>*explain like I'm 5</p>",
        "id": 165906361,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1558104610
    },
    {
        "content": "<p>there's this: <a href=\"https://rust-lang.github.io/rustc-guide/queries/query-evaluation-model-in-detail.html#parallel-query-execution\" target=\"_blank\" title=\"https://rust-lang.github.io/rustc-guide/queries/query-evaluation-model-in-detail.html#parallel-query-execution\">https://rust-lang.github.io/rustc-guide/queries/query-evaluation-model-in-detail.html#parallel-query-execution</a></p>",
        "id": 165906369,
        "sender_full_name": "mw",
        "timestamp": 1558104622
    },
    {
        "content": "<p>but it doesn't go into any detail at all</p>",
        "id": 165906386,
        "sender_full_name": "mw",
        "timestamp": 1558104643
    },
    {
        "content": "<p>Ah, yeah. I definitely feel like a \"high-level strategy overview with details about interesting add'l cases\" would be nice; I'm not sure it's reasonable to put that on <span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span> to write, but it'd be nice if they could support whoever does</p>",
        "id": 165906399,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104656
    },
    {
        "content": "<p>I guess other topics that jump to mind might be jobserver integration</p>",
        "id": 165906429,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104689
    },
    {
        "content": "<p>Query execution, waiting and cycle handling are the tricky bits</p>",
        "id": 165906438,
        "sender_full_name": "Zoxc",
        "timestamp": 1558104701
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span> do you think you'd be game to produce an \"outline form\" of docs? i.e., what are the interesting bits, and a few brief notes?  I think something like that would be very interesting -- and actually already good docs in and of itself</p>",
        "id": 165906502,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104746
    },
    {
        "content": "<p>but more importantly I think it could be \"handed off\" to others to work on elaborating and coming back to you with questions</p>",
        "id": 165906521,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104780
    },
    {
        "content": "<p>alternatively, I could try to sketch out what i'm thinking, and you can correct the mistakes I make :)</p>",
        "id": 165906544,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104799
    },
    {
        "content": "<blockquote>\n<p>might be jobserver integration</p>\n</blockquote>\n<p>That too, please, e.g. from the discussion above it wasn't clear why -t and -j options are separate, I though the total number of \"tasks\" (both threads and processes) are controlled by the jobserver.</p>",
        "id": 165906578,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1558104841
    },
    {
        "content": "<p><a href=\"https://internals.rust-lang.org/t/parallelizing-rustc-using-rayon/6606\" target=\"_blank\" title=\"https://internals.rust-lang.org/t/parallelizing-rustc-using-rayon/6606\">https://internals.rust-lang.org/t/parallelizing-rustc-using-rayon/6606</a> is still pretty good, but there's some changes from it</p>",
        "id": 165906606,
        "sender_full_name": "Zoxc",
        "timestamp": 1558104843
    },
    {
        "content": "<p>Can we collect <span class=\"user-mention\" data-user-id=\"123856\">@Vadim Petrochenkov</span>'s questions somewhere and try to answer them?</p>",
        "id": 165906707,
        "sender_full_name": "mw",
        "timestamp": 1558104925
    },
    {
        "content": "<p>and invite others to ask questions like that</p>",
        "id": 165906710,
        "sender_full_name": "mw",
        "timestamp": 1558104934
    },
    {
        "content": "<p>I'm going to make a hackmd :)</p>",
        "id": 165906712,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104936
    },
    {
        "content": "<p>please <a href=\"https://hackmd.io/XDC24IlWT4OIxYdmIxH4Xg\" target=\"_blank\" title=\"https://hackmd.io/XDC24IlWT4OIxYdmIxH4Xg\">add your questions into here</a>  everybody</p>",
        "id": 165906790,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104973
    },
    {
        "content": "<p>I think this is actually a good idea :)</p>",
        "id": 165906797,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104977
    },
    {
        "content": "<p>OK, well, we're at the hour point -- this was informative. I think the conclusion was:</p>\n<ul>\n<li>perf results look good, while we have a few major regressions, they are localized</li>\n<li>we should gather more crate data (see the <a href=\"#narrow/stream/131828-t-compiler/topic/measuring.20parallel.20rustc\" title=\"#narrow/stream/131828-t-compiler/topic/measuring.20parallel.20rustc\">measuring parallel rustc</a> topic)</li>\n<li>we definitely need documentation -- we are currently <a href=\"https://hackmd.io/XDC24IlWT4OIxYdmIxH4Xg\" target=\"_blank\" title=\"https://hackmd.io/XDC24IlWT4OIxYdmIxH4Xg\">brainstorming questions and things here</a>.</li>\n</ul>\n<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> seems to be coordinating the second bullet -- correct?</p>\n<p>I am happy to take on the job of coordinating documentation etc though I'll probably pester <span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span>. I will hopefully try to delegate this to <span class=\"user-mention\" data-user-id=\"116266\">@Santiago Pastorino</span> or somebody else from <span class=\"user-group-mention\" data-user-group-id=\"1380\">@WG-learning</span> at some point. =)</p>",
        "id": 165907247,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558105280
    },
    {
        "content": "<p>I will try to coordinate first point (see <a href=\"#narrow/stream/131828-t-compiler/topic/measuring.20parallel.20rustc\" title=\"#narrow/stream/131828-t-compiler/topic/measuring.20parallel.20rustc\">https://rust-lang.zulipchat.com/#narrow/stream/131828-t-compiler/topic/measuring.20parallel.20rustc</a>)</p>",
        "id": 165907283,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105308
    },
    {
        "content": "<p>(and I guess bullet two?)</p>",
        "id": 165907336,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105324
    },
    {
        "content": "<p>sorry, I inserted a \"0th\" bullet :)</p>",
        "id": 165907355,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558105345
    },
    {
        "content": "<p>I'd be curious to know if we should dig a bit more into the perf results -- i.e., can we figure out the problems with those major regressions? <span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span>, you mentioned a pending PR?</p>",
        "id": 165907364,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558105357
    },
    {
        "content": "<p>Any other pending improvements, <span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span>?</p>",
        "id": 165907406,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558105390
    },
    {
        "content": "<p>Here's a final question -- who wants to write-up and post a summary comment somewhere... =)</p>",
        "id": 165907412,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558105394
    },
    {
        "content": "<p><a href=\"https://github.com/rust-lang/rust/pull/60035\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/pull/60035\">https://github.com/rust-lang/rust/pull/60035</a> is pending, but quite large and invasive</p>",
        "id": 165907428,
        "sender_full_name": "Zoxc",
        "timestamp": 1558105419
    },
    {
        "content": "<p>I think the current  WG-learning todo list is this paper doc <a href=\"https://paper.dropbox.com/doc/Learning-Working-Group-Ideas--AdBCtWsfHAZYwARoovEhE2PzAg-2R49k1GWZFojHIQ5x1fuB\" target=\"_blank\" title=\"https://paper.dropbox.com/doc/Learning-Working-Group-Ideas--AdBCtWsfHAZYwARoovEhE2PzAg-2R49k1GWZFojHIQ5x1fuB\">https://paper.dropbox.com/doc/Learning-Working-Group-Ideas--AdBCtWsfHAZYwARoovEhE2PzAg-2R49k1GWZFojHIQ5x1fuB</a></p>",
        "id": 165907563,
        "sender_full_name": "Iñaki Garay",
        "timestamp": 1558105514
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span> To what extent does it make sense to benchmark with a try build from that PR?</p>",
        "id": 165907601,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105547
    },
    {
        "content": "<p>We might be able to get rid of some locks by having large virtual memory allocation for <code>Vec</code>s like the list of symbols</p>",
        "id": 165907613,
        "sender_full_name": "Zoxc",
        "timestamp": 1558105560
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> That would probably make a lot of sense, especially to compare it with parallel compiler @ master, which perf can't do</p>",
        "id": 165907717,
        "sender_full_name": "Zoxc",
        "timestamp": 1558105625
    },
    {
        "content": "<p>well, given just-collected data, we can (i.e., PR vs PR is fine with perf)</p>",
        "id": 165907748,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105661
    },
    {
        "content": "<p>but I meant the whole crate graph stuff more so</p>",
        "id": 165907761,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105669
    },
    {
        "content": "<p>Whole crate graphs have less incremental crates, so probably less important for that PR</p>",
        "id": 165908153,
        "sender_full_name": "Zoxc",
        "timestamp": 1558105924
    },
    {
        "content": "<p>okay, I will hold off on anything then for now -- you should be able to compare vs. master if you use <code>parallel-rustc-N</code> where N is the -Zthreads argument on perf</p>",
        "id": 165908238,
        "sender_full_name": "simulacrum",
        "timestamp": 1558106003
    },
    {
        "content": "<p>As a final note, <span class=\"user-mention\" data-user-id=\"125270\">@scottmcm</span> wrote to me this:</p>\n<blockquote>\n<p>Yeah, 20% faster or slower is what the book I have said, as the \"Just Noticable Difference\"</p>\n</blockquote>",
        "id": 165912542,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558108820
    },
    {
        "content": "<blockquote>\n<blockquote>\n<p>Yeah, 20% faster or slower is what the book I have said, as the \"Just Noticeable Difference\"</p>\n</blockquote>\n</blockquote>\n<p>Ref: <a href=\"https://learning.oreilly.com/library/view/designing-and-engineering/9780321562944/ch05.html#ch05lev2sec2\" target=\"_blank\" title=\"https://learning.oreilly.com/library/view/designing-and-engineering/9780321562944/ch05.html#ch05lev2sec2\">https://learning.oreilly.com/library/view/designing-and-engineering/9780321562944/ch05.html#ch05lev2sec2</a></p>",
        "id": 165918020,
        "sender_full_name": "scottmcm",
        "timestamp": 1558113091
    },
    {
        "content": "<p>That book also includes some latency categories:<br>\n- Instantaneous (0.1 - 0.2s) -- like a light switch<br>\n- Immediate (0.5 - 1s) -- prompt acknowledgment <br>\n- Continuous (2 - 5s) -- flow of conversation<br>\n- Captive (7 - 10s) -- \"goldfish time\" after which people do something else</p>\n<p>(Essentially the same as the order of magnitude ones that <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> mentioned earlier)</p>",
        "id": 165918809,
        "sender_full_name": "scottmcm",
        "timestamp": 1558113637
    }
]