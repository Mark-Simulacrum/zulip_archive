[
    {
        "content": "<p>reading over <a href=\"https://github.com/rust-lang/rust/issues/65927\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/issues/65927\">#65927</a>, I was idly wondering whether we could make it easier for developers to catch these regressions <em>locally</em>. Namely, <strong>without</strong> using <code>perf</code> or any other infrastructure.</p>",
        "id": 179423662,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436447
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"119009\">@eddyb</span> and I talked a bit about that -- in theory, this should've been caught by incremental tests, and I believe <span class=\"user-mention\" data-user-id=\"124287\">@mw</span> was surprised it wasn't</p>",
        "id": 179423726,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436526
    },
    {
        "content": "<p>and that led me to thus potentially bonkers idea: Would it make any sense to track the historical completed build times of stage2 <code>rustc</code> for each commit, and then after each build that is a child of the <code>master</code> commit, compare the median values in the history, and print out the time delta...?</p>",
        "id": 179423753,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436556
    },
    {
        "content": "<p>and it's definitely possible to run perf locally, at least on Linux-based systems -- but that's sort of a non-answer</p>",
        "id": 179423754,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436556
    },
    {
        "content": "<p>(by <code>perf</code> I meant <code>perf.rlo</code>)</p>",
        "id": 179423803,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436572
    },
    {
        "content": "<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> and I talked a bit about that -- in theory, this should've been caught by incremental tests, and I believe <span class=\"user-mention silent\" data-user-id=\"124287\">mw</span> was surprised it wasn't</p>\n</blockquote>\n<p>the incremental tests check compile times?</p>",
        "id": 179423831,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436617
    },
    {
        "content": "<p>No, but in this case the regression was \"we stopped skipping codegen\"</p>",
        "id": 179423844,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436631
    },
    {
        "content": "<p>heh</p>",
        "id": 179423848,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436635
    },
    {
        "content": "<p>which should've been caught</p>",
        "id": 179423852,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436638
    },
    {
        "content": "<p>i see</p>",
        "id": 179423856,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436642
    },
    {
        "content": "<p>(but we apparently didn't have a test)</p>",
        "id": 179423861,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436645
    },
    {
        "content": "<p>still, the more general idea may have some value</p>",
        "id": 179423873,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436655
    },
    {
        "content": "<p>if we can implement it semi-robustly...</p>",
        "id": 179423879,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436662
    },
    {
        "content": "<p>I think part of the problem is that we have really high variance on CI, and locally there's maybe less variance but there's nothing to compare against reliably</p>",
        "id": 179423943,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436693
    },
    {
        "content": "<p>(and in any case, it wouldn't help with this AFAIK)</p>",
        "id": 179423946,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436698
    },
    {
        "content": "<p>the thing to compare it against is the stored history , I'd say</p>",
        "id": 179423961,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436711
    },
    {
        "content": "<p>since you're almost never recompiling the compiler in a \"perfect\" incremental scenario</p>",
        "id": 179423967,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436718
    },
    {
        "content": "<p>Oh I suppose you're right: incremental compiles mean that the times are useless</p>",
        "id": 179423990,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436738
    },
    {
        "content": "<p>okay so comparing the stage2 <code>rustc</code> times is no good</p>",
        "id": 179424007,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436749
    },
    {
        "content": "<p>an alternative might be to make a compile-time benchmark suite part of <code>x.py test</code>, and have that store local history in the build directory</p>",
        "id": 179424067,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436797
    },
    {
        "content": "<p>where the benchmark suite would presumably be some subset of perf.rlo</p>",
        "id": 179424163,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436826
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span> are you expecting devs to use stage2?</p>",
        "id": 179424177,
        "sender_full_name": "centril",
        "timestamp": 1572436847
    },
    {
        "content": "<p>sure, we can do something like that</p>",
        "id": 179424178,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436847
    },
    {
        "content": "<p>this is not quite as nice as tracking the build time for <code>rustc</code>, since that's a build artifact that people are always going to need ...</p>",
        "id": 179424184,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436854
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"126931\">@centril</span> this was one of the flaws in my plan</p>",
        "id": 179424196,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436866
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"126931\">@centril</span> but a test benchmark suite would not need to rely on a stage2 rustc</p>",
        "id": 179424210,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436882
    },
    {
        "content": "<p>Yes, I think you'll have pitchforks at the gates if you make everyone use stage2 ;)</p>",
        "id": 179424220,
        "sender_full_name": "centril",
        "timestamp": 1572436894
    },
    {
        "content": "<p>I think it could work in theory, though we've not had super reliable measurements historically for e.g. wall time</p>",
        "id": 179424230,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436910
    },
    {
        "content": "<p>and instruction counts I'm not sure how to record on windows/macOS</p>",
        "id": 179424277,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436934
    },
    {
        "content": "<p>maybe we wouldn't report anything at all unless the wall-clock time was truly absurd</p>",
        "id": 179424279,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436936
    },
    {
        "content": "<p>i.e. a 10x regression or something</p>",
        "id": 179424286,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572436944
    },
    {
        "content": "<p>we could, sure -- I personally think it would not be helpful, i.e., in practice doesn't catch enough</p>",
        "id": 179424297,
        "sender_full_name": "simulacrum",
        "timestamp": 1572436960
    },
    {
        "content": "<p>Personally I'm happy that there's a central perf.rl.o cause I'm one of those egghead type-theory types that knows little about perf and wouldn't be able to handle local perf testing in a reliable way</p>",
        "id": 179424324,
        "sender_full_name": "centril",
        "timestamp": 1572436989
    },
    {
        "content": "<p>basically a 10x regression would time out CI reliably</p>",
        "id": 179424400,
        "sender_full_name": "simulacrum",
        "timestamp": 1572437048
    },
    {
        "content": "<blockquote>\n<p>we could, sure -- I personally think it would not be helpful, i.e., in practice doesn't catch enough</p>\n</blockquote>\n<p>you mean because a 10x regression, while filtering noise, is too high a threshold in general? E.g. for <a href=\"https://github.com/rust-lang/rust/issues/65927\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/issues/65927\">#65927</a>, only half of the benchmarks regressed at all, and of those, the median regression was like 3x or so?</p>",
        "id": 179424420,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572437073
    },
    {
        "content": "<p>maybe part of the problem here is that I'm coupling two distinct things: Gathering the data itself, and reporting it by default during build, and/or gating on it</p>",
        "id": 179424457,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572437121
    },
    {
        "content": "<p>i.e. it might be interesting to have the information captured locally and some easy way to query it</p>",
        "id": 179424484,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572437154
    },
    {
        "content": "<p>we can definitely start capturing the information (e.g., run cargo with -Ztiming and save that off) -- I suspect most people wouldn't really find this helpful, but we can do it</p>",
        "id": 179424714,
        "sender_full_name": "simulacrum",
        "timestamp": 1572437389
    },
    {
        "content": "<p>I think the trickiest thing, in terms of my ideal setup, would be making sure the data-sets are properly separated. In particular, its not enough to treat the commit-id as a unique key to identify the data-set; I think you'd probably want commit-id + <code>git diff</code> output, or something.</p>",
        "id": 179424946,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572437531
    },
    {
        "content": "<p>that, or only do the tracking if the <code>git diff</code> is empty</p>",
        "id": 179424973,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572437549
    },
    {
        "content": "<p>(which is probably the best way to go. At least for me, the point where I commit is usually the point where I'm saying \"okay I finally got this into a plausible and buildable state.)</p>",
        "id": 179425003,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572437582
    },
    {
        "content": "<p>yes, I think that'd be fine, some similar heuristic (maybe enough, then, to just save by commit id and a bit of \"clean git diff\")</p>",
        "id": 179425435,
        "sender_full_name": "simulacrum",
        "timestamp": 1572437938
    },
    {
        "content": "<p>which would overwrite by commit id so if you did end up building in clean mode then you'd be fine</p>",
        "id": 179425459,
        "sender_full_name": "simulacrum",
        "timestamp": 1572437954
    },
    {
        "content": "<p>the more I reflect on this, I think the reason I want it is that usually by the time I realize I want to see the data here, I've already done several builds, and its expensive to redo them just to get timing history. Maybe I <em>do</em> want to measure the stage1 build times after all, too... hmm.</p>",
        "id": 179425608,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572438090
    },
    {
        "content": "<p>well, it sounds like something I can play with locally at first</p>",
        "id": 179425672,
        "sender_full_name": "pnkfelix",
        "timestamp": 1572438129
    },
    {
        "content": "<p>I think tracking build times is something we should be doing more (in general, not just in rustc) so we can have hopefully happier users -- right now compile times are mostly a gut feeling</p>",
        "id": 179425808,
        "sender_full_name": "simulacrum",
        "timestamp": 1572438249
    },
    {
        "content": "<p>but _how_ to do that is another story :)</p>",
        "id": 179425816,
        "sender_full_name": "simulacrum",
        "timestamp": 1572438258
    },
    {
        "content": "<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> and I talked a bit about that -- in theory, this should've been caught by incremental tests, and I believe <span class=\"user-mention silent\" data-user-id=\"124287\">mw</span> was surprised it wasn't</p>\n</blockquote>\n<p>let's put it this way: it wouldn't be too hard write a test that makes sure that clean rebuilds completely skip codegen (for the given test). I would have thought that there already is a test like that but apparently there isn't. Meanwhile I remembered that the <a href=\"https://github.com/nikomatsakis/cargo-incremental/\" target=\"_blank\" title=\"https://github.com/nikomatsakis/cargo-incremental/\">cargo-incremental</a> tool and the rust-icci infrastructure based on it were doing such tests (extensively so). But rust-icci was decommissioned because it didn't seem worth the maintenance effort. That's still true because perf.rlo also let us spot the regression just as quickly.</p>",
        "id": 179426233,
        "sender_full_name": "mw",
        "timestamp": 1572438604
    },
    {
        "content": "<p>part of what I want is CI in the loop so we catch at least <em>some</em> things before ever landing a PR</p>",
        "id": 179427278,
        "sender_full_name": "eddyb",
        "timestamp": 1572439597
    },
    {
        "content": "<p>one thing I was suggesting to <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> was that <em>if there is a cheap way to do it</em>, we could run some of the more stress-test-y benchmarks that only take a few seconds (like <code>inflate</code>... wait how is that that fast? is that old <code>inflate</code> or the new one? I remember it taking minutes o_O)</p>",
        "id": 179427365,
        "sender_full_name": "eddyb",
        "timestamp": 1572439669
    },
    {
        "content": "<p>so basically spend no more than 5 minutes per PR CI (<em>not</em> <code>@bors</code>) checking a few benchmarks and reporting back above a certain threshold, to suggest a try + perf run</p>",
        "id": 179427437,
        "sender_full_name": "eddyb",
        "timestamp": 1572439716
    },
    {
        "content": "<p><a href=\"/user_uploads/4715/VZsDL4HAuBnDKty6A_O4EQlc/pasted_image.png\" target=\"_blank\" title=\"pasted_image.png\">pasted image</a> we've made it faster over time</p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/4715/VZsDL4HAuBnDKty6A_O4EQlc/pasted_image.png\" target=\"_blank\" title=\"pasted image\"><img src=\"/user_uploads/4715/VZsDL4HAuBnDKty6A_O4EQlc/pasted_image.png\"></a></div>",
        "id": 179427468,
        "sender_full_name": "simulacrum",
        "timestamp": 1572439750
    },
    {
        "content": "<p>wow</p>",
        "id": 179427577,
        "sender_full_name": "eddyb",
        "timestamp": 1572439839
    },
    {
        "content": "<p>wait why is min/max confusing when in relative terms? I guess it's the %Î” between the absolute min/max</p>",
        "id": 179427608,
        "sender_full_name": "eddyb",
        "timestamp": 1572439882
    },
    {
        "content": "<p>hm, no, that's the min/max percent</p>",
        "id": 179428527,
        "sender_full_name": "simulacrum",
        "timestamp": 1572440571
    },
    {
        "content": "<p>it's not anything fancy</p>",
        "id": 179428537,
        "sender_full_name": "simulacrum",
        "timestamp": 1572440580
    },
    {
        "content": "<p>it's not \"magnitude\" min/max though</p>",
        "id": 179428555,
        "sender_full_name": "eddyb",
        "timestamp": 1572440599
    },
    {
        "content": "<p>that's what confused me, sorry, I expected to find \"smallest delta\" and \"largest delta\" not literally min/max of the signed percentage</p>",
        "id": 179428686,
        "sender_full_name": "eddyb",
        "timestamp": 1572440677
    },
    {
        "content": "<p>oh</p>",
        "id": 179428841,
        "sender_full_name": "simulacrum",
        "timestamp": 1572440778
    },
    {
        "content": "<p>yeah</p>",
        "id": 179428876,
        "sender_full_name": "simulacrum",
        "timestamp": 1572440812
    }
]