[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span> I don't quite understand what you mean by that, no</p>",
        "id": 165905953,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104329
    },
    {
        "content": "<p>so you have a nested for loop</p>",
        "id": 165905964,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104340
    },
    {
        "content": "<p>with N cases in the outer loop and M cases in the inner one</p>",
        "id": 165905973,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104347
    },
    {
        "content": "<p>and my immediate reaction was</p>",
        "id": 165905976,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104352
    },
    {
        "content": "<p>its not clear that we/you get much value in short term from exploring all those cases</p>",
        "id": 165906039,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104367
    },
    {
        "content": "<p>instead, might be better to loop over all N thread values while varying job among { j=1, j=2 }, for example</p>",
        "id": 165906069,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104394
    },
    {
        "content": "<p>ah, okay, yeah, that makes some sense</p>",
        "id": 165906078,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104402
    },
    {
        "content": "<p>I think I'm also not quite sure yet what the \"correct\" / \"interesting\" -j/-t arguments are</p>",
        "id": 165906105,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104424
    },
    {
        "content": "<p>and then loop over all M job values while varying thread count over the most important cases (which are probably { t=1, t=4 }, is my guess)</p>",
        "id": 165906106,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104424
    },
    {
        "content": "<p>yeah I agree its not clear what the interesting cases are</p>",
        "id": 165906125,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104436
    },
    {
        "content": "<p>but we can dive in gathering more data later</p>",
        "id": 165906133,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104450
    },
    {
        "content": "<p>I just don't want to swamp your machine time gathering lots of data for one crate</p>",
        "id": 165906152,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104466
    },
    {
        "content": "<p>I'm going to try to get full N x M data on Cargo with lower counts since that's pretty fast -- Cargo builds in a couple minutes</p>",
        "id": 165906156,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104467
    },
    {
        "content": "<p>when we want to spend less time and get data for more crates</p>",
        "id": 165906164,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104476
    },
    {
        "content": "<p>okay, I can understand that.</p>",
        "id": 165906166,
        "sender_full_name": "pnkfelix",
        "timestamp": 1558104480
    },
    {
        "content": "<p>I think that should be done in an hour or so</p>",
        "id": 165906209,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104484
    },
    {
        "content": "<p>From there it seems viable that we'll/I'll be able to get  a better sense of interesting cases and switch to 2xN + 2xM or something like that</p>",
        "id": 165906244,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104523
    },
    {
        "content": "<p>I think <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> the high order bit is that the \"order of exploration\" matters -- we probably want \"breadth-first\" more than \"depth-first\"</p>",
        "id": 165906637,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104861
    },
    {
        "content": "<p>in other words, we'd rather see the \"single thread overhead\" and \"two thread win\" for all crates</p>",
        "id": 165906644,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104870
    },
    {
        "content": "<p>before seeing the \"four thread win\" for any crate</p>",
        "id": 165906647,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104875
    },
    {
        "content": "<p>at least that's my guess</p>",
        "id": 165906648,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104878
    },
    {
        "content": "<p>hm, that's a good point</p>",
        "id": 165906656,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104884
    },
    {
        "content": "<p>I feel like if we're regressing on 2 threads, that's a problem</p>",
        "id": 165906657,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104885
    },
    {
        "content": "<p>and <em>presumably</em> it'll only get better from there (...famous last words...)</p>",
        "id": 165906690,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558104905
    },
    {
        "content": "<p>that would make sense</p>",
        "id": 165906785,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104967
    },
    {
        "content": "<p>So we're thinking maybe <code>-j{1,2,8,16}</code> and <code>-t{0,1,2}</code> where <code>-t0</code> is the single-threaded compiler?</p>",
        "id": 165906810,
        "sender_full_name": "simulacrum",
        "timestamp": 1558104994
    },
    {
        "content": "<p>or even less data than that</p>",
        "id": 165906818,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105005
    },
    {
        "content": "<p>I could imagine not trying to optimize <code>-j</code> since presumably users won't set that</p>",
        "id": 165906829,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105017
    },
    {
        "content": "<p>i.e., just do <code>-j16</code> and <code>-t{0,1,2}</code></p>",
        "id": 165906863,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105035
    },
    {
        "content": "<p>that sounds reasonable</p>",
        "id": 165906917,
        "sender_full_name": "mw",
        "timestamp": 1558105079
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span> which option -- the latter <code>-j16</code> or the first bit?</p>",
        "id": 165906980,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105101
    },
    {
        "content": "<p>the latter</p>",
        "id": 165906989,
        "sender_full_name": "mw",
        "timestamp": 1558105109
    },
    {
        "content": "<p><code>t &gt; j</code> never makes sense anyway, right?</p>",
        "id": 165907005,
        "sender_full_name": "mw",
        "timestamp": 1558105124
    },
    {
        "content": "<p>hm, presumably no</p>",
        "id": 165907036,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105150
    },
    {
        "content": "<p>It does not</p>",
        "id": 165907039,
        "sender_full_name": "Zoxc",
        "timestamp": 1558105151
    },
    {
        "content": "<p>except for testing the jobserver :)</p>",
        "id": 165907054,
        "sender_full_name": "mw",
        "timestamp": 1558105164
    },
    {
        "content": "<p>okay, so the plan is ripgrep, servo, cranelift, maybe some more rustc measurements with <code>-j16</code> and varying <code>-t{0,1,2}</code> for now</p>",
        "id": 165907092,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105196
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span>  <span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> does that sound to you? Should we add anything?</p>",
        "id": 165907171,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105212
    },
    {
        "content": "<p>And to what extent do we want -opt, -check, -debug runs?</p>",
        "id": 165907528,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105491
    },
    {
        "content": "<p>Currently I've just been doing -opt runs but those are both slower and maybe not as important?</p>",
        "id": 165907553,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105506
    },
    {
        "content": "<p>i.e., measuring LLVM to an extent</p>",
        "id": 165907559,
        "sender_full_name": "simulacrum",
        "timestamp": 1558105513
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> that sounds good -- re: -opt, -check, and -debug, I think we definitely want more than just -opt -- but it's a good question. I guess I would prioritize doing;</p>\n<ul>\n<li>opt</li>\n<li>debug</li>\n<li>check</li>\n</ul>\n<p>in that order.</p>",
        "id": 165913370,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558109431
    },
    {
        "content": "<p>Mostly because we know check is the best case</p>",
        "id": 165913382,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558109443
    },
    {
        "content": "<p>Okay -- I'm putting data in <a href=\"https://docs.google.com/spreadsheets/d/1vadQWQQqTODU1_cAENnUjLyXM6cxms-tiCf2kCiNGGM/edit?usp=sharing\" target=\"_blank\" title=\"https://docs.google.com/spreadsheets/d/1vadQWQQqTODU1_cAENnUjLyXM6cxms-tiCf2kCiNGGM/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/1vadQWQQqTODU1_cAENnUjLyXM6cxms-tiCf2kCiNGGM/edit?usp=sharing</a></p>",
        "id": 165913393,
        "sender_full_name": "simulacrum",
        "timestamp": 1558109455
    },
    {
        "content": "<p>I'm not actually sure if the order I wrote makes sense, I guess I could see an arugment for opt, check, debug</p>",
        "id": 165913415,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558109473
    },
    {
        "content": "<p>worst, best, middle :)</p>",
        "id": 165913423,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1558109480
    },
    {
        "content": "<p>mhm, makes sense</p>",
        "id": 165913602,
        "sender_full_name": "simulacrum",
        "timestamp": 1558109636
    },
    {
        "content": "<p>so far data collection is going fairly well</p>",
        "id": 165913654,
        "sender_full_name": "simulacrum",
        "timestamp": 1558109650
    },
    {
        "content": "<p>I also have potentially interesting non-timing data as a side-effect of using perf to collect:</p>\n<div class=\"codehilite\"><pre><span></span>cargo-t1-check:\n Performance counter stats for &#39;cargo +6f087ac1c17723a84fd45f445c9887dbff61f8c0 check&#39; (2 runs):\n\n     181022.616812      task-clock (msec)         #    4.248 CPUs utilized            ( +-  0.20% )\n             17903      context-switches          #    0.099 K/sec                    ( +-  0.37% )\n              4038      cpu-migrations            #    0.022 K/sec                    ( +-  0.35% )\n           3348166      page-faults               #    0.018 M/sec                    ( +-  0.01% )\n      669715893598      cycles                    #    3.700 GHz                      ( +-  0.19% )  (33.58%)\n       87652401496      stalled-cycles-frontend   #   13.09% frontend cycles idle     ( +-  1.26% )  (33.51%)\n       69564486867      stalled-cycles-backend    #   10.39% backend cycles idle      ( +-  0.33% )  (33.45%)\n      595648635822      instructions              #    0.89  insn per cycle\n                                                  #    0.15  stalled cycles per insn  ( +-  0.20% )  (33.38%)\n      102489636524      branches                  #  566.170 M/sec                    ( +-  0.41% )  (33.27%)\n        3548257867      branch-misses             #    3.46% of all branches          ( +-  0.14% )  (33.12%)\n      315611174080      L1-dcache-loads           # 1743.490 M/sec                    ( +-  0.24% )  (33.05%)\n         683586581      L1-dcache-load-misses     #    0.22% of all L1-dcache hits    ( +-  0.05% )  (33.05%)\n                 0      LLC-loads                 #    0.000 K/sec                    (33.11%)\n                 0      LLC-load-misses           #    0.00% of all LL-cache hits     (33.14%)\n      145804411502      L1-icache-loads           #  805.449 M/sec                    ( +-  0.10% )  (33.20%)\n       10244177108      L1-icache-load-misses                                         ( +-  0.49% )  (33.28%)\n      312502970939      dTLB-loads                # 1726.320 M/sec                    ( +-  0.01% )  (33.37%)\n         916415446      dTLB-load-misses          #    0.29% of all dTLB cache hits   ( +-  1.34% )  (33.44%)\n      145367320817      iTLB-loads                #  803.034 M/sec                    ( +-  0.27% )  (33.45%)\n         346043620      iTLB-load-misses          #    0.24% of all iTLB cache hits   ( +-  0.63% )  (33.48%)\n           1437970      L1-dcache-prefetches      #    0.008 M/sec                    ( +-  0.02% )  (33.53%)\n           3763609      L1-dcache-prefetch-misses #    0.021 M/sec                    ( +-  0.06% )  (33.61%)\n\n      42.616428285 seconds time elapsed                                          ( +-  1.16% )\n</pre></div>",
        "id": 165913691,
        "sender_full_name": "simulacrum",
        "timestamp": 1558109705
    },
    {
        "content": "<p>but not sure if any of it is useful/helpful so going to leave it out of spreadsheet for now</p>",
        "id": 165913707,
        "sender_full_name": "simulacrum",
        "timestamp": 1558109727
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116015\">@Alex Crichton</span> Do you have any insight into measuring jobserver \"contention\"? I'm interested in whether we can get better performance if we restrict rustcs invocations but still have all cores \"available\" to the internal threading within rustc</p>",
        "id": 165931761,
        "sender_full_name": "simulacrum",
        "timestamp": 1558123239
    },
    {
        "content": "<p>basically say that only 4 rustcs processes should run at once but each can use up to 4 cores (since I have 16)</p>",
        "id": 165931800,
        "sender_full_name": "simulacrum",
        "timestamp": 1558123276
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> not currently, the protocol is basically an IPC semaphore which means there's not really any data other than \"can I get something at this point\" and \"I can release something at this point</p>",
        "id": 165933135,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1558124332
    },
    {
        "content": "<p>but no data on like \"how many waiters are there\"</p>",
        "id": 165933143,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1558124338
    },
    {
        "content": "<p>we'd have to instrument rustc for more information like that (or make a better protocol)</p>",
        "id": 165933158,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1558124348
    },
    {
        "content": "<p>hm, okay -- I seemed to recall some graphs from you when we were just adding this but I guess I'm remembering the wrong thing or creating memories</p>",
        "id": 165933185,
        "sender_full_name": "simulacrum",
        "timestamp": 1558124379
    },
    {
        "content": "<p>thanks!</p>",
        "id": 165933272,
        "sender_full_name": "simulacrum",
        "timestamp": 1558124440
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> (and maybe others?) -- we have data for cargo, ripgrep, servo, and cranelift now (opt, debug, check, with -t{0,1,2} and -j16)</p>",
        "id": 165937287,
        "sender_full_name": "simulacrum",
        "timestamp": 1558127569
    },
    {
        "content": "<p><a href=\"https://docs.google.com/spreadsheets/d/1vadQWQQqTODU1_cAENnUjLyXM6cxms-tiCf2kCiNGGM/edit#gid=0\" target=\"_blank\" title=\"https://docs.google.com/spreadsheets/d/1vadQWQQqTODU1_cAENnUjLyXM6cxms-tiCf2kCiNGGM/edit#gid=0\">https://docs.google.com/spreadsheets/d/1vadQWQQqTODU1_cAENnUjLyXM6cxms-tiCf2kCiNGGM/edit#gid=0</a></p>",
        "id": 165937290,
        "sender_full_name": "simulacrum",
        "timestamp": 1558127571
    },
    {
        "content": "<p>Overall -t2 is pretty much a win, if slight, across the board</p>",
        "id": 165937307,
        "sender_full_name": "simulacrum",
        "timestamp": 1558127587
    },
    {
        "content": "<p>and -t1 is almost always a ~4% regression (ranging between ~1 second to 30 seconds at max)</p>",
        "id": 165937330,
        "sender_full_name": "simulacrum",
        "timestamp": 1558127622
    },
    {
        "content": "<p>the 30 second case is possibly spurious but I've gotten pretty consistent measurements around that point after ~4 runs so probably not, even though it's odd how much it stands out</p>",
        "id": 165937398,
        "sender_full_name": "simulacrum",
        "timestamp": 1558127656
    },
    {
        "content": "<p>it might point at some underlying problem that would be good to solve (cc <span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span> )</p>",
        "id": 165937409,
        "sender_full_name": "simulacrum",
        "timestamp": 1558127670
    },
    {
        "content": "<p>Gathered data to build curves for essentially all meaningful values of -t while still keeping -j constant for Cargo</p>",
        "id": 165954949,
        "sender_full_name": "simulacrum",
        "timestamp": 1558149347
    },
    {
        "content": "<p><a href=\"https://docs.google.com/spreadsheets/d/1vadQWQQqTODU1_cAENnUjLyXM6cxms-tiCf2kCiNGGM/edit#gid=1621301791&amp;range=A1\" target=\"_blank\" title=\"https://docs.google.com/spreadsheets/d/1vadQWQQqTODU1_cAENnUjLyXM6cxms-tiCf2kCiNGGM/edit#gid=1621301791&amp;range=A1\">https://docs.google.com/spreadsheets/d/1vadQWQQqTODU1_cAENnUjLyXM6cxms-tiCf2kCiNGGM/edit#gid=1621301791&amp;range=A1</a></p>",
        "id": 165954950,
        "sender_full_name": "simulacrum",
        "timestamp": 1558149350
    },
    {
        "content": "<p>(I adapted the Y-axis in the charts to start at zero)</p>",
        "id": 166068613,
        "sender_full_name": "mw",
        "timestamp": 1558343141
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> thanks, those charts are super interesting. The data there is raw time values?</p>",
        "id": 167791141,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1560196789
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> Yes - in seconds.</p>",
        "id": 167791974,
        "sender_full_name": "simulacrum",
        "timestamp": 1560197302
    },
    {
        "content": "<p>OK. It doesn't look too impressive, does it? :)</p>",
        "id": 167792036,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1560197361
    },
    {
        "content": "<p>But I guess these are the whole crate graph numbers, the \"just tip crate\" numbers look better</p>",
        "id": 167792115,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1560197405
    },
    {
        "content": "<p>Yes, indeed</p>",
        "id": 167794874,
        "sender_full_name": "simulacrum",
        "timestamp": 1560199521
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> also, shaving 5-6 seconds off e.g. Cargo compilation isn't actually that bad</p>",
        "id": 167794900,
        "sender_full_name": "simulacrum",
        "timestamp": 1560199552
    },
    {
        "content": "<p>plus this is presumably still with \"single-threaded\" looking code (i.e., we have some global locks that Zoxc mentioned a while back)</p>",
        "id": 167794962,
        "sender_full_name": "simulacrum",
        "timestamp": 1560199576
    }
]