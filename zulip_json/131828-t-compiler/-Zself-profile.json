[
    {
        "content": "<p>BTW <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> are you currently working on extending <code>-Zself-profile</code> in any way?</p>\n<p>I ran against the style-servo crate and I got this:</p>\n<div class=\"codehilite\"><pre><span></span>| Phase            | Time (ms)      | Queries        | Hits (%) |\n| ---------------- | -------------- | -------------- | -------- |\n| Parsing          | 143            |                |          |\n| Expansion        | 3532           |                |          |\n| TypeChecking     | 16340          | 95991164       | 97.21    |\n| BorrowChecking   | 1525           | 718742         | 64.41    |\n| Codegen          | 33423          | 3779295        | 87.41    |\n| Linking          | 614            | 474496         | 91.10    |\n| Other            | 7901           | 85816990       | 97.52    |\n</pre></div>\n\n\n<p>Seem like one obvious thing is it'd be nice to have %ages for the time in each of those categories</p>",
        "id": 148882704,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1543605767
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> <span class=\"user-mention\" data-user-id=\"124287\">@mw</span> asked for that the other day</p>",
        "id": 148882731,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1543605807
    },
    {
        "content": "<p>It's on my TODO list :)</p>",
        "id": 148882733,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1543605812
    },
    {
        "content": "<p>heh ok</p>",
        "id": 148882737,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1543605818
    },
    {
        "content": "<p>I'm in the middle of tracking down an issue with the inline changes I've been working on but after I've fixed this one, I'll take a break on work on the profiler</p>",
        "id": 148882812,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1543605888
    },
    {
        "content": "<p>ok</p>",
        "id": 148882853,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1543605952
    },
    {
        "content": "<p>So <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> I think the next steps would be:</p>\n<ul>\n<li>Gather data per-query instead of per-category so that we can emit more detailed information</li>\n<li>Display percentages and perhaps a bit more info -- but I suppose if we can emit JSON or CSV we can kind of play with that independently</li>\n<li>Review the categories (probably other members of compiler team are better suited)</li>\n</ul>\n<p>Longer term:</p>\n<ul>\n<li>Optionally gather \"query call-stack\" information -- this would add overhead, but it seems like we should be able to do it very reliably, and account for the extra overhead. The idea would be to be able to answer questions like \"what %age of the time was spent in query X when invoked from query Y\" or \"who invokes query X\", that sort of thing.</li>\n</ul>",
        "id": 152655637,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1546006543
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span> may have thoughts, though</p>",
        "id": 152655640,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1546006560
    },
    {
        "content": "<p>although I think they are on PTO :)</p>",
        "id": 152655681,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1546006568
    },
    {
        "content": "<blockquote>\n<p>Display percentages and perhaps a bit more info -- but I suppose if we can emit JSON or CSV we can kind of play with that independently</p>\n</blockquote>\n<p>Do you mean like this? <a href=\"https://github.com/rust-lang/rust/pull/56702\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/pull/56702\">https://github.com/rust-lang/rust/pull/56702</a></p>",
        "id": 152655905,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1546006989
    },
    {
        "content": "<p>I suppose I do =)</p>",
        "id": 152656411,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1546007844
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> do we have JSON or CSV output?</p>",
        "id": 152656418,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1546007874
    },
    {
        "content": "<p>JSON</p>",
        "id": 152656462,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1546007887
    },
    {
        "content": "<p>Thanks to <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span>, it's actually being collected on perf.rlo <a href=\"https://github.com/rust-lang-nursery/rustc-perf/issues/299#issuecomment-444736451\" target=\"_blank\" title=\"https://github.com/rust-lang-nursery/rustc-perf/issues/299#issuecomment-444736451\">https://github.com/rust-lang-nursery/rustc-perf/issues/299#issuecomment-444736451</a></p>",
        "id": 152656472,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1546007937
    },
    {
        "content": "<p>There's no visualization yet though</p>",
        "id": 152656481,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1546007947
    },
    {
        "content": "<p>Yep, we're waiting on a proposal though mainly. FWIW I have the time to invest in the next ~week or two so proposals are welcome :)</p>",
        "id": 152656487,
        "sender_full_name": "simulacrum",
        "timestamp": 1546007990
    },
    {
        "content": "<p>I'd like to re-evaluate what we want from -Zself-profile and then set some goals from there.</p>",
        "id": 155250658,
        "sender_full_name": "mw",
        "timestamp": 1547643049
    },
    {
        "content": "<p>Ideally self-profile would answered all questions about \"where is the compiler spending its time\". perf and cachegrind are not so good for that (for various reasons).</p>",
        "id": 155250796,
        "sender_full_name": "mw",
        "timestamp": 1547643170
    },
    {
        "content": "<p>So some of the requirements for this are:</p>\n<ul>\n<li>Measure the total time the compiler process runs. This seems trivial but -Ztime-passes for example never did it. This seems to be a prerequisite for being able to tell whether we are measuring everything.</li>\n</ul>",
        "id": 155250981,
        "sender_full_name": "mw",
        "timestamp": 1547643336
    },
    {
        "content": "<p>A better break-down of which queries are actually executed would be nice. Just seeing <code>Other</code> or <code>Type checking</code> taking 80% of the time isn't all that useful.</p>",
        "id": 155251186,
        "sender_full_name": "Björn Steinbrink",
        "timestamp": 1547643529
    },
    {
        "content": "<ul>\n<li>Record individual query invocations. It seems like for a real profile we want to be able know which query ran for how long on what thread. From this raw data, we can build tools for rich visualization</li>\n</ul>",
        "id": 155251192,
        "sender_full_name": "mw",
        "timestamp": 1547643542
    },
    {
        "content": "<blockquote>\n<p>A better break-down of which queries are actually executed would be nice.</p>\n</blockquote>\n<p>Agreed, but I think want to go even a step further and record actual start and end timestamps.</p>",
        "id": 155251220,
        "sender_full_name": "mw",
        "timestamp": 1547643578
    },
    {
        "content": "<p>I also noticed that the time attribution seems to be a bit off. Time increased in one area, but the query count in another. Most likely this is because the timing only starts if the query is not answered from cache?</p>",
        "id": 155251235,
        "sender_full_name": "Björn Steinbrink",
        "timestamp": 1547643596
    },
    {
        "content": "<p>How much more info does -Zprofile-queries already provide? The only time I tried to use that, rustc got OOM'd, 32GB just wasn't enough</p>",
        "id": 155251368,
        "sender_full_name": "Björn Steinbrink",
        "timestamp": 1547643696
    },
    {
        "content": "<ul>\n<li>Record more data about query execution.  Cache-hit, cache-miss, found-in-incremental-cache, would-be-reusable-but-we-dont-cache-it, etc. I.e. make -Zincremental-info obsolete</li>\n</ul>",
        "id": 155251387,
        "sender_full_name": "mw",
        "timestamp": 1547643722
    },
    {
        "content": "<blockquote>\n<p>How much more info does -Zprofile-queries already provide? </p>\n</blockquote>\n<p>I think it collects a lot of data but is not optimized enough for actual profiling.</p>",
        "id": 155251520,
        "sender_full_name": "mw",
        "timestamp": 1547643835
    },
    {
        "content": "<p>I probably stores query keys too.</p>",
        "id": 155251610,
        "sender_full_name": "mw",
        "timestamp": 1547643893
    },
    {
        "content": "<p>but to be honest, I've never used it in earnest and would opt for removing it from the compiler</p>",
        "id": 155251655,
        "sender_full_name": "mw",
        "timestamp": 1547643955
    },
    {
        "content": "<ul>\n<li>self-profile should also record instances of lock-contention during query invocation.</li>\n</ul>",
        "id": 155251754,
        "sender_full_name": "mw",
        "timestamp": 1547644027
    },
    {
        "content": "<ul>\n<li>we need to keep supporting profiling outside of the query system too. At least in the medium term.</li>\n</ul>",
        "id": 155251934,
        "sender_full_name": "mw",
        "timestamp": 1547644170
    },
    {
        "content": "<ul>\n<li>we need to support at least two levels of profiling detail. Collecting the full profiles that I suggested above is probably too much for perf.rlo. Although the broad categorization we have at the moment is not so useful yet either. I suggest that  we keep the categories but also collect accumulated times per-query when doing a non-detailed profile. <br>\nEDIT: If there is a cheap way to also record the net time spent in a query (i.e. total time minus time spent in sub-queries) that would be nice to have too. The detailed profiling data has the information via timestamps, but maybe we can also do it for summary queries somehow.</li>\n</ul>",
        "id": 155252192,
        "sender_full_name": "mw",
        "timestamp": 1547644413
    },
    {
        "content": "<p>I think with detailed profiles like described above we can finally easily answer questions like:</p>\n<ul>\n<li>Metadata encoding (or what have you) seems to take a really long time. What portion of that is spent in queries being invoked the first time, and what is the actual cost of it?</li>\n<li>How much do parallel queries suffer from contention and where?</li>\n<li>The times don't add up to the total time, what are we missing?</li>\n</ul>",
        "id": 155252769,
        "sender_full_name": "mw",
        "timestamp": 1547644963
    },
    {
        "content": "<ul>\n<li>How much time do we spend in trait selection, and which queries account for how much of that?</li>\n</ul>",
        "id": 155252947,
        "sender_full_name": "mw",
        "timestamp": 1547645151
    },
    {
        "content": "<p>Can anyone think of anything else? Does anyone see a problem with my proposed requirements?</p>",
        "id": 155253229,
        "sender_full_name": "mw",
        "timestamp": 1547645417
    },
    {
        "content": "<p>It would be nice to have a way to see the query stacks per query. IE: <code>query a</code> was invoked from <code>query b</code> which was invoked from <code>query c</code>.</p>",
        "id": 155256557,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1547648490
    },
    {
        "content": "<p>yes, that would be cool</p>",
        "id": 155256655,
        "sender_full_name": "mw",
        "timestamp": 1547648547
    },
    {
        "content": "<p>I mean, this can be inferred once you have time-stamps</p>",
        "id": 155256679,
        "sender_full_name": "mw",
        "timestamp": 1547648575
    },
    {
        "content": "<p>Probably only in single threaded mode right?</p>",
        "id": 155256702,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1547648595
    },
    {
        "content": "<p>I'd like to record time stamps per thread</p>",
        "id": 155256716,
        "sender_full_name": "mw",
        "timestamp": 1547648611
    },
    {
        "content": "<p>Oh ok</p>",
        "id": 155256735,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1547648629
    },
    {
        "content": "<p>I was thinking that we can have a \"profile\" mode that records basically everything about execution as a series of \"per thread events\", right? I thnk this is probably what <span class=\"user-mention\" data-user-id=\"124287\">@mw</span> is describing too. Then we can reconstruct whatever view we want from that</p>",
        "id": 155256801,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1547648655
    },
    {
        "content": "<p>yes</p>",
        "id": 155256859,
        "sender_full_name": "mw",
        "timestamp": 1547648696
    },
    {
        "content": "<p>it should not be invasive performance-wise</p>",
        "id": 155256881,
        "sender_full_name": "mw",
        "timestamp": 1547648710
    },
    {
        "content": "<p>e.g., you might log:</p>\n<ul>\n<li>Thread T1 started Executing Query Q1 at timestamp N1</li>\n<li>Thread T1 started Executing Query Q2 at timestamp N2 </li>\n<li>Thread T1 finished Executing Query Q2 at timestamp N2</li>\n<li>Thread T1 had cache hit for Query Q2<br>\n...</li>\n</ul>",
        "id": 155256882,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1547648710
    },
    {
        "content": "<p>I feel like..even if it is... we can kind of \"account for it\"</p>",
        "id": 155256893,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1547648722
    },
    {
        "content": "<p>but it probably shouldn't that expensive</p>",
        "id": 155256902,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1547648730
    },
    {
        "content": "<p>but if we only record the data but don't process it immediately that should be fine</p>",
        "id": 155256905,
        "sender_full_name": "mw",
        "timestamp": 1547648731
    },
    {
        "content": "<p>yes, that</p>",
        "id": 155256912,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1547648736
    },
    {
        "content": "<p>right now at least our compilation times are sufficiently big that I am not very worried about this at all =)</p>",
        "id": 155256928,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1547648754
    },
    {
        "content": "<p>:)</p>",
        "id": 155256983,
        "sender_full_name": "mw",
        "timestamp": 1547648770
    },
    {
        "content": "<blockquote>\n<p>EDIT: If there is a cheap way to also record the net time spent in a query (i.e. total time minus time spent in sub-queries) that would be nice to have too. The detailed profiling data has the information via timestamps, but maybe we can also do it for summary queries somehow.</p>\n</blockquote>\n<p>This is actually what the summary times currently show. We need to start tracking at the query level though instead of just the category level to get most of the other requirements.</p>",
        "id": 155257051,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1547648812
    },
    {
        "content": "<p>so if a \"TypeCheck\" query calls an \"Other\" query, the execution time of the \"Other\" query is substracted from the \"TypeCheck\" query?</p>",
        "id": 155257199,
        "sender_full_name": "mw",
        "timestamp": 1547648893
    },
    {
        "content": "<p>Yes, exactly</p>",
        "id": 155257378,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1547649030
    },
    {
        "content": "<p>it seems like producing the log is step 1</p>",
        "id": 155257584,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1547649193
    },
    {
        "content": "<p>It would be great if this also worked out of the box with parallel queries.</p>",
        "id": 155257752,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1547649301
    },
    {
        "content": "<p>I don't really have a handle on how parallel queries works though</p>",
        "id": 155257773,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1547649312
    },
    {
        "content": "<p>I don't think that's a big problem</p>",
        "id": 155258981,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1547650231
    },
    {
        "content": "<p>as long as we make the logs \"thread-local\" basically</p>",
        "id": 155258986,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1547650237
    },
    {
        "content": "<p>I have an initial (incomplete) implementation which gives <a href=\"https://gist.github.com/wesleywiser/e86e5212da50947f43274cb5e2137208\" target=\"_blank\" title=\"https://gist.github.com/wesleywiser/e86e5212da50947f43274cb5e2137208\">this output</a></p>",
        "id": 157144875,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548801251
    },
    {
        "content": "<p>To make the output easier to understand, I decided to omit queries that took less than 1ms in total. Feel free to push back if you don't like that.</p>",
        "id": 157144942,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548801347
    },
    {
        "content": "<p>Could you right align the time columns? =P</p>",
        "id": 157145005,
        "sender_full_name": "Zoxc",
        "timestamp": 1548801395
    },
    {
        "content": "<p>Probably :)</p>",
        "id": 157145057,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548801468
    },
    {
        "content": "<p>Nice!</p>",
        "id": 157177303,
        "sender_full_name": "mw",
        "timestamp": 1548845697
    },
    {
        "content": "<p>It would be great if there was a way to easily spot the most expensive queries. Maybe omit the category and just sort them?</p>",
        "id": 157177423,
        "sender_full_name": "mw",
        "timestamp": 1548845815
    },
    {
        "content": "<p>You know what would be awesome for the verbose profiling mode: If we store absolute timestamps (i.e. not relative to the beginning of the <code>rustc</code> process) we can profile the entire crate graph compilation, not just a single crate.</p>",
        "id": 157177571,
        "sender_full_name": "mw",
        "timestamp": 1548845972
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span>  They are sorted most-to-least expensive under the categories. I think I'll also sort the categories by total time so the most expensive query should be at the top.</p>\n<p>We're also storing absolute times in the event log so that is possible :)</p>",
        "id": 157236662,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548895540
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span>Self profiling results:\n\n| Phase                                     | Time (ms)      | Time (%) | Queries        | Hits (%)\n| ----------------------------------------- | -------------- | -------- | -------------- | --------\n| Other                                     |            417 |    54.02 |             -1 |       -1\n| - {time spent not running queries}        |            352 |    45.60 |             -1 |       -1\n| - const_eval                              |             16 |     2.07 |             -1 |       -1\n| - type_of                                 |             10 |     1.30 |             -1 |       -1\n| - adt_def                                 |              8 |     1.04 |             -1 |       -1\n| - const_eval_raw                          |              8 |     1.04 |             -1 |       -1\n| - visible_parent_map                      |              7 |     0.91 |             -1 |       -1\n| - item_attrs                              |              6 |     0.78 |             -1 |       -1\n| - item_children                           |              6 |     0.78 |             -1 |       -1\n| - adt_dtorck_constraint                   |              3 |     0.39 |             -1 |       -1\n| - adt_destructor                          |              1 |     0.13 |             -1 |       -1\n| Linking                                   |            245 |    31.74 |             -1 |       -1\n| - {time spent not running queries}        |            245 |    31.74 |             -1 |       -1\n| TypeChecking                              |             62 |     8.03 |             -1 |       -1\n| - trait_impls_of                          |             10 |     1.30 |             -1 |       -1\n| - typeck_item_bodies                      |              9 |     1.17 |             -1 |       -1\n| - typeck_tables_of                        |              9 |     1.17 |             -1 |       -1\n| - {time spent not running queries}        |              9 |     1.17 |             -1 |       -1\n| - evaluate_obligation                     |              7 |     0.91 |             -1 |       -1\n| - const_is_rvalue_promotable_to_static    |              5 |     0.65 |             -1 |       -1\n| - is_copy_raw                             |              5 |     0.65 |             -1 |       -1\n| - rvalue_promotable_map                   |              5 |     0.65 |             -1 |       -1\n| - dropck_outlives                         |              2 |     0.26 |             -1 |       -1\n| - layout_raw                              |              1 |     0.13 |             -1 |       -1\n| Codegen                                   |             30 |     3.89 |             -1 |       -1\n| - {time spent not running queries}        |             17 |     2.20 |             -1 |       -1\n| - collect_and_partition_mono_items        |             11 |     1.42 |             -1 |       -1\n| - mir_const                               |              1 |     0.13 |             -1 |       -1\n| - mir_validated                           |              1 |     0.13 |             -1 |       -1\n| Expansion                                 |             17 |     2.20 |             -1 |       -1\n| - {time spent not running queries}        |             17 |     2.20 |             -1 |       -1\n| BorrowChecking                            |              1 |     0.13 |             -1 |       -1\n| - borrowck                                |              1 |     0.13 |             -1 |       -1\n| Parsing                                   |              0 |     0.00 |             -1 |       -1\n\nOptimization level: No\nIncremental: off\n</pre></div>",
        "id": 157244069,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548905229
    },
    {
        "content": "<p>Yeah, I think that's a good solution. There is no clear chronological order to categories anyway.</p>",
        "id": 157261891,
        "sender_full_name": "mw",
        "timestamp": 1548930680
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> are you currently capturing stack trace information btw?</p>",
        "id": 157274984,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548944800
    },
    {
        "content": "<p>(Just curious, this is awesome work regardless! <span aria-label=\"tada\" class=\"emoji emoji-1f389\" role=\"img\" title=\"tada\">:tada:</span>)</p>",
        "id": 157274989,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548944810
    },
    {
        "content": "<p>I'm wondering if we can use this to gather some data on some benchmarks before all hands</p>",
        "id": 157274998,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548944819
    },
    {
        "content": "<p>This is really awesome <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span></p>",
        "id": 157275706,
        "sender_full_name": "blitzerr",
        "timestamp": 1548945448
    },
    {
        "content": "<p>Thanks!</p>",
        "id": 157275716,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548945460
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> Not currently but I don't think it would be difficult to add that. I'm not sure how to aggregate and display the stack trace data though.</p>\n<p>Do you just want them dumped to a file or something? Or do we want to do some kind of automated deeper analysis?</p>",
        "id": 157275849,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548945585
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> <br>\n<code>Time not spent running queries</code>  what does that indicate ?</p>",
        "id": 157276091,
        "sender_full_name": "blitzerr",
        "timestamp": 1548945744
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"128294\">@blitzerr</span> So, for example, in Codegen, we have some queries which are tagged as being codegen related. But we also just a general timer that runs when we call into LLVM. The \"Time not spent running queries\" represents that time spent in LLVM which isn't covered by a query.</p>",
        "id": 157276167,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548945835
    },
    {
        "content": "<p>Is there a PR I can look at ?</p>",
        "id": 157276214,
        "sender_full_name": "blitzerr",
        "timestamp": 1548945845
    },
    {
        "content": "<p>Ahh! Makes sense. thank you</p>",
        "id": 157276241,
        "sender_full_name": "blitzerr",
        "timestamp": 1548945874
    },
    {
        "content": "<p>Not yet. It's all changes I have locally that I haven't pushed yet because it regresses the cache hits/misses data and the json output.</p>",
        "id": 157276296,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548945920
    },
    {
        "content": "<p>I'm hoping to have a PR up in the next day or two</p>",
        "id": 157276323,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548945943
    },
    {
        "content": "<p>So this profiling is for query based compilation ? I think, at this point not all compiler stages are query based. So we don't have profiling information for that ?</p>",
        "id": 157276329,
        "sender_full_name": "blitzerr",
        "timestamp": 1548945947
    },
    {
        "content": "<p>We start a timer at the beginning of compilation in the \"Other\" category. So we should have coverage of 99% of time that rustc runs. It just won't be categorized super helpfully.</p>",
        "id": 157276421,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548945998
    },
    {
        "content": "<blockquote>\n<p>I'm not sure how to aggregate and display the stack trace data though.</p>\n</blockquote>\n<p>I wouldn't try. I would want an option that dumps out all the data in some format for others to piece through.</p>",
        "id": 157276737,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548946268
    },
    {
        "content": "<p>Basically, we can provide the \"flat data\" in a convenient way, but if you want to do more advanced queries, we can provide a tool for that</p>",
        "id": 157276757,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548946291
    },
    {
        "content": "<p>e.g., I'd probably adapt something like <a href=\"https://github.com/nikomatsakis/perf-focus\" target=\"_blank\" title=\"https://github.com/nikomatsakis/perf-focus\">perf-focus</a></p>",
        "id": 157276783,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548946312
    },
    {
        "content": "<p>(Also, depending how huge that data is, we could maybe even publish it from perf, which would be <strong>amazing</strong> -- we might need to adopt some compression techniques, though)</p>",
        "id": 157276873,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548946356
    },
    {
        "content": "<blockquote>\n<p>(Also, depending how huge that data is, we could maybe even publish it from perf, which would be <strong>amazing</strong> -- we might need to adopt some compression techniques, though)</p>\n</blockquote>\n<p><code>perf</code> the Linux tool or <code>perf.r-l.o</code>?</p>",
        "id": 157277004,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548946485
    },
    {
        "content": "<p>I meant publish it from <a href=\"http://perf.rust-lang.org/\" target=\"_blank\" title=\"http://perf.rust-lang.org/\">http://perf.rust-lang.org/</a></p>",
        "id": 157277156,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548946612
    },
    {
        "content": "<p>perf.rlo I'd guess</p>",
        "id": 157277158,
        "sender_full_name": "mw",
        "timestamp": 1548946613
    },
    {
        "content": "<p>we'd have to make sure though that profiling doesn't add too much overhead</p>",
        "id": 157277192,
        "sender_full_name": "mw",
        "timestamp": 1548946643
    },
    {
        "content": "<p>Would plain text files in a folder structure be ok? Something like <code>perf_data/{category_name}/{query_name}/stack_traces/{timestamp}.txt</code></p>",
        "id": 157277198,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548946645
    },
    {
        "content": "<p>I guess at that point there could be a <code>perf_data/log.txt</code> at the root which has the raw data in it with timestamps like <span class=\"user-mention\" data-user-id=\"124287\">@mw</span> wanted</p>",
        "id": 157277303,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548946727
    },
    {
        "content": "<p>I think that there aren't many restrictions on how the data is written to disk because there'll be a post-processing step outside the compiler anyway</p>",
        "id": 157277499,
        "sender_full_name": "mw",
        "timestamp": 1548946861
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> I would prefer one big file I think</p>",
        "id": 157277560,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548946912
    },
    {
        "content": "<p>but I guess whatever is fine</p>",
        "id": 157277569,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548946919
    },
    {
        "content": "<p>maybe it's better to have a directory; seems a bit harder to load up</p>",
        "id": 157277637,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548946945
    },
    {
        "content": "<p>I don't feel strongly either way. Just want to get it to be whatever you find useful :)</p>",
        "id": 157277732,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548947024
    },
    {
        "content": "<p>maybe allowing for one file per thread would make the implementation simpler</p>",
        "id": 157277846,
        "sender_full_name": "mw",
        "timestamp": 1548947108
    },
    {
        "content": "<p>yeah I mean ultimately anything is fine</p>",
        "id": 157277857,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548947122
    },
    {
        "content": "<p>so i'd sort of be guided by the impl</p>",
        "id": 157277861,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548947127
    },
    {
        "content": "<p>I'm semi-inclined not to do a JSON-representation</p>",
        "id": 157277873,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548947146
    },
    {
        "content": "<p>because that will require serde etc etc, and I found with perf-focus that time to construct the final data structure is kind of important</p>",
        "id": 157277928,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548947165
    },
    {
        "content": "<p>so something that let me just charge through line-by-line and push onto some vectors was good</p>",
        "id": 157277944,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548947180
    },
    {
        "content": "<p>but then against JSON is kind of nice :P and serde is of course fast, it's more that then you have this intermediate thing you have to convert from. There are probably ways to do this in a streaming fashion with serde, I don't really know</p>",
        "id": 157277968,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548947206
    },
    {
        "content": "<p>yeah, having some like JSON for something simple like this is probably overkill</p>",
        "id": 157277977,
        "sender_full_name": "mw",
        "timestamp": 1548947216
    },
    {
        "content": "<p>Ok. I'll try the \"one large file\" approach for now and we can see how that feels</p>",
        "id": 157278096,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548947295
    },
    {
        "content": "<p>I'm trying to a PR with these changes up for review before I leave on Saturday for All Hands</p>",
        "id": 157278155,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548947328
    },
    {
        "content": "<p>(random question, and definitely <em>not</em> for the first pass: I wonder if we can easily emit a gzip'd version in the end, and then easily gunzip when loading; I imagine there will be a lot of repetition. Presumably we have some rust bindings to some such compression library.)</p>",
        "id": 157278212,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548947375
    },
    {
        "content": "<p>is that something the compiler would need to do?</p>",
        "id": 157278329,
        "sender_full_name": "mw",
        "timestamp": 1548947438
    },
    {
        "content": "<p>Seems possible <a href=\"https://crates.io/crates/flate2\" target=\"_blank\" title=\"https://crates.io/crates/flate2\">https://crates.io/crates/flate2</a></p>",
        "id": 157278393,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548947485
    },
    {
        "content": "<p>worth noting, i dunno how many files you were thinking of creating if you didn't go with the \"one huge file\" approach, but emitting loads of files is itself the biggest performance bottleneck in rustdoc</p>",
        "id": 157278418,
        "sender_full_name": "QuietMisdreavus",
        "timestamp": 1548947513
    },
    {
        "content": "<p>so it may slow down the collection process to have a lot of little files</p>",
        "id": 157278487,
        "sender_full_name": "QuietMisdreavus",
        "timestamp": 1548947533
    },
    {
        "content": "<blockquote>\n<p>is that something the compiler would need to do?</p>\n</blockquote>\n<p>not necessarily</p>",
        "id": 157278583,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1548947635
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"133692\">@QuietMisdreavus</span> That's a good point. Right now this all runs at the very end of compilation so there shouldn't be IO performance issues during collection. Perhaps it won't be feasible to continue capturing everything into memory directly while getting stack traces though...</p>",
        "id": 157278648,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1548947663
    }
]