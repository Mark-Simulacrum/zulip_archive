[
    {
        "content": "<p>Hey, folks! I've been working on understanding parallelism in Rust, and I noticed one opportunity for improvement. That's in how we handle interning strings as Symbols.  I decided to avoid placing all \"static\" symbols (symbols known at compile time) in the <code>Interner</code> table, and instead to just assign them static indices. </p>\n<p>The advantage of this is that you can avoid taking a lock for resolution of static symbols. I measured, and for many Rust crates, the number of symbol lookups that can be resolved statically is between 45% and 75%. So, this could significantly reduce the amount of lock contention in <code>Symbol::intern</code>, if/when we ever get the compiler moved to parallel builds.</p>\n<p>I have a branch where all of this works, and I've run <code>./x.py test src/tests/ui</code>, and everything passes. But there's still some cleanup left to do, so it's not ready for a real PR on rust-lang. Would anyone be interested in taking a look at this as it is now, and giving me feedback?</p>\n<p>Tagging <span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> , since I know you were interested in ||ism.</p>",
        "id": 217936149,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606336560
    },
    {
        "content": "<p>The branch is: <a href=\"https://github.com/sivadeilra/rust/tree/user/ardavis/better_syms\">https://github.com/sivadeilra/rust/tree/user/ardavis/better_syms</a></p>",
        "id": 217936288,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606336634
    },
    {
        "content": "<p>The top of <code>compiler/rustc_macros/src/symbols.rs</code> has a bunch of comments that describe what's going on in this change.</p>",
        "id": 217936492,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606336742
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"274471\">@Arlie Davis</span> If you open a draft PR, I can do a perf run</p>",
        "id": 217937861,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1606337570
    },
    {
        "content": "<p>to see what effect it has so far</p>",
        "id": 217937896,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1606337584
    },
    {
        "content": "<p>Thanks, will do.</p>",
        "id": 217938430,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606337879
    },
    {
        "content": "<p>As always, perf could actually be worse. I've done enough perf work to know how counter-intuitive it can be. :)</p>",
        "id": 217938521,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606337911
    },
    {
        "content": "<p><a href=\"https://github.com/rust-lang/rust/pull/79425\">https://github.com/rust-lang/rust/pull/79425</a> &lt;-- draft PR</p>",
        "id": 217938703,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606338005
    },
    {
        "content": "<p><span class=\"user-group-mention\" data-user-group-id=\"2943\">@T-infra</span>: could someone look at <a href=\"https://github.com/rust-lang/rust/pull/79425/checks?check_run_id=1455727791\">https://github.com/rust-lang/rust/pull/79425/checks?check_run_id=1455727791</a> ? That failure looks strange and spurious.</p>",
        "id": 217939408,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606338365
    },
    {
        "content": "<p>(There was an issue with the PR, but \"read-only filesystem\" should not be the failure there.)</p>",
        "id": 217939480,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606338412
    },
    {
        "content": "<p>It's probably because I omitted <code>Cargo.lock</code> from my PR. I just updated it to include the change to <code>Cargo.lock</code>.</p>",
        "id": 217939485,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606338415
    },
    {
        "content": "<p>Sure, but the failure is still weird.</p>",
        "id": 217939508,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606338427
    },
    {
        "content": "<p>Ah, ok.</p>",
        "id": 217939534,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606338436
    },
    {
        "content": "<p>I added a test tool to the build, for counting the number of symbol lookups.  I'll probably remove it from the final for-reals PR.  It's interesting to be able to measure different crates, but probably not interesting enough to include in the repo.</p>",
        "id": 217939576,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606338468
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> I <em>think</em> that's because the source directory is read-only on CI, and when there is no <code>Cargo.lock</code> cargo tries to write down a new one</p>",
        "id": 217940054,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1606338766
    },
    {
        "content": "<p>Agreed.</p>",
        "id": 217940084,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606338780
    },
    {
        "content": "<p>Ah. So, weird failure message but legitimate failure?</p>",
        "id": 217940107,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606338788
    },
    {
        "content": "<p>so that's expected</p>",
        "id": 217940108,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1606338788
    },
    {
        "content": "<p>yep</p>",
        "id": 217940119,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1606338793
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"121055\">@Pietro Albini</span> Thank you.</p>",
        "id": 217940132,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606338803
    },
    {
        "content": "<p>I'm expecting the perf results to be neutral, assuming we're not measuring parallel compiles right now. There will be some benefit for single-threaded compiles, but not much.</p>",
        "id": 217940504,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606339073
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"274471\">@Arlie Davis</span> You have some failures due to rustdoc issues.</p>",
        "id": 217941995,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606339888
    },
    {
        "content": "<p>Will that prevent the perf run?</p>",
        "id": 217942023,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606339906
    },
    {
        "content": "<p>If the try build fails, it would.</p>",
        "id": 217942461,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606340195
    },
    {
        "content": "<p>So probably.</p>",
        "id": 217942465,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606340201
    },
    {
        "content": "<p>Yeah. Fixed.</p>",
        "id": 217942539,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606340255
    },
    {
        "content": "<p>Any thoughts on the PR itself?</p>",
        "id": 217942652,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606340347
    },
    {
        "content": "<p>Reading...</p>",
        "id": 217942987,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606340597
    },
    {
        "content": "<p>The comments at the top of <code>rustc_macros/src/symbols.rs</code> are the best place to start.</p>",
        "id": 217943001,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606340616
    },
    {
        "content": "<p>That's what I'm reading.</p>",
        "id": 217943011,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606340623
    },
    {
        "content": "<p>It looks like you've put a lot of effort into carefully figuring out the static symbols as efficiently as possible. The perf run will show if that pays off. I do wonder if it'd be possible to use a rustc-compile-time-generated <code>phf</code> perfect hash for that, to save yourself a lot of manual work.</p>",
        "id": 217943034,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606340639
    },
    {
        "content": "<p>I also wonder if the fastest way to compare a 4-character symbol might just be to compare 32-bit numbers.</p>",
        "id": 217943146,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606340714
    },
    {
        "content": "<p>Just got to your analysis about perfect hashes.</p>",
        "id": 217943180,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606340753
    },
    {
        "content": "<p>Yeah, I thought of that. All sorts of fun strategies. The main thing, though, is just avoiding hitting the dynamic state _at all_, regardless of what static data structure you use.</p>",
        "id": 217943234,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606340765
    },
    {
        "content": "<p>That much is completely understandable, yeah. Probably a major win for parallel.</p>",
        "id": 217943255,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606340787
    },
    {
        "content": "<p>You've got another CI failure, this one looks easy to fix.</p>",
        "id": 217943281,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606340822
    },
    {
        "content": "<p>The overall approach seems reasonable to me, and I like that you're doing as much as possible when rustc is compiled. If it's straightforward, I'd love to see a perf run comparing this approach to just using <code>phf</code> at build time in the simplest possible way. Whatever wins, let's use that.</p>",
        "id": 217943712,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606341163
    },
    {
        "content": "<p>(If they roughly tie, maintaining less code would be nice. If your approach wins, by all means let's use it.)</p>",
        "id": 217943741,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606341212
    },
    {
        "content": "<p>Yeah, it'll be interesting to see what the different metrics do.  Binary size, working set, CPU time, etc.  I suspect they're all in the noise, until we have substantial parallelism involved.</p>",
        "id": 217943846,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606341295
    },
    {
        "content": "<p>I set up a Criterion-based test for just parsing files, but I don't have it using any parallelism yet.  I want to wire that up to rustc's rayon, and see what happens.</p>",
        "id": 217943885,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606341330
    },
    {
        "content": "<p>If this change doesn't affect performance, you could try a draft PR on top that does parallelism by default, and do a perf run on that.</p>",
        "id": 217944552,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606341798
    },
    {
        "content": "<p>(with and without this change, to see if it helps in the parallel case.)</p>",
        "id": 217944562,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606341808
    },
    {
        "content": "<p>/me feels like there ought to be a way to ask for a perf run with parallelism, without having to make a commit manually enabling it.</p>",
        "id": 217944637,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606341849
    },
    {
        "content": "<p>Thank you for working on this.</p>",
        "id": 217944677,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606341885
    },
    {
        "content": "<p>Eh, I'll do the perf runs locally.  I just build a Threadripper (64 cores, 128 threads) just for compiler work.  :)</p>",
        "id": 217944681,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606341887
    },
    {
        "content": "<p>Between the TLS changes, and changes like this, I'm really hoping that the bottlenecks in parallel compilation can go away and we can consider doing it by default.</p>",
        "id": 217944716,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606341916
    },
    {
        "content": "<p>I sure hope so. Because we are so, so very slow right now.  Sigh.</p>",
        "id": 217944750,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606341944
    },
    {
        "content": "<p>This topic was moved by <span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> to <a class=\"stream-topic\" data-stream-id=\"122651\" href=\"/#narrow/stream/122651-general/topic/Build.20times.20and.20build.20systems\">#general &gt; Build times and build systems</a></p>",
        "id": 217945095,
        "sender_full_name": "Notification Bot",
        "timestamp": 1606342181
    },
    {
        "content": "<p>There's a new failure, related to marking tests as ignored.</p>",
        "id": 217946045,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606342782
    },
    {
        "content": "<p>I think tidy shouldn't actually matter</p>",
        "id": 217946229,
        "sender_full_name": "simulacrum",
        "timestamp": 1606342921
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> ^ -- CI doesn't need to pass for perf to run, we just need to be able to build things. Tidy, for example, or other tests don't matter.</p>",
        "id": 217946463,
        "sender_full_name": "simulacrum",
        "timestamp": 1606343120
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> Ah, OK. I knew that not <em>everything</em> had to pass, but I didn't know which bits did or didn't well enough to want to waste bors time if I got it wrong.</p>",
        "id": 217946568,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606343199
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span>  I have some perf results. Unsurprisingly, avoiding acquiring a mutex is a big win, in benchmarks that do nothing but look up symbols. I mean, we knew that would be the case, but it's still good to see the numbers. I wrote a basic benchmark using Criterion, which I've used a lot and which does a good job on rigorous analysis of data, warmups, etc. I did a run of rustc which printed out every symbol lookup, and then stored that in a fine. That's my test input; the benchmark just repeatedly looks up the same sequence of symbols (10,000 symbols or so), from the rustc source code.</p>\n<p>Even for 1 CPU (no contention), static interning reduces lookup time by 13%, from 37ns to 31ns.<br>\nFor 2 to 4 CPUs, the improvement is above 21%.<br>\nFor 8 CPUs, the improvement is 49%.<br>\nFor 16 CPUs, 57%.<br>\nFor 24 CPUs, 58%.<br>\nFor 48 CPUs, 56%, [edited]<br>\nFor 64 CPUs, 58%.</p>\n<p>So it looks like we reach a certain plateau. I'm guessing it's mainly because the test inputs are a mix of dynamic and static symbols. Every time we fail to find a symbol during static lookups, we acquire that mutex. There are ways to improve even that, of course, but I'll keep that out of scope for this work.</p>",
        "id": 218339002,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606767053
    },
    {
        "content": "<p>That sounds awesome.</p>",
        "id": 218339274,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767203
    },
    {
        "content": "<p>Like all microbenchmarks, that doesn't translate to a significant win for overall parsing or compiling, of course.  But it does show that there is no cost to this, some minor gain, and it sets us up for parallelism.</p>",
        "id": 218339337,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606767234
    },
    {
        "content": "<p>I'm looking forward to seeing the overall compiler perf results, too, especially for parallel operation.</p>",
        "id": 218339452,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767276
    },
    {
        "content": "<p>Does the plateau go up if you have a larger dataset to parallelize on?</p>",
        "id": 218339507,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767309
    },
    {
        "content": "<p>I'm guessing it's more about the ratio of static-to-dynamic symbols in that dataset, rather than the size of the set.  I could artificially add more static symbols, but I wanted a mix that reflected ordinary source code.</p>",
        "id": 218339582,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606767351
    },
    {
        "content": "<p>That was what I was curious about: if you keep the ratio the same, but increase the dataset to one from a much much larger crate, how does it do?</p>",
        "id": 218339740,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767417
    },
    {
        "content": "<p>The dataset I'm testing is all of rustc's source code (across all crates). So, pretty big to begin with.</p>",
        "id": 218339840,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606767472
    },
    {
        "content": "<p>Ah, interesting. That'll definitely be large, but it wouldn't surprise me if it has a different ratio of static to dynamic than regular code, in either direction.</p>",
        "id": 218339964,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767521
    },
    {
        "content": "<p>In any case, promising microbenchmark results.</p>",
        "id": 218339993,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767532
    },
    {
        "content": "<p>Are you planning to run the rustc-perf suite locally, or get it to run on the PR?</p>",
        "id": 218340071,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767573
    },
    {
        "content": "<p>I looked at the ratios for a bunch of common crates. Before my changes, most were in the range of 35% to 50% static symbols. Then I added the \"common words\" (a set of common identifiers, but not known to rustc's implementation), which raised the ratios to 50% to 75% or so.  I checked rust/compiler, rust/library, rust/src/toolsl, all of Servo, rand, syn, quote, a few others.</p>",
        "id": 218340215,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606767639
    },
    {
        "content": "<p>If the rustc-perf suite can be run locally, I'd like to start with that. Is it straightforward to run it?</p>",
        "id": 218340278,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606767666
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"274471\">Arlie Davis</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Making.20Symbol.20more.20efficient.3A.20PR.20feedback.3F/near/218340215\">said</a>:</p>\n<blockquote>\n<p>I looked at the ratios for a bunch of common crates. Before my changes, most were in the range of 35% to 50% static symbols. Then I added the \"common words\" (a set of common identifiers, but not known to rustc's implementation), which raised the ratios to 50% to 75% or so.  I checked rust/compiler, rust/library, rust/src/toolsl, all of Servo, rand, syn, quote, a few others.</p>\n</blockquote>\n<p>Nice analysis! That sounds like it should go into your PR's description.</p>",
        "id": 218340296,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767674
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"274471\">Arlie Davis</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Making.20Symbol.20more.20efficient.3A.20PR.20feedback.3F/near/218340278\">said</a>:</p>\n<blockquote>\n<p>If the rustc-perf suite can be run locally, I'd like to start with that. Is it straightforward to run it?</p>\n</blockquote>\n<p>It's feasible. Not trivial, but feasible. Best place to ask is probably in <a class=\"stream\" data-stream-id=\"247081\" href=\"/#narrow/stream/247081-t-compiler.2Fperformance\">#t-compiler/performance</a>.</p>",
        "id": 218340347,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767701
    },
    {
        "content": "<p>Many folks there know the details for how to run it locally.</p>",
        "id": 218340366,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767711
    },
    {
        "content": "<p>there's instructions in the readme: <a href=\"https://github.com/rust-lang/rustc-perf/tree/master/collector\">https://github.com/rust-lang/rustc-perf/tree/master/collector</a></p>",
        "id": 218340376,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1606767719
    },
    {
        "content": "<p>Thanks.  I'm honestly not expecting much of a change at all, though, because currently other phases of compilation dominate. I've been using \"compile libcore\" as my main target, and in that case, most of the time goes to typeck.</p>",
        "id": 218340492,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606767769
    },
    {
        "content": "<p>I would not trust benchmarks on the standard library tbh, it has lots of weird code</p>",
        "id": 218340568,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1606767805
    },
    {
        "content": "<p>like, no other codebase has that many lang_items</p>",
        "id": 218340595,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1606767817
    },
    {
        "content": "<p>Sure. But since the only benefit of this is reducing symbol lookup times, and the ratios between libcore and others are pretty similar, I expect similar results.</p>",
        "id": 218340677,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606767845
    },
    {
        "content": "<p>Well, smaller heap space, too, but that's minor.</p>",
        "id": 218340714,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606767865
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"274471\">@Arlie Davis</span> What I'm personally hoping for is \"neutral or marginally positive\" with single-threaded rustc, and then significant improvements on parallel.</p>",
        "id": 218340719,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767868
    },
    {
        "content": "<p>(I'm also hoping those results stay roughly the same without the custom hashing.)</p>",
        "id": 218341009,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606767992
    },
    {
        "content": "<p>Because you want to just use an ordinary hash table, or <code>phf</code>?</p>",
        "id": 218341051,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606768022
    },
    {
        "content": "<p>Because optimizing the CPU-local symbol lookup seems entirely orthogonal to making it possible to run in parallel, and because <a href=\"https://github.com/rust-lang/rust/pull/79425#issuecomment-735244857\">https://github.com/rust-lang/rust/pull/79425#issuecomment-735244857</a> . It'll be much easier to get this change in if it comes in two phases: localize symbol lookup, then potentially optimize symbol lookup.</p>",
        "id": 218341263,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606768132
    },
    {
        "content": "<p>(I don't necessarily think this is going to need a <em>dozen</em> PRs, but I think it'll absolutely need at least 2.)</p>",
        "id": 218341381,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606768197
    },
    {
        "content": "<p>Overall I agree. But I'm not eager to add <code>phf</code> as a dependency of <code>rustc</code>, at least not just for this. The fewer dependencies, the better.</p>",
        "id": 218342847,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606768807
    },
    {
        "content": "<p>Yeah, dozen is a hyperbole, but there are clearly several orthogonal parts here.</p>",
        "id": 218343031,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1606768908
    },
    {
        "content": "<p>For example, I really wouldn't want to land the \"divide and conquer\" part here, unless there are significant performance benefits on non-synthetic benchmarks.</p>",
        "id": 218343383,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1606769061
    },
    {
        "content": "<p>The column-search part?  So, I can understand the reaction, but can you elaborate why?</p>",
        "id": 218343475,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606769122
    },
    {
        "content": "<p>Which is not certain, because accesses to string representation of symbols are rare and we may be optimizing cold code.</p>",
        "id": 218343499,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1606769140
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"274471\">Arlie Davis</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Making.20Symbol.20more.20efficient.3A.20PR.20feedback.3F/near/218343475\">said</a>:</p>\n<blockquote>\n<p>The column-search part?  So, I can understand the reaction, but can you elaborate why?</p>\n</blockquote>\n<p>Anything beyond a simple <code>HashMap</code>.<br>\nBecause complexity, no code is always better than code.</p>",
        "id": 218343603,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1606769180
    },
    {
        "content": "<p>The divide-and-conquer strategy only applies to the string --&gt; symbol translation, though.</p>",
        "id": 218343616,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606769188
    },
    {
        "content": "<p>Agreed that no code is better than code.  But there's also \"no dependency is better than dependency\", and \"no start-up heap allocs are better than start-up heap allocs\".  It's trade-offs.</p>",
        "id": 218343684,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606769230
    },
    {
        "content": "<p>I'm working on wiring up <code>phf</code> to this right now, so we'll see how it does.</p>",
        "id": 218343845,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606769316
    },
    {
        "content": "<p>Sure, that's why perf needs to first show that the positive side of this trade-off exists at least.</p>",
        "id": 218343847,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1606769316
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"274471\">@Arlie Davis</span> I assume you're doing the pre-compiled thing, so that at runtime the perfect hash is already compiled into the rustc binary?</p>",
        "id": 218344108,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606769450
    },
    {
        "content": "<p>Also, you should probably start by trying a simple HashTable, and then show that phf is a win over that.</p>",
        "id": 218344137,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1606769463
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"274471\">Arlie Davis</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Making.20Symbol.20more.20efficient.3A.20PR.20feedback.3F/near/218343845\">said</a>:</p>\n<blockquote>\n<p>I'm working on wiring up <code>phf</code> to this right now, so we'll see how it does.</p>\n</blockquote>\n<p>(If smarter string search strategy could be offloaded to a crate with simplicity of use similar to <code>HashMap</code>, it would certainly be great for rustc.)</p>",
        "id": 218344772,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1606769781
    },
    {
        "content": "<p>One interesting approach would be: Make <code>match</code> on string literals generate essentially the same optimal code, and then this code would just generate a single, trivial <code>match symbol_test { \"foo\" =&gt; ... }</code> expression.</p>",
        "id": 218345881,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606770280
    },
    {
        "content": "<p><code>phf</code> is significantly slower. For single-threaded, PHF is 45% slower than column-divide.</p>",
        "id": 218346997,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606770842
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>intern/1                time:   [47.577 ns 47.685 ns 47.801 ns]\n                        change: [+40.669% +45.576% +49.536%] (p = 0.00 &lt; 0.05)\n                        Performance has regressed.\n</code></pre></div>",
        "id": 218347121,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606770889
    },
    {
        "content": "<p>As number of threads go up, the effect decreases, because lock contention becomes the dominant factor.</p>",
        "id": 218347237,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1606770954
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span>  Hey, an update. I did more rigorous perf investigations, and found that <code>phf</code> actually has the best perf.  I've updated the PR, removed all of my \"work-in-progress\" stuff, switched it to use <code>phf</code>, and converted the PR draft to a regular PR.  <a href=\"https://github.com/rust-lang/rust/pull/79425\">https://github.com/rust-lang/rust/pull/79425</a></p>",
        "id": 218737682,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607021480
    },
    {
        "content": "<p>I had thought that <code>phf</code> was slower, when really what happened was that <code>phf</code> lookups were completing quickly enough that they enabled more thread contention, because the current thread would move to the next symbol quickly enough. Anyway, the details aren't terribly important. The key thing is that <code>phf</code> is good enough, and fits the model that I want, where the static lookup table is truly static (no heap allocs, no initialization work).</p>",
        "id": 218737859,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607021558
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"274471\">@Arlie Davis</span> How hard might it be to add a <code>-Z</code> option to track and list stats for the most looked-up dynamic symbols, with an eye towards adding them to the static table?</p>",
        "id": 218754255,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1607029461
    },
    {
        "content": "<p>...that also raises an interesting idea.</p>",
        "id": 218754324,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1607029501
    },
    {
        "content": "<p>Pretty straight-forward, although I think I would want that to be something that can be conditionally-enabled, so that it doesn't affect normal compiles.</p>",
        "id": 218754386,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607029524
    },
    {
        "content": "<p>Fair point; might not be possible to make it zero cost when not in use.</p>",
        "id": 218754411,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1607029541
    },
    {
        "content": "<p>I have a little standalone binary that links to rustc_span and rustc_session. It crawls a directory tree, finds all *.rs files, parses them, and dumps symbol stats.</p>",
        "id": 218754440,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607029556
    },
    {
        "content": "<p>(I wish Rust had a \"static branch\" mechanism like the Linux kernel, for such things.)</p>",
        "id": 218754447,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1607029560
    },
    {
        "content": "<p>I don't know if this is possible or not, but:<br>\nSuppose, in addition to the compile-time table, we reserved a large range of ID space for additional static IDs, and provided the ability to load a single pre-compiled phf table from a disk file to use for those static IDs?</p>",
        "id": 218754609,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1607029646
    },
    {
        "content": "<p>Then, if you have a huge codebase, you could create a cached set of symbols.</p>",
        "id": 218754637,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1607029665
    },
    {
        "content": "<p>rustc could even help you handle that, in the incremental case.</p>",
        "id": 218754648,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1607029673
    },
    {
        "content": "<p>I spent a bunch of time this morning looking at the perf impact. Right now, the perf impact is precisely zero, because everything else is so slow. I've compared rustc with and without my symbols changes, and all of the results are in the noise.  I've compiled with the <code>parallel_compiler</code> option enabled, used <code>-Zthreads=NN</code>, and seen that it really is using multiple threads.  But the time that we spend parsing is small, compared to analysis.</p>",
        "id": 218754720,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607029698
    },
    {
        "content": "<p>And on your <em>next</em> compile after you have that cache, you might have 90+% static lookups, because you cached all your common symbols. If the cache is outdated, no big deal.</p>",
        "id": 218754747,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1607029714
    },
    {
        "content": "<p>(Yeah, all of what I'm mentioning there only matters if symbol lookup turns out to be a bottleneck still.)</p>",
        "id": 218754779,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1607029732
    },
    {
        "content": "<p>For libcore, CPU time to compile is about 28 seconds.  Time for lexing, parsing, building AST, and stopping before analysis is about 5.4 seconds.</p>",
        "id": 218754811,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607029759
    },
    {
        "content": "<p>The impact is in the noise even on your Threadripper?</p>",
        "id": 218754819,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1607029764
    },
    {
        "content": "<p>And, during lexing / parsing, we're currently single-threaded, even if we're using -Zthreads=64.</p>",
        "id": 218754843,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607029778
    },
    {
        "content": "<p>-Zthreads appears to enable multithreading during analysis, but not during lexing / parsing.</p>",
        "id": 218754874,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607029801
    },
    {
        "content": "<p>lexing, parsing, and macro expansion/resolution are all going to be single threaded right now, yes</p>",
        "id": 218755019,
        "sender_full_name": "simulacrum",
        "timestamp": 1607029862
    },
    {
        "content": "<p>We _could_ do some multi-threaded parsing, by doing things like parsing separate files.  Whenever we load <code>mod foo;</code>, we could start that, then later wait for all of the async / parallel parsing to complete.</p>",
        "id": 218755036,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607029868
    },
    {
        "content": "<p>Or, we could pipeline some of it, where lexing was done by a separate thread, which fed results to the thread consuming it. But that seems unlikely to gain much.</p>",
        "id": 218755091,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607029909
    },
    {
        "content": "<p>I've been looking at applying the static-symbol technique to Rust Analyzer, since RA spends far more of its time in lexing/parsing than rustc does. It might help more there, in the near term.</p>",
        "id": 218755239,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607029966
    },
    {
        "content": "<p>rust-analyzer is already shockingly fast :)</p>",
        "id": 218756654,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1607030727
    },
    {
        "content": "<p>Ehhh, it could be faster. And crash less. There are a number of projects that I work with, where I have to disable RA just to get a usable editor again.</p>",
        "id": 218756851,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607030811
    },
    {
        "content": "<p>It's mostly great, and I love the design.</p>",
        "id": 218756901,
        "sender_full_name": "Arlie Davis",
        "timestamp": 1607030855
    }
]