[
    {
        "content": "<p>It is possible to somehow codegen LLVM unroll metadata through an attr on statements/exprs in a custom codegen which uses LLVM?<br>\nThe codegen i am working on targets the GPU, and on the GPU, unrolling is especially important, so i would like to provide ways of telling llvm/libnvvm to unroll certain loops, e.g.</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"cp\">#[unroll]</span><span class=\"w\"></span>\n<span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">i</span><span class=\"w\"> </span><span class=\"k\">in</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"o\">..</span><span class=\"mi\">20</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"c1\">// ...</span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>\n<p>I can easily implement this at the function level, but i don't think its possible to implement it at the statement level currently. This is because to be able to do this, i would probably have to track back a cg_ssa-dispatched method on the builder trait, to its MIR counterpart, so that i can then see if it contains an attr, check if the instruction is the back-edge of a loop... and it just seems impossible.</p>\n<p>Is there perhaps any other way? I cant think of a way to do this without physically tracking how MIR maps to instructions. Maybe i could desugar unroll to something like <code>__nvvm_unroll_next(0..20)</code> then have the codegen treat that function explicitly when it sees it being called? But then again id have to find the back-edge with that or something.</p>",
        "id": 256173580,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633406440
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276242\">@Riccardo D'Ambrosio</span> Could you have the compiler just detect that it should unroll that loop?</p>",
        "id": 256174640,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633407252
    },
    {
        "content": "<p>Another approach would be a macro that unrolls the loop manually.</p>",
        "id": 256174690,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633407295
    },
    {
        "content": "<p>LLVM will already unroll some of the loops, but it won't unroll every single loop, and in CUDA it is often useful to tell the compile to unroll fully or by a certain factor</p>",
        "id": 256174722,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407314
    },
    {
        "content": "<p>I would rather not use a macro approach, it feels a bit hacky to me, and id like to support loops more complex than just simple ranges</p>",
        "id": 256174771,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407356
    },
    {
        "content": "<p>it would have to be a proc macro too which would murder intellisense...</p>",
        "id": 256174841,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407393
    },
    {
        "content": "<p>I'd be really hesitant to add that degree of tuning attribute, rather than just teaching the compiler to figure out the right amount to unroll.</p>",
        "id": 256174884,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633407438
    },
    {
        "content": "<p>How would you know how much to partially or fully unroll? Based on the number of instructions, or the amount of parallelism available on the GPU, or what?</p>",
        "id": 256174910,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633407468
    },
    {
        "content": "<p>The right amount to unroll is not easily figured out, oftentimes a programmer can guess it better, utilizing registers more efficiently</p>",
        "id": 256174981,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407502
    },
    {
        "content": "<p>Unroll would try to unroll it fully, that usually yields good perf benefits if the kernel is not using a lot of registers</p>",
        "id": 256175017,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407540
    },
    {
        "content": "<p>The amount of registers available depends a lot on launch bounds, compute capability, virtual architecture, etc</p>",
        "id": 256175056,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407574
    },
    {
        "content": "<p>\"unroll the right amount to use the right number of registers\" seems like something the compiler could do well if it were taught to.</p>",
        "id": 256175059,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633407576
    },
    {
        "content": "<p>Well the thing is, it cannot really do it until the ptx is assembled</p>",
        "id": 256175077,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407594
    },
    {
        "content": "<p>If, for instance, you gave a specific GPU target and the compiler knew the capabilities of that target.</p>",
        "id": 256175079,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633407595
    },
    {
        "content": "<p>PTX uses a virtual architecture, which means that it uses virtual registers because it doesnt know the amount of registers available until it jit compiles it to SASS</p>",
        "id": 256175150,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407625
    },
    {
        "content": "<p>so LLVM/libnvvm cannot reliably guess how many registers are available</p>",
        "id": 256175160,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407637
    },
    {
        "content": "<p>it can to some degree, but not fully</p>",
        "id": 256175167,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407644
    },
    {
        "content": "<p>its kind of like \"why have #[inline] if llvm does inlining already?\"</p>",
        "id": 256175180,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407656
    },
    {
        "content": "<p>this explains it pretty well <a href=\"https://www.nvidia.com/docs/IO/116711/sc11-unrolling-parallel-loops.pdf\">https://www.nvidia.com/docs/IO/116711/sc11-unrolling-parallel-loops.pdf</a></p>",
        "id": 256175228,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407699
    },
    {
        "content": "<p>CUDA provides plenty of tools to analyze the occupancy/utilization of the total GPU resources, for example, Nsight compute. Nsight can offer some pretty useful statistics about registers which users can use to base unrolling decisions on. It can't always be guessed by the compiler</p>",
        "id": 256175400,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633407828
    },
    {
        "content": "<p>This seems like a limitation of generating PTX rather than doing codegen for a specific target GPU with a given \"compute capability\" level.</p>",
        "id": 256175671,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633407996
    },
    {
        "content": "<p>moreover, because LLVM generally assumes its working on CPU code, it is more conservative with its unrolling, but on the gpu, there are thousands of registers readily available for each iteration to utilize</p>",
        "id": 256175679,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408002
    },
    {
        "content": "<p>But even with PTX, it would be possible to tune for a specific GPU, if the backend knew approximately how many registers to use.</p>",
        "id": 256175696,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408021
    },
    {
        "content": "<p>The compute capability passed to libnvvm says nothing about register amount</p>",
        "id": 256175708,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408031
    },
    {
        "content": "<p>register amount isnt a thing until the PTX is JIT compiled to SASS when you actually run it with the cuda driver API</p>",
        "id": 256175729,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408050
    },
    {
        "content": "<p>I know that's true for PTX, but I also know the toolchain is capable of generating target-specific binaries...</p>",
        "id": 256175752,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408072
    },
    {
        "content": "<p>I'm assuming <em>something</em> knows the number of registers.</p>",
        "id": 256175758,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408081
    },
    {
        "content": "<p>And there is no physical way to tell libnvvm to target a specific GPU with some amount of registers, it leaves that control to the user</p>",
        "id": 256175804,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408090
    },
    {
        "content": "<p>yes, ptxas does, but that runs at runtime, not at compile time, PTX is deliberately gpu-agnostic (other than compute capabilities, but thats a virtual architecture)</p>",
        "id": 256175837,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408126
    },
    {
        "content": "<p>This sounds like a problem with libnvvm.</p>",
        "id": 256175879,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408164
    },
    {
        "content": "<p>(And a limitation of not actually having an open toolchain.)</p>",
        "id": 256175887,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408173
    },
    {
        "content": "<p>I'm not trying to belabor that point, but this is the kind of thing that <em>should</em> be better, and there's no technical reason it <em>can't</em> be better.</p>",
        "id": 256175906,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408189
    },
    {
        "content": "<p>In what way? Id argue this is actually a really good thing, because u can compile to PTX and have that run efficiently on every GPU</p>",
        "id": 256175917,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408201
    },
    {
        "content": "<p>if i compiled to SASS, you couldnt redistribute that, it would only work on your GPU</p>",
        "id": 256175971,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408215
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276242\">Riccardo D'Ambrosio</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Codegenning.20unroll.20pragmas.20for.20the.20GPU/near/256175917\">said</a>:</p>\n<blockquote>\n<p>u can compile to PTX and have that run efficiently on every GPU</p>\n</blockquote>\n<p>Evidently not as efficiently as it could.</p>",
        "id": 256175976,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408217
    },
    {
        "content": "<p>And in any case, it would be reasonable to allow running on any GPU but <em>tuning</em> for a specific GPU.</p>",
        "id": 256176001,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408238
    },
    {
        "content": "<p>On x86-64, you can compile for a certain baseline but tune for a specific newer CPU, so that it knows the timings and capabilities of that newer CPU.</p>",
        "id": 256176017,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408257
    },
    {
        "content": "<p>You could do the same with PTX: compile generic code but tune for the capabilities of a given generation of GPU so it runs well on that GPU.</p>",
        "id": 256176038,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408276
    },
    {
        "content": "<p>I mean i guess if ptxas could dynamically unroll during codegen yeah, but that seems weird to me, not to mention expensive</p>",
        "id": 256176047,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408286
    },
    {
        "content": "<p>(Or, for that matter, generate a few different binaries for different generations and ship them all.)</p>",
        "id": 256176048,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408287
    },
    {
        "content": "<p>i know ptxas does some optimizations, but they are limited because PTX -&gt; SASS is meant to be extremely fast</p>",
        "id": 256176070,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408307
    },
    {
        "content": "<p>If PTX-&gt;SASS runs once per GPU rather than once per frame or similar, it doesn't seem unreasonable to do some larger optimizations and cache the result.</p>",
        "id": 256176135,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408334
    },
    {
        "content": "<p>In any case, it sounds like that isn't what libnvvm supports, and you're stuck using libnvvm.</p>",
        "id": 256176164,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408368
    },
    {
        "content": "<p>but that would evidently introduce feature creep, PTX is meant to be a minimal assembly format, if you start pouring everything including tons of optimization hints in there, you end up with a very bloated format</p>",
        "id": 256176185,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408388
    },
    {
        "content": "<p>But it still seems <em>possible</em> to at least teach LLVM to generate PTX with a specific number of registers.</p>",
        "id": 256176193,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408394
    },
    {
        "content": "<p>LLVM is not generating the PTX, it is just optimizing</p>",
        "id": 256176211,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408408
    },
    {
        "content": "<p>i could tell LLVM to unroll more by modifying the pass manager, but other than that, not much</p>",
        "id": 256176221,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408420
    },
    {
        "content": "<p>but id rather introduce per-function and per-loop hints than global hints</p>",
        "id": 256176233,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408434
    },
    {
        "content": "<p>I don't see how those hints would be useful for any other backend, where the compiler can know the capabilities of the target and optimize accordingly.</p>",
        "id": 256176576,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1633408691
    },
    {
        "content": "<p>This is not for cg_llvm, this is just for my own codegen, this would not make it into \"normal\" rust</p>",
        "id": 256176598,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1633408715
    }
]