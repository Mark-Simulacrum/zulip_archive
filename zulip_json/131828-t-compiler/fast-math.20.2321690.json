[
    {
        "content": "<p>Hi all!</p>\n<p>I was wondering if there's any ongoing work on <code>-ffast-math</code> support in Rust?</p>\n<p>This would be a great addition, as <code>fast-math</code> can lead to significant performance gains, e.g. in DSP code. In particular it is sometimes crucial to vectorize code, such as the following snippet:</p>\n<div class=\"codehilite\"><pre><span></span>pub fn sum(arr: &amp;[f32; 512]) -&gt; f32 {\n    let mut result = 0.0;\n    for idx in 0..arr.len() {\n        result += arr[idx];\n    }\n    result\n}\n</pre></div>\n\n\n<p>Being aware of <code>std::intrinsics::{fadd_fast, fdiv_fast,...}</code>, those can easily get verbose compared to single character operators (<code>+</code>,<code>-</code>,..).</p>",
        "id": 176778318,
        "sender_full_name": "Alexander Droste",
        "timestamp": 1569612399
    },
    {
        "content": "<p>I don't think we will ever want an option exactly equivalent to C -ffast-math that combines safe and unsafe optimizations. But there's interest in providing access to faster floating-point in a smoother manner than individual intrinsics.</p>",
        "id": 176790495,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569622478
    },
    {
        "content": "<p>I would be fine with e.g. providing other types than <code>f32</code> and <code>f64</code> (e.g. <code>r32</code> and <code>r64</code>) that would provide such faster FP. I am however against introducing global flags or changing the behavior of the existing types.</p>",
        "id": 176791940,
        "sender_full_name": "centril",
        "timestamp": 1569624221
    },
    {
        "content": "<p>I'm aware of that position. I personally feel there <em>should</em> be an option to change algorithms written in terms of the standard floating point types to use safe optimizations, with careful definition of \"safe\".</p>",
        "id": 176793893,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569626364
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><span class=\"cp\">#[cfg(feature = </span><span class=\"s\">&quot;fast_math&quot;</span><span class=\"cp\">)]</span><span class=\"w\"></span>\n<span class=\"k\">type</span> <span class=\"nc\">fp32</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">r32</span><span class=\"p\">;</span><span class=\"w\"></span>\n\n<span class=\"cp\">#[cfg(not(feature = </span><span class=\"s\">&quot;fast_math&quot;</span><span class=\"cp\">))]</span><span class=\"w\"></span>\n<span class=\"k\">type</span> <span class=\"nc\">fp32</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"kt\">f32</span><span class=\"p\">;</span><span class=\"w\"></span>\n</pre></div>\n\n\n<p>and then <code>--feature fast_math</code></p>",
        "id": 176794009,
        "sender_full_name": "centril",
        "timestamp": 1569626475
    },
    {
        "content": "<p>I think that satisfies \"option to change algorithms\"</p>",
        "id": 176794028,
        "sender_full_name": "centril",
        "timestamp": 1569626495
    },
    {
        "content": "<p>Not if you have to put that at the top of every file using floating point, and in every crate.</p>",
        "id": 176794381,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569626972
    },
    {
        "content": "<p>That code only needs to be in one crate, the main work is in <code>Cargo.toml</code> instead. Cargo could also add <code>--global-feature fast_math</code> to propagate the <code>cfg</code>. Alternatively this could be built on <code>option_env!(..)</code></p>",
        "id": 176795248,
        "sender_full_name": "centril",
        "timestamp": 1569627766
    },
    {
        "content": "<p>I could see a global flag for <code>r32</code> to switch off the default fast-math behavior, but not a flag to switch it on for <code>f32</code></p>",
        "id": 176795656,
        "sender_full_name": "centril",
        "timestamp": 1569628084
    },
    {
        "content": "<p>Why does that distinction matter given that it's opt-in either way? I can see an argument for why f32 couldn't default to it and r32 could (though I don't necessarily agree with that argument), but I don't see the argument against an opt-in for f32.</p>",
        "id": 176795888,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569628251
    },
    {
        "content": "<p>Because it becomes opt-in for the crate author, who was the one who made the assumptions, not the end user of the crate somewhere deep in the dependency graph.</p>\n<p>Also, I think there should be a type which is deterministic-ish irrespective of flags and standards compliant and since <code>f32</code> is that today, it seems to me it should stay that way.</p>",
        "id": 176796050,
        "sender_full_name": "centril",
        "timestamp": 1569628380
    },
    {
        "content": "<p>I also don't think floating point numbers are so special that they deserve so much more attention from the language. There are other things which could get global flags.</p>",
        "id": 176796110,
        "sender_full_name": "centril",
        "timestamp": 1569628424
    },
    {
        "content": "<p>I think an attribute might make sense, which could then be applied crate/module/function/block level, modulo hygiene interactions with macros and such possibly.</p>",
        "id": 176799578,
        "sender_full_name": "simulacrum",
        "timestamp": 1569632207
    },
    {
        "content": "<p>Scoped attributes seem like costly solutions spec-wise</p>",
        "id": 176799965,
        "sender_full_name": "centril",
        "timestamp": 1569632783
    },
    {
        "content": "<p>Hm, I don't see how so? Like, attributes are pretty simple I feel</p>",
        "id": 176800701,
        "sender_full_name": "simulacrum",
        "timestamp": 1569634044
    },
    {
        "content": "<p>How do they interact with generic functions and inlining?<br>\nThey may be relatively easy to implement in a stateful compiler, but that doesn't mean it's easy to specify.<br>\nMoreover, to my knowledge, we do not have any such \"propagate runtime behavior\" attribute at the moment, so it would \"open a new axis\" in the language design.</p>",
        "id": 176800849,
        "sender_full_name": "centril",
        "timestamp": 1569634243
    },
    {
        "content": "<p>Meanwhile, types are a known concept which are not fundamentally different and which we know how to specify</p>",
        "id": 176800871,
        "sender_full_name": "centril",
        "timestamp": 1569634305
    },
    {
        "content": "<p>rustc_inherit_overflow_checks :)</p>",
        "id": 176802869,
        "sender_full_name": "simulacrum",
        "timestamp": 1569637468
    },
    {
        "content": "<p>but true.</p>",
        "id": 176802871,
        "sender_full_name": "simulacrum",
        "timestamp": 1569637472
    },
    {
        "content": "<p>That was bound to be brought up lol :D</p>",
        "id": 176802878,
        "sender_full_name": "centril",
        "timestamp": 1569637499
    },
    {
        "content": "<p>But \"syntactically in the attributed scope\" seems feasible?</p>",
        "id": 176802901,
        "sender_full_name": "simulacrum",
        "timestamp": 1569637551
    },
    {
        "content": "<p>I think it's implementable (<code>rustc_inherit_overflow_checks</code> does so) but I don't think it's a good idea</p>",
        "id": 176802954,
        "sender_full_name": "centril",
        "timestamp": 1569637628
    },
    {
        "content": "<p>My understanding is that fast math is purely for operators, basically - from the type system POV it's no different to adding unsafe(?) methods</p>",
        "id": 176802955,
        "sender_full_name": "simulacrum",
        "timestamp": 1569637632
    },
    {
        "content": "<p>Is that right? Like, we could expose the relevant llvm intrinsics and people could newtype implement this today</p>",
        "id": 176803009,
        "sender_full_name": "simulacrum",
        "timestamp": 1569637728
    },
    {
        "content": "<p>taking the expose-intrinsics route seems sensible</p>",
        "id": 176803075,
        "sender_full_name": "centril",
        "timestamp": 1569637812
    },
    {
        "content": "<p>at least as a start</p>",
        "id": 176803076,
        "sender_full_name": "centril",
        "timestamp": 1569637817
    },
    {
        "content": "<p>And <code>f32</code> isn't special cases anywhere, right? Other than having primitive syntax (1.0) for it.</p>",
        "id": 176803077,
        "sender_full_name": "simulacrum",
        "timestamp": 1569637822
    },
    {
        "content": "<p>that probably needs to be checked to answer with authority =)</p>",
        "id": 176803089,
        "sender_full_name": "centril",
        "timestamp": 1569637868
    },
    {
        "content": "<p>but it seems likely</p>",
        "id": 176803090,
        "sender_full_name": "centril",
        "timestamp": 1569637873
    },
    {
        "content": "<p>aside from pattern matching but that's going out</p>",
        "id": 176803091,
        "sender_full_name": "centril",
        "timestamp": 1569637882
    },
    {
        "content": "<p>Right yeah</p>",
        "id": 176803094,
        "sender_full_name": "simulacrum",
        "timestamp": 1569637893
    },
    {
        "content": "<p>Do people want this as a global switch?</p>",
        "id": 176803141,
        "sender_full_name": "simulacrum",
        "timestamp": 1569637969
    },
    {
        "content": "<p>Like, to me that seems not great</p>",
        "id": 176803145,
        "sender_full_name": "simulacrum",
        "timestamp": 1569637981
    },
    {
        "content": "<p>From a usability - even ignoring our desire to avoid it in the language - standpoint</p>",
        "id": 176803166,
        "sender_full_name": "simulacrum",
        "timestamp": 1569638018
    },
    {
        "content": "<p>I believe these are the options (some mutually compatible):</p>\n<ol>\n<li>\n<p>Global switch for <code>f32</code> [opt-in, out-out]</p>\n</li>\n<li>\n<p>Expose LLVM intrinsics but use <code>f32</code> as types.</p>\n<p>a) Newtype <code>f32</code> with those.</p>\n</li>\n<li>\n<p>Introduce a primitive type <code>r32</code></p>\n<p>a) Global switch for <code>r32</code> [opt-in, out-out]</p>\n<p>b) Add ability to cargo to have <code>--global-feature fast_math</code><br>\n c) Use <code>option_env!(...)</code> instead with enhanced CTFE</p>\n</li>\n<li>\n<p>Scoped attributes</p>\n</li>\n</ol>",
        "id": 176803277,
        "sender_full_name": "centril",
        "timestamp": 1569638264
    },
    {
        "content": "<p>I'm OK with 2. and 3.</p>",
        "id": 176803321,
        "sender_full_name": "centril",
        "timestamp": 1569638295
    },
    {
        "content": "<p>I do believe many people want 1.</p>",
        "id": 176803322,
        "sender_full_name": "centril",
        "timestamp": 1569638308
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> Clarification: this isn't just for operators, it's also for code generation between functions and similar.</p>",
        "id": 176819345,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569664734
    },
    {
        "content": "<p>So, for instance, you could do multiple operations and not truncate/round between them.</p>",
        "id": 176819355,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569664759
    },
    {
        "content": "<p>That isn't just about addition or multiplication (though that's important), it's also about any other floating point function.</p>",
        "id": 176819406,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569664814
    },
    {
        "content": "<p>Thanks everyone for giving this some thought! </p>\n<p>I much agree that it would be nice to scope fast-math and not have it globally enabled. </p>\n<p>Looking at the options <span class=\"user-mention\" data-user-id=\"126931\">@centril</span>  listed:<br>\n1) Nah, I agree, a global switch would most likely apply fast-math to code where not anticipated, breaking things<br>\n2) Would this require casting when interacting with <code>f32</code>?<br>\n3) still processing this variant :)<br>\n4) As far as I can tell, I'd probably prefer this variant as it would be explicit which part of the code is using fast-math. fast-math could be seen as a property which a function or module could be designed for/robust against.</p>",
        "id": 176820162,
        "sender_full_name": "Alexander Droste",
        "timestamp": 1569666003
    },
    {
        "content": "<p>Newtypes are not great for this. \"fast/deterministic\" already has problems (some discussed above; I'd also add the extra annotation burden for both library code that tries to be generic over the different types and its users) but that binary choice is an illusion. In reality there are at least four different kinds of fast-math flags (FMFs) that should be offered independently: contraction, algebraic rewrites, approximating built-in functions, existence of nans/infs/signed zeros. Many of those can usefully subdivided further (for reference, LLVM currently has 7 and would have more if not for storage space limitations).</p>\n<p>So the newtyping approach leads to a combinatorial explosion of types. This can cause various problems but I am especially worried about the code size impact it has. Besides multiplying any generic code that handles float values without caring for the fast-math flags (e.g., Vec and slice methods), we'd also probably need  a massive (also generic, but massively monomorphized) matrix of operator overloads to allow some interoperability between values computed with different FMFs. And this will be imperfect, e.g. <code>if cond { /* compute f32 with some FMFs */ } else { /* compute f32 with slightly different FMFs */}</code> will need an explicit cast.</p>\n<p>There's also a related problem with libms, which mostly have a monomorphic interface in terms of f32 and f64 but the optimizer should see FMFs applied to those calls (so it can perform optimizations) even if the libm never even sees the FMFs. There's no good way to expose this with intrinsics or newtypes AFAIK.</p>",
        "id": 176820375,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569666319
    },
    {
        "content": "<p>This is not to say I endorse a special new language feature such as global or scoped (sets of) flags. Propagating through function boundaries is necessary and trying to do that with ad-hoc flags doesn't play nicely with the compilation model (and also abstraction boundaries, only <em>some</em> functions want to inherit FMFs). But if a satisfactory solution to that can be found, it would solve the problems newtypes have.</p>",
        "id": 176820536,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569666602
    },
    {
        "content": "<blockquote>\n<p>2) Would this require casting when interacting with f32?</p>\n</blockquote>\n<p>Since it's a newtype <code>struct R32(pub f32);</code> you'd need to wrap manually. The main benefit of a primitive would be to feel more built-in. Though maybe we should consider user defined literals...</p>\n<blockquote>\n<p>I'd also add the extra annotation burden for both library code that tries to be generic over the different types and its users) but that binary choice is an illusion.</p>\n</blockquote>\n<p>Ostensibly <code>f32</code> and <code>f64</code> already incur such a burden cause some authors would want to deal with both so it's not a novel burden but it is likely that the desire to be generic would increase. I think we can reduce that burden through <code>impl Trait</code>, <code>associated_type_defaults</code>, <code>associated_type_bounds</code>, <code>trait_aliases</code>, and so on to make the syntactic overhead substantially smaller.</p>\n<blockquote>\n<p>In reality there are at least four different kinds of fast-math flags (FMFs) that should be offered independently: contraction, algebraic rewrites, approximating built-in functions, existence of nans/infs/signed zeros. [...]</p>\n</blockquote>\n<p>That's a lot of complexity. I'm not sure all should be offered independently except as perhaps exposed intrinsics.</p>\n<blockquote>\n<p>So the newtyping approach leads to a combinatorial explosion of types.</p>\n</blockquote>\n<p>The newtype / <code>r32</code> approach is intended as a fairly blunt instrument that says \"prioritize performance at the cost of standards compliance and reliability within the limits soundness provides\". I'm not sure we have to provide control over every niche trough types. We could provide some global flags to tweak the semantics of <code>r32</code> if we communicate from the get-go that crate authors using these types should be ready for such semantic changes through flags.</p>",
        "id": 176841006,
        "sender_full_name": "centril",
        "timestamp": 1569703600
    },
    {
        "content": "<blockquote>\n<blockquote>\n<p>In reality there are at least four different kinds of fast-math flags (FMFs) that should be offered independently: contraction, algebraic rewrites, approximating built-in functions, existence of nans/infs/signed zeros. [...]</p>\n</blockquote>\n<p>That's a lot of complexity. I'm not sure all should be offered independently except as perhaps exposed intrinsics.</p>\n</blockquote>\n<p>I am quite sure they should. Most users will still default to enabling all or none for convenience (as they do in C and Fortran, where these distinctions exist), but greater level of control is absolutely needed sometimes -- some aspects of \"fast-math\" break your algorithm but others are essential for its performance. The step from \"use this newtype\" to \"write ALL your math out as intrinsics\" seems too steep to be acceptable, so I fear people will either fall back to no FMFs at all (bad since they won't get C-competitive performance) or use the blunt \"fast-math\" hammer and try to work around the issues it causes as they go (bad since they jeopardize their program's reliability).</p>\n<p>I also don't think it is that much complexity. No matter what approach we take precisely, there will definitely be aliases for common groups of FMFs (so UX is about the same for those who don't care) and on the implementation side it's just a bitset instead of a boolean to track. Also, alternative implementations that don't care can always collapse (e.g., into a binary fast/precise) or outright ignore FMFs. Embracing finger-grained FMFs does shift the balance towards somewhat more complex ways for users to choose FMFs, but personally I think those approaches are strong candidates even with a binary switch (e.g., due to the \"libm problem\" I described earlier).</p>\n<p>Another consideration is that fast-math is not the only \"modification of float rules\" knob, there's also much space to go in the opposite direction and constrain optimizations <em>more</em> to allow users to change rounding mode, inspect and modify fp exception flags, install non-default fp exception handling, and preserve NaN bit patterns. Nobody has even sketched a design of what this would look like in Rust, but since it similarly needs to affect all primitive operations and some function calls within a certain scope or program slice, it seems plausible to me we could use the same mechanism as for FMFs.</p>",
        "id": 176860072,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569741318
    },
    {
        "content": "<blockquote>\n<p>The newtype / <code>r32</code> approach is intended as a fairly blunt instrument that says \"prioritize performance at the cost of standards compliance and reliability within the limits soundness provides\". I'm not sure we have to provide control over every niche trough types. We could provide some global flags to tweak the semantics of <code>r32</code> if we communicate from the get-go that crate authors using these types should be ready for such semantic changes through flags.</p>\n</blockquote>\n<p>A bit tangential but global flags (as in, affecting all crates in the crate graph) would be useless IMO. The whole reason for finer-grained flags is to allow different parts of the program different sets of optimizations. If it's a whole-program switch, all code using <code>r32</code> has to be correct under the full set of FMFs, so it might as well use those and get more optimization potential. But of course, in reality library authors won't be perfect about this, so leaving this choice to the user who compiles the crate graph causes the same problems (to a lesser degree) as a global flag that changes all <code>f32</code>-using code to \"fast-math mode\".</p>\n<p>Note that even C  and Fortran let you choose on a file-by-file bases. For contraction, there is even a pragma in the C standard (<code>#pragma STDC FP_CONTRACT &lt;on/off&gt;</code>) that allows one to choose on a statement-by-statement basis.</p>",
        "id": 176860449,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569742060
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228402\">@Alexander Droste</span> as you probably already noticed that would be a new language feature and would need an RFC</p>",
        "id": 177037774,
        "sender_full_name": "gnzlbg",
        "timestamp": 1569921990
    },
    {
        "content": "<p>It is possible to make correct unsafe Rust code exhibit undefined behavior by changing floating point arithmetic, so solving the problem isn’t as easy as just adding compiler flags</p>",
        "id": 177038336,
        "sender_full_name": "gnzlbg",
        "timestamp": 1569922428
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span> Makes sense and thanks for the heads up.</p>",
        "id": 177047964,
        "sender_full_name": "Alexander Droste",
        "timestamp": 1569931362
    },
    {
        "content": "<p>You can make correct unsafe code exhibit unsafe behavior by changing <em>any</em> defined feature in the language.</p>",
        "id": 177050824,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569933903
    },
    {
        "content": "<p>Just by having a conditional testing the existing behavior and performing undefined behavior if it goes the other way.</p>",
        "id": 177050881,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569933956
    },
    {
        "content": "<p>I don't see how that negates <span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span>'s point.</p>",
        "id": 177050960,
        "sender_full_name": "centril",
        "timestamp": 1569933995
    },
    {
        "content": "<p>I don't think that, by itself, implies we can never ever change any behavior. The question is whether anyone is relying on that behavior, as well as whether that behavior was actually defined in practice or whether the documentation said one thing but the code said another.</p>",
        "id": 177051020,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569934029
    },
    {
        "content": "<p>For instance, the documentation says one thing about floating point precision, but if you rely on that as an ironclad spec, you will find different behavior on 32-bit x86 (for instance).</p>",
        "id": 177051125,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569934088
    },
    {
        "content": "<p>then there's a bug in 32-bit x86</p>",
        "id": 177051144,
        "sender_full_name": "centril",
        "timestamp": 1569934108
    },
    {
        "content": "<p>Indeed; we have other cases (like integer-overflow) where one can observe different behaviors based on compiler flags; but we have <em>specified</em> the range of behaviors there.</p>",
        "id": 177051153,
        "sender_full_name": "pnkfelix",
        "timestamp": 1569934121
    },
    {
        "content": "<p>In practice, it isn't actually something you can rely on.</p>",
        "id": 177051178,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569934142
    },
    {
        "content": "<p>You could say there's a bug in 32-bit x86. Or you could say there's a bug in the docs.</p>",
        "id": 177051206,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569934163
    },
    {
        "content": "<p>I think you'd actually be hard-pressed to find any explicitly specified behavior that is inconsistent with -ffast-math or x87 precision issues. To some degree this is annoying language lawyering but e.g. we never actually say anywhere in the reference that fp addition is correctly rounded</p>",
        "id": 177051240,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569934194
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> can you be more specific about what the docs say w.r.t. floating point precision that is contradicted by 32-bit x86?</p>",
        "id": 177051257,
        "sender_full_name": "pnkfelix",
        "timestamp": 1569934201
    },
    {
        "content": "<p>(not that I doubt you; at this point I'm just curious since you seem to have something concrete in mind)</p>",
        "id": 177051317,
        "sender_full_name": "pnkfelix",
        "timestamp": 1569934219
    },
    {
        "content": "<p>I would say there's a bug in the docs, and a cautious and correct programmer would observe the actual behavior.</p>",
        "id": 177051323,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569934221
    },
    {
        "content": "<p>nitpick: it's only the tier 1 i586-* target where these issues crop up, all the mainstream 32 bit x86 targets require SSE2 and thus have correctly rounded f32 and f64 arithmetic</p>",
        "id": 177051420,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569934298
    },
    {
        "content": "<p>Before anyone tries to reproduce this with an <code>i686-*</code> rustc</p>",
        "id": 177051455,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569934316
    },
    {
        "content": "<p>Sure. The specs don't <em>quite</em> actually say, but implicitly imply, that you won't get excess precision. Because they define the floating-point types by reference to IEEE 754, and 754 doesn't prohibit excess precision but a strict reading of 754 says you should have exactly the specified precision.</p>",
        "id": 177051503,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569934324
    },
    {
        "content": "<p>And yes, sorry, i586. Though you'd get the same behavior with i686 if you actually build for a target where you can't assume SSE.</p>",
        "id": 177051567,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569934381
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 177051599,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569934410
    },
    {
        "content": "<p>My point is, when the spec and the implementation differ, sometimes the spec is wrong, sometimes the implementation is wrong, and sometimes you could argue either case.</p>",
        "id": 177051704,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569934481
    },
    {
        "content": "<p>Oh, also, since I don't see it linked anywhere in this topic thus far: <a href=\"https://github.com/rust-lang/rust/issues/21690\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/issues/21690\">#21690</a></p>",
        "id": 177051744,
        "sender_full_name": "pnkfelix",
        "timestamp": 1569934522
    },
    {
        "content": "<p>Sometimes the spec needs to change (if that is even possible), but such a change should be intentional and go through the regular channels (i.e. FCP / RFC / ...).</p>",
        "id": 177051753,
        "sender_full_name": "centril",
        "timestamp": 1569934537
    },
    {
        "content": "<p>and in fact maybe I'll add it to the topic</p>",
        "id": 177051755,
        "sender_full_name": "pnkfelix",
        "timestamp": 1569934539
    },
    {
        "content": "<p>I agree re: \"sometimes the spec is wrong, sometimes the impl is wrong, sometimes you could argue either\". I brought up the ambiguity of the spec under a very strict reading as more ammo  for the arguing :)</p>",
        "id": 177051826,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569934576
    },
    {
        "content": "<p>Speaking of, it's kind of funny to me that <a href=\"https://github.com/rust-lang-nursery/reference/pull/607\" target=\"_blank\" title=\"https://github.com/rust-lang-nursery/reference/pull/607\">https://github.com/rust-lang-nursery/reference/pull/607</a> is not just the only explicit definition of any fp operation's semantics but probably the only one which would explicitly contradict <code>-ffast-math</code></p>",
        "id": 177052733,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569935173
    },
    {
        "content": "<blockquote>\n<p>The step from \"use this newtype\" to \"write ALL your math out as intrinsics\" seems too steep to be acceptable, so I fear people will either fall back to no FMFs at all (bad since they won't get C-competitive performance) or use the blunt \"fast-math\" hammer and try to work around the issues it causes as they go (bad since they jeopardize their program's reliability).</p>\n</blockquote>\n<p>It seems to me a small minority of will want to use a lot of tweaks a lot of the time. If you just do it sometimes then using some intrinsics doesn't feel very onerous. Also, you can still implement your own <code>Add</code> and such impls which should make it even less onerous. Maybe user defined literals (which folks want for different things anyways, e.g. units and such) and some enhanced inference would make it feel even more first-class.</p>\n<p>On the flip-side, if you provide too many of these baked into the language I think that is contributing to decision paralysis.</p>",
        "id": 177053010,
        "sender_full_name": "centril",
        "timestamp": 1569935382
    },
    {
        "content": "<p>I don't know how small a minority it actually would be if we provided comprehensible and convenient knobs. Contraction is widely desired (to be able to use FMA instructions), and trading accuracy of built-in functions for performance is super common in some domains such as graphics, while algebraic rewrites are more unconstrained and scary (e.g., more likely to cause numeric accuracy problems in practice) and mostly relevant for automatic vectorization. I think that -ffast-math in C is mostly a binary matter is also partially due to history and bad flag naming.</p>\n<p>Decision paralysis is a real risk, but can be mitigated by presentation. I mentioned shortcuts for common options earlier, and the docs could put them front-and-center (with e.g. one sentence pointing out that more control is available and link to a document with the details). Besides, solving decision paralysis by making most options so unattractive that people never consider them isn't exactly a great solution ;-)</p>",
        "id": 177054938,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569936620
    },
    {
        "content": "<blockquote>\n<p>Besides, solving decision paralysis by making most options so unattractive that people never consider them isn't exactly a great solution ;-)</p>\n</blockquote>\n<p>Granted but I think \"so unattractive\" is rather debatable ^^ -- a newtype with a short, say 2-letter name for the constructor + <code>Add</code>&amp;-friends impls + maybe user defined literals feels attractive-ish</p>",
        "id": 177055205,
        "sender_full_name": "centril",
        "timestamp": 1569936786
    },
    {
        "content": "<p>I refrained from writing a whole response to that suggestion but in brief this is a significant amount of boilerplate for any one library to hand-roll. And if it gets centralized into a shared library, more generality and thus more boilerplate is needed. (And none of this does anything to address the other problems with newtypes. You didn't claim it does, but let's not forget that it's also controversial whether newtypes are a decent option no matter who writes them.)</p>",
        "id": 177055464,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569936979
    },
    {
        "content": "<p>I think we should have a couple of types, one to opt into optimizations that increase precision or are similarly safe, and one to carefully opt into flexible precision. The precise semantics of the former should be selectable via global flags; the latter should be controlled by global flags but limitable locally. Personal opinion.</p>",
        "id": 177056603,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569937799
    },
    {
        "content": "<p>I would call the former types <code>f32</code> and <code>f64</code> (and eventually <code>f16b</code>), and I don't know what I'd call the latter types. I absolutely understand the argument for calling the former types <code>r32</code> and <code>r64</code> instead though.</p>",
        "id": 177056778,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569937881
    },
    {
        "content": "<blockquote>\n<p>You can make correct unsafe code exhibit unsafe behavior by changing <em>any</em> defined feature in the language.</p>\n</blockquote>\n<p>Which is why we don’t do that?</p>",
        "id": 177057173,
        "sender_full_name": "gnzlbg",
        "timestamp": 1569938168
    },
    {
        "content": "<blockquote>\n<p>I think we should have a couple of types, one to opt into optimizations that increase precision or are similarly safe, and one to carefully opt into flexible precision. The precise semantics of the former should be selectable via global flags; the latter should be controlled by global flags but limitable locally. Personal opinion.</p>\n</blockquote>\n<p>The problem is specifying which optimizations each of the types and flags allows/disallows and how to satisfy the granularity requirement of users without breaking existing code as well as how to compose these flags with existing code.</p>\n<p>Those global flags can cause UB on any of your dependencies, add another couple of rows to the test matrixes that numeric crates need to cover, provide no barrier of defense for crates that are known not to work with those flags enabled, as-hoc cfg-like fixes to detect the flags and eg compile_error on them cause ecosystem splits, etc.</p>",
        "id": 177057997,
        "sender_full_name": "gnzlbg",
        "timestamp": 1569938714
    },
    {
        "content": "<p>IMO the assumption that the caller or the binary builder can correctly choose which optimizations are sound for all code in a binary is flawed</p>",
        "id": 177058338,
        "sender_full_name": "gnzlbg",
        "timestamp": 1569938916
    },
    {
        "content": "<p>As flawed as offering a global option to make all pointers “noalias” or similar</p>",
        "id": 177058359,
        "sender_full_name": "gnzlbg",
        "timestamp": 1569938933
    },
    {
        "content": "<blockquote>\n<blockquote>\n<p>You can make correct unsafe code exhibit unsafe behavior by changing <em>any</em> defined feature in the language.</p>\n</blockquote>\n<p>Which is why we don’t do that?</p>\n</blockquote>\n<p>See above. Sometimes the spec is wrong and the implementation is correct.</p>",
        "id": 177058787,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569939139
    },
    {
        "content": "<blockquote>\n<p>how to satisfy the granularity requirement of users</p>\n</blockquote>\n<p>I would argue that to a first approximation, users don't have that fine of granularity requirements. \"Exactly IEEE 754\" and \"feel free to make it more precise, just never less\" are two obvious convergence points.</p>\n<p>As I said, it's debatable which of those two types should be called <code>f32</code>/<code>f64</code>.</p>\n<blockquote>\n<p>provide no barrier of defense for crates that are known not to work with those flags enabled, as-hoc cfg-like fixes to detect the flags and eg compile_error on them cause ecosystem splits, etc.</p>\n</blockquote>\n<p>There would of course be a well-supported mechanism: use a type that guarantees IEEE 754.</p>",
        "id": 177059303,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569939450
    },
    {
        "content": "<blockquote>\n<p>I would argue that to a first approximation, users don't have that fine of granularity requirements. \"Exactly IEEE 754\" and \"feel free to make it more precise, just never less\" are two obvious convergence points.</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span>  I think that is a balance well struck <span aria-label=\"+1\" class=\"emoji emoji-1f44d\" role=\"img\" title=\"+1\">:+1:</span></p>",
        "id": 177060023,
        "sender_full_name": "centril",
        "timestamp": 1569939845
    },
    {
        "content": "<p>(I just disagree on <code>f32</code> tho as you know ^^)</p>",
        "id": 177060068,
        "sender_full_name": "centril",
        "timestamp": 1569939867
    },
    {
        "content": "<p>I'm aware. But I also think it's useful to get down to the smallest and most precise (heh) point of disagreement, rather than leaving that point...floating. ;)</p>",
        "id": 177060123,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569939906
    },
    {
        "content": "<p><span aria-label=\"rofl\" class=\"emoji emoji-1f923\" role=\"img\" title=\"rofl\">:rofl:</span></p>",
        "id": 177060193,
        "sender_full_name": "centril",
        "timestamp": 1569939956
    },
    {
        "content": "<p>So, you would support having r32 and r64 types that defaulted to contraction and increased precision, even target-specific precision?</p>",
        "id": 177060267,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569939989
    },
    {
        "content": "<p>You just wouldn't support making f32 and f64 those types?</p>",
        "id": 177060293,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940014
    },
    {
        "content": "<p>That seems right, yeah</p>",
        "id": 177060323,
        "sender_full_name": "centril",
        "timestamp": 1569940026
    },
    {
        "content": "<p>Would you support crate-local flags to make the f types have that behavior, and just not global flags?</p>",
        "id": 177060432,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940084
    },
    {
        "content": "<p>At first instance I would not. I think it would be better, due to e.g. interactions with generics and higher order functions that the <code>f*</code> types have a single canonical meaning no matter what</p>",
        "id": 177060745,
        "sender_full_name": "centril",
        "timestamp": 1569940249
    },
    {
        "content": "<p>Interesting. I find that a rather compelling argument against crate-local flags, though not against global flags.</p>",
        "id": 177060839,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940307
    },
    {
        "content": "<p>Also, would you support building in the r types so that they can have the appropriate LLVM behavior enabled for them?</p>",
        "id": 177060928,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940347
    },
    {
        "content": "<p>\"Global\" flags would be rustc command line flags and so would not be truly global (i.e., apply through the entire crate graph) due to separate compilation</p>",
        "id": 177060929,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569940347
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124289\">@rkruppe</span> Something something std-aware cargo. ;)</p>",
        "id": 177060999,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940399
    },
    {
        "content": "<p>Even then someone can build one crate with one set of flags and another crate with different flags and link them</p>",
        "id": 177061044,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569940434
    },
    {
        "content": "<p>We'd need a mechanism like global allocators or panic runtimes (not to be confused with panic strategy) to truly enforce \"one crate graph = one semantics\"</p>",
        "id": 177061154,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569940486
    },
    {
        "content": "<p>Fair point.</p>",
        "id": 177061173,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940502
    },
    {
        "content": "<p>Modulo what <span class=\"user-mention\" data-user-id=\"124289\">@rkruppe</span>  said I'd agree with you <span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span></p>",
        "id": 177061198,
        "sender_full_name": "centril",
        "timestamp": 1569940517
    },
    {
        "content": "<p>(but there are other arguments wrt. back compat and \"undoing the expectations that crates were written with that are unrelated to separate compilation)</p>",
        "id": 177061254,
        "sender_full_name": "centril",
        "timestamp": 1569940562
    },
    {
        "content": "<p>I should also say that to a first approximation having the r types wouldn't be terrible. I'd then end up effectively telling people (with a footnote for the details) that r32 and r64 are the floating-point types and f32 and f64 are the slow floating-point types that you shouldn't use unless you have reason to know you need them.</p>",
        "id": 177061371,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940629
    },
    {
        "content": "<p>We're probably all aware but for the record: <a href=\"https://github.com/rust-lang/rfcs/pull/2686\" target=\"_blank\" title=\"https://github.com/rust-lang/rfcs/pull/2686\">https://github.com/rust-lang/rfcs/pull/2686</a></p>",
        "id": 177061385,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569940645
    },
    {
        "content": "<p>It would be <em>annoying</em> to go through and fix <em>everything</em> to use generics though.</p>",
        "id": 177061518,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940714
    },
    {
        "content": "<p>And any algorithm that works fine with extra precision (which is to say, just about every algorithm) should work with r32 and r64.</p>",
        "id": 177061593,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940778
    },
    {
        "content": "<blockquote>\n<p>I should also say that to a first approximation having the r types wouldn't be terrible. I'd then end up effectively telling people (with a footnote for the details) that r32 and r64 are the floating-toint types and f32 and f64 are the slow floating-point types that you shouldn't use unless you have reason to know you need them.</p>\n</blockquote>\n<p>Well, we probably can't get around providing a third option (at least) for the parts of -ffast-math that don't fit under your definition of rN (higher precision). In particular, numerically unsafe algebraic transformations (e.g. reassociation) would not be covered by it but are often a key component of the large performance gains which motivate people to compile with -ffast-math.</p>",
        "id": 177061599,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569940788
    },
    {
        "content": "<p>I don't have as much of a problem with the idea that if you want things like reassociation that lower precision you need to use special operations or a specific block.</p>",
        "id": 177061779,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940894
    },
    {
        "content": "<p>Sure.</p>",
        "id": 177061865,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569940934
    },
    {
        "content": "<p>Those should <em>definitely</em> be case-by-case opt in.</p>",
        "id": 177061884,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940951
    },
    {
        "content": "<p>Only if they don't break your algorithm.</p>",
        "id": 177061907,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569940969
    },
    {
        "content": "<p>But it should be easy to get FMA or multiple operations in a higher precision register with minimal effort and without rewriting any code (or at most, changing types).</p>",
        "id": 177062052,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569941065
    },
    {
        "content": "<p>I bring it up because it's a highly related matter and ideally we'd have a coherent story for all of this rather than several things which were designed completely separately and don't fit together conceptually</p>",
        "id": 177062131,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569941140
    },
    {
        "content": "<p>Also, there should be trivial infallible conversions via into and from to go between f and r types.</p>",
        "id": 177062147,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569941158
    },
    {
        "content": "<p>This is not to say these things all need to use the same mechanism, but we'd often be telling people not just \"these are the fast types and these are the slow ones\" but also mention next that there's also &lt;whatever other fast-math-y things we add&gt;</p>",
        "id": 177062306,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569941254
    },
    {
        "content": "<p>I understand. I get that people do want to carefully opt into \"go even faster at the expense of accuracy\" mode.</p>",
        "id": 177062581,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569941411
    },
    {
        "content": "<p>And in that mode, you do need control over \"how much inaccuracy\".</p>",
        "id": 177062623,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569941442
    },
    {
        "content": "<p>Unlike the r types, where it makes sense to enable all \"more precision\" optimisations at once.</p>",
        "id": 177062675,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569941478
    },
    {
        "content": "<p>I actually have a soft spot for C-standard-like \"contraction at the source level only\" which can be deterministic/reproducible in ways other optimizations (even contraction, when the FMAs are formed by the optimizer) aren't. But yeah it's a sensible option to group them all together.</p>",
        "id": 177063022,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569941698
    },
    {
        "content": "<p>Anyway, if we're going to end up with local controls of some of these optimizations in some form, then I do wonder whether we could use the same for \"increasing precision\". New types, built-in or not, have drawbacks that have been discussed extensively. Plus, to pick up your point about getting FMAs and higher precision registers without rewriting code, changing types everywhere can still be really involved -- a module level annotation is much easier.</p>",
        "id": 177063422,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1569941944
    },
    {
        "content": "<p>A module level annotation seems like the worst of both worlds to me.</p>",
        "id": 177098487,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569964275
    },
    {
        "content": "<p>Not global, possible type system interactions/limitations...</p>",
        "id": 177098532,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569964316
    },
    {
        "content": "<p>To your other point: I do want a coherent picture here. But I'd like the common cases to be simple.</p>",
        "id": 177100634,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569966218
    },
    {
        "content": "<p>(And I'm much less concerned about things that would require reprogramming the floating-point unit's behavior.)</p>",
        "id": 177100703,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1569966246
    },
    {
        "content": "<p>I'm curious why \"not global\" is a drawback? The C precedent is a (translation-unit-)global flag, but if we're all in agreement that there should be <em>some</em> opt-in to the optimizations from the code author (e.g., by using a different data type) then why do we need a global(-ish) flag in addition? Why not just always apply the optimizations to the code that opts in?</p>",
        "id": 177130567,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1570004520
    },
    {
        "content": "<p>Hey participants of this thread! It looks like seem really useful information was exchanged here. I'm not quite sure what because the thread is really long and I'm trying to catch up on hundreds of messages. =) Do you think somebody could try to write a summary of what was said? (I don't expect a consensus was reached, but just outlining the major points would be amazing.) </p>\n<p>I'm not 100% sure, admittedly, where to <em>push</em> such a summary. This seems like largely a lang-design thing -- I think perhaps that we could create a directory on the lang-team repo to push summaries on interesting topics that should be considered in the future. (I would happily create such a directory to house this summary).</p>\n<p>cc <span class=\"user-mention\" data-user-id=\"124289\">@rkruppe</span> <span class=\"user-mention\" data-user-id=\"126931\">@centril</span> <span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> <span class=\"user-mention\" data-user-id=\"228402\">@Alexander Droste</span> <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span></p>",
        "id": 178752186,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1571748834
    }
]