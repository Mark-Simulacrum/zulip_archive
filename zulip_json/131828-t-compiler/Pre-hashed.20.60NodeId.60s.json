[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"384014\">@Patrick Walton</span> had an interesting suggestion to avoid hashing <code>NodeId</code>s: <a href=\"https://twitter.com/pcwalton/status/1464687523628609537\">https://twitter.com/pcwalton/status/1464687523628609537</a></p>\n<div class=\"inline-preview-twitter\"><div class=\"twitter-tweet\"><a href=\"https://twitter.com/pcwalton/status/1464687523628609537\"><img class=\"twitter-avatar\" src=\"https://uploads.zulipusercontent.net/106ebf871f7e16a9c776d347794ede671c46a992/68747470733a2f2f7062732e7477696d672e636f6d2f70726f66696c655f696d616765732f3631393038383731382f747769747465722d69636f6e5f6e6f726d616c2e6a706567\"></a><p>Is there a reason why rustc can't just generate NodeIds with a hardcoded 2^32 period LCG (instead of sequential integers) so hashing them is literally free? <a href=\"https://twitter.com/eddyb_r\">@eddyb_r</a> <a href=\"https://twitter.com/nnethercote\">@nnethercote</a></p><span>- Patrick Walton (@pcwalton)</span></div></div>",
        "id": 263101707,
        "sender_full_name": "nnethercote",
        "timestamp": 1638247896
    },
    {
        "content": "<p>I’ve been thinking a lot about that tweet.</p>",
        "id": 263101763,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638247935
    },
    {
        "content": "<p>are there not cheap scrambling functions that would achieve the same end effect when used as the hash function on an i32 ?</p>",
        "id": 263101777,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638247963
    },
    {
        "content": "<p><a href=\"https://github.com/rust-lang/rust/blob/master/compiler/rustc_ast/src/node_id.rs#L21-L24\">https://github.com/rust-lang/rust/blob/master/compiler/rustc_ast/src/node_id.rs#L21-L24</a> says we initially use <code>DUMMY_NODE_ID</code>, and then fill them in later</p>",
        "id": 263101778,
        "sender_full_name": "nnethercote",
        "timestamp": 1638247965
    },
    {
        "content": "<p>Where are they filled in?</p>",
        "id": 263101783,
        "sender_full_name": "nnethercote",
        "timestamp": 1638247977
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span> One might argue that <code>FxHasher</code> is a cheap scrambling function, but I guess you mean something even cheaper</p>",
        "id": 263101805,
        "sender_full_name": "nnethercote",
        "timestamp": 1638248029
    },
    {
        "content": "<p>yeah I guess I was thinking of some operation that would just permute the bits.</p>",
        "id": 263101881,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248126
    },
    {
        "content": "<p>But then that might not achieve the desired goal</p>",
        "id": 263101889,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248142
    },
    {
        "content": "<p>I guess part of the problem is that I need to revisit what a “good” hash function needs to do in order to perform well with our hashtables.</p>",
        "id": 263101933,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248167
    },
    {
        "content": "<p>If it's just for a hash table, and these IDs are assigned linearly from 0 on up, is there anything wrong with just using the identity?</p>",
        "id": 263101940,
        "sender_full_name": "nnethercote",
        "timestamp": 1638248186
    },
    {
        "content": "<p>Thank god someone else asked that Q</p>",
        "id": 263101943,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248198
    },
    {
        "content": "<p>LOL</p>",
        "id": 263101948,
        "sender_full_name": "nnethercote",
        "timestamp": 1638248205
    },
    {
        "content": "<p>i.e. I’ve been assuming there’s some reason that the identity function is a no-no here</p>",
        "id": 263101954,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248219
    },
    {
        "content": "<p>Oh, linear numbers are bad for hash tables, you want the entries spread out.</p>",
        "id": 263102167,
        "sender_full_name": "nnethercote",
        "timestamp": 1638248424
    },
    {
        "content": "<p>Otherwise you get bad behaviour on collisions</p>",
        "id": 263102205,
        "sender_full_name": "nnethercote",
        "timestamp": 1638248461
    },
    {
        "content": "<p>because of how other entries are inserted on collisions, yes, okay</p>",
        "id": 263102209,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248468
    },
    {
        "content": "<p>So alright. What if you reverse the bits?</p>",
        "id": 263102215,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248476
    },
    {
        "content": "<p>is risk there that the hash table will only look at least significant bits?</p>",
        "id": 263102221,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248499
    },
    {
        "content": "<p>Quite possible</p>",
        "id": 263102235,
        "sender_full_name": "nnethercote",
        "timestamp": 1638248520
    },
    {
        "content": "<p>/me reads <a href=\"https://en.wikipedia.org/wiki/Perfect_hash_function\">https://en.wikipedia.org/wiki/Perfect_hash_function</a></p>",
        "id": 263102243,
        "sender_full_name": "nnethercote",
        "timestamp": 1638248523
    },
    {
        "content": "<p>yeah okay</p>",
        "id": 263102255,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248524
    },
    {
        "content": "<p>see also: <a href=\"https://stackoverflow.com/questions/38304877/why-stdhashint-seems-to-be-identity-function\">https://stackoverflow.com/questions/38304877/why-stdhashint-seems-to-be-identity-function</a></p>",
        "id": 263102285,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248551
    },
    {
        "content": "<p>(nonetheless, I suspect that some fixed permutation of the bits might actually work quite well in practice here…)</p>",
        "id": 263102375,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248656
    },
    {
        "content": "<p><del>(which the Perfect_hash_function page probably discusses, I now realize)</del> (or maybe not)</p>",
        "id": 263102389,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638248699
    },
    {
        "content": "<p>Well, Patrick's suggestion is basically a way to compute a perfect hash function incrementally -- for each new integer, you compute its hash based on the previous integer's hash (cheap), and you store it for free by using it as the ID <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 263102459,
        "sender_full_name": "nnethercote",
        "timestamp": 1638248771
    },
    {
        "content": "<p>To answer my own question from above, looks like <code>NodeId</code>s are generated here: <a href=\"https://github.com/rust-lang/rust/blob/master/compiler/rustc_resolve/src/lib.rs#L1432-L1440\">https://github.com/rust-lang/rust/blob/master/compiler/rustc_resolve/src/lib.rs#L1432-L1440</a></p>",
        "id": 263102559,
        "sender_full_name": "nnethercote",
        "timestamp": 1638248929
    },
    {
        "content": "<p>Hmm:</p>\n<div class=\"codehilite\"><pre><span></span><code>    pub fn next_node_id(&amp;mut self) -&gt; NodeId {\n        let next = self\n            .next_node_id\n            .as_usize()\n            .checked_add(1)\n            .expect(&quot;input too large; ran out of NodeIds&quot;);\n        self.next_node_id = ast::NodeId::from_usize(next);\n        self.next_node_id\n    }\n</code></pre></div>\n<p><code>NodeId</code> is 32 bits. Why does this function convert it to a usize before doing the checked add, and then converts the result back to 32 bits?</p>",
        "id": 263103551,
        "sender_full_name": "nnethercote",
        "timestamp": 1638250239
    },
    {
        "content": "<p>Surely <code>as_u32()</code>/<code>from_u32()</code> is the right thing here?</p>",
        "id": 263103565,
        "sender_full_name": "nnethercote",
        "timestamp": 1638250291
    },
    {
        "content": "<p>Back to the viability of the idea: we have a couple of <code>IndexVec&lt;NodeId, T&gt;</code> occurrences:</p>\n<ul>\n<li><code>node_id_to_hir_id: IndexVec&lt;NodeId, Option&lt;hir::HirId&gt;&gt;</code></li>\n<li><code>nodes: IndexVec&lt;NodeId, Node&lt;'tcx&gt;&gt;</code></li>\n</ul>",
        "id": 263103742,
        "sender_full_name": "nnethercote",
        "timestamp": 1638250530
    },
    {
        "content": "<p>There's also the question: how much time do we actually spend hashing <code>NodeId</code>s? I just looked at a profile, seems like the answer is \"not much\"...</p>",
        "id": 263103965,
        "sender_full_name": "nnethercote",
        "timestamp": 1638250898
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263103965\">said</a>:</p>\n<blockquote>\n<p>There's also the question: how much time do we actually spend hashing <code>NodeId</code>s? I just looked at a profile, seems like the answer is \"not much\"...</p>\n</blockquote>\n<p>That's the first thought I had after seeing this thread - do we even hash node IDs at this point.<br>\nThey exist for a pretty short period of time starting from macro expansion and ending with lowering AST to HIR, and even during that time all \"coarse grained\" nodes are identified with <code>LocalDefId</code>s.</p>",
        "id": 263105013,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1638252256
    },
    {
        "content": "<p>so then the question becomes: Is pcwalton seeing hashing of NodeID’s in their profiling results? Or was this just idle thinking on their part?</p>",
        "id": 263105066,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638252327
    },
    {
        "content": "<p>I’ll privmsg pcwalton and ask</p>",
        "id": 263105080,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638252362
    },
    {
        "content": "<p>pcwalton clarified: they meant Defid’s, not node-ids. pcwalton also says that the relevant hashing code will not show up  will be inlined and \"smeared all over the code” (I believe that tooo).</p>",
        "id": 263161791,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638286503
    },
    {
        "content": "<p>pcwalton also mentioned something that I had not considered: The FxHash constants are copy-and-pasted over and over, which hurts code size. (I need to investigate that aspect of this more; there’s a mismatch of what pcwalton is saying and my mental model of what FxHash does.)</p>",
        "id": 263163514,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638287217
    },
    {
        "content": "<p>oh hmm, you mean these constants here? <a href=\"https://docs.rs/rustc-hash/1.1.0/src/rustc_hash/lib.rs.html#64-67\">https://docs.rs/rustc-hash/1.1.0/src/rustc_hash/lib.rs.html#64-67</a></p>",
        "id": 263164316,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638287586
    },
    {
        "content": "<p>it should be pretty easy to change those to <code>static</code> and run perf to see whether that hurts or helps</p>",
        "id": 263164361,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638287604
    },
    {
        "content": "<p>I only see that constant used once, and in a non-generic function: <a href=\"https://docs.rs/rustc-hash/1.1.0/src/rustc_hash/lib.rs.html#79\">https://docs.rs/rustc-hash/1.1.0/src/rustc_hash/lib.rs.html#79</a></p>",
        "id": 263164492,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638287652
    },
    {
        "content": "<p>although that function is marked <code>inline</code>, and called quite a lot from other functions also marked inline ... yeah this seems like a worthwhile experiment</p>",
        "id": 263164563,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638287687
    },
    {
        "content": "<p>(maybe we should also experiment with removing <code>#[inline]</code>? a lot of those functions are quite big)</p>",
        "id": 263164634,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638287715
    },
    {
        "content": "<p>i was assuming a big reason they are inlined is to give LLVM a chance to optimize them heavily</p>",
        "id": 263164896,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638287820
    },
    {
        "content": "<p>i.e. the kind of code they provide lends itself to massive optimization in each invocation context, right?</p>",
        "id": 263164978,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638287857
    },
    {
        "content": "<p>(i might be wrong about that, I don’t know how much the panic machinery will mess with that in those unwrap calls.)</p>",
        "id": 263165095,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638287891
    },
    {
        "content": "<p>((I wonder if we should be replace <code>unwrap()</code> with <code>unwrap_or(0)</code> there… that would then not have any panic stuff injected, right?))</p>",
        "id": 263165204,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638287941
    },
    {
        "content": "<p>yeah these functions are called so much I can imagine even tiny changes having a big impact</p>",
        "id": 263165319,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638287991
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116083\">pnkfelix</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263164978\">said</a>:</p>\n<blockquote>\n<p>i.e. the kind of code they provide lends itself to massive optimization in each invocation context, right?</p>\n</blockquote>\n<p>hmm, I'm a little confused - do you mean massive optimization <em>compared to optimizing them on their own</em>, without LTO / MIR inlining? I'm not sure how to predict how big the difference is</p>",
        "id": 263165694,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638288101
    },
    {
        "content": "<p>yes, I’m talking about without LTO/MIR inlining.</p>",
        "id": 263165909,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638288171
    },
    {
        "content": "<p>seems like it wouldn't be too hard to test :)</p>",
        "id": 263166070,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638288234
    },
    {
        "content": "<p>(i also assume the #[inline] attributes on these functions long predate our support for LTO and MIR-inlining. It probably mattered a lot more at that time.)</p>",
        "id": 263166488,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638288374
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span> I have some time - do you want to make a PR experimenting with <code>#[inline]</code>/<code>static</code> or should I? :)</p>",
        "id": 263168448,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638289096
    },
    {
        "content": "<p>static will not make a difference, LLVM will still codegen the constants inline, is my guess</p>",
        "id": 263168513,
        "sender_full_name": "simulacrum",
        "timestamp": 1638289128
    },
    {
        "content": "<p>it only really potentially matters for larger structs and references, but typically not too significant</p>",
        "id": 263168560,
        "sender_full_name": "simulacrum",
        "timestamp": 1638289150
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116083\">pnkfelix</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263165204\">said</a>:</p>\n<blockquote>\n<p>((I wonder if we should be replace <code>unwrap()</code> with <code>unwrap_or(0)</code> there… that would then not have any panic stuff injected, right?))</p>\n</blockquote>\n<p>I am pretty sure LLVM can optimize the <code>.unwrap()</code> for <code>.try_into()</code> out in any case.</p>",
        "id": 263168587,
        "sender_full_name": "bjorn3",
        "timestamp": 1638289164
    },
    {
        "content": "<p>inline will likely make a difference.</p>",
        "id": 263168596,
        "sender_full_name": "simulacrum",
        "timestamp": 1638289168
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133247\">bjorn3</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263168587\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"116083\">pnkfelix</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263165204\">said</a>:</p>\n<blockquote>\n<p>((I wonder if we should be replace <code>unwrap()</code> with <code>unwrap_or(0)</code> there… that would then not have any panic stuff injected, right?))</p>\n</blockquote>\n<p>I am pretty sure LLVM can optimize the <code>.unwrap()</code> for <code>.try_into()</code> out in any case.</p>\n</blockquote>\n<p>these functions are hot enough it would be nice to verify that (maybe just by looking at the ASM once?)</p>",
        "id": 263168653,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638289197
    },
    {
        "content": "<p>The disassembly for <code>write</code> doesn't contain any panic at <code>-Copt-level=3</code>: <a href=\"https://rust.godbolt.org/z/KrhbaqPzd\">https://rust.godbolt.org/z/KrhbaqPzd</a></p>",
        "id": 263169171,
        "sender_full_name": "bjorn3",
        "timestamp": 1638289425
    },
    {
        "content": "<p>even so, why make LLVM do the work there?</p>",
        "id": 263170434,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638289961
    },
    {
        "content": "<p>It still has to do the work for <code>.unwrap_or(0)</code>.</p>",
        "id": 263176491,
        "sender_full_name": "bjorn3",
        "timestamp": 1638292233
    },
    {
        "content": "<p>By the way, my original thought was to change that function to <code>crc32</code>, which was a 15% improvement in my tests.</p>",
        "id": 263190303,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1638298157
    },
    {
        "content": "<p>The <code>crc32</code> instruction on x86, that is.</p>",
        "id": 263190318,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1638298169
    },
    {
        "content": "<p>But then I realized we could just get rid of the hash entirely by using an LCG. (BTW I think it might be possible to run the hash in reverse and go back to sequential def ids if for whatever reason we need them.)</p>",
        "id": 263190481,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1638298235
    },
    {
        "content": "<p>I seem to recall that every little hash table improvement made measurable differences in rustc performance.</p>",
        "id": 263190614,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1638298299
    },
    {
        "content": "<p>In any case, I'm pretty sure there is room for improvement in the <code>rustc-hash</code> crate by using SSE4.2 (and the ARM crc32 instruction) if available. (Unless the hash has to be stable across platforms for some reason -- and I don't think it does?)</p>",
        "id": 263191315,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1638298578
    },
    {
        "content": "<p>I think it has to be for the crate metadata to remain stable across platforms. This is necessary to allow a cross-compiled standard library to be used.</p>",
        "id": 263198353,
        "sender_full_name": "bjorn3",
        "timestamp": 1638301517
    },
    {
        "content": "<p>I'm not sure that crate metadata depends on the hashing algorithm. At least it should not, it should only include information from <code>HashStable</code>.</p>",
        "id": 263201004,
        "sender_full_name": "cjgillot",
        "timestamp": 1638302760
    },
    {
        "content": "<p>Forgot about <code>HashStable</code>.</p>",
        "id": 263201447,
        "sender_full_name": "bjorn3",
        "timestamp": 1638302946
    },
    {
        "content": "<p>It does have the potential to introduce platform specific results for things like error ordering or object output though if something depends on hashmap iteration order.</p>",
        "id": 263201624,
        "sender_full_name": "bjorn3",
        "timestamp": 1638303035
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"384014\">Patrick Walton</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263190303\">said</a>:</p>\n<blockquote>\n<p>By the way, my original thought was to change that function to <code>crc32</code>, which was a 15% improvement in my tests.</p>\n</blockquote>\n<p>What did the test do?</p>",
        "id": 263202867,
        "sender_full_name": "nnethercote",
        "timestamp": 1638303692
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116083\">pnkfelix</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263161791\">said</a>:</p>\n<blockquote>\n<p>pcwalton clarified: they meant Defid’s, not node-ids.</p>\n</blockquote>\n<p><code>DefId</code> is a struct contains a <code>CrateNum</code> and a <code>DefIndex</code>. Perhap they meant <code>DefIndex</code>? We have two <code>IndexVec&lt;DefIndex, T&gt;</code> types I can see that would need changing.</p>",
        "id": 263203573,
        "sender_full_name": "nnethercote",
        "timestamp": 1638304077
    },
    {
        "content": "<p>The IndexVec&lt;LocalDefId, _&gt; will need changing too.</p>",
        "id": 263206195,
        "sender_full_name": "cjgillot",
        "timestamp": 1638305266
    },
    {
        "content": "<p>LocalDefId is a newtype around DefIndex.</p>",
        "id": 263206259,
        "sender_full_name": "cjgillot",
        "timestamp": 1638305286
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"232545\">@Joshua Nelson</span> Do you want to experiment? I can do local profiling easily, so I can try different things more easily than having to do a CI run.</p>",
        "id": 263209634,
        "sender_full_name": "nnethercote",
        "timestamp": 1638306820
    },
    {
        "content": "<p>I ended up getting sidetracked with <a href=\"https://github.com/rust-lang/rust/issues/90852\">https://github.com/rust-lang/rust/issues/90852</a> <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span> so feel free to tackle it yourself :)</p>",
        "id": 263209713,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638306846
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263203573\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"116083\">pnkfelix</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263161791\">said</a>:</p>\n<blockquote>\n<p>pcwalton clarified: they meant Defid’s, not node-ids.</p>\n</blockquote>\n<p><code>DefId</code> is a struct contains a <code>CrateNum</code> and a <code>DefIndex</code>. Perhap they meant <code>DefIndex</code>? We have two <code>IndexVec&lt;DefIndex, T&gt;</code> types I can see that would need changing.</p>\n</blockquote>\n<p>DefIndex I guess. I'm not up to date on all the renames of things :)</p>",
        "id": 263214499,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1638309413
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263202867\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"384014\">Patrick Walton</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263190303\">said</a>:</p>\n<blockquote>\n<p>By the way, my original thought was to change that function to <code>crc32</code>, which was a 15% improvement in my tests.</p>\n</blockquote>\n<p>What did the test do?</p>\n</blockquote>\n<p>Just a raw benchmark of hashing performance for integer keys.</p>",
        "id": 263214520,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1638309427
    },
    {
        "content": "<p>I tried removing the <code>#[inline]</code>s on all the <code>write_*</code> functions:</p>\n<div class=\"codehilite\"><pre><span></span><code>diff --git a/src/lib.rs b/src/lib.rs\nindex ee9ad31..4f919a7 100644\n--- a/src/lib.rs\n+++ b/src/lib.rs\n@@ -81,7 +81,6 @@ impl FxHasher {\n }\n\n impl Hasher for FxHasher {\n-    #[inline]\n     fn write(&amp;mut self, mut bytes: &amp;[u8]) {\n         #[cfg(target_pointer_width = &quot;32&quot;)]\n         let read_usize = |bytes: &amp;[u8]| u32::from_ne_bytes(bytes[..4].try_into().unwrap());\n@@ -108,35 +107,29 @@ impl Hasher for FxHasher {\n         self.hash = hash.hash;\n     }\n\n-    #[inline]\n     fn write_u8(&amp;mut self, i: u8) {\n         self.add_to_hash(i as usize);\n     }\n\n-    #[inline]\n     fn write_u16(&amp;mut self, i: u16) {\n         self.add_to_hash(i as usize);\n     }\n\n-    #[inline]\n     fn write_u32(&amp;mut self, i: u32) {\n         self.add_to_hash(i as usize);\n     }\n\n     #[cfg(target_pointer_width = &quot;32&quot;)]\n-    #[inline]\n     fn write_u64(&amp;mut self, i: u64) {\n         self.add_to_hash(i as usize);\n         self.add_to_hash((i &gt;&gt; 32) as usize);\n     }\n\n     #[cfg(target_pointer_width = &quot;64&quot;)]\n-    #[inline]\n     fn write_u64(&amp;mut self, i: u64) {\n         self.add_to_hash(i as usize);\n     }\n\n-    #[inline]\n     fn write_usize(&amp;mut self, i: usize) {\n         self.add_to_hash(i);\n     }\n</code></pre></div>\n<p>Results were <em>terrible</em>. Here's the first quarter of the results:</p>\n<div class=\"codehilite\"><pre><span></span><code>externs debug   full    13.61%  68.04x\nexterns opt     full    13.59%  67.94x\nctfe-stress-4 debug     full    7.32%   36.58x\nctfe-stress-4 check     full    7.31%   36.57x\nctfe-stress-4 opt   full    7.24%   36.18x\ncoercions check     full    7.09%   35.43x\ndeeply-nested check     full    6.97%   34.87x\nwg-grammar check    full    6.17%   30.86x\nwg-grammar debug    full    6.12%   30.60x\ncoercions opt   full    5.94%   29.68x\nregression-31157 check  full    5.93%   29.64x\nwg-grammar opt  full    5.85%   29.25x\nunused-warnings check   full    5.49%   27.46x\nstm32f4 check   full    5.27%   26.34x\nwebrender check     full    5.27%   26.33x\nclap-rs check   full    5.25%   26.24x\nregex check     full    5.21%   26.05x\nwebrender-wrench check  full    5.21%   26.05x\nripgrep check   full    5.16%   25.78x\nderive check    full    5.09%   25.45x\npiston-image check  full    5.07%   25.34x\nmatch-stress-exhaustive_patterns check  full    5.02%   25.12x\nfutures check   full    4.99%   24.95x\nunused-warnings debug   full    4.98%   24.92x\ntokio-webpush-simple check  full    4.98%   24.89x\n</code></pre></div>",
        "id": 263226406,
        "sender_full_name": "nnethercote",
        "timestamp": 1638316668
    },
    {
        "content": "<p>I.e. those are compile time increases of 5 to 13%</p>",
        "id": 263226474,
        "sender_full_name": "nnethercote",
        "timestamp": 1638316692
    },
    {
        "content": "<p>That's instruction counts. Cycles and wall-time also regressed, not quite as badly</p>",
        "id": 263226554,
        "sender_full_name": "nnethercote",
        "timestamp": 1638316756
    },
    {
        "content": "<p>what if you only remove inline from <code>write</code> and nothing else?</p>",
        "id": 263226752,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638316827
    },
    {
        "content": "<p>that's the largest one I think</p>",
        "id": 263226784,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638316839
    },
    {
        "content": "<p>I'll try it, but I suspect we don't call that one all that much</p>",
        "id": 263226839,
        "sender_full_name": "nnethercote",
        "timestamp": 1638316866
    },
    {
        "content": "<p><a href=\"https://github.com/rust-lang/rust/issues/69153\">https://github.com/rust-lang/rust/issues/69153</a> was the PR where I tried switching back to SipHash, BTW, results were awful</p>",
        "id": 263227325,
        "sender_full_name": "nnethercote",
        "timestamp": 1638317127
    },
    {
        "content": "<p>How is <code>rustc-hash</code> at 1.1.0 at <a href=\"https://crates.io/crates/rustc-hash\">https://crates.io/crates/rustc-hash</a>, but its <code>Cargo.toml</code> is only at 1.0.1: <a href=\"https://github.com/rust-lang/rustc-hash/blob/master/Cargo.toml\">https://github.com/rust-lang/rustc-hash/blob/master/Cargo.toml</a> ?</p>",
        "id": 263227946,
        "sender_full_name": "nnethercote",
        "timestamp": 1638317505
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"232545\">Joshua Nelson</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263226752\">said</a>:</p>\n<blockquote>\n<p>what if you only remove inline from <code>write</code> and nothing else?</p>\n</blockquote>\n<p>A handful of tiny instruction count regressions:</p>",
        "id": 263229608,
        "sender_full_name": "nnethercote",
        "timestamp": 1638318682
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>coercions check     full    0.72%   3.58x\ncoercions opt   full    0.70%   3.51x\nucd check   full    0.38%   1.88x\ntuple-stress check  full    0.36%   1.78x\nucd debug   full    0.35%   1.77x\ntuple-stress opt    full    0.35%   1.76x\ntuple-stress debug  full    0.35%   1.75x\n</code></pre></div>",
        "id": 263229615,
        "sender_full_name": "nnethercote",
        "timestamp": 1638318688
    },
    {
        "content": "<p>I also tried changing the multiply constant from 0x517cc1b727220a95 to 0x517cc1b727220a97 and it made negligible differences</p>",
        "id": 263231449,
        "sender_full_name": "nnethercote",
        "timestamp": 1638320260
    },
    {
        "content": "<p>I bet the inlining is important because of that constant. When you are hashing multiple things in sequence, you only need to load the constant into a register once</p>",
        "id": 263232091,
        "sender_full_name": "nnethercote",
        "timestamp": 1638320770
    },
    {
        "content": "<p>Plus the function entry/exit, of course</p>",
        "id": 263232414,
        "sender_full_name": "nnethercote",
        "timestamp": 1638321044
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263227946\">said</a>:</p>\n<blockquote>\n<p>How is <code>rustc-hash</code> at 1.1.0 at <a href=\"https://crates.io/crates/rustc-hash\">https://crates.io/crates/rustc-hash</a>, but its <code>Cargo.toml</code> is only at 1.0.1: <a href=\"https://github.com/rust-lang/rustc-hash/blob/master/Cargo.toml\">https://github.com/rust-lang/rustc-hash/blob/master/Cargo.toml</a> ?</p>\n</blockquote>\n<p>Someone probably cargo published it after making the edition change. I opened <a href=\"https://github.com/rust-lang/rustc-hash/pull/11\">https://github.com/rust-lang/rustc-hash/pull/11</a> an age ago but no one reviewed/merged it, so.</p>",
        "id": 263234213,
        "sender_full_name": "Jubilee",
        "timestamp": 1638322675
    },
    {
        "content": "<p>Thank! I added a comment to that PR. <span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> started rustc-hash, so he should have merge permissions <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 263237424,
        "sender_full_name": "nnethercote",
        "timestamp": 1638325934
    },
    {
        "content": "<p>For reference: we already have <a href=\"https://github.com/rust-lang/rust/blob/673d0db5e393e9c64897005b470bfeb6d5aec61b/compiler/rustc_data_structures/src/unhash.rs\">UnhashMap</a> which is a hashmap that expects keys to already be good hash values.</p>",
        "id": 263261342,
        "sender_full_name": "mw",
        "timestamp": 1638349707
    },
    {
        "content": "<p>Somewhat related: We often use pointers to interned things as hashmap keys, right? Have we ever tried using the pointer as hash value verbatim (or maybe shifted to the right by a few bits to make up for alignment)? Our hashbrown hashmaps should be pretty good at dealing with low-quality hash values (as you already get via FxHash).</p>",
        "id": 263448385,
        "sender_full_name": "mw",
        "timestamp": 1638456856
    },
    {
        "content": "<p>Lower bits find the initial bucket, but hashbrown also uses the upper 7 bits for simd matching. A pointer will need more of a transform to be useful on both ends.</p>",
        "id": 263455757,
        "sender_full_name": "cuviper",
        "timestamp": 1638459644
    },
    {
        "content": "<p>Right, I forget about that. I suspect that, for a single pointer value, FxHash is pretty close to being free anyway.</p>",
        "id": 263581752,
        "sender_full_name": "mw",
        "timestamp": 1638539361
    },
    {
        "content": "<p>What about using BTreeMap or other order-based maps? I seem to recall someone saying that for small keys like DefId it could be faster.</p>",
        "id": 263674919,
        "sender_full_name": "Noah Lev",
        "timestamp": 1638582029
    },
    {
        "content": "<p>With randomly-generated DefIds, how are collisions handled? Would every creation of a DefId check that it's not already in use?</p>",
        "id": 263674945,
        "sender_full_name": "Noah Lev",
        "timestamp": 1638582074
    },
    {
        "content": "<p>Going back to the original topic of this thread: the critical function is this:</p>\n<div class=\"codehilite\"><pre><span></span><code>impl FxHasher {\n    #[inline]\n    fn add_to_hash(&amp;mut self, i: usize) {\n        self.hash = self.hash.rotate_left(5).bitxor(i).wrapping_mul(K);\n    }\n}\n</code></pre></div>\n<p>You don't just hash an integer in isolation, you combine it with the running hash. So now I'm not sure how pcwalton's original suggestion would even work? Maybe you could skip the multiply for DefId if it's already effectively been hashed, or something</p>",
        "id": 263798465,
        "sender_full_name": "nnethercote",
        "timestamp": 1638751432
    },
    {
        "content": "<p>If you have <code>FxHashMap&lt;NodeId, ...&gt;</code>, if the NodeId was pre-hashed, you'd use <code>UnHashMap</code> or so, where the hasher is just expecting a single write_u64, IIRC</p>",
        "id": 263800508,
        "sender_full_name": "simulacrum",
        "timestamp": 1638754121
    },
    {
        "content": "<p><a href=\"https://github.com/rust-lang/rust/blob/e2116acae59654bfab2a9729a024f3e2fd6d4b02/compiler/rustc_data_structures/src/unhash.rs#L4\">https://github.com/rust-lang/rust/blob/e2116acae59654bfab2a9729a024f3e2fd6d4b02/compiler/rustc_data_structures/src/unhash.rs#L4</a></p>",
        "id": 263800530,
        "sender_full_name": "simulacrum",
        "timestamp": 1638754161
    },
    {
        "content": "<p>That only works if the type being hashed is a single u64. Most of the types we hash are compound, like a pair of integers, etc.</p>",
        "id": 263801025,
        "sender_full_name": "nnethercote",
        "timestamp": 1638754856
    },
    {
        "content": "<p>There's potentially simpler combine functions, but yeah, I agree that for those cases there's less/no benefit</p>",
        "id": 263801202,
        "sender_full_name": "simulacrum",
        "timestamp": 1638755124
    },
    {
        "content": "<p>No, <code>Unhash</code> <em>requires</em> that you only hash a single <code>u64</code>. Debug assertions enforce this.</p>",
        "id": 263805713,
        "sender_full_name": "nnethercote",
        "timestamp": 1638762089
    },
    {
        "content": "<p>I've been looking today at FxHasher use some more, I'm understanding better why it's so hard to beat.</p>",
        "id": 263805731,
        "sender_full_name": "nnethercote",
        "timestamp": 1638762116
    },
    {
        "content": "<p>One of the common invocations of FxHasher process just two integers, e.g. for a struct with two integer fields <code>a</code> and <code>b</code>. With inlining, FxHasher gives something like this:</p>\n<div class=\"codehilite\"><pre><span></span><code>let hash = FxHasher { hash: 0 };\nself.hash = self.hash.rotate_left(5).bitxor(self.a).wrapping_mul(K);\nself.hash = self.hash.rotate_left(5).bitxor(self.b).wrapping_mul(K);\nself.hash as u64\n</code></pre></div>",
        "id": 263805788,
        "sender_full_name": "nnethercote",
        "timestamp": 1638762160
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 263805797,
        "sender_full_name": "nnethercote",
        "timestamp": 1638762185
    },
    {
        "content": "<p>Single integer cases are even more common. Longer ones are increasingly less common.</p>",
        "id": 263805812,
        "sender_full_name": "nnethercote",
        "timestamp": 1638762209
    },
    {
        "content": "<p>FxHasher is so fast because:</p>\n<ul>\n<li>No setup</li>\n<li>No teardown</li>\n<li>Brutally fast for each integer</li>\n<li>Can be inlined, so no function call costs</li>\n<li>Is just high quality enough</li>\n</ul>",
        "id": 263805872,
        "sender_full_name": "nnethercote",
        "timestamp": 1638762269
    },
    {
        "content": "<p>I tried fiddling with it a bunch, without much luck. E.g. I tried moving the multiply out of each iteration and just to the <code>finish</code>, and there were huge slowdowsn (e.g. 350% was the worst!)</p>",
        "id": 263805911,
        "sender_full_name": "nnethercote",
        "timestamp": 1638762311
    },
    {
        "content": "<p>One thing that does bug me is that if the first integer hashed is 0 (very common, something like 20% of the cases) the <code>hash</code> value isn't changed at all, stays at 0. I tried setting <code>hash</code> to 1 instead to start with, but it made barely any difference (+/- 1.5% at most on a few benchmarks, roughly equal wins and losses)</p>",
        "id": 263806074,
        "sender_full_name": "nnethercote",
        "timestamp": 1638762579
    },
    {
        "content": "<p>I think that would only matter if you had collisions from hashing <code>0,x,..</code> vs. <code>x,..</code> -- but for types of variable size we typically hash the length too, so there will still be a distinguishing factor.</p>",
        "id": 263814515,
        "sender_full_name": "cuviper",
        "timestamp": 1638774289
    },
    {
        "content": "<p>Here's some data on frequencies of hashing sequence: between <code>new</code> and <code>finish</code>, what values are passed to <code>add_to_hash</code>?<br>\n(<code>0</code> = zero, <code>s</code> &lt; 256, <code>m</code> &lt; 2^32, <code>l</code> otherwise):</p>\n<div class=\"codehilite\"><pre><span></span><code>272772788 counts:\n(  1) 60359935 (22.1%, 22.1%): m\n(  2) 41010721 (15.0%, 37.2%): 0 m\n(  3) 32512233 (11.9%, 49.1%): s\n(  4) 14003400 ( 5.1%, 54.2%): l l\n(  5) 12665764 ( 4.6%, 58.9%): s m\n(  6) 12202604 ( 4.5%, 63.3%): s l l\n(  7)  9553654 ( 3.5%, 66.8%):\n(  8)  7824521 ( 2.9%, 69.7%): m 0\n(  9)  7664300 ( 2.8%, 72.5%): s l\n( 10)  7499810 ( 2.7%, 75.3%): 0\n( 11)  7464398 ( 2.7%, 78.0%): s 0\n( 12)  5835356 ( 2.1%, 80.1%): l\n( 13)  5035969 ( 1.8%, 82.0%): s s\n( 14)  3207243 ( 1.2%, 83.2%): m s\n( 15)  2636992 ( 1.0%, 84.1%): 0 l l l\n( 16)  2395809 ( 0.9%, 85.0%): 0 s\n( 17)  2159919 ( 0.8%, 85.8%): 0 s m l 0 0 l\n( 18)  1818917 ( 0.7%, 86.5%): 0 0 m s\n( 19)  1561616 ( 0.6%, 87.0%): s s m\n( 20)  1499057 ( 0.5%, 87.6%): s s s l s\n( 21)  1322186 ( 0.5%, 88.1%): 0 0 m l 0 0 l\n( 22)  1228112 ( 0.5%, 88.5%): s l l l\n( 23)  1184468 ( 0.4%, 89.0%): s 0 s\n( 24)  1053428 ( 0.4%, 89.3%): 0 l s m l 0\n( 25)   975966 ( 0.4%, 89.7%): s s l s\n( 26)   941603 ( 0.3%, 90.0%): s s 0\n( 27)   843387 ( 0.3%, 90.4%): 0 0 s s\n( 28)   804405 ( 0.3%, 90.6%): m 0 s 0\n( 29)   774534 ( 0.3%, 90.9%): 0 l 0 m l 0\n( 30)   764697 ( 0.3%, 91.2%): 0 0\n</code></pre></div>",
        "id": 263819221,
        "sender_full_name": "nnethercote",
        "timestamp": 1638778806
    },
    {
        "content": "<p>The <code>rotate_left</code> does nothing for the first integer in the sequence, because it's just rotating 0, which is a shame.</p>",
        "id": 263819413,
        "sender_full_name": "nnethercote",
        "timestamp": 1638778938
    },
    {
        "content": "<p>But yes, all of the following will hash to zero: empty sequence, [0], [0, 0]</p>",
        "id": 263819443,
        "sender_full_name": "nnethercote",
        "timestamp": 1638778965
    },
    {
        "content": "<p>I tried just removing the <code>rotate_left</code> altogether. Gave small instr count wins of up to 1.5% on quite a few benchmarks, but up to 12% losses on two of the artificial ones, so doesn't seem worthwhile.</p>",
        "id": 263819596,
        "sender_full_name": "nnethercote",
        "timestamp": 1638779060
    },
    {
        "content": "<p>I also tried changing the order from rol/xor/mul to xor/rol/mul, it was a slight loss, up to 3%</p>",
        "id": 263819634,
        "sender_full_name": "nnethercote",
        "timestamp": 1638779091
    },
    {
        "content": "<p>Changing <code>inline</code> to <code>inline(always)</code> on every method except for <code>FxHasher::write()</code> was up to a 1.5% win on <code>keccak</code> and <code>inflate</code>, and no change on anything else. Those two benchmarks stress ObligationForest code heavily, so there must be some hash calls in that code that currently aren't inlined</p>",
        "id": 263819767,
        "sender_full_name": "nnethercote",
        "timestamp": 1638779166
    },
    {
        "content": "<p>add, xor, rol based hashes instead of a mul, xor, rol aren't good enough in quality?</p>",
        "id": 263830530,
        "sender_full_name": "The 8472",
        "timestamp": 1638786291
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263819443\">said</a>:</p>\n<blockquote>\n<p>But yes, all of the following will hash to zero: empty sequence, [0], [0, 0]</p>\n</blockquote>\n<p>not if the sequence type also hashes the length, as <code>[T]</code> does. i.e. <code>[]</code> hashes <code>0</code>, <code>[0]</code> hashes <code>1,0</code>, and <code>[0,0]</code> hashes <code>2,0,0</code></p>",
        "id": 263882448,
        "sender_full_name": "cuviper",
        "timestamp": 1638810571
    },
    {
        "content": "<p><code>[T]</code> does, but does <code>[T; N]</code>?</p>",
        "id": 263882506,
        "sender_full_name": "bjorn3",
        "timestamp": 1638810595
    },
    {
        "content": "<p>yes, arrays just forward to slice hashing, and they <strong>must</strong> because <code>Borrow</code> requires that they agree</p>",
        "id": 263882965,
        "sender_full_name": "cuviper",
        "timestamp": 1638810767
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263805788\">said</a>:</p>\n<blockquote>\n<p>One of the common invocations of FxHasher process just two integers, e.g. for a struct with two integer fields <code>a</code> and <code>b</code>. With inlining, FxHasher gives something like this:</p>\n<p><div class=\"codehilite\"><pre><span></span><code>let hash = FxHasher { hash: 0 };\nself.hash = self.hash.rotate_left(5).bitxor(self.a).wrapping_mul(K);\nself.hash = self.hash.rotate_left(5).bitxor(self.b).wrapping_mul(K);\nself.hash as u64\n</code></pre></div><br>\n</p>\n</blockquote>\n<p>This doesn't look very ILP-friendly.</p>",
        "id": 263885664,
        "sender_full_name": "The 8472",
        "timestamp": 1638811859
    },
    {
        "content": "<p>hmm, what if you moved the <code>mul</code> onto the input alone, then those should be done in parallel -- the dependent instruction chain would only be the faster rotate and xor</p>",
        "id": 263895442,
        "sender_full_name": "cuviper",
        "timestamp": 1638815629
    },
    {
        "content": "<p>it'll probably be weaker, but maybe still good enough?</p>",
        "id": 263895621,
        "sender_full_name": "cuviper",
        "timestamp": 1638815676
    },
    {
        "content": "<p>@cuviper You mean this?</p>\n<div class=\"codehilite\"><pre><span></span><code>self.hash = self.hash.rotate_left(5).bitxor(self.a.wrapping_mul(K));\n</code></pre></div>",
        "id": 263924956,
        "sender_full_name": "nnethercote",
        "timestamp": 1638824963
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"330154\">@The 8472</span> I think the mul is important for spreading the bits out, but I'm happy to try an add/xor/rol hash. Any suggestions?</p>",
        "id": 263925098,
        "sender_full_name": "nnethercote",
        "timestamp": 1638825035
    },
    {
        "content": "<p>I'm thinking about writing a blog post on this topic, calling it \"A brutally effective hash function used in Rust\", and talking about how unreasonably effective <code>FxHasher</code> is in the hope that it angers someone who has forgotten more about hash functions than I'll ever know into telling me how to make it better</p>",
        "id": 263925307,
        "sender_full_name": "nnethercote",
        "timestamp": 1638825140
    },
    {
        "content": "<p>No concrete suggestions, I was just basing this on ARX constructions seems to be \"good enough\" for some ciphers to achieve mixing, but that might be due to many more rounds.</p>",
        "id": 263925310,
        "sender_full_name": "The 8472",
        "timestamp": 1638825144
    },
    {
        "content": "<p>But yeah, it's hard to beat the 3 instructions for a single <code>usize</code>. You have to give up some quality for that. Or maybe replace two of them with a CRC32 instruction.</p>",
        "id": 263927690,
        "sender_full_name": "The 8472",
        "timestamp": 1638826388
    },
    {
        "content": "<p>For more than 1 usize it should be possible to beat it with exploiting parallelism.</p>",
        "id": 263927747,
        "sender_full_name": "The 8472",
        "timestamp": 1638826419
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263924956\">said</a>:</p>\n<blockquote>\n<p>@cuviper You mean this?</p>\n<p><div class=\"codehilite\"><pre><span></span><code>self.hash = self.hash.rotate_left(5).bitxor(self.a.wrapping_mul(K));\n</code></pre></div><br>\n</p>\n</blockquote>\n<p>Yeah that should improve ILP since for each input the mul can be computed independently and only rol/xor would form a dependency chain.</p>",
        "id": 263928145,
        "sender_full_name": "The 8472",
        "timestamp": 1638826576
    },
    {
        "content": "<blockquote>\n<p>Or maybe replace two of them with a CRC32 instruction.</p>\n</blockquote>\n<p>How would that work? I'm imagining this, but it's only one CRC32 instruction per field:</p>\n<div class=\"codehilite\"><pre><span></span><code>let hash = FxHasher { hash: 0 };\nself.hash = _mm_crc32_u64(self.hash, self.a);\nself.hash = _mm_crc32_u64(self.hash, self.b);\nself.hash as u64\n</code></pre></div>",
        "id": 263929716,
        "sender_full_name": "nnethercote",
        "timestamp": 1638827462
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"120989\">@nnethercote</span> That honestly seems worth trying on any hardware that has one-instruction CRC32.</p>",
        "id": 263933009,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638829034
    },
    {
        "content": "<p>x86 and aarch64 both have CRC32 instructions on sufficiently new hardware.</p>",
        "id": 263933061,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638829074
    },
    {
        "content": "<p>I'll try it out shortly, thanks</p>",
        "id": 263933138,
        "sender_full_name": "nnethercote",
        "timestamp": 1638829097
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"384014\">Patrick Walton</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263190303\">said</a>:</p>\n<blockquote>\n<p>By the way, my original thought was to change that function to <code>crc32</code>, which was a 15% improvement in my tests.</p>\n</blockquote>\n<p>^ as a reminder, at least one experiment along these lines <em>did</em> bear fruit (at some point in the past).</p>",
        "id": 263933396,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638829286
    },
    {
        "content": "<blockquote>\n<p>x86 and aarch64 both have CRC32 instructions on sufficiently new hardware.</p>\n</blockquote>\n<p>At least macos could benefit. No/few other targets have it in their baselines and it would take a lot of branches or indirect calls to do this at runtime.</p>",
        "id": 263933722,
        "sender_full_name": "The 8472",
        "timestamp": 1638829468
    },
    {
        "content": "<p>/me wonders how much performance boost we could get by optimizing rustc for a high baseline, and if we could reasonably do that by shipping a second binary (or letting rustup do feature detection, or something).</p>",
        "id": 263935471,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638830625
    },
    {
        "content": "<p>IIRC, very little - someone tried targeting znver2 (which is the perf machine) and it had minimal effect. Of course, if we start actively developing to target this use case, that might change. (e.g. with specialized crc instructions and such)</p>",
        "id": 263935716,
        "sender_full_name": "simulacrum",
        "timestamp": 1638830781
    },
    {
        "content": "<p>On the libs side we could use higher baselines in core, e.g. for faster string validation or wider vectors when implementing compares as SIMD.</p>",
        "id": 263936984,
        "sender_full_name": "The 8472",
        "timestamp": 1638831576
    },
    {
        "content": "<p>So even if user crates don't immediately benefit we could still dogfood simd/intrinsics-in-core if the compiler used a higher baseline by default.</p>",
        "id": 263937196,
        "sender_full_name": "The 8472",
        "timestamp": 1638831672
    },
    {
        "content": "<p>What is the x86-64 baseline instruction set?</p>",
        "id": 263939820,
        "sender_full_name": "nnethercote",
        "timestamp": 1638833478
    },
    {
        "content": "<p>stolen from another thread:</p>\n<blockquote>\n<p>x86-64: CMOV, CMPXCHG8B, FPU, FXSR, MMX, FXSR, SCE, SSE, SSE2<br>\nx86-64-v2: (close to Nehalem) CMPXCHG16B, LAHF-SAHF, POPCNT, SSE3, SSE4.1, SSE4.2, SSSE3<br>\nx86-64-v3: (close to Haswell) AVX, AVX2, BMI1, BMI2, F16C, FMA, LZCNT, MOVBE, XSAVE<br>\nx86-64-v4: AVX512F, AVX512BW, AVX512CD, AVX512DQ, AVX512VL</p>\n</blockquote>",
        "id": 263941019,
        "sender_full_name": "The 8472",
        "timestamp": 1638834429
    },
    {
        "content": "<p>crc32 is part of sse4.2</p>",
        "id": 263941156,
        "sender_full_name": "The 8472",
        "timestamp": 1638834544
    },
    {
        "content": "<p>Thanks! Where are those v2, v3, v4 definitions from -- is it a Rust-specific thing? What can we use within rustc?</p>",
        "id": 263941438,
        "sender_full_name": "nnethercote",
        "timestamp": 1638834788
    },
    {
        "content": "<p>They were defined last year. You can use them as <code>-Ctarget-cpu=x86-64-v2</code> instead of native, icelake, znver2 etc.</p>",
        "id": 263941615,
        "sender_full_name": "The 8472",
        "timestamp": 1638834928
    },
    {
        "content": "<p>They're not rust specific - I think origins in gcc? But have now been included in llvm (and so rustc), as well</p>",
        "id": 263942454,
        "sender_full_name": "simulacrum",
        "timestamp": 1638835505
    },
    {
        "content": "<p>Also part of the sysv abi specs now</p>",
        "id": 263942544,
        "sender_full_name": "The 8472",
        "timestamp": 1638835567
    },
    {
        "content": "<p>They were defined in collaboration with glibc.</p>",
        "id": 263945501,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638838030
    },
    {
        "content": "<p>Partly as a replacement for some of the classic hwcap support glibc had, where it'd search a combinatorial set of feature directories looking for optimized libraries.</p>",
        "id": 263945529,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638838063
    },
    {
        "content": "<p>Running <code>LD_LIBRARY_PATH=/dir-in-ld-library-path strace ./hello</code> produces this:</p>",
        "id": 263945722,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638838206
    },
    {
        "content": "<div class=\"codehilite\" data-code-language=\"Text only\"><pre><span></span><code>openat(AT_FDCWD, \"/dir-in-ld-library-path/tls/haswell/avx512_1/x86_64/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/tls/haswell/avx512_1/x86_64\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/tls/haswell/avx512_1/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/tls/haswell/avx512_1\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/tls/haswell/x86_64/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/tls/haswell/x86_64\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/tls/haswell/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/tls/haswell\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/tls/avx512_1/x86_64/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/tls/avx512_1/x86_64\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/tls/avx512_1/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/tls/avx512_1\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/tls/x86_64/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/tls/x86_64\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/tls/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/tls\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/haswell/avx512_1/x86_64/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/haswell/avx512_1/x86_64\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/haswell/avx512_1/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/haswell/avx512_1\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/haswell/x86_64/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/haswell/x86_64\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/haswell/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/haswell\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/avx512_1/x86_64/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/avx512_1/x86_64\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/avx512_1/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/avx512_1\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/x86_64/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path/x86_64\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\nopenat(AT_FDCWD, \"/dir-in-ld-library-path/libc.so.6\", O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)\nstat(\"/dir-in-ld-library-path\", 0x7ffd41ac8980) = -1 ENOENT (No such file or directory)\n</code></pre></div>",
        "id": 263945744,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638838234
    },
    {
        "content": "<p>Note the combinatorial explosion here: <code>tls</code>, <code>haswell</code>, <code>x86_64</code>, <code>avx512_1</code>, that's just 4, and the dynamic linker made two syscalls for each of the 16 possible combinations.</p>",
        "id": 263945770,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638838283
    },
    {
        "content": "<p>It does that for <em>each</em> library.</p>",
        "id": 263945777,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638838292
    },
    {
        "content": "<p>The new hwcaps mechanism and the microarchitectural feature levels (v2, v3, v4) are an effort to turn that linear.</p>",
        "id": 263945799,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638838315
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263941438\">said</a>:</p>\n<blockquote>\n<p>Thanks! Where are those v2, v3, v4 definitions from -- is it a Rust-specific thing? What can we use within rustc?</p>\n</blockquote>\n<p>Within rustc, unfortunately we can't assume any more than the <code>x86-64</code> baseline on general x86-64 platforms.</p>",
        "id": 263945873,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638838363
    },
    {
        "content": "<p>I guess it'd need a new <code>stable-x86_64_v3-pc-windows-msvc</code> toolchain and such?</p>",
        "id": 263946530,
        "sender_full_name": "scottmcm",
        "timestamp": 1638838896
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263945873\">said</a>:</p>\n<blockquote>\n<p>Within rustc, unfortunately we can't assume any more than the <code>x86-64</code> baseline on general x86-64 platforms.</p>\n</blockquote>\n<p>Well, I have some good news then: the <code>_mm_crc32_u64</code> results were bad</p>",
        "id": 263949202,
        "sender_full_name": "nnethercote",
        "timestamp": 1638841413
    },
    {
        "content": "<p>Instruction counts were up to 20% higher, cycles and wall-times were similar</p>",
        "id": 263949284,
        "sender_full_name": "nnethercote",
        "timestamp": 1638841478
    },
    {
        "content": "<p>This is at least part of the story:</p>\n<div class=\"codehilite\"><pre><span></span><code>        .           #[inline]\n        .           #[target_feature(enable = &quot;sse4.2&quot;)]\n        .           #[cfg_attr(test, assert_instr(crc32))]\n        .           #[stable(feature = &quot;simd_x86&quot;, since = &quot;1.27.0&quot;)]\n1,351,933 ( 0.68%)  pub unsafe fn _mm_crc32_u64(crc: u64, v: u64) -&gt; u64 {\n1,351,933 ( 0.68%)      crc32_64_64(crc, v)\n1,351,933 ( 0.68%)  }\n</code></pre></div>",
        "id": 263949301,
        "sender_full_name": "nnethercote",
        "timestamp": 1638841505
    },
    {
        "content": "<p>That's marked with <code>inline</code> but it's not being inlined</p>",
        "id": 263949310,
        "sender_full_name": "nnethercote",
        "timestamp": 1638841521
    },
    {
        "content": "<p>Also, I don't know what's within <code>crc32_64_64</code>.</p>",
        "id": 263949352,
        "sender_full_name": "nnethercote",
        "timestamp": 1638841564
    },
    {
        "content": "<p>And there seems to be extra instructions happening around all the places where hashing is being triggered, presumably due to codegen effects</p>",
        "id": 263949395,
        "sender_full_name": "nnethercote",
        "timestamp": 1638841595
    },
    {
        "content": "<p>I'm increasingly in awe of <code>FxHasher</code>, it's like a machete; crude, but unbeatable for certain tasks</p>",
        "id": 263949430,
        "sender_full_name": "nnethercote",
        "timestamp": 1638841629
    },
    {
        "content": "<p>yeah, inlining is problematic across target_feature boundaries iirc</p>",
        "id": 263949775,
        "sender_full_name": "simulacrum",
        "timestamp": 1638842008
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263924956\">said</a>:</p>\n<blockquote>\n<p>@cuviper You mean this?</p>\n<p><div class=\"codehilite\"><pre><span></span><code>self.hash = self.hash.rotate_left(5).bitxor(self.a.wrapping_mul(K));\n</code></pre></div><br>\n</p>\n</blockquote>\n<p>I just tried that. Up to 5% instruction count regressions.</p>",
        "id": 263951102,
        "sender_full_name": "nnethercote",
        "timestamp": 1638843482
    },
    {
        "content": "<p>The cachegrind diff is a bit hard to interpret. I would have thought the hash function itself is unchanged in terms of how many instructions it runs in. Perhaps the quality is worse so there are more collisions</p>",
        "id": 263951159,
        "sender_full_name": "nnethercote",
        "timestamp": 1638843538
    },
    {
        "content": "<p>Too bad, oh well</p>",
        "id": 263951556,
        "sender_full_name": "cuviper",
        "timestamp": 1638844067
    },
    {
        "content": "<p>Thanks for trying it</p>",
        "id": 263951611,
        "sender_full_name": "cuviper",
        "timestamp": 1638844098
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"120989\">@nnethercote</span> Very strange that that wasn't inlined; that would completely break performance.</p>",
        "id": 263958610,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638853003
    },
    {
        "content": "<p>The whole point of instruction intrinsics is to turn into a single instruction.</p>",
        "id": 263958624,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638853026
    },
    {
        "content": "<p>Doesn't guarantee that the function containing the intrinsic is inlined, though?</p>",
        "id": 263958935,
        "sender_full_name": "nnethercote",
        "timestamp": 1638853301
    },
    {
        "content": "<p>I could try putting <code>inline(always)</code> on <code>_mm_crc32_u64</code>, see if it helps</p>",
        "id": 263958991,
        "sender_full_name": "nnethercote",
        "timestamp": 1638853337
    },
    {
        "content": "<p>The design of #[target_feature] means simd instructions cannot be inline(always), I think. Usually they... should get inlined unless you have a mismatch of enabled target features between caller and callee though (probably the case here?), but this has historically been very annoying to work through.</p>",
        "id": 263961819,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1638856467
    },
    {
        "content": "<p>Indeed: <code>error: cannot use '#[inline(always)]' with '#[target_feature]'</code></p>",
        "id": 263969253,
        "sender_full_name": "nnethercote",
        "timestamp": 1638864581
    },
    {
        "content": "<p>You'd have to build the compiler with <code>RUSTFLAGS=-Ctarget-feature=+sse4.2</code> and replace <code>#[target_feature(enable = \"sse4.2\")]</code> with <code>#[cfg(target-feature = \"sse4.2\")]</code> and have the fxhash fallback as <code>#[cfg(not(target-feature = \"sse4.2\"))]</code> then there shouldn't be an inlining barrier. But then you also need a sse4.2 without crc32 hashing as benchmark baseline.</p>",
        "id": 263981897,
        "sender_full_name": "The 8472",
        "timestamp": 1638872881
    },
    {
        "content": "<p><code>RUSTFLAGS=-Ctarget-feature=+sse4.2</code> should be enough to allow inlining, shouldn't it?</p>",
        "id": 263983167,
        "sender_full_name": "Hans Kratz",
        "timestamp": 1638873706
    },
    {
        "content": "<p>Yes.</p>",
        "id": 263988511,
        "sender_full_name": "nagisa",
        "timestamp": 1638876939
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/263925307\">said</a>:</p>\n<blockquote>\n<p>I'm thinking about writing a blog post on this topic, calling it \"A brutally effective hash function used in Rust\", and talking about how unreasonably effective <code>FxHasher</code> is in the hope that it angers someone who has forgotten more about hash functions than I'll ever know into telling me how to make it better</p>\n</blockquote>\n<p>I have done this. The post is up on my blog but hasn't been publicized yet. If anyone wants to give feedback I'd be happy to hear it before I put it on blast later today. Thanks!  <a href=\"https://nnethercote.github.io/2021/12/08/a-brutally-effective-hash-function-in-rust.html\">Link</a></p>",
        "id": 264083956,
        "sender_full_name": "nnethercote",
        "timestamp": 1638916682
    },
    {
        "content": "<blockquote>\n<p>I like the optimism of that #[inline] attribute!</p>\n</blockquote>\n<p><span aria-label=\"joy\" class=\"emoji emoji-1f602\" role=\"img\" title=\"joy\">:joy:</span></p>",
        "id": 264086001,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638917927
    },
    {
        "content": "<p>looks good to me :)</p>",
        "id": 264086267,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638918055
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"120989\">@nnethercote</span> thank you for including the origin of the <code>0x517cc1b727220a95</code> constant.</p>",
        "id": 264086369,
        "sender_full_name": "pnkfelix",
        "timestamp": 1638918114
    },
    {
        "content": "<p>It should really be a comment in the code <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 264086442,
        "sender_full_name": "nnethercote",
        "timestamp": 1638918130
    },
    {
        "content": "<p>My memory was that it was 1/e, I was surprised to find it was 1/pi</p>",
        "id": 264086551,
        "sender_full_name": "nnethercote",
        "timestamp": 1638918189
    },
    {
        "content": "<p>I think the golden ratio wasn't used here because it flukily ends up being a binary number that ends in like 10 zeroes</p>",
        "id": 264086593,
        "sender_full_name": "nnethercote",
        "timestamp": 1638918212
    },
    {
        "content": "<p>have you tried 1/e? :P</p>",
        "id": 264086677,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638918246
    },
    {
        "content": "<blockquote>\n<p>Different multiplication constants: sometimes negligible differences, sometimes terrible results.</p>\n</blockquote>\n<p>(this suggests probably yes)</p>",
        "id": 264086728,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1638918272
    },
    {
        "content": "<p>I tried the 32-bit constant, that gave terrible results</p>",
        "id": 264086785,
        "sender_full_name": "nnethercote",
        "timestamp": 1638918316
    },
    {
        "content": "<p>I think any 64-bit irrational constant would probably give similar results</p>",
        "id": 264086804,
        "sender_full_name": "nnethercote",
        "timestamp": 1638918333
    },
    {
        "content": "<p>Though I'm secretly hoping some hashing genius will say \"use this K instead\" and it's an improvement <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 264086828,
        "sender_full_name": "nnethercote",
        "timestamp": 1638918355
    },
    {
        "content": "<p>1/pi sounds like it was picked as a \"nothing up my sleeve\" number rather than based on any mathematical principle.</p>",
        "id": 264087507,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1638918737
    },
    {
        "content": "<p>With enough computational power one could find another viable constant using brute-force.</p>",
        "id": 264087654,
        "sender_full_name": "mati865",
        "timestamp": 1638918838
    },
    {
        "content": "<p>With enough computational power we could have the compiler written by beam search over all possible source code only given unit tests <span aria-label=\"monkey\" class=\"emoji emoji-1f412\" role=\"img\" title=\"monkey\">:monkey:</span><span aria-label=\"keyboard\" class=\"emoji emoji-2328\" role=\"img\" title=\"keyboard\">:keyboard:</span>️</p>",
        "id": 264087841,
        "sender_full_name": "The 8472",
        "timestamp": 1638918953
    },
    {
        "content": "<p>The firefox code comments give some explanation of the constant choice</p>",
        "id": 264088416,
        "sender_full_name": "nnethercote",
        "timestamp": 1638919278
    },
    {
        "content": "<p>It claims any constant will suffice if it is (a) odd, and (b) has a reasonable mix of 1s and 0s</p>",
        "id": 264088545,
        "sender_full_name": "nnethercote",
        "timestamp": 1638919341
    },
    {
        "content": "<p>Ok, blog post is now publicized</p>",
        "id": 264097091,
        "sender_full_name": "nnethercote",
        "timestamp": 1638924541
    },
    {
        "content": "<p>Let the wailing and gnashing of teeth begin</p>",
        "id": 264097105,
        "sender_full_name": "nnethercote",
        "timestamp": 1638924561
    },
    {
        "content": "<p>I'm a little surprised that the constant is not prime, but I guess it only needs to be odd, relatively prime to the modulus 2^64</p>",
        "id": 264100158,
        "sender_full_name": "cuviper",
        "timestamp": 1638927325
    },
    {
        "content": "<p>I'm happy to try other constants <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 264101538,
        "sender_full_name": "nnethercote",
        "timestamp": 1638928719
    },
    {
        "content": "<p>maybe a \"good\" PRNG multiplier? e.g. <a href=\"https://arxiv.org/abs/2001.05304\">https://arxiv.org/abs/2001.05304</a> (page 18, tables 4-7)</p>",
        "id": 264104952,
        "sender_full_name": "cuviper",
        "timestamp": 1638931857
    },
    {
        "content": "<p>I think it probably doesn't matter too much, but that would be a little more principled, I guess</p>",
        "id": 264104981,
        "sender_full_name": "cuviper",
        "timestamp": 1638931900
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/264086804\">said</a>:</p>\n<blockquote>\n<p>I think any 64-bit irrational constant would probably give similar results</p>\n</blockquote>\n<p>Part of my wants to say it should be transcendental, but the rest of me knows that's not actually important.</p>\n<p>That said, when it's doing <code>.wrapping_mul(K)</code>, it might still be a good idea to not pick <code>K</code> that's a root of an integer.</p>",
        "id": 264105982,
        "sender_full_name": "scottmcm",
        "timestamp": 1638932838
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"138448\">cuviper</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/264104952\">said</a>:</p>\n<blockquote>\n<p>maybe a \"good\" PRNG multiplier? e.g. <a href=\"https://arxiv.org/abs/2001.05304\">https://arxiv.org/abs/2001.05304</a> (page 18, tables 4-7)</p>\n</blockquote>\n<p>I tried two different ones, negligible changes</p>",
        "id": 264117675,
        "sender_full_name": "nnethercote",
        "timestamp": 1638945760
    },
    {
        "content": "<p>Thanks for the suggestion!</p>",
        "id": 264117685,
        "sender_full_name": "nnethercote",
        "timestamp": 1638945777
    },
    {
        "content": "<p>For two pre-hashed u64s you should be able to just xor them.</p>",
        "id": 264249646,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639017659
    },
    {
        "content": "<p>Pre-hashed crate ID and pre-hashed node ID.</p>",
        "id": 264249657,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639017676
    },
    {
        "content": "<p>I don't think crate IDs need to be sequential unless we're putting them in a smallintmap somewhere (and there are ways to work around this if they are, I still can't imagine that hashing them over and over millions of times during compilation is the fastest thing)</p>",
        "id": 264249737,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639017742
    },
    {
        "content": "<p>I also idly wonder whether we could get away with, say, 16-bit crate IDs and 48-bit node IDs. Will anyone have 65,536 crates, or 281,474,976,710,656 AST nodes, in a single rustc invocation?</p>",
        "id": 264249853,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639017852
    },
    {
        "content": "<p>There must be zillions of def IDs stored everywhere during compilation and shaving 8 bytes off each one could add up, in addition to cutting hash time down by half</p>",
        "id": 264250021,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639018033
    },
    {
        "content": "<p>How do you accomplish 48-bit node IDs given that there's no <code>u48</code>? Do you have an array of <code>u8</code>s?</p>",
        "id": 264251102,
        "sender_full_name": "Noah Lev",
        "timestamp": 1639019072
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"384014\">@Patrick Walton</span> I can imagine getting away with, say, 20-bit crate IDs and 44-bit node IDs.</p>",
        "id": 264252997,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639021240
    },
    {
        "content": "<p>64k crates doesn't seem <em>utterly</em> ridiculous, if you're constructing crates.</p>",
        "id": 264253005,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639021257
    },
    {
        "content": "<p>Are we talking about <a href=\"https://github.com/rust-lang/rust/blob/master/compiler/rustc_span/src/def_id.rs#L209-L212\">DefId</a>? Because it's currently 32-bits for the crate and 32-bits for the <code>DefIndex</code></p>",
        "id": 264253049,
        "sender_full_name": "nnethercote",
        "timestamp": 1639021339
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/264253005\">said</a>:</p>\n<blockquote>\n<p>64k crates doesn't seem <em>utterly</em> ridiculous, if you're constructing crates.</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> what do you mean by constructing crates?</p>\n<p>for comparison, there are about 30k crates on <a href=\"http://crates.io\">crates.io</a> right now; putting them all in a single dependency graph seems kind of absurd.</p>",
        "id": 264254846,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1639023222
    },
    {
        "content": "<p>(at that point rustc would probably run out of memory just loading the metadata)</p>",
        "id": 264254894,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1639023252
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"232545\">@Joshua Nelson</span> Code generation. It's not hard for me to imagine generating a pile of utility crates as inputs to something. I'm not talking about real unique crates downloaded from <a href=\"http://crates.io\">crates.io</a>; I'm imagining a scenario like <code>codegen19581::generated_function</code>.</p>",
        "id": 264261419,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639030591
    },
    {
        "content": "<p>I've seen weird enough build systems out there that the idea of generating a crate (or a couple of crates) for every unique source file in a project would not be <em>shocking</em>.</p>",
        "id": 264261438,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639030629
    },
    {
        "content": "<p>And I've seen projects with tens of thousands of source files.</p>",
        "id": 264261443,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639030648
    },
    {
        "content": "<p>I could even imagine weird scenarios like \"make a library crate for every function\".</p>",
        "id": 264261453,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639030671
    },
    {
        "content": "<p>In short, I've seen weird enough stuff that the idea of hitting 64k crates didn't seem <em>out of the realm of future possibility</em>.</p>",
        "id": 264261495,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639030694
    },
    {
        "content": "<p>Well 20 bits will fit more than 640k, which ought to be enough for anyone.</p>",
        "id": 264266367,
        "sender_full_name": "cuviper",
        "timestamp": 1639036244
    },
    {
        "content": "<p>We shouldn't overfocus on <code>DefIndex</code>, though. I have some data, not the highest quality, but it indicates that other types like <code>GenericArg</code>, <code>TyKind</code>, and <code>RegionKind</code> are hashed as often as <code>DefIndex</code>, if not more often.</p>",
        "id": 264266855,
        "sender_full_name": "nnethercote",
        "timestamp": 1639036736
    },
    {
        "content": "<p>crate ids are used as an index into an IndexVec (or at least an equivalent to this) used for storing crate metadata so they need to be sequential.</p>",
        "id": 264278330,
        "sender_full_name": "bjorn3",
        "timestamp": 1639043952
    },
    {
        "content": "<p>a significant part of the hashing costs come from rehashing the interning maps. if we could avoid resizes somehow that'd also help</p>",
        "id": 264279638,
        "sender_full_name": "The 8472",
        "timestamp": 1639044644
    },
    {
        "content": "<p>Perhaps we could store some statistics about the sizes of those interning maps in the incremental cache and use that data to appropriately size the maps in subsequent compilation sessions?</p>",
        "id": 264332815,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1639069774
    },
    {
        "content": "<p>So it turns out that crate IDs and node IDs are all 32-bit anyway. I'm testing a simple change that hashes them in one go instead of individually <span class=\"user-mention\" data-user-id=\"120989\">@nnethercote</span></p>",
        "id": 264337291,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639071491
    },
    {
        "content": "<p>Note that FxHash reduces to just a single multiply (i.e. a Lehmer RNG) if you are hashing just a single 64-bit value.</p>",
        "id": 264337492,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639071592
    },
    {
        "content": "<p>hello did someone say SIMD</p>",
        "id": 264339790,
        "sender_full_name": "Jubilee",
        "timestamp": 1639072506
    },
    {
        "content": "<p>I don't think SIMD will help here. <code>DefId</code> is only 64bit.</p>",
        "id": 264339923,
        "sender_full_name": "bjorn3",
        "timestamp": 1639072555
    },
    {
        "content": "<p><em>checks</em> Ah we were just talking about feature levels.</p>",
        "id": 264340057,
        "sender_full_name": "Jubilee",
        "timestamp": 1639072596
    },
    {
        "content": "<p>I think hashing DefId in one go (still rebuilding the compiler to test) will probably get us most of the way there, because it shrinks mul+ror+xor+mul into just mul.</p>",
        "id": 264340210,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639072659
    },
    {
        "content": "<p>(since xor(ror(0, x), y) is just y.)</p>",
        "id": 264340337,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639072698
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"281757\">Jubilee</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/264340057\">said</a>:</p>\n<blockquote>\n<p><em>checks</em> Ah we were just talking about feature levels.</p>\n</blockquote>\n<p>that was for crc32</p>",
        "id": 264340724,
        "sender_full_name": "bjorn3",
        "timestamp": 1639072835
    },
    {
        "content": "<p>A single mul should be unbeatable except by unhash</p>",
        "id": 264340889,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639072904
    },
    {
        "content": "<p>hashing defids as a single u64 is being tried, with some success, in <a href=\"https://github.com/rust-lang/rust/pull/91660\">https://github.com/rust-lang/rust/pull/91660</a></p>",
        "id": 264345570,
        "sender_full_name": "lqd",
        "timestamp": 1639074621
    },
    {
        "content": "<p>oh, OK, beat me to it</p>",
        "id": 264346420,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639074943
    },
    {
        "content": "<p><code>TyKind</code> looks nasty to hash. Might be good to pre-hash that.</p>",
        "id": 264348918,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639075958
    },
    {
        "content": "<p>there are also other fun things being hashed IIRC, like big strings -- which is not fx's forte but doesn't seem terrible since it's pretty rare in the following case: I seem to recall the coercions benchmark (which is a 2MB source file) hashing like a million bytes array ^^</p>",
        "id": 264349963,
        "sender_full_name": "lqd",
        "timestamp": 1639076408
    },
    {
        "content": "<p>oh yeah I've been meaning to look at <a href=\"https://github.com/rust-lang/rust/issues/81124\">https://github.com/rust-lang/rust/issues/81124</a> at some point</p>",
        "id": 264350160,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1639076480
    },
    {
        "content": "<p>(more discussion around <a href=\"https://github.com/rust-lang/rust/issues/81188#issuecomment-763532889\">https://github.com/rust-lang/rust/issues/81188#issuecomment-763532889</a>)</p>",
        "id": 264350199,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1639076499
    },
    {
        "content": "<p>it will be good to check again indeed, e.g. 81124 seemed related to borrowck, and (IIRC) mark has a couple PRs helping the scalability there (<del>but maybe not RSS per se</del> <a href=\"https://github.com/rust-lang/rust/pull/90637\">https://github.com/rust-lang/rust/pull/90637</a> does help with RSS in at least one case similar to that issue)</p>",
        "id": 264350649,
        "sender_full_name": "lqd",
        "timestamp": 1639076697
    },
    {
        "content": "<p>Combining the two u32 fields in <code>DefIndex</code> exposed <code>FxHasher</code>'s weakness with upper bits. If the <code>CrateNum</code> was in the upper bits, that was fine because it's a low-entropy value. But if the <code>DefIndex</code> was in the upper bits the increase in collisions was catastrophic. Normally this weakness isn't exposed because, in rustc, <code>FxHasher</code>is mostly hashing u32 or smaller integers (which have zero entropy in the upper bits of a usize, on 64-bit platforms at least) or pointers (which have not much entropy in the upper bits).</p>\n<p>The <a href=\"https://github.com/tkaitchuck/aHash/blob/e77cab8c1e15bfc9f54dfd28bd8820c2a7bb27c4/src/fallback_hash.rs#L97-L99\"><code>update</code></a> function in ahash does a clever folded multiply that avoids this problem while remaining competitive in raw speed with <code>FxHasher</code>. I'll probably update my blog post to mention this, and I'm considering switching <code>FxHasher</code> to using it.</p>",
        "id": 264356327,
        "sender_full_name": "nnethercote",
        "timestamp": 1639079298
    },
    {
        "content": "<p>zoxc also had a change that seemed to perform better in rustc <a href=\"https://github.com/rust-lang/rustc-hash/pull/18\">https://github.com/rust-lang/rustc-hash/pull/18</a> (but also mentions ahash's fallback)</p>",
        "id": 264356675,
        "sender_full_name": "lqd",
        "timestamp": 1639079443
    },
    {
        "content": "<p>Oh, taking advantage of the x64 multiply producing the high word too?  That's a nice touch.</p>",
        "id": 264356932,
        "sender_full_name": "scottmcm",
        "timestamp": 1639079552
    },
    {
        "content": "<p>If I were to change the hash function to use the folded multiply, I guess it would make sense to make a new crate? Because <code>FxHasher</code> is a misnomer if it's not the hash function from Firefox. Maybe <code>FmHasher</code> for \"folded multiply hasher\".</p>",
        "id": 264379137,
        "sender_full_name": "nnethercote",
        "timestamp": 1639090280
    },
    {
        "content": "<p>I don't know how to go about getting a new repo created under <code>rust-lang</code>, though.</p>",
        "id": 264379161,
        "sender_full_name": "nnethercote",
        "timestamp": 1639090304
    },
    {
        "content": "<p>the crate is not \"fx\" though, just make a breaking change with new items :)</p>",
        "id": 264379308,
        "sender_full_name": "cuviper",
        "timestamp": 1639090410
    },
    {
        "content": "<p>Oh, so have both <code>FxHasher</code> and <code>FmHasher</code> in <code>rustc-hash</code>? That runs the risk of people still using <code>FxHasher</code> when they should use <code>FmHasher</code>, but I guess we already have a lint about using the default hashmaps</p>",
        "id": 264379504,
        "sender_full_name": "nnethercote",
        "timestamp": 1639090539
    },
    {
        "content": "<p>if you want to keep both, sure, else move to rustc-hash v2 with <code>RustcHasher</code> without any implications</p>",
        "id": 264379627,
        "sender_full_name": "cuviper",
        "timestamp": 1639090607
    },
    {
        "content": "<p>Sure, but in v2 would the name <code>FxHasher</code> still be used?</p>",
        "id": 264381466,
        "sender_full_name": "nnethercote",
        "timestamp": 1639091897
    },
    {
        "content": "<p>probably not</p>",
        "id": 264381983,
        "sender_full_name": "cuviper",
        "timestamp": 1639092311
    },
    {
        "content": "<p>crate <code>fxhash</code> also exists for that</p>",
        "id": 264382002,
        "sender_full_name": "cuviper",
        "timestamp": 1639092321
    },
    {
        "content": "<p>(open bike shed) <code>RustcHasher</code>, <code>RsHasher</code>, <code>RHasher</code></p>",
        "id": 264382137,
        "sender_full_name": "cuviper",
        "timestamp": 1639092412
    },
    {
        "content": "<p><code>Rustc</code> kind of implies it's only for the compiler (like <code>RustcSerialize</code> or whatever it's called now). SimpleFastHasher (SfHasher) or something might be better :)</p>",
        "id": 264382866,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639092907
    },
    {
        "content": "<p>Or TinyHasher</p>",
        "id": 264382894,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639092927
    },
    {
        "content": "<p>Since you can kind of see this as an exercise in optimizing for code size for small keys.</p>",
        "id": 264382939,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639092957
    },
    {
        "content": "<p>hashers are not that big, we could also move this into <code>rustc_data_structures</code> and make it really just the compiler's own toy</p>",
        "id": 264383154,
        "sender_full_name": "cuviper",
        "timestamp": 1639093083
    },
    {
        "content": "<p>True, but I kind of want to use this for lots of my projects :)</p>",
        "id": 264384114,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639093758
    },
    {
        "content": "<p>aside, as far as features go we have certainly discussed shipping copies of rustc or std optimized for x86 feature levels in the past as possible new targets or something.</p>",
        "id": 264394873,
        "sender_full_name": "Jubilee",
        "timestamp": 1639102050
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"384014\">@Patrick Walton</span> I was just told about <a href=\"https://crates.io/crates/zwohash\">https://crates.io/crates/zwohash</a>, which may be of interest to you</p>",
        "id": 264398136,
        "sender_full_name": "nnethercote",
        "timestamp": 1639105901
    },
    {
        "content": "<p>Interesting, I'm worried about the extra mixing step though.</p>",
        "id": 264398211,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639106018
    },
    {
        "content": "<p>I'm more curious to try unhash now that we have 64 bit single-word def ids.</p>",
        "id": 264398262,
        "sender_full_name": "Patrick Walton",
        "timestamp": 1639106050
    },
    {
        "content": "<p>There are a couple of Index</p>",
        "id": 264398278,
        "sender_full_name": "nnethercote",
        "timestamp": 1639106090
    },
    {
        "content": "<p>For unhash, you might want reverse bits on the upper part to get interesting stuff in the 7 MSBs.</p>",
        "id": 264398737,
        "sender_full_name": "cuviper",
        "timestamp": 1639106696
    },
    {
        "content": "<p>Also, hashbrown truncates to <code>usize</code>.</p>",
        "id": 264398756,
        "sender_full_name": "cuviper",
        "timestamp": 1639106736
    },
    {
        "content": "<p>AFAIK, the author of zwohash already evaluated the use in rustc and found that FxHash performs better, as the inputs that zwohash is optimized for are uncommon in rustc</p>",
        "id": 264411704,
        "sender_full_name": "NeoRaider",
        "timestamp": 1639122154
    },
    {
        "content": "<p>I updated <a href=\"https://nnethercote.github.io/2021/12/08/a-brutally-effective-hash-function-in-rust.html\">https://nnethercote.github.io/2021/12/08/a-brutally-effective-hash-function-in-rust.html</a> with some extra details</p>",
        "id": 264413794,
        "sender_full_name": "nnethercote",
        "timestamp": 1639123815
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"294290\">NeoRaider</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/264411704\">said</a>:</p>\n<blockquote>\n<p>AFAIK, the author of zwohash already evaluated the use in rustc and found that FxHash performs better, as the inputs that zwohash is optimized for are uncommon in rustc</p>\n</blockquote>\n<p>I did, see the <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/Testing.20another.20alternative.20to.20FxHash\">\"Testing another alternative to FxHash\"</a> topic and <a href=\"https://github.com/rust-lang/rust/pull/75679#issuecomment-675897456\">the corresponding perf run</a>. That was over a year ago though and I didn't really look into what's different between rustc's usage patterns where it doesn't seem to help and those of my code, where it is faster.</p>",
        "id": 264633444,
        "sender_full_name": "Jannis Harder",
        "timestamp": 1639329723
    },
    {
        "content": "<p>I wonder if we can reduce the assembly generated for hashing <code>TyKind</code>. While that likely will have little direct effect, it may reduce cache usage on the hot path.</p>",
        "id": 264767246,
        "sender_full_name": "llogiq",
        "timestamp": 1639428191
    },
    {
        "content": "<p>I just looked at FxHasher again, thinking about changing it to use the clever folded multiply I mentioned in the update on my <a href=\"https://nnethercote.github.io/2021/12/08/a-brutally-effective-hash-function-in-rust.html\">blog post</a></p>",
        "id": 265253409,
        "sender_full_name": "nnethercote",
        "timestamp": 1639715886
    },
    {
        "content": "<p>The core update function would be changed from rol/xor/mul to xor/mul/xor, so it seems like it should be just as fast, but give higher quality results</p>",
        "id": 265253413,
        "sender_full_name": "nnethercote",
        "timestamp": 1639715916
    },
    {
        "content": "<p>I tried doing this before I wrote the post and found it slightly increased instruction counts</p>",
        "id": 265253421,
        "sender_full_name": "nnethercote",
        "timestamp": 1639715936
    },
    {
        "content": "<p>Now I worked out why, with some <a href=\"https://rust.godbolt.org/z/58vGdzEhP\">help from godbolt</a></p>",
        "id": 265253433,
        "sender_full_name": "nnethercote",
        "timestamp": 1639715982
    },
    {
        "content": "<p>Imagine a type with two fields. The FxHasher code, once inlined, boils down to this:</p>\n<div class=\"codehilite\"><pre><span></span><code>    hash = 0\n    --\n    rol hash          // eval&#39;d at compile time\n    xor a into hash   // eval&#39;d at compile time\n    mul hash\n    ---\n    rol hash\n    xor b into hash\n    mul hash\n</code></pre></div>",
        "id": 265253486,
        "sender_full_name": "nnethercote",
        "timestamp": 1639716014
    },
    {
        "content": "<p>The folded multiply version boils down to this:</p>\n<div class=\"codehilite\"><pre><span></span><code>    hash = 0\n    --\n    xor a into hash  // eval&#39;d at compile time\n    mul hash\n    xor for fold\n    --\n    xor b into hash\n    mul hash\n    xor for fold\n</code></pre></div>",
        "id": 265253492,
        "sender_full_name": "nnethercote",
        "timestamp": 1639716034
    },
    {
        "content": "<p>That one extra instruction being compile time evaluated gives FxHasher the instruction count advantage</p>",
        "id": 265253497,
        "sender_full_name": "nnethercote",
        "timestamp": 1639716064
    },
    {
        "content": "<p>An even bigger difference if you're hashing a type with a single field, where FxHasher is basically just a single multiply</p>",
        "id": 265253562,
        "sender_full_name": "nnethercote",
        "timestamp": 1639716148
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/265253413\">said</a>:</p>\n<blockquote>\n<p>The core update function would be changed from rol/xor/mul to xor/mul/xor, so it seems like it should be just as fast, but give higher quality results</p>\n</blockquote>\n<p>In theory the high quality results would correspond to a better hash distribution, right? I would have hoped that better hash distribution would itself lower instruction counts enough to compensate for the effect you describe, but I guess it does not.</p>",
        "id": 265296232,
        "sender_full_name": "pnkfelix",
        "timestamp": 1639748374
    },
    {
        "content": "<p>(or maybe removing the left-rotate (rol) has other effects on the distribution that need to be accounted for in my naive analysis…)</p>",
        "id": 265297583,
        "sender_full_name": "pnkfelix",
        "timestamp": 1639749187
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"120989\">@nnethercote</span> I wonder if we could change xor into an add, and then do an FMA intrinsic?</p>",
        "id": 265341150,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639766460
    },
    {
        "content": "<p>Something similar was already tried with crc32c, which was tried but ran into issues with inlining barriers around target features.</p>",
        "id": 265341310,
        "sender_full_name": "The 8472",
        "timestamp": 1639766533
    },
    {
        "content": "<p>Ah, right, that'd only work if std was built with the requisite target features to guarantee those instructions.</p>",
        "id": 265344078,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639767803
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/265253413\">said</a>:</p>\n<blockquote>\n<p>The core update function would be changed from rol/xor/mul to xor/mul/xor, so it seems like it should be just as fast, but give higher quality results</p>\n</blockquote>\n<p>I guess what you're seeing is that <code>FxHasher</code> is already Good Enough at avoiding collisions for our workload</p>",
        "id": 265351337,
        "sender_full_name": "cuviper",
        "timestamp": 1639770463
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/265341150\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"120989\">nnethercote</span> I wonder if we could change xor into an add, and then do an FMA intrinsic?</p>\n</blockquote>\n<p>you want to FMA <strong>integers</strong>?</p>",
        "id": 265351498,
        "sender_full_name": "Jubilee",
        "timestamp": 1639770555
    },
    {
        "content": "<p>Like no one invested in that circuitry for integers until very recently, when Intel's engineers were passing around ideas after Having A Few.</p>",
        "id": 265351673,
        "sender_full_name": "Jubilee",
        "timestamp": 1639770629
    },
    {
        "content": "<p>Hrm. For some reason I thought there was an intrinsic to do that for integers, but it would seem not.</p>",
        "id": 265354002,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639771657
    },
    {
        "content": "<p>Only for AVX512.</p>",
        "id": 265354270,
        "sender_full_name": "Jubilee",
        "timestamp": 1639771708
    },
    {
        "content": "<p>Nevermind then.</p>",
        "id": 265354717,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639771947
    },
    {
        "content": "<blockquote>\n<p>I guess what you're seeing is that FxHasher is already Good Enough at avoiding collisions for our workload</p>\n</blockquote>\n<p>Well, the attempt of cramming 2x u32 into an u64 for hashing showed that that is fragile.</p>",
        "id": 265354721,
        "sender_full_name": "The 8472",
        "timestamp": 1639771950
    },
    {
        "content": "<p>can we detect collision rate somehow?</p>",
        "id": 265354922,
        "sender_full_name": "The 8472",
        "timestamp": 1639772063
    },
    {
        "content": "<p>With a chaining hash table, we could look at the distribution of chain lengths. With a non-chaining hash table like hashbrown, I think you'd have to look at \"number of probes required per item in the table\" or similar.</p>",
        "id": 265355558,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639772486
    },
    {
        "content": "<p>Which seems like an easy stat to collect at the end of a hash table's lifespan.</p>",
        "id": 265355575,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1639772499
    },
    {
        "content": "<p>or the dumb way, calculate hashes for all items and count duplicates (modulo whatever masking hashbrown does)</p>",
        "id": 265356785,
        "sender_full_name": "The 8472",
        "timestamp": 1639773187
    },
    {
        "content": "<blockquote>\n<p>I guess what you're seeing is that FxHasher is already Good Enough at avoiding collisions for our workload</p>\n</blockquote>\n<p>Yes, on 64-bit platforms at least. Because so many inputs have little entropy (pointers) or no entropy (32-bit and smaller integers) in the upper usize bits. <a href=\"https://github.com/rust-lang/rust/pull/91660\">https://github.com/rust-lang/rust/pull/91660</a> was an interesting test for this, it combined two 32-bit fields into a 64-bit value before hashing, and the ordering choice made a huge difference with FxHasher, but didn't matter when I changed it to use a folded-multiply.</p>",
        "id": 265358838,
        "sender_full_name": "nnethercote",
        "timestamp": 1639774380
    },
    {
        "content": "<p>I wonder what things are like on a 32-bit build of the compiler, where usize inputs <em>do</em> have significant entropy in the upper bits.</p>",
        "id": 265358876,
        "sender_full_name": "nnethercote",
        "timestamp": 1639774416
    },
    {
        "content": "<p>But I suspect the number of people using a 32-bit build of the compiler seriously is very small</p>",
        "id": 265358957,
        "sender_full_name": "nnethercote",
        "timestamp": 1639774444
    },
    {
        "content": "<p>The whole thing is a bit frustrating; FxHasher is terrible, but it's a real worse is better case</p>",
        "id": 265359155,
        "sender_full_name": "nnethercote",
        "timestamp": 1639774566
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"281757\">Jubilee</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Pre-hashed.20.60NodeId.60s/near/265354270\">said</a>:</p>\n<blockquote>\n<p>Only for AVX512.</p>\n</blockquote>\n<p>And for this case, what they do is they don't actually offer a full 64-bit FMA. They offer a <strong>52-bit</strong> FMA, because they just allow you to do an integer FMA using the existing floating point circuitry.</p>",
        "id": 265361972,
        "sender_full_name": "Jubilee",
        "timestamp": 1639775975
    },
    {
        "content": "<p>It's quite possible that people have tried a 32-bit compiler and it was terribly slow and they gave up, assuming it was an address space issue, but really it was an FxHasher issue(!)</p>",
        "id": 265362571,
        "sender_full_name": "nnethercote",
        "timestamp": 1639776281
    },
    {
        "content": "<p>I would have thought exhausting your address space just leads to crashes, not slowness. Its not like virtual memory swap space can save you when you’re out of address space. (One <em>could</em> of course imagine flushing software caches, storing stuff to disk, adopting alterantive data representations, etc. But … I don’t think rustc is doing anything like that to accommodate address space exhaustion…)</p>",
        "id": 265379804,
        "sender_full_name": "pnkfelix",
        "timestamp": 1639787085
    },
    {
        "content": "<p>(clearly the right answer is for me to “just try it and see…”)</p>",
        "id": 265379926,
        "sender_full_name": "pnkfelix",
        "timestamp": 1639787242
    }
]