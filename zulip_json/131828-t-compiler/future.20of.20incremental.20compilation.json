[
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"232957\">Jack Huey</span> <a href=\"#narrow/stream/131828-t-compiler/topic/roadmap.20for.202022.20discussion/near/272744001\">said</a>:</p>\n<blockquote>\n<p>Should this be moved to its own topic</p>\n</blockquote>\n<p>seconded, this deserves its own topic</p>",
        "id": 272794314,
        "sender_full_name": "bstrie",
        "timestamp": 1645532083
    },
    {
        "content": "<p>I will say that the last time that incremental was disabled it resulted in overwhelming discontent from the community and a large number of projects that simply pinned to the prior version. This needs to be handled carefully, because if people start talking about simply removing incremental without talking about what's going to replace it, there's going to be an enormous negative backlash</p>",
        "id": 272795054,
        "sender_full_name": "bstrie",
        "timestamp": 1645532558
    },
    {
        "content": "<p>to clarify, <em>is</em> incremental being last-minute disabled for 1.59? I don't know what discussion or document is being referenced in the original comment</p>",
        "id": 272809449,
        "sender_full_name": "bstrie",
        "timestamp": 1645539956
    },
    {
        "content": "<p>Yes, that's the case -- current thread is <a href=\"https://github.com/rust-lang/rust/issues/94124\">https://github.com/rust-lang/rust/issues/94124</a>.</p>",
        "id": 272809587,
        "sender_full_name": "simulacrum",
        "timestamp": 1645540014
    },
    {
        "content": "<p>I wonder if chalk will help at all with tracking trait selection dependencies</p>",
        "id": 272823670,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645545639
    },
    {
        "content": "<p>Since IIRC there's an explicit abstraction layer mapping from chalk types to rustc types (and associated 'db lookups')</p>",
        "id": 272823752,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645545669
    },
    {
        "content": "<p>out of curiosity: what do people think about the query system in general, as in: Is it desirable to describe the compilation process as a set of side-effect-free functions that produce their results by \"pulling on them\" (setting aside the question of whether these functions are memoized or executed in parallel)? Is such a model a good fit for the kinds of tasks that a compiler has to do? Can the major algorithms be implemented that way without going through contortions?</p>",
        "id": 272823756,
        "sender_full_name": "mw",
        "timestamp": 1645545670
    },
    {
        "content": "<p>I think that's worked out pretty well so far - the main side effect that we need is diagnostics</p>",
        "id": 272824059,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645545778
    },
    {
        "content": "<p>Many of the nasty incremental bugs have resulted from the fact that we always need to call the actual query</p>",
        "id": 272824132,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645545808
    },
    {
        "content": "<p>which causes issues if we try to cache the result in a thread-local or tcx map, even if the query itself is pure</p>",
        "id": 272824203,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645545839
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"124287\">mw</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272823756\">said</a>:</p>\n<blockquote>\n<p>out of curiosity: what do people think about the query system in general, as in: Is it desirable to describe the compilation process as a set of side-effect-free functions that produce their results by \"pulling on them\" (setting aside the question of whether these functions are memoized or executed in parallel)? Is such a model a good fit for the kinds of tasks that a compiler has to do? Can the major algorithms be implemented that way without going through contortions?</p>\n</blockquote>\n<p>FWIW, I love the concept of \"pull-based\" compilation, and I'm really hopeful that it might enable parallel compilation in a way that seems like it'd be much harder in a traditional compiler architecture.</p>",
        "id": 272824929,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1645546104
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"124287\">mw</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272823756\">said</a>:</p>\n<blockquote>\n<p>out of curiosity: what do people think about the query system in general, as in: Is it desirable to describe the compilation process as a set of side-effect-free functions that produce their results by \"pulling on them\" (setting aside the question of whether these functions are memoized or executed in parallel)? Is such a model a good fit for the kinds of tasks that a compiler has to do? Can the major algorithms be implemented that way without going through contortions?</p>\n</blockquote>\n<p>One such \"contorsion\" is the <code>WithOptConstParam</code>business for anonymous constants. Using side-effects, typechecking could just declare that one constant has such type based on the const parameter it replaces, and compilation could go on with it.<br>\nThere are some examples of queries which perform a bunch of computations together, just for other queries to unbundle the results. This happens for lifetime resolution for instance. Meanwhile, some other queries are tightly coupled because they work on the same data (type parameter &amp; predicate collection?).<br>\nOne other difficulty is that the information flow is <em>really</em> difficult to understand. For most queries, I have absolutely no idea which code uses them, and how.</p>",
        "id": 272827128,
        "sender_full_name": "cjgillot",
        "timestamp": 1645546899
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272824929\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"124287\">mw</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272823756\">said</a>:</p>\n<blockquote>\n<p>out of curiosity: what do people think about the query system in general, as in: Is it desirable to describe the compilation process as a set of side-effect-free functions that produce their results by \"pulling on them\" (setting aside the question of whether these functions are memoized or executed in parallel)? Is such a model a good fit for the kinds of tasks that a compiler has to do? Can the major algorithms be implemented that way without going through contortions?</p>\n</blockquote>\n<p>FWIW, I love the concept of \"pull-based\" compilation, and I'm really hopeful that it might enable parallel compilation in a way that seems like it'd be much harder in a traditional compiler architecture.</p>\n</blockquote>\n<p>I'm not sure I agree with you. We can have parallel compilation in a stage-based model, as long as we specify stages as pure functions on a limited part of the code (an item or a body?). This could be relaxed to allow some side effects, but with a lot of care.<br>\nA lot of passes are embarrassingly parallel: lints, typechecking a function body, borrowck, MIR opts. Load balancing and synchronization points will also be an issue.<br>\nOf course, the main complexity will be the feedback between CTFE and typechecking, that on-demand compilation handles very nicely.</p>",
        "id": 272828792,
        "sender_full_name": "cjgillot",
        "timestamp": 1645547498
    },
    {
        "content": "<p>Why do we need a side effect to collect what should be a simple refinement?</p>",
        "id": 272829270,
        "sender_full_name": "Jubilee",
        "timestamp": 1645547675
    },
    {
        "content": "<p>i think that using a query system is generally really cool  though it currently doesn't currently feel strong enough to express what we want</p>",
        "id": 272829443,
        "sender_full_name": "lcnr",
        "timestamp": 1645547749
    },
    {
        "content": "<p>that is something we can incrementally improve, e.g. by allowing cyclic queries where one query only accesses a part of the results of the other query, locking these results to prevent any future mutation</p>",
        "id": 272829589,
        "sender_full_name": "lcnr",
        "timestamp": 1645547799
    },
    {
        "content": "<p>that would remove the need for <code>WithoptConstParam</code> and some other issue i can't remember rn</p>",
        "id": 272829659,
        "sender_full_name": "lcnr",
        "timestamp": 1645547831
    },
    {
        "content": "<p>though i think that if incremental compilation doesn't pull its weight, having a staged compiler with some \"pseudo queries\" for typeck to deal with const generics would probably be easier to maintain</p>",
        "id": 272830006,
        "sender_full_name": "lcnr",
        "timestamp": 1645547972
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"216206\">lcnr</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272829589\">said</a>:</p>\n<blockquote>\n<p>that is something we can incrementally improve, e.g. by allowing cyclic queries where one query only accesses a part of the results of the other query, locking these results to prevent any future mutation</p>\n</blockquote>\n<p>You mean like haskell's lazy evaluation which can do weird time traveling things? <a href=\"https://hackage.haskell.org/package/tardis-0.4.1.0/docs/Control-Monad-Tardis.html\">https://hackage.haskell.org/package/tardis-0.4.1.0/docs/Control-Monad-Tardis.html</a></p>",
        "id": 272830010,
        "sender_full_name": "bjorn3",
        "timestamp": 1645547974
    },
    {
        "content": "<p>A lot of the design involving queries has been heavily inspired by a paradigm of constraint-driven programming. In constraint programming you have one of two choices. You can push an update to a value and then everything adjusts based on that update (the \"functional reactive\" or \"perturbation\" model) or you can use refinement where something's value at any given point is the range of values it can possibly be. Until you evaluate it to a single one, anyways.</p>",
        "id": 272830149,
        "sender_full_name": "Jubilee",
        "timestamp": 1645548023
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133247\">bjorn3</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272830010\">said</a>:</p>\n<blockquote>\n<p>You mean like haskell's lazy evaluation which can do weird time traveling things? <a href=\"https://hackage.haskell.org/package/tardis-0.4.1.0/docs/Control-Monad-Tardis.html\">https://hackage.haskell.org/package/tardis-0.4.1.0/docs/Control-Monad-Tardis.html</a></p>\n</blockquote>\n<p>haven't seen that before and i can't say for sure. never worked with a reverse state monad and can't really tell how it's useful</p>",
        "id": 272830450,
        "sender_full_name": "lcnr",
        "timestamp": 1645548168
    },
    {
        "content": "<p>the query system also suffers from <code>Ord</code> impls which are incorrect wrt incremental compilation, i think that this is largely an issue with our current impl and not a general one though</p>",
        "id": 272830806,
        "sender_full_name": "lcnr",
        "timestamp": 1645548311
    },
    {
        "content": "<p><em>having a query system would be so much nicer if rust was actually just a functional language</em> <span aria-label=\"sparkles\" class=\"emoji emoji-2728\" role=\"img\" title=\"sparkles\">:sparkles:</span></p>",
        "id": 272830982,
        "sender_full_name": "lcnr",
        "timestamp": 1645548372
    },
    {
        "content": "<p>Or even if rust had an effect system of some kind, though at that point the line with fp starts to get real blurry</p>",
        "id": 272831534,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1645548591
    },
    {
        "content": "<p>AN EFFECT SYSTEM YOU SAY</p>",
        "id": 272832616,
        "sender_full_name": "Jubilee",
        "timestamp": 1645548948
    },
    {
        "content": "<p>hahaha the <span class=\"user-mention\" data-user-id=\"220273\">@Jane Lusby [she/her]</span> signal.</p>",
        "id": 272832705,
        "sender_full_name": "Jubilee",
        "timestamp": 1645548975
    },
    {
        "content": "<p>As a not so frequent contributor, I do want to add this: The query system makes it fairly easy for me to figure out where I should go to get the information I need. It provides a fairly uniform API, at least in the sense that I know that with a <code>tcx</code>and the appropriate parameters, I can basically always solve my problem. There are definitely things to improve as well here (some way to answer the question \"can I call this query at this point without inducing a query cycle\" for example), but in general I think it is relatively friendly model. Other models run the risk of \"fragmenting\" the APIs in some way that would increase the difficulty of contributing significantly</p>",
        "id": 272834010,
        "sender_full_name": "Jake",
        "timestamp": 1645549424
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"216206\">lcnr</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272830806\">said</a>:</p>\n<blockquote>\n<p>the query system also suffers from <code>Ord</code> impls which are incorrect wrt incremental compilation, i think that this is largely an issue with our current impl and not a general one though</p>\n</blockquote>\n<p>This is something we're definitely making progress on.</p>",
        "id": 272834533,
        "sender_full_name": "pierwill",
        "timestamp": 1645549618
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125294\">Aaron Hill</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272823752\">said</a>:</p>\n<blockquote>\n<p>Since IIRC there's an explicit abstraction layer mapping from chalk types to rustc types (and associated 'db lookups')</p>\n</blockquote>\n<p>this is correct for now, but the goal is to eventually make this a no-op</p>",
        "id": 272834738,
        "sender_full_name": "Jack Huey",
        "timestamp": 1645549701
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125294\">Aaron Hill</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272823670\">said</a>:</p>\n<blockquote>\n<p>I wonder if chalk will help at all with tracking trait selection dependencies</p>\n</blockquote>\n<p>I did think about this a little bit though. But more generally in the \"what does incremental look like during trait selection\". For the current rustc trait solver, there's caching done in selection &amp; confirmation. For Chalk, that's likely <code>program_clauses_that_could_match</code></p>",
        "id": 272834998,
        "sender_full_name": "Jack Huey",
        "timestamp": 1645549841
    },
    {
        "content": "<blockquote>\n<p>What also might be interesting: Could we have a compiler based on rust-analyzer that only supports debug builds (rust-analyzer was built with the Salsa model from the get-go and I suspect it has much fewer incr. comp. related problems).</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"133169\">@matklad</span> , any thoughts?</p>",
        "id": 272839413,
        "sender_full_name": "bstrie",
        "timestamp": 1645551627
    },
    {
        "content": "<p>I think we are at a tipping point.  We can either continue using the current on-demand query system, or we can reverse directions and use a more stage-based design.  This can be done step by step, starting from lowering, and pushing towards typechecking.  We can use this as an opportunity to rebuild parallel compilation from the ground up: drop all parallel stuff from the current compiler (which is not tested anyway), and re-implement lowering to process each item in parallel.</p>",
        "id": 272845606,
        "sender_full_name": "cjgillot",
        "timestamp": 1645554208
    },
    {
        "content": "<blockquote>\n<p>What also might be interesting: Could we have a compiler based on rust-analyzer that only supports debug builds (rust-analyzer was built with the Salsa model from the get-go and I suspect it has much fewer incr. comp. related problems).</p>\n</blockquote>\n<p>that'd be interesting and probably fun, but rust-analyzer is still very far from it being viable</p>",
        "id": 272847327,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1645554905
    },
    {
        "content": "<blockquote>\n<p>(which is not tested anyway)</p>\n</blockquote>\n<p>The alt builders all run with the parallel compiler enabled aiui</p>",
        "id": 272848411,
        "sender_full_name": "The 8472",
        "timestamp": 1645555385
    },
    {
        "content": "<p>Some ui tests have been ICEing for a few months.</p>",
        "id": 272849095,
        "sender_full_name": "cjgillot",
        "timestamp": 1645555712
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"248906\">cjgillot</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272845606\">said</a>:</p>\n<blockquote>\n<p>I think we are at a tipping point.  We can either continue using the current on-demand query system, or we can reverse directions and use a more stage-based design.  This can be done step by step, starting from lowering, and pushing towards typechecking.  We can use this as an opportunity to rebuild parallel compilation from the ground up: drop all parallel stuff from the current compiler (which is not tested anyway), and re-implement lowering to process each item in parallel.</p>\n</blockquote>\n<p>Do you (or others) have any kind of intuition what the benefits of a complete re-implementation of the query system would be? I know very little about this, but could a push towards librarification or some other large design change alleviate many of the problems?</p>",
        "id": 272849608,
        "sender_full_name": "Jake",
        "timestamp": 1645555966
    },
    {
        "content": "<p>I'm not suggesting a re-implementation of the query system.  I'm suggesting to gradually stop using it, or restricted to some stages (trait selection?).</p>",
        "id": 272850883,
        "sender_full_name": "cjgillot",
        "timestamp": 1645556454
    },
    {
        "content": "<p>It seems like there's enough meat on this topic to drive a Friday meeting (or a series of them)</p>",
        "id": 272851050,
        "sender_full_name": "pnkfelix",
        "timestamp": 1645556518
    },
    {
        "content": "<p>I don't have any quantified evidence of the benefits, of course.  On the contrary, we will have to take great care to avoid introducing regressions when incremental skips a lot of work.</p>",
        "id": 272851134,
        "sender_full_name": "cjgillot",
        "timestamp": 1645556534
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"248906\">cjgillot</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272850883\">said</a>:</p>\n<blockquote>\n<p>I'm not suggesting a re-implementation of the query system.  I'm suggesting to gradually stop using it, or restricted to some stages (trait selection?).</p>\n</blockquote>\n<p>Sorry, I should have been more clear. I didn't mean to imply that you were suggesting that, I was asking a separate question</p>",
        "id": 272851371,
        "sender_full_name": "Jake",
        "timestamp": 1645556644
    },
    {
        "content": "<p>FWIW, I'm expecting to post a PR (for running perf) soon that drops incremental entirely per my earlier point, to try and see what the impact on regular compilations it has. Obviously, not intending for that to be merged in any shape.</p>",
        "id": 272851426,
        "sender_full_name": "simulacrum",
        "timestamp": 1645556676
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272851426\">said</a>:</p>\n<blockquote>\n<p>FWIW, I'm expecting to post a PR (for running perf) soon that drops incremental entirely per my earlier point, to try and see what the impact on regular compilations it has. Obviously, not intending for that to be merged in any shape.</p>\n</blockquote>\n<p>I expect a perf regression between 200% and 300% on incr-unchanged benchmarks (= pretty much the ratio full/incr-unchanged).  We may get &lt;10% back by dropping the weight of the query engine.</p>",
        "id": 272851795,
        "sender_full_name": "cjgillot",
        "timestamp": 1645556842
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310518\">Jake</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272851371\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"248906\">cjgillot</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272850883\">said</a>:</p>\n<blockquote>\n<p>I'm not suggesting a re-implementation of the query system.  I'm suggesting to gradually stop using it, or restricted to some stages (trait selection?).</p>\n</blockquote>\n<p>Sorry, I should have been more clear. I didn't mean to imply that you were suggesting that, I was asking a separate question</p>\n</blockquote>\n<p>What would be the constraints of this re-implementation?  Dropping parallel-compiler cfg may simplify a lot of things, but I wouldn't expect it to have a very large effect on perf.</p>",
        "id": 272852194,
        "sender_full_name": "cjgillot",
        "timestamp": 1645556992
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"248906\">cjgillot</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272852194\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"310518\">Jake</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272851371\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"248906\">cjgillot</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272850883\">said</a>:</p>\n<blockquote>\n<p>I'm not suggesting a re-implementation of the query system.  I'm suggesting to gradually stop using it, or restricted to some stages (trait selection?).</p>\n</blockquote>\n<p>Sorry, I should have been more clear. I didn't mean to imply that you were suggesting that, I was asking a separate question</p>\n</blockquote>\n<p>What would be the constraints of this re-implementation?  Dropping parallel-compiler cfg may simplify a lot of things, but I wouldn't expect it to have a very large effect on perf.</p>\n</blockquote>\n<p>I was not thinking about perf, mostly just about correctness. People above seemed to feel that the complexity of the existing system was a problem - is this something that could be fixed be fixed by a ground up re-implementation, or is the complexity just inherent in the task? (ofc, whether this is a good idea even if the answer is yes is a different question)</p>",
        "id": 272852809,
        "sender_full_name": "Jake",
        "timestamp": 1645557269
    },
    {
        "content": "<p>I think the complexity is inherent in the way that the current system needs to work</p>",
        "id": 272853268,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557461
    },
    {
        "content": "<p>We need to ensure that we always call the actual query functions (no caching in thread-locals / tcx), so that we properly register all dependencies</p>",
        "id": 272853364,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557504
    },
    {
        "content": "<p>Whenever we have any mutable global state in the compiler, we need to make sure it interacts properly with incremental complation (since one query could read a result written by a different query)</p>",
        "id": 272853455,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557551
    },
    {
        "content": "<p>Types like <code>DefId</code> cannot implement <code>Ord</code> in the expected way, since that leaks untracked state (the preciese <code>DefIndex</code> value). This transitively affects a large number of types containing a <code>DefId</code> (see <span class=\"user-mention\" data-user-id=\"316352\">@pierwill</span> 's work)</p>",
        "id": 272853602,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557610
    },
    {
        "content": "<p>Code inside <code>Decodable</code> impls is heavily restricted - it cannot invoke queries, since we may invoke the <code>Decodable</code> impl while decoding the result for another query (or even the same query!)</p>",
        "id": 272853745,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557693
    },
    {
        "content": "<p>Getting any of this wrong will lead to ICEs at best, and miscompilations at worse</p>",
        "id": 272853794,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557717
    },
    {
        "content": "<p>there are probably a bunch of other things that I'm not thinking of</p>",
        "id": 272853848,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557724
    },
    {
        "content": "<p>oh, yeah, the whole <code>Ident</code> impl of <code>PartialEq</code>/<code>Eq</code></p>",
        "id": 272853902,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557743
    },
    {
        "content": "<p>it's supposed to agree with <code>HashStable</code>, but the current impl ignores the <code>Span</code> location</p>",
        "id": 272853928,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557757
    },
    {
        "content": "<p>to fix that, I have a PR open creating an new trait <code>HashStableEq</code> with a ton of impls</p>",
        "id": 272853952,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557770
    },
    {
        "content": "<p>I think that the worst aspect by far is the infectious nature of this. If this was all 'confined' to a singlar part of the compiler, it would probably be manageable. For example, the codegen backends are very complex, but someone working on a separate part of the compiler (e.g. macro invocation) doesn't need to think about it at all</p>",
        "id": 272854145,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557845
    },
    {
        "content": "<p>However, virtually <em>every</em> part of the compiler needs to have its interactions with incr comp properly managed</p>",
        "id": 272854190,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557870
    },
    {
        "content": "<p>For example, there's a ton of logic around properly encoding/decoding <code>ExpnId</code>s and <code>SyntaxContext</code>s (which are created during parsing and expasion) into the incremental cache</p>",
        "id": 272854249,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557904
    },
    {
        "content": "<p>Trait selection has a weird 'anon query' thing to allow us to do global caching in a way that doesn't break incr comp</p>",
        "id": 272854302,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557938
    },
    {
        "content": "<p>and on and on</p>",
        "id": 272854317,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557945
    },
    {
        "content": "<p>This is difficult even for experienced contributors, and is probably a huge footgun for new contributors (though maybe not very much in practice, since newer contributors tend to make localized changs that don't add new global state)</p>",
        "id": 272854418,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645557999
    },
    {
        "content": "<p>TL;DR - I would <em>love</em> to replace the current system with something that's much more self-contained</p>",
        "id": 272854454,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645558027
    },
    {
        "content": "<p>Of course, what we <em>gain</em> by all of this complexity is the ability to do fine-grained re-use during incremental complation</p>",
        "id": 272854611,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645558095
    },
    {
        "content": "<p>Knowing that we can re-use the optimized MIR for a function, for example, despite other modifications that have happened in the same file</p>",
        "id": 272854690,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645558141
    },
    {
        "content": "<p>It's also worth noting that we're heavily constrained by the design of the Rust language itself</p>",
        "id": 272854783,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645558202
    },
    {
        "content": "<p>In C/C++, you get a large amount of re-use and parallelism for free, since the code author is responsible for writing header files such that you can compile one <code>.c</code>/<code>.cpp</code> file without looking at any other <code>.c</code>/<code>.cpp</code> files</p>",
        "id": 272854876,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645558249
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"248906\">cjgillot</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272851795\">said</a>:</p>\n<blockquote>\n<p>I expect a perf regression between 200% and 300% on incr-unchanged benchmarks (= pretty much the ratio full/incr-unchanged).  We may get &lt;10% back by dropping the weight of the query engine.</p>\n</blockquote>\n<p>This definitely makes me curious what kinds of paradigm shifts would be needed to get that ratio up to like 20x (or, if I'm dreaming, 100x).  Is there anything about Rust itself that's forcing something to be awkward, and which removing (or heavily restricting) could help simplify the work needed?</p>\n<p>EDIT: Thanks, <span class=\"user-mention silent\" data-user-id=\"125294\">Aaron Hill</span>, for writing an answer before I finished typing the question <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>",
        "id": 272854992,
        "sender_full_name": "scottmcm",
        "timestamp": 1645558312
    },
    {
        "content": "<p>In Rust, that burden is shifted to the compiler - allowing for things like cyclic dependencies between modules in the same crate, but also forcing us to parse + expand the entire crate in one go</p>",
        "id": 272855011,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645558319
    },
    {
        "content": "<p>We converged on the same topic from two different directions :)</p>",
        "id": 272855204,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645558400
    },
    {
        "content": "<p>I don't have much to contribute as a response, but this was interesting and helpful, thanks for sharing!</p>",
        "id": 272855458,
        "sender_full_name": "Jake",
        "timestamp": 1645558525
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125294\">Aaron Hill</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272855011\">said</a>:</p>\n<blockquote>\n<p>In Rust, that burden is shifted to the compiler - allowing for things like cyclic dependencies between modules in the same crate, but also forcing us to parse + expand the entire crate in one go</p>\n</blockquote>\n<p>Would it be possible to first expand everything except function bodies and then incrementally expand function bodies individually as a separate step? Or can macros leak out of function bodies?</p>",
        "id": 272856184,
        "sender_full_name": "bjorn3",
        "timestamp": 1645558918
    },
    {
        "content": "<p>you can impl traits inside function bodies, which are globally visible</p>",
        "id": 272856315,
        "sender_full_name": "simulacrum",
        "timestamp": 1645558962
    },
    {
        "content": "<p>Sure, but I was talking about macro expansion, not typechecking.</p>",
        "id": 272856382,
        "sender_full_name": "bjorn3",
        "timestamp": 1645559003
    },
    {
        "content": "<p>Some related conversation: <a href=\"https://github.com/rust-lang/rust/issues/65516\">\n[Edition vNext] Consider deprecating weird nesting of items\n#65516 </a></p>",
        "id": 272856420,
        "sender_full_name": "scottmcm",
        "timestamp": 1645559027
    },
    {
        "content": "<p>HIR lowering doesn't depend on which traits are implemented afaik.</p>",
        "id": 272856423,
        "sender_full_name": "bjorn3",
        "timestamp": 1645559029
    },
    {
        "content": "<p>I think if you define a macro_rules! macro inside a function, it can be used anywhere latter in the file/crate</p>",
        "id": 272856424,
        "sender_full_name": "simulacrum",
        "timestamp": 1645559029
    },
    {
        "content": "<p>but not 100% sure on that.</p>",
        "id": 272856488,
        "sender_full_name": "simulacrum",
        "timestamp": 1645559045
    },
    {
        "content": "<p>The rules around <code>macro_rules!</code> importing are really weird</p>",
        "id": 272856501,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645559057
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272856424\">said</a>:</p>\n<blockquote>\n<p>I think if you define a macro_rules! macro inside a function, it can be used anywhere latter in the file/crate</p>\n</blockquote>\n<p>Looks like it can't. <a href=\"https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=5ef4869ffeb87a178627f2b3249284cc\">https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=5ef4869ffeb87a178627f2b3249284cc</a></p>",
        "id": 272856602,
        "sender_full_name": "bjorn3",
        "timestamp": 1645559110
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272856424\">said</a>:</p>\n<blockquote>\n<p>I think if you define a macro_rules! macro inside a function, it can be used anywhere latter in the file/crate</p>\n</blockquote>\n<p>Looks like that's no longer true, at least in 2021: <a href=\"https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=94f45d831cf93be23116d975494adda7\">https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=94f45d831cf93be23116d975494adda7</a></p>",
        "id": 272856604,
        "sender_full_name": "scottmcm",
        "timestamp": 1645559112
    },
    {
        "content": "<p>Same in the 2015 edition.</p>",
        "id": 272856655,
        "sender_full_name": "bjorn3",
        "timestamp": 1645559140
    },
    {
        "content": "<p>Oh, but maybe you can put a <code>#[macro_use] extern crate foo</code> inside a function body?</p>",
        "id": 272856687,
        "sender_full_name": "scottmcm",
        "timestamp": 1645559153
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125270\">scottmcm</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272856604\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272856424\">said</a>:</p>\n<blockquote>\n<p>I think if you define a macro_rules! macro inside a function, it can be used anywhere latter in the file/crate</p>\n</blockquote>\n<p>Looks like that's no longer true, at least in 2021: <a href=\"https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=94f45d831cf93be23116d975494adda7\">https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=94f45d831cf93be23116d975494adda7</a></p>\n</blockquote>\n<p>Works if you <code>#[macro_export]</code>...</p>",
        "id": 272856809,
        "sender_full_name": "cjgillot",
        "timestamp": 1645559198
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125270\">scottmcm</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272856687\">said</a>:</p>\n<blockquote>\n<p>Oh, but maybe you can put a <code>#[macro_use] extern crate foo</code> inside a function body?</p>\n</blockquote>\n<div class=\"codehilite\"><pre><span></span><code>error[E0468]: an `extern crate` loading macros must be at the crate root\n --&gt; src/lib.rs:2:18\n  |\n2 |     #[macro_use] extern crate serde_derive;\n  |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nFor more information about this error, try `rustc --explain E0468`.\nerror: could not compile `playground` due to previous error\n</code></pre></div>",
        "id": 272856826,
        "sender_full_name": "bjorn3",
        "timestamp": 1645559205
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"248906\">cjgillot</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272856809\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"125270\">scottmcm</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272856604\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272856424\">said</a>:</p>\n<blockquote>\n<p>I think if you define a macro_rules! macro inside a function, it can be used anywhere latter in the file/crate</p>\n</blockquote>\n<p>Looks like that's no longer true, at least in 2021: <a href=\"https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=94f45d831cf93be23116d975494adda7\">https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=94f45d831cf93be23116d975494adda7</a></p>\n</blockquote>\n<p>Works if you <code>#[macro_export]</code>...</p>\n</blockquote>\n<p>That's really unfortunate</p>",
        "id": 272856878,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645559236
    },
    {
        "content": "<p>Can we crater disallowing this?</p>",
        "id": 272856918,
        "sender_full_name": "bjorn3",
        "timestamp": 1645559262
    },
    {
        "content": "<p>IIRC, part of the discussion around petrochenkov's <code>pub macro_rules!</code> PR was related to the fact that you can do weird shadowing of <code>macro_rules!</code> in a way that couldn't easily be replicated otherwise</p>",
        "id": 272857036,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645559317
    },
    {
        "content": "<p>I can't remember if anyone was found to actually be using that</p>",
        "id": 272857065,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645559328
    },
    {
        "content": "<p>but this seems like a similar case, conceptually</p>",
        "id": 272857079,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645559334
    },
    {
        "content": "<p>Is there any case where that shadowing would be useful to leak out of a function?</p>",
        "id": 272857184,
        "sender_full_name": "bjorn3",
        "timestamp": 1645559393
    },
    {
        "content": "<p>I'm sure someone like dtolany or yandros could make something that used it :) I have no idea whether or not there's any practical use-case that <em>require</em>s it, though</p>",
        "id": 272857510,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1645559536
    },
    {
        "content": "<p>This discussion is oscillating back towards end-to-end queries :)</p>",
        "id": 272857578,
        "sender_full_name": "cjgillot",
        "timestamp": 1645559582
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133247\">bjorn3</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272856918\">said</a>:</p>\n<blockquote>\n<p>Can we crater disallowing this?</p>\n</blockquote>\n<p>I went and <a href=\"#narrow/stream/213817-t-lang/topic/Deprecating.20macro.20scoping.20shenanigans/near/272857859\">made a lang thread</a> about \"just say no\"ing this.  I'd love to find out that nobody is using it and just make it disallowed.</p>",
        "id": 272858093,
        "sender_full_name": "scottmcm",
        "timestamp": 1645559792
    },
    {
        "content": "<p>To continue on the discussion, a small write-up of what would be required to move towards staged compilation.  This does not go all the way, but paves some steps.  The hard part is the remaining steps keeping typeck &amp; cfte self-consistent.</p>",
        "id": 272872919,
        "sender_full_name": "cjgillot",
        "timestamp": 1645567457
    },
    {
        "content": "<p><a href=\"https://hackmd.io/WX8ioGMFSZ2ErL_m_3QTsw?view\">https://hackmd.io/WX8ioGMFSZ2ErL_m_3QTsw?view</a></p>",
        "id": 272872926,
        "sender_full_name": "cjgillot",
        "timestamp": 1645567460
    },
    {
        "content": "<p>A couple of random thoughts:</p>",
        "id": 272906537,
        "sender_full_name": "nnethercote",
        "timestamp": 1645594168
    },
    {
        "content": "<ul>\n<li>I find the query system very hard to understand. So many layers of macros.</li>\n</ul>",
        "id": 272906543,
        "sender_full_name": "nnethercote",
        "timestamp": 1645594186
    },
    {
        "content": "<ul>\n<li>I've always felt like the incr. comp. approach doesn't align nicely with parallel compilation. Making a single global data structure (the incr. comp. cache) the bottleneck for everything make things hard for parallel. Sure you can shard the tables, but that only gets you so far.</li>\n</ul>",
        "id": 272906649,
        "sender_full_name": "nnethercote",
        "timestamp": 1645594280
    },
    {
        "content": "<p>Another thing that would be nice to improve would be disk space usage. This is the reason I currently don't use incr comp when building rust on my system.</p>",
        "id": 272925234,
        "sender_full_name": "bjorn3",
        "timestamp": 1645609695
    },
    {
        "content": "<p>If I can add my two cents: </p>\n<p>I don't know if this is intrinsic to query based approaches or just Rust's implementation, but a limitation I encounter fairly often is the 'immutability' of inputs. For my usecases of the API, I find myself wanting to add trait implementations, or even create DefIds (for 'synthetic' items) which don't correspond to source code the user wrote. With a more traditional pass based compiler I feel like I could sneak in between two passes to add information to the relevant tables. </p>\n<p>On the other hand, I am worried that a pass based approach would have a more coarse-grained API: ie where do the passes end? I find myself needing to stop different items at different stages: HIR, THIR, MIR depending on what I intend to do with them.</p>",
        "id": 272926500,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1645610374
    },
    {
        "content": "<p>Some thoughts:</p>\n<ul>\n<li>I think the query system as implemented right now is not in good shape. It is incredibly hard to understand what's going on internally (even though its basically just a system that allows for caching the results of functions). Some of that is due to parallel support, some of it is just because it has grown over the years without a major trim-down and gone through many performance optimizations that regressed readability. It probably could be moved to a completely external library like Salsa.</li>\n<li>I think one of main problems of the current system is that the abstractions are so leaky. Everything still has access to what is in Session and there are many other things in the tcx that should really only be accessible as a query. And types like Span and DefId, which are constructed before the query system kicks in, just don't fit the model -- these are things that probably would never have shown up as an issue for something that was written atop of e.g. Salsa from the start.</li>\n<li>I think query-based / pull-based architectures have a lot going for them. They force you to make data dependencies explicit. One can read a query provider and look at what other queries it calls until one reaches the inputs. Having a common kind of API, as <span class=\"user-mention\" data-user-id=\"310518\">@Jake</span> mentions is a big plus. A query-based architecture also makes it \"easy enough\" to synchronize parallel evaluation of things because all computations are explicitly structured into a DAG. And you can only partially compile a crate, as <span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> mentions.</li>\n<li>Pull-based architectures also have their downsides. One kind of has to think about everything backwards. And it is hard to know when resources are not needed anymore and thus can be dropped.</li>\n<li>IIRC, at the time when the query system was adopted, it was still the plan to have rustc be an LSP server. So there was no real alternative to having a fine-grained on-demand system. I don't think this a requirement anymore.</li>\n<li>A pass-based architecture sounds appealing if it can be kept simple. There is a risk though, that it would end up as a complex mix of forward passes and ad-hoc on-demand evaluation, just without a clear governing structure, like a query system (in theory) can provide.</li>\n<li>It would really be awesome if one could view the compiler as a series of passes, each with a clear inputs and outputs.</li>\n<li>Independently of pass-based or on-demand, dealing with incremental compilation introduces a strong requirement for producing deterministic and \"stable\" intermediate artifacts and being able to match values between compilation sessions. One still has to know if something from an on-disk cache can be re-used or not. Getting rid of queries would not solve things like DefId drift. On the other hand, there might be simpler ways of keeping things stable. </li>\n<li>I suspect that doing any kind of interning of complex values actually introduces some of the same constraints that we have for incr. comp. at the moment, like <code>Eq</code> not ignoring parts of the interned value. The current incr. comp. system however makes it much more likely that a failure of upholding these constraints turns into an ICE.</li>\n<li>For a pass-based approach that supports parallelism one will likely want to write most data transformations as side-effect-free functions that don't access global state. A which point you are pretty close to a query system :)</li>\n<li>Many of the current system's problems stem from dependency tracking, not from being on-demand, I think. A pass-based approach that also tries to do dependency tracking would have to solve the same problems.</li>\n<li>Many of our current problems also stem from refactoring the compiler in-place. That would also be a problem for any other kind of global refactoring.</li>\n</ul>",
        "id": 272932574,
        "sender_full_name": "mw",
        "timestamp": 1645613864
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span> I had the impression that the long-term plan was for rustc and r-a to share more and more code?</p>",
        "id": 272969778,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1645632386
    },
    {
        "content": "<p>Is that not still a goal?</p>",
        "id": 272969805,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1645632401
    },
    {
        "content": "<p>Having rustc and r-a share more code does not necessarily imply that they share the same way of implementing incremental compilation. If anything they probably need a different way. Rust-analyzer needs to be as lazy as possible up to ignoring any errors for not currently open files, while rustc needs to at least check for errors in the whole crate and more eagerly calculate things.</p>",
        "id": 272976984,
        "sender_full_name": "bjorn3",
        "timestamp": 1645635443
    },
    {
        "content": "<p>I think the parts shared between rustc and r-a could be externally driven to do one unit of work. It is then up to rustc and r-a do run the code either always (rustc) or only when necessary (r-a)</p>",
        "id": 272977455,
        "sender_full_name": "bjorn3",
        "timestamp": 1645635615
    },
    {
        "content": "<p>We probably shouldn't consider fully dropping incremental compilation, just reform which flavour we prefer it.<br>\nWe are actually discussion with two orthogonal questions:</p>\n<ul>\n<li>code execution: pull-based (the current system) vs push-based (explicit calls which are eventually skipped);</li>\n<li>dependency handling: registration-based (the current system) vs forward-declared (a closed list of dependencies a query is allowed to use at will).</li>\n</ul>\n<p>On the code execution side:<br>\nPull-based execution allows to re-compute information just-in-time when required, while push-based execution can only skip computations if the value can be loaded from disk.<br>\nOTOH, pull-based makes execution order unpredictable and does not handle cycles, while push-based execution allows to reason about the order of execution, and allows to handle cycles explicitly. For instance, trait selection switches from pull- to push-based execution to handle cycles.<br>\nRe-implementation of the parallel compiler would be much easier with a push-based compiler than with the pull-based version: we know what is executed, when it is executed, and we don't have to detect cycles.</p>\n<p>On dependency handling:<br>\nRegistration-based system needs to be able to exhaust all possible data dependencies, where code basically rely on a global <code>TyCtxt</code> handling everything.<br>\nForward-declared dependencies are opt-in, and the available information each query can access is restricted. This is much more cumbersome to work with, but the abstraction is more robust.</p>",
        "id": 272978532,
        "sender_full_name": "cjgillot",
        "timestamp": 1645636008
    },
    {
        "content": "<p>perf results for deleting most of the incremental code - <a href=\"https://perf.rust-lang.org/compare.html?start=c651ba8a542c7d89b271efbf024a31091c824f4b&amp;end=08f996275290797d9c0192603890eb7ae11d7ebd\">https://perf.rust-lang.org/compare.html?start=c651ba8a542c7d89b271efbf024a31091c824f4b&amp;end=08f996275290797d9c0192603890eb7ae11d7ebd</a></p>",
        "id": 272980438,
        "sender_full_name": "simulacrum",
        "timestamp": 1645636743
    },
    {
        "content": "<p>So up to 4% wins. Not a whole lot.</p>",
        "id": 272980542,
        "sender_full_name": "bjorn3",
        "timestamp": 1645636797
    },
    {
        "content": "<p>It does save a minute (8%) in compiling rustc a single crate at a time though.</p>",
        "id": 272980702,
        "sender_full_name": "bjorn3",
        "timestamp": 1645636853
    },
    {
        "content": "<p>I suspect there's a long tail of removing the duplicate hashmaps that incremental semi-forces on us due to the caching of 'trivial' queries that consist of just a hashmap lookup</p>",
        "id": 272981124,
        "sender_full_name": "simulacrum",
        "timestamp": 1645637008
    },
    {
        "content": "<p>though some of that can be mitigated without actually deleting code, it's just more work to do so.</p>",
        "id": 272981169,
        "sender_full_name": "simulacrum",
        "timestamp": 1645637025
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/131828-t-compiler/topic/future.20of.20incremental.20compilation/near/272969778\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"124287\">mw</span> I had the impression that the long-term plan was for rustc and r-a to share more and more code?<br>\nIs that not still a goal?</p>\n</blockquote>\n<p>First a disclaimer: I don't set goals or have special insight into what the \"plans\" are. I'm just putting down my personal thoughts. As far as I know, the roadmap discussion on the other thread is the closest thing to a plan that we have. </p>\n<p>With that in mind, I agree with <span class=\"user-mention silent\" data-user-id=\"133247\">bjorn3</span>'s statement: re-using code between the two projects can happen at a different level, by implementing complex logic in an environment-independent manner (as I think e.g. Chalk attempts to do). I think this has been referred to as \"librarification\" of the compiler. And I think that would be a good way to go about it (because things can be tested in isolation and implementation details don't creep into the logic), but I guess it's non-trivial to properly abstract the environment away in many cases.</p>",
        "id": 273069352,
        "sender_full_name": "mw",
        "timestamp": 1645697406
    },
    {
        "content": "<p>Triggered by a discussion with <span class=\"user-mention\" data-user-id=\"312719\">@Xavier Denis</span>, extending the discussion with hybrid incr. comp. models:</p>\n<blockquote>\n<p>The (pull-based, registration) and (push-based, declaration) models kind of work well together. However, I imagine the hybrids as follows:<br>\n- push-based + registration model: each query would be invoked in two ways:<br>\n   compute which calls the backing function and stores its result, and get which recovers the result but does not compute it.<br>\n   Calling compute in the right order would be the responsibility of an orchestrator. A query would not be allowed to call compute, only the orchestrator can. This can be enshrined into types, having a OrchestrationCtxtand a DataCtxt in place of the TyCtxt. When compute is called, the dependency graph is probed to see if the node is green. If it is and the value can be recovered from disk, the computation is skipped.<br>\n   Calling get is only allowed from queries. When the data has not been computed yet, get would return None. Dependency handling would happen in calls to get, like it does now. We could add the possibility for a query to push a result into another one as a side effect, with a specific marker for dependency handling (this allows to handle cycles).<br>\n- pull-based + forward declaration: each query would list all of its dependencies in a separate function, and the actual query code would ICE if it accesses information outside of this list. (There may be a better way to do this, for instance to have compile-time checks, but I haven't tought of it yet.) As the list of dependencies is known in advance, the query system can walk the dependency graph, and detect cycles before calling any computation. This would allow to have dedicated code to handle the cycle.</p>\n</blockquote>",
        "id": 273272750,
        "sender_full_name": "cjgillot",
        "timestamp": 1645816585
    },
    {
        "content": "<p>agreed that there should be only one set of \"red\" computational functions, and agreed that we should have much more representation of \"ambiguous\" state if we really want to go all Prolog on everything.</p>",
        "id": 273274626,
        "sender_full_name": "Jubilee",
        "timestamp": 1645817564
    },
    {
        "content": "<p>It should be possible, for debugging purposes if nothing else, however, for queries to determine what unsatisfied edges remain for a computation.</p>",
        "id": 273275022,
        "sender_full_name": "Jubilee",
        "timestamp": 1645817770
    },
    {
        "content": "<p>This would also be useful for profiling.  One blind spot we have right now is profiling the dependency graph, especially: what are the \"almost useless\" dependency edges we have in it.</p>",
        "id": 273275319,
        "sender_full_name": "cjgillot",
        "timestamp": 1645817935
    },
    {
        "content": "<p>To move this forward: What would be a good way to start prototyping this?</p>",
        "id": 273719060,
        "sender_full_name": "Aaron Hill",
        "timestamp": 1646172632
    },
    {
        "content": "<p>Once we make a decision, the migration can be made step by step, starting with lowering and pushing towards type checking. The work on the incr. comp. infra can be done at the same time, using already-existing tools for dependency tracking.<br>\nThe question is merely to provide an accurate description of the trade-off to decide upon.</p>",
        "id": 273800726,
        "sender_full_name": "cjgillot",
        "timestamp": 1646225266
    },
    {
        "content": "<p>Our next T-compiler planning meeting is on <time datetime=\"2022-03-11T15:00:00Z\">2022-03-11T10:00:00-05:00</time> . So,  one possible (and very easy) next step would be to have a <em>meeting proposal</em> ready by that date (note, \"meeting\", not the full document that drives the meeting). (We can of course work on making forward progress well before that time, but I think a steering meeting will be necessary before we take any major action here.)</p>",
        "id": 273801675,
        "sender_full_name": "pnkfelix",
        "timestamp": 1646225792
    },
    {
        "content": "<p>like all meeting proposals, it would need 1. what is the meeting about (which, in this case, is probably a matter of identifying a suitable <em>restriction</em>/<em>subset</em> of the scope of the possible topic areas), and 2. specifying <em>who</em> is going to own creating the document that will drive the meeting.</p>",
        "id": 273801764,
        "sender_full_name": "pnkfelix",
        "timestamp": 1646225877
    },
    {
        "content": "<p>I have another stone to cast in the pit, as an external api user I make heavy use of the laziness that the query system provides: in particular I need to be able to handle functions which dont satisfy the borrow checker, which I do by only requesting thir for those functions. At the same time, I request mir for different functions. </p>\n<p>If we switch to a pass &amp; table based approach, it would be very important to me and other similar users that it be possible to mutate the tables between passes (to force certain definitions to get skipped by later passes)</p>",
        "id": 274127732,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1646400489
    },
    {
        "content": "<p>What functions don't pass borrowck?</p>",
        "id": 274129047,
        "sender_full_name": "bjorn3",
        "timestamp": 1646401065
    },
    {
        "content": "<p>I encode specifications as rust functions but dont enforce single ownership on them as they are not program functions</p>",
        "id": 274129969,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1646401479
    },
    {
        "content": "<p>I do this as I need access to rusts resolution and type checking / inference</p>",
        "id": 274130067,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1646401504
    },
    {
        "content": "<p>And until a future in which the rust compiler is truly librarified its hard to develop a satisfactory alternative</p>",
        "id": 274130139,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1646401540
    },
    {
        "content": "<p>FYI, I just posted <a href=\"https://github.com/rust-lang/compiler-team/issues/490\">this meeting proposal</a> for discussing concrete ways of improving the state of the current system in the short-to-medium term.</p>",
        "id": 274138271,
        "sender_full_name": "mw",
        "timestamp": 1646405120
    },
    {
        "content": "<p>^^^ cc <span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span> &amp; <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span></p>",
        "id": 274138795,
        "sender_full_name": "mw",
        "timestamp": 1646405349
    },
    {
        "content": "<p>mind if I copy out that hackmd into a read-only medium and share it more widely? I think after seeing incremental get disabled twice a lot of people at large are curious about why incremental is so difficult, and getting to peer behind the curtain might be instructive</p>",
        "id": 274151081,
        "sender_full_name": "bstrie",
        "timestamp": 1646410129
    },
    {
        "content": "<p>idk, it's just a very rough brain dump</p>",
        "id": 274151383,
        "sender_full_name": "mw",
        "timestamp": 1646410265
    },
    {
        "content": "<p>and it hasn't had input from other folks working on incr. comp. yet. Maybe it's better to wait until after it has been discussed in the planning meeting.</p>",
        "id": 274151589,
        "sender_full_name": "mw",
        "timestamp": 1646410386
    }
]