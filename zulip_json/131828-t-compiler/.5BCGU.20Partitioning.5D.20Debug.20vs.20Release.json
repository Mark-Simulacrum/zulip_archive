[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116107\">@davidtwco</span> brought an interesting idea, which I think makes a lot of sense:</p>\n<ul>\n<li>CGUs for LLVM are generated in equal ways for debug and release builds</li>\n<li>Release would prefer the CGU partitioning scheme to be biased towards runtime performance.</li>\n<li>Yet debug cares a lot more about compile times than release does. Like a lot <em>a lot</em>. Debug would much prefer shorter compile times if it meant a bit less of runtime performance.</li>\n<li>This makes optimizing the CGU partitioning scheme for one use case not really great for the other.</li>\n<li>Therefore: <strong>should we have the same scheme?</strong> Maybe we could have a runtime-perf oriented scheme for Release builds and a compile-time oriented scheme for Debug builds.</li>\n</ul>\n<p>Relevant meeting: <a href=\"#narrow/stream/238009-t-compiler.2Fmeetings/topic/.5Bdesign.20meeting.5D.20codegen.20unit.20partitioning.20compiler-team.23281\">https://rust-lang.zulipchat.com/#narrow/stream/238009-t-compiler.2Fmeetings/topic/.5Bdesign.20meeting.5D.20codegen.20unit.20partitioning.20compiler-team.23281</a></p>",
        "id": 198453301,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590160463
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span></p>",
        "id": 198453551,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590160599
    },
    {
        "content": "<p>It would also be nice to have a scheme for when there is no inlining support at all in the codegen backend (aka cg_clif) It could for example not copy functions marked as <code>#[inline]</code> into every cgu that uses them but instead treat them like normal functions.</p>",
        "id": 198453583,
        "sender_full_name": "bjorn3",
        "timestamp": 1590160618
    },
    {
        "content": "<p>Yeah, for <code>release</code> builds, we'd ideally have large but equally sized CGUs so that we don't waste idle cycles on different cores waiting for large outlier CGUs to finish compiling.</p>",
        "id": 198453793,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590160744
    },
    {
        "content": "<p>For <code>debug</code> (with incremental), we'd really want the CGUs to be as small as possible with no regard to inlining.</p>",
        "id": 198453845,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590160774
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"133247\">@bjorn3</span> <br>\nYAAAAS. Omg, I completely forgot to bring up the importance of having different backends. Dangit! <span aria-label=\"face palm\" class=\"emoji emoji-1f926\" role=\"img\" title=\"face palm\">:face_palm:</span><br>\nOkay, next time.</p>\n<p>I think the fact that our current scheme is tailored towards LLVM is somewhat dangerous. We should avoid being too tied to LLVM.</p>\n<p>(Edit: sorry got a bit off topic)</p>",
        "id": 198453848,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590160775
    },
    {
        "content": "<p>I think a scheme like the debug one would work pretty well with cg_clif</p>",
        "id": 198453934,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590160817
    },
    {
        "content": "<p>I think it may make a lot of sense to have separate partitioning schemes per-backend, but I wouldn't hesitate to make improvements <em>today</em> even if they are llvm-only somehow</p>",
        "id": 198453940,
        "sender_full_name": "simulacrum",
        "timestamp": 1590160823
    },
    {
        "content": "<p>Now I'm kind of wondering how those cg_clif perf runs would look without inlining logic enabled...</p>",
        "id": 198454011,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590160885
    },
    {
        "content": "<p>Adapting it for cg_clif should be much much easier than improving it for cg_llvm, as cg_clif doesn't do any inlining, which means that you don't have to be smart about copying functions. Just don't copy them and don't merge codegen units.</p>",
        "id": 198454015,
        "sender_full_name": "bjorn3",
        "timestamp": 1590160889
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198453940\">said</a>:</p>\n<blockquote>\n<p>I think it may make a lot of sense to have separate partitioning schemes per-backend, but I wouldn't hesitate to make improvements <em>today</em> even if they are llvm-only somehow</p>\n</blockquote>\n<p>No, I completely agree... but what I mean is... we should if possible try to not build something too complex that's llvm-based if that meant that further support for other backends would be hindered. Does that make sense?</p>",
        "id": 198454075,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590160922
    },
    {
        "content": "<p>Yeah. I think I agree in general but we should be careful not to overly generalize here since we only have two backends.</p>",
        "id": 198454277,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161043
    },
    {
        "content": "<p>I disagree :)</p>\n<p>I care much more at this point about optimizing the compiler we have today than a future compiler. I do think we should avoid undue complexity if it doesn't make sense, but if that complexity gives us wins, then we should do it.</p>",
        "id": 198454287,
        "sender_full_name": "simulacrum",
        "timestamp": 1590161048
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198453845\">said</a>:</p>\n<blockquote>\n<p>For <code>debug</code> (with incremental), we'd really want the CGUs to be as small as possible with no regard to inlining.</p>\n</blockquote>\n<p>On that same line, should we maybe run different mir-opts based on whether or not we're in Release mode? Because if inlining is always slow to compile, maybe we could experiment and ditch other opts that make debug slower to compile as well :3</p>",
        "id": 198454328,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590161075
    },
    {
        "content": "<p>I suspect using different algorithms that tailor to specific use cases will make the overall code simpler since it is trying to juggle fewer concerns.</p>",
        "id": 198454402,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161119
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"212698\">@Félix Fischer</span> Most mir opts reduce the amount of generated LLVM IR enough and thus save LLVM optimization time that it outweighs the cost of optimizing.</p>",
        "id": 198454432,
        "sender_full_name": "bjorn3",
        "timestamp": 1590161138
    },
    {
        "content": "<p>I think right now we always run mir-opts because like <span class=\"user-mention\" data-user-id=\"133247\">@bjorn3</span> says, they improve the throughput of LLVM even though we're in debug</p>",
        "id": 198454500,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161163
    },
    {
        "content": "<p>Including inlining? Although I think the mir-opt for inlining was disabled, wasn't it</p>",
        "id": 198454503,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590161164
    },
    {
        "content": "<p>MIR inlining is always disabled</p>",
        "id": 198454530,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161173
    },
    {
        "content": "<p>Ohh, okay :)</p>",
        "id": 198454545,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590161182
    },
    {
        "content": "<p>Well \"always\" in that the only time it gets used is in the mir-opt tests.</p>",
        "id": 198454585,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161203
    },
    {
        "content": "<p>In terms of normal uses of rustc, it is never run.</p>",
        "id": 198454612,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161218
    },
    {
        "content": "<p>You have to opt-in via <code>-Zmir-opt-level=2</code></p>",
        "id": 198454629,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161227
    },
    {
        "content": "<p>And you can't do that on a stable compiler.</p>",
        "id": 198454639,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161233
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198454287\">said</a>:</p>\n<blockquote>\n<p>I disagree :)</p>\n<p>I care much more at this point about optimizing the compiler we have today than a future compiler. I do think we should avoid undue complexity if it doesn't make sense, but if that complexity gives us wins, then we should do it.</p>\n</blockquote>\n<p>That's fair :)</p>\n<p>I dunno, I guess I just worry about the recent LLVM compile-time regressions too much. Also their interests not being all that aligned with ours as well.</p>\n<p>Like don't get me wrong, LLVM is a marvel and a gem. Compiler development was a wasteland before LLVM came along. <br>\nBut... I can't avoid thinking about their path forward diverging from ours in the future.</p>",
        "id": 198454821,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590161336
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198454530\">said</a>:</p>\n<blockquote>\n<p>MIR inlining is always disabled</p>\n</blockquote>\n<p>Do you think inlining in the MIR before partitioning - so that inlining isn't a concern at all during partitioning - could be worthwhile?</p>",
        "id": 198454899,
        "sender_full_name": "davidtwco",
        "timestamp": 1590161383
    },
    {
        "content": "<p>If we were in a future land where LLVM wasn't our primary backend, my opinion would definitely be different</p>",
        "id": 198454903,
        "sender_full_name": "simulacrum",
        "timestamp": 1590161387
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198454629\">said</a>:</p>\n<blockquote>\n<p>You have to opt-in via <code>-Zmir-opt-level=2</code></p>\n</blockquote>\n<p>Maybe we could run it in Release?</p>",
        "id": 198454910,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590161389
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116107\">davidtwco</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198454899\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198454530\">said</a>:</p>\n<blockquote>\n<p>MIR inlining is always disabled</p>\n</blockquote>\n<p>Do you think inlining in the MIR before partitioning - so that inlining isn't a concern at all during partitioning - could be worthwhile?</p>\n</blockquote>\n<p>MIR inlining happens during the <code>optimized_mir</code> query long before partitioning.</p>",
        "id": 198455048,
        "sender_full_name": "bjorn3",
        "timestamp": 1590161443
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"212698\">Félix Fischer</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198454910\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198454629\">said</a>:</p>\n<blockquote>\n<p>You have to opt-in via <code>-Zmir-opt-level=2</code></p>\n</blockquote>\n<p>Maybe we could run it in Release?</p>\n</blockquote>\n<p>I believe there are still broken optimizations at that level. At least a while ago there were.</p>",
        "id": 198455107,
        "sender_full_name": "bjorn3",
        "timestamp": 1590161472
    },
    {
        "content": "<p>Having some release-only MIR opts will happen at some point, I believe – currently we were lucky enough that all MIR opts improve compile times, but that is unlikely to be the case forever.</p>",
        "id": 198455136,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1590161487
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133247\">bjorn3</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198455107\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"212698\">Félix Fischer</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198454910\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198454629\">said</a>:</p>\n<blockquote>\n<p>You have to opt-in via <code>-Zmir-opt-level=2</code></p>\n</blockquote>\n<p>Maybe we could run it in Release?</p>\n</blockquote>\n<p>I believe there are still broken optimizations at that level. At least a while ago there were.</p>\n</blockquote>\n<p>Ahh, yes. I meant running the inlining :3</p>",
        "id": 198455168,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590161511
    },
    {
        "content": "<p>Currently though there's still bugs in the inliner and copy-prop passes (and possibly more), so we couldn't just turn on the full level 2 suite</p>",
        "id": 198455236,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1590161531
    },
    {
        "content": "<p>nono I agree</p>",
        "id": 198455259,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590161541
    },
    {
        "content": "<p>FWIW I see y'all talking a lot about cgus and partitioning, and I know a fair bit about what we currently do and would be more than happy to answer questions or talk about it. I don't have a ton of time to implement changes but brain dumps are easier. Feel free to CC me if I can help!</p>",
        "id": 198455337,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1590161585
    },
    {
        "content": "<p>(there was more discussion in <a class=\"stream-topic\" data-stream-id=\"238009\" href=\"/#narrow/stream/238009-t-compiler.2Fmeetings/topic/.5Bdesign.20meeting.5D.20codegen.20unit.20partitioning.20compiler-team.23281\">#t-compiler/meetings &gt; [design meeting] codegen unit partitioning compiler-team#281</a> that you might not have saw)</p>",
        "id": 198455394,
        "sender_full_name": "davidtwco",
        "timestamp": 1590161622
    },
    {
        "content": "<p>(anyone mind if I rename this topic to use \"CGU\" instead of spelling it out? Its very long in the side bar at the moment and I'd like to add other topics that are also CGU releated)</p>",
        "id": 198455464,
        "sender_full_name": "pnkfelix",
        "timestamp": 1590161648
    },
    {
        "content": "<p>I was thinking more on the line of... instead of having \"levels\" mean both \"unstability/unsoundness\" and \"compile time regressions\", having an enum where we had:</p>\n<ul>\n<li>\"Unstability/Unsoundness\"</li>\n<li>\"Compile Time Improvement for Debug\"</li>\n<li>\"Compile Time Improvement/Runtime improvement for Release\"</li>\n</ul>",
        "id": 198455472,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590161651
    },
    {
        "content": "<p>Because there are sound opts in level 2</p>",
        "id": 198455502,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590161671
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116083\">pnkfelix</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198455464\">said</a>:</p>\n<blockquote>\n<p>(anyone mind if I rename this topic to use \"CGU\" instead of spelling it out? Its very long in the side bar at the moment and I'd like to add other topics that are also CGU releated)</p>\n</blockquote>\n<p>Oh, I spelled it out so that people not familiar with it could understand what we were talking about :)</p>",
        "id": 198455584,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590161718
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116015\">Alex Crichton</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCGU.20Partitioning.5D.20Debug.20vs.20Release/near/198455337\">said</a>:</p>\n<blockquote>\n<p>FWIW I see y'all talking a lot about cgus and partitioning, and I know a fair bit about what we currently do and would be more than happy to answer questions or talk about it. I don't have a ton of time to implement changes but brain dumps are easier. Feel free to CC me if I can help!</p>\n</blockquote>\n<p>Thanks Alex, that's super helpful!</p>",
        "id": 198455627,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161748
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116107\">davidtwco</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCGU.20Partitioning.5D.20Debug.20vs.20Release/near/198454899\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCode.20Generation.20Unit.20Partitioning.5D.20Debug.20vs.20Release/near/198454530\">said</a>:</p>\n<blockquote>\n<p>MIR inlining is always disabled</p>\n</blockquote>\n<p>Do you think inlining in the MIR before partitioning - so that inlining isn't a concern at all during partitioning - could be worthwhile?</p>\n</blockquote>\n<p>I think that is an interesting idea but I'm not sure it would pay off in debug mode where LLVM doesn't inline anyway. For release? Yeah, I think it would.</p>",
        "id": 198455783,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161814
    },
    {
        "content": "<p>I've done perf runs in the past with the inliner switched on and there are performance improvements.</p>",
        "id": 198455819,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161834
    },
    {
        "content": "<p>OH. We should definitely have this distinction then. Should I open a topic in wg-mir-opt?</p>",
        "id": 198455879,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590161869
    },
    {
        "content": "<p>Seems good, yeah!</p>",
        "id": 198455895,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590161879
    },
    {
        "content": "<p>Oh, you mean fully replace LLVM's inliner with the MIR inliner?</p>",
        "id": 198455973,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1590161906
    },
    {
        "content": "<p>I just meant running it in addition to LLVM's since theirs can probably do things ours can't because of query cycles.</p>",
        "id": 198456754,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590162292
    },
    {
        "content": "<p>But for polymorphic functions, if we can generate better MIR that leaves them with less to do, that should be a win.</p>",
        "id": 198456823,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1590162328
    },
    {
        "content": "<p>(and also inlining post-llvm optimizations is better, e.g. because it's monomorphized \"more\")</p>",
        "id": 198456829,
        "sender_full_name": "simulacrum",
        "timestamp": 1590162334
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCGU.20Partitioning.5D.20Debug.20vs.20Release/near/198456829\">said</a>:</p>\n<blockquote>\n<p>(and also inlining post-llvm optimizations is better, e.g. because it's monomorphized \"more\")</p>\n</blockquote>\n<p>Wait, I don't 100% understand what you mean here. Why is it better post-llvm opts? Sorry, I'm a bit sleep deprived today.</p>",
        "id": 198457649,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590162701
    },
    {
        "content": "<p>For those interested in following up on the mir-opts specific conversation, here you go:<br>\n<a href=\"#narrow/stream/189540-t-compiler.2Fwg-mir-opt/topic/Debug.20vs.20Release.20opts\">https://rust-lang.zulipchat.com/#narrow/stream/189540-t-compiler.2Fwg-mir-opt/topic/Debug.20vs.20Release.20opts</a></p>",
        "id": 198457875,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590162792
    },
    {
        "content": "<p>Yeah that makes sense, but it wouldn't resolve any of the interactions with partitioning, which was mentioned above</p>",
        "id": 198458103,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1590162897
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"211727\">Jonas Schievink</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCGU.20Partitioning.5D.20Debug.20vs.20Release/near/198458103\">said</a>:</p>\n<blockquote>\n<p>Yeah that makes sense, but it wouldn't resolve any of the interactions with partitioning, which was mentioned above</p>\n</blockquote>\n<p>What were you answering to here? Sorry, I think I'm not following where the replies lie anymore &gt;.&lt;</p>",
        "id": 198459008,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590163299
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"212698\">Félix Fischer</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCGU.20Partitioning.5D.20Debug.20vs.20Release/near/198457649\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCGU.20Partitioning.5D.20Debug.20vs.20Release/near/198456829\">said</a>:</p>\n<blockquote>\n<p>(and also inlining post-llvm optimizations is better, e.g. because it's monomorphized \"more\")</p>\n</blockquote>\n<p>Wait, I don't 100% understand what you mean here. Why is it better post-llvm opts? Sorry, I'm a bit sleep deprived today.</p>\n</blockquote>\n<p>I mean that LLVM's inlining is better able to see, in theory, that e.g. the function being inlined has been removed entirely because it had some complicated logic that worked out to <code>return false;</code> or so</p>",
        "id": 198459253,
        "sender_full_name": "simulacrum",
        "timestamp": 1590163386
    },
    {
        "content": "<p>I was referring to the response to:</p>\n<blockquote>\n<p>Do you think inlining in the MIR before partitioning - so that inlining isn't a concern at all during partitioning - could be worthwhile?</p>\n</blockquote>",
        "id": 198459260,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1590163389
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCGU.20Partitioning.5D.20Debug.20vs.20Release/near/198459253\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"212698\">Félix Fischer</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCGU.20Partitioning.5D.20Debug.20vs.20Release/near/198457649\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCGU.20Partitioning.5D.20Debug.20vs.20Release/near/198456829\">said</a>:</p>\n<blockquote>\n<p>(and also inlining post-llvm optimizations is better, e.g. because it's monomorphized \"more\")</p>\n</blockquote>\n<p>Wait, I don't 100% understand what you mean here. Why is it better post-llvm opts? Sorry, I'm a bit sleep deprived today.</p>\n</blockquote>\n<p>I mean that LLVM's inlining is better able to see, in theory, that e.g. the function being inlined has been removed entirely because it had some complicated logic that worked out to <code>return false;</code> or so</p>\n</blockquote>\n<p>Ahh! I see. But this is something that we are also able to do at MIR level. Specially with some of the recent opts, I think we are really close to this exact feature.</p>\n<p>There's also two or three things I think?</p>\n<ol>\n<li>The fact that we have more information than LLVM does, so most of the opts that we and LLVM both have, happen faster on our side.</li>\n<li>That this more or less depends on the order you apply optimizations in.</li>\n<li>How prevalent is this case in real codebases? Aren't most functions not reducible to constants?</li>\n</ol>\n<p>Anywho. I think I owe you an illustration of where we stand here in mir-opts:</p>\n<ul>\n<li>A recent PR I did implemented constant propagation into function call arguments.</li>\n<li>We have unstable function inlining in mir-opts, which seems to be close to completion?</li>\n<li>Constant propagation and folding has progressed a lot lately. We're almost at feature completion, I think. What we lack today is control-flow aware propagation (which I plan on working during the following months), which should complete this optimization branch.</li>\n<li>NRVO opts are WIP, but we're working on it.</li>\n</ul>\n<p>Thing is, I think with those four things you can basically have exactly the same transformation you speak of! So there. I hope I was not too rambly, but I wanted to illustrate that this kind of optimization is also approaching MIR :3</p>",
        "id": 198460377,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590163888
    },
    {
        "content": "<p>We're not trying to nor do I think we can with the small amount of work we've put in match LLVM's insight and ability to remove code -- that's just not really feasible with the tiny amount of resources we've dedicated so far. I do think we can do a lot (and are doing a lot) though!</p>",
        "id": 198460605,
        "sender_full_name": "simulacrum",
        "timestamp": 1590163979
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"211727\">Jonas Schievink</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCGU.20Partitioning.5D.20Debug.20vs.20Release/near/198459260\">said</a>:</p>\n<blockquote>\n<p>I was referring to the response to:</p>\n<blockquote>\n<p>Do you think inlining in the MIR before partitioning - so that inlining isn't a concern at all during partitioning - could be worthwhile?</p>\n</blockquote>\n</blockquote>\n<p>Ahh. I see ^^<br>\n<span class=\"user-mention\" data-user-id=\"116107\">@davidtwco</span> they were answering to you there. I'm tagging you so that you don't miss it :)</p>",
        "id": 198460697,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590164031
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/131828-t-compiler/topic/.5BCGU.20Partitioning.5D.20Debug.20vs.20Release/near/198460605\">said</a>:</p>\n<blockquote>\n<p>We're not trying to nor do I think we can with the small amount of work we've put in match LLVM's insight and ability to remove code -- that's just not really feasible with the tiny amount of resources we've dedicated so far. I do think we can do a lot (and are doing a lot) though!</p>\n</blockquote>\n<p>I do agree :)</p>",
        "id": 198460769,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590164059
    },
    {
        "content": "<p>Well, still, I think this question has kind of a murky answer... in the sense that we probably need benchmarking to see the nuances</p>",
        "id": 198460978,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590164151
    },
    {
        "content": "<p>(<span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span>)</p>",
        "id": 198461000,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1590164159
    },
    {
        "content": "<p>I would love to see the performance numbers on a prototype that only pays attention to <code>inline(always)</code>, and doesn't mind generating a large number of CGUs.</p>",
        "id": 198483170,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590175016
    },
    {
        "content": "<p>The preliminary prototype numbers posted earlier looked great.</p>",
        "id": 198483192,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590175028
    },
    {
        "content": "<p>And I definitely agree with the premise that debug should be happy to trade more runtime performance for faster compilation.</p>",
        "id": 198483227,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590175046
    },
    {
        "content": "<p>(Within reason.)</p>",
        "id": 198483233,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1590175049
    }
]