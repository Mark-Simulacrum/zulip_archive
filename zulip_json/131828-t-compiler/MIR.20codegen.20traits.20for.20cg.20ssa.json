[
    {
        "content": "<p>For my codegen, one of the issues i have with cg_ssa is that i would like to control some parts of the mir lowering process, for example, to optimize thread index calculation (for the gpu), optimize out bounds checks better, and make shared mem codegen easier. However, this cannot really be done through cg_ssa because cg_ssa is basically \"opaque\" to the original MIR and the lowering process. So i was thinking, would it be acceptable to refactor cg_ssa a little bit to use traits for the MIR lowering too?<br>\nFor example, a <code>LowerMir</code> or <code>LowerStmt</code> trait, then cg_ssa defaults to its own MIR lowering struct that implements that, but also allows you to override it with your own, as well as supplement impls with cg_ssa's lowering (for example, preprocessing a stmt before giving it to cg_ssa).<br>\nThis would not break existing code, it would only supplement existing code, allowing users to potentially handle more exotic codegen cases. I am aware that it is possible to just call the cg_ssa driver for codegenning individual functions, but cg_ssa has a lot of logic that is not really feasible or useful to reimplement.<br>\nMoreover, this may help cg_gcc in refactoring certain cases that are hard to handle for libgccjit, what do you think <span class=\"user-mention\" data-user-id=\"404242\">@antoyo</span> ?</p>\n<p>what do you think <span class=\"user-mention\" data-user-id=\"133247\">@bjorn3</span> <span class=\"user-mention\" data-user-id=\"123586\">@nagisa</span> ?</p>",
        "id": 257583658,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1634236586
    },
    {
        "content": "<p>In my case, it could help in some cases, but it would feel more like a hack. What I really need to do is to fix the actual cg_ssa API.</p>",
        "id": 257584764,
        "sender_full_name": "antoyo",
        "timestamp": 1634237046
    },
    {
        "content": "<p>I see, yeah for cg_gccâ€™s case the actual API being more specific in terms of stuff like values would help, for my codegen having more control over analyzing gpu kernels would help a lot</p>",
        "id": 257585906,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1634237494
    },
    {
        "content": "<p>For context, the issues im having with shared mem on the gpu is:</p>\n<ul>\n<li>for static shared mem, libnvvm/llvm expects you to declare an extern variable in the shared addrspace, this is a bit hard to do because i need to tell the codegen to somehow generate a global every time the user calls a function. This can prob be done by \"intercepting\" calls to a special intrinsic like <code>__nvvm_get_shared_mem_ptr</code>, but its a bit of a hack.</li>\n<li>for dynamic shared mem, this one is a bit more exotic, because in CUDA, if you ask for dynamic shared mem multiple times in a kernel, it yields the same exact pointer. Therefore i need to somehow limit accesses to a function to get the shared mem, or a mutable ref to it may be aliased.</li>\n</ul>\n<p>I would also like to potentially analyze access patterns for buffers and encoded them in the final ptx to make kernel launches safer. As well as eliminate multiple bounds checks by verifying launch dimensions once.</p>",
        "id": 257590192,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1634239197
    }
]