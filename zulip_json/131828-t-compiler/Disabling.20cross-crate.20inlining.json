[
    {
        "content": "<p>Is it possible to somehow get rustc to just not do cross-crate inlining with <code>#[inline]</code>? I.e. telling it to still keep the attribute but not  include the MIR of the functions in the rlib? <br>\nMy CUDA codegen essentially does LTO every time, so it does not need rustc duplicating inline functions, and it may yield a good speedup to tell rustc to not do that, but because this is a core thing rustc does, im not quite sure if it is possible to get rustc to just not do that. Maybe it could be querified if it isn't already, then the codegen overrides the query?</p>",
        "id": 263629868,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1638561426
    },
    {
        "content": "<p>I guess i could kind of hack it together in the codegen by overriding such function definitions when defining mono items, but that seems like a hack, it would be better if rustc didnt try to do it in the first place</p>",
        "id": 263630267,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1638561621
    },
    {
        "content": "<p>AFAIK there isn't any way to do this without modifying rustc itself.</p>",
        "id": 263653086,
        "sender_full_name": "bjorn3",
        "timestamp": 1638565617
    },
    {
        "content": "<p>Disabling <code>#[inline]</code> may actually slow down compilation as it requires a lot of functions to be unconditionally codegened, even if they aren't used in the first place. This includes 128bit int ops, which may crash nvvm.</p>",
        "id": 263653267,
        "sender_full_name": "bjorn3",
        "timestamp": 1638565706
    },
    {
        "content": "<p>How would that cause them to be unconditionally codegenned? They are already codegenned into LLVM IR</p>",
        "id": 263654115,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1638566187
    },
    {
        "content": "<p>i fixed 128bit things so that should not be a problem</p>",
        "id": 263654150,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1638566209
    },
    {
        "content": "<p>Oh you mean they arent codegenned since something upstream will codegen it if it needs it</p>",
        "id": 263654587,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1638566468
    },
    {
        "content": "<blockquote>\n<p>Oh you mean they arent codegenned since something upstream will codegen it if it needs it</p>\n</blockquote>\n<p>Exactly!</p>",
        "id": 263692432,
        "sender_full_name": "bjorn3",
        "timestamp": 1638606231
    },
    {
        "content": "<p>Im not quite convinced that thats as big of an issue here, because probably the slowest part is linking together every bitcode file from the rlibs. I am not codegenning to PTX for every crate (this is what CUDA C++ does). The codegen part is actually really fast because its only codegenning functions that are actually used by kernels</p>",
        "id": 263723942,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1638642261
    },
    {
        "content": "<p>This also makes me think it might be worth it to just not optimize before libnvvm, because libnvvm does its own opts, and if i optimized on the final small llvm module itd be much faster</p>",
        "id": 263723964,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1638642329
    },
    {
        "content": "<p>I should really time my codegen...</p>",
        "id": 263724400,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1638642914
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"276242\">Riccardo D'Ambrosio</span> <a href=\"#narrow/stream/131828-t-compiler/topic/Disabling.20cross-crate.20inlining/near/263723964\">said</a>:</p>\n<blockquote>\n<p>This also makes me think it might be worth it to just not optimize before libnvvm, because libnvvm does its own opts, and if i optimized on the final small llvm module itd be much faster</p>\n</blockquote>\n<p>It might still be helpful to <code>-O1</code> optimize (or a similar custom pass list, maybe with the commonality between <code>-O1</code> and <code>-Os</code>), just to clean up a bunch of the extra noise in the IR.  I wouldn't be surprised if a couple of cheap passes could get the volume of IR down by half, and thus be a net win for the serialization over to nvvm.</p>",
        "id": 263731547,
        "sender_full_name": "scottmcm",
        "timestamp": 1638652277
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125270\">@scottmcm</span> I already run global DCE before giving it to libnvvm, so the IR shrinks to like -95%</p>",
        "id": 263732348,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1638653216
    },
    {
        "content": "<p>anything not directly or indirectly used by a kernel is eliminated</p>",
        "id": 263732372,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1638653243
    }
]