[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span> is there a single scenario where invoking a collector in check mode is a correct course of action?</p>",
        "id": 158994456,
        "sender_full_name": "nagisa",
        "timestamp": 1550683355
    },
    {
        "content": "<p>I figure that in case there isn't one it would make sense to add the condition inside the collector query.</p>",
        "id": 158994510,
        "sender_full_name": "nagisa",
        "timestamp": 1550683413
    },
    {
        "content": "<p>@mw ping.</p>",
        "id": 159084725,
        "sender_full_name": "nagisa",
        "timestamp": 1550768259
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span> do you have any idea why cargo check would end up invoking the full codegen?</p>",
        "id": 159084740,
        "sender_full_name": "nagisa",
        "timestamp": 1550768277
    },
    {
        "content": "<p>I had hoped that fixing metadata generation code to not use the optimising context would work.</p>",
        "id": 159084790,
        "sender_full_name": "nagisa",
        "timestamp": 1550768292
    },
    {
        "content": "<p>but now it is invoking the regular one...</p>",
        "id": 159084801,
        "sender_full_name": "nagisa",
        "timestamp": 1550768300
    },
    {
        "content": "<p>but this in general goes against my intuition about what cargo check ought to be doing</p>",
        "id": 159085174,
        "sender_full_name": "nagisa",
        "timestamp": 1550768568
    },
    {
        "content": "<p>I think it basically uses the existing pipeline to pack the metadata into the rlib</p>",
        "id": 159085180,
        "sender_full_name": "mw",
        "timestamp": 1550768572
    },
    {
        "content": "<p>(i.e. generate metadata and quit)</p>",
        "id": 159085182,
        "sender_full_name": "nagisa",
        "timestamp": 1550768573
    },
    {
        "content": "<p>you should be able to just add an early exit in the query provider</p>",
        "id": 159085244,
        "sender_full_name": "mw",
        "timestamp": 1550768637
    },
    {
        "content": "<p>doing the same check as the metadata encoder does</p>",
        "id": 159085305,
        "sender_full_name": "mw",
        "timestamp": 1550768668
    },
    {
        "content": "<p>but I agree that this isn't the cleanest setup</p>",
        "id": 159085316,
        "sender_full_name": "mw",
        "timestamp": 1550768686
    },
    {
        "content": "<p>yaeh so I was wondering, why not add such an early exit to the partition query in the first place.</p>",
        "id": 159085450,
        "sender_full_name": "nagisa",
        "timestamp": 1550768796
    },
    {
        "content": "<p>it seems fine for me for partitioner to return an empty set of CUs when it knows that it would fail collecting either way</p>",
        "id": 159085481,
        "sender_full_name": "nagisa",
        "timestamp": 1550768828
    },
    {
        "content": "<p>for now Iâ€™ll just make sure that non-optimising context is used in ssa backend as well</p>",
        "id": 159085603,
        "sender_full_name": "nagisa",
        "timestamp": 1550768922
    },
    {
        "content": "<p>It's a bit tricky. Technically we don't know that it will fail. We know the current build is only producing metadata data but upstream crates might have been compiled the regular way in which case everything would work fine.</p>",
        "id": 159138750,
        "sender_full_name": "mw",
        "timestamp": 1550822755
    },
    {
        "content": "<p>in practice this does not usually occur</p>",
        "id": 159138805,
        "sender_full_name": "mw",
        "timestamp": 1550822794
    }
]