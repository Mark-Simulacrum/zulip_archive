[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> Since you asked for \"small\" ideas around async improvements in your latest interview post: Here is one that I started writing up a while ago, but haven't submitted as an RFC so far: <a href=\"https://github.com/Matthias247/rfcs/pull/1/files?short_path=36fc3ab#diff-36fc3abc58ca828473861e924cd90cf4\" title=\"https://github.com/Matthias247/rfcs/pull/1/files?short_path=36fc3ab#diff-36fc3abc58ca828473861e924cd90cf4\">https://github.com/Matthias247/rfcs/pull/1/files?short_path=36fc3ab#diff-36fc3abc58ca828473861e924cd90cf4</a></p>\n<p>The idea is to have a an additional type of async functions which run to completion. Besides working more like synchronous functions, those could also abstract around completion based IO (like io_uring) without resorting to owned buffer types, and solve the \"leapokalypse\" issues which prevented us from offering scoped async tasks that are able to borrow data in their parent tasks scope (<a href=\"https://github.com/tokio-rs/tokio/issues/1879\" title=\"https://github.com/tokio-rs/tokio/issues/1879\">https://github.com/tokio-rs/tokio/issues/1879</a>). </p>\n<p>I think the implementation effort might be rather small - likely smaller than any kind of async drop. But I would love to get some feedback from you and <span class=\"user-mention\" data-user-id=\"116883\">@tmandry</span> on the feasibility on the compiler side.</p>",
        "id": 196035816,
        "sender_full_name": "Matthias247",
        "timestamp": 1588399183
    },
    {
        "content": "<p>I did indeed! But I'm not sure this qualifies as small -- I'm skimming now, but adding a new kind of future trait seems like a quite large change to me.</p>",
        "id": 196220181,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1588616613
    },
    {
        "content": "<p>(The linked text says <code>RunToCompletionFuture</code> is a type, but I think it means trait.)</p>",
        "id": 196220288,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1588616654
    },
    {
        "content": "<p>It's not minimal. But I do actually feel it's smaller than the necesssary changes that would make any kind of async drop or lifecycle traits helpful for real applications. And those had been mentioned in the blog post</p>",
        "id": 196228577,
        "sender_full_name": "Matthias247",
        "timestamp": 1588620498
    },
    {
        "content": "<p>I have to respond to that users thread -- I don't quite understand the believe that the async-drop changes are so massive, though I can believe that it's not <em>useful</em></p>",
        "id": 196230222,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1588621260
    },
    {
        "content": "<blockquote>\n<p>I don't quite understand the believe that the async-drop changes are so massive</p>\n</blockquote>\n<p>I think that will just depend about which part we are talking about. Maybe it's not a big change in the compiler (would it care about it at all? I don't know) -  or the standard library. But having to change every single combinator in Rusts ecosystem to make it somewhat useful is a gigantic task.</p>\n<p>And for the case someone forgets to implement such a combinator, all the methods that use async drop would need to implement async drop in addition to a safe synchronous drop. That introduces additional work for every library author afterwards, and raise the question why to do it at all.</p>",
        "id": 196231492,
        "sender_full_name": "Matthias247",
        "timestamp": 1588621862
    },
    {
        "content": "<p>they have to implement synchronous drop regardless, I believe</p>",
        "id": 196231805,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1588622012
    },
    {
        "content": "<p>I don't really think there's a way around that except (as you are proposing) changing the underlying model completely</p>",
        "id": 196231840,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1588622034
    },
    {
        "content": "<p>I'm pushing this one up, since I'm still very interested in seeing this included. I'm rather motivated by some the discussions like <a href=\"#narrow/stream/187312-wg-async-foundations/topic/mutex-usage\">https://rust-lang.zulipchat.com/#narrow/stream/187312-wg-async-foundations/topic/mutex-usage</a> as well as <a href=\"https://internals.rust-lang.org/t/pre-pre-rfc-unsafe-futures/13186\">https://internals.rust-lang.org/t/pre-pre-rfc-unsafe-futures/13186</a> that this is the right thing to do. </p>\n<p>Just like <span class=\"user-mention\" data-user-id=\"137147\">@Didrik Nordstrom</span>  my experience is that most async users are not aware about the special cancellation semantics and all the nitty-gritty details of how async/await works. They just want to write code as usual, and place async annotations on it to make sure code runs on an eventloop. <code>async-trait</code> is a huge success and enabler for getting us there. But other semantic differences - like the cancellation one - still makes it tricky to convert synchronous code into asynchronous one and be assured things still work.</p>\n<p>I also feel like this is a blocker to for building a good framework around structured concurrency (which was discussed in <a href=\"https://github.com/tokio-rs/tokio/issues/1879\">https://github.com/tokio-rs/tokio/issues/1879</a> but then rejected due to issues with synchronous drop). <br>\nImho enabling structured concurrency would be huge plus for enabling more correct concurrent applications, since it avoids certain kinds of race conditions and runaway background tasks which are non concurrency limited. Swift is now also heading into this direction, which should work out fine for them due to non cancellable tasks: <a href=\"https://github.com/DougGregor/swift-evolution/blob/06fd6b3937f4cd2900bbaf7bb22889c46b5cb6c3/proposals/nnnn-structured-concurrency.md\">https://github.com/DougGregor/swift-evolution/blob/06fd6b3937f4cd2900bbaf7bb22889c46b5cb6c3/proposals/nnnn-structured-concurrency.md</a></p>\n<p><span class=\"user-mention\" data-user-id=\"137147\">@Didrik Nordstrom</span> , <span class=\"user-mention\" data-user-id=\"116883\">@tmandry</span> , <span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> Let me please know if you are interested in this, and what the best way is go forward here. Happy to have a meeting to talk about this, before  just blindly submitting the RFC.</p>\n<p>I know that on the AWS end <span class=\"user-mention\" data-user-id=\"207781\">@Lucio Franco</span> also might be interested to be involved in this.</p>",
        "id": 219657434,
        "sender_full_name": "Matthias247",
        "timestamp": 1607718338
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"204219\">@Matthias247</span> Sorry for being slow to respond here. My current thinking is that while the model we have can be surprising compared to other languages, I haven't personally seen a convincing argument that it's fundamentally flawed and we need to make a new one. Though it's possible one might exist, I'm limited in my perspective. Adding a new \"function color\" or type linearization would create a lot of churn and would have to be very well motivated. The biggest use case I've seen cited is completion queue / shared buffer ownership semantics, where the approach taken by ringbahn seems promising to me.</p>",
        "id": 221376030,
        "sender_full_name": "tmandry",
        "timestamp": 1609546576
    },
    {
        "content": "<p>Thanks for the response <span class=\"user-mention\" data-user-id=\"116883\">@tmandry</span> . I think \"completion based IO\" things are only  one part of the motivation. But in the meantime I'm actually more interested in the additional guarantees that potentially important cleanup code is really run, and in enabling structured concurrency.</p>\n<p>The \"Async Drop\" discussion definitely showed there was more interest in the problem. And I am not sure why this model had more interest/support so far despite having far weaker guarantees and being less ergonomic than this model (where we don't need manually written futures and <code>poll_drop</code> functions - just regular code which could be a 1:1 migration of the synchronous variant).</p>\n<p>Regarding data and motivation: I so far audited a couple of internal codebases using Rust + async/await (\"internal\" here mostly means being written by people who are not the well-known Rust async-experts). None of them had pre-cautions against tasks being forcefully cancelled, e.g by using destructors for everything -so I don't think this \"feature\" of async/await is well-known. These codebases also often lacked structured ways to shut down / cancel tasks. This is necessary in many production environments to prevent resource exhaustion - however I think with the current tools people simply grab for <code>task::spawn</code>, create run-away tasks and don't care about it until they hit the first production issue. To prevent this I would still like to introduce better ways to manage the lifetime of tasks overall. Structured concurrency, as available in Kotlin and now also adopted in async Swift seems like the way to go. This would also work without run to completion tasks - but static guarantees seem a lot more preferrable for most people.</p>\n<p>I might also work on a survey to gather more feedback about how many people are aware about the cancellation behavior, and how they handle it.</p>",
        "id": 221483035,
        "sender_full_name": "Matthias247",
        "timestamp": 1609725900
    },
    {
        "content": "<p>Thanks for clarifying. I do really think we need to get better at documenting this, in the async book and standard library docs to start.</p>",
        "id": 221496192,
        "sender_full_name": "tmandry",
        "timestamp": 1609745993
    },
    {
        "content": "<p>And perhaps that should include emphasis on patterns like RAII.</p>",
        "id": 221496330,
        "sender_full_name": "tmandry",
        "timestamp": 1609746170
    },
    {
        "content": "<p>I think lack of async drop is a problem we need to solve</p>",
        "id": 221496529,
        "sender_full_name": "tmandry",
        "timestamp": 1609746422
    },
    {
        "content": "<p>I read the <code>poll_drop</code> proposal and I think it's super clever to solve many problems in a backwards compatible way. Do y'all know what happens in the early return case, i.e. using <code>?</code> or other ways of short-circuiting control flow? Is <code>poll_drop</code> meant to be invoked in these cases as well?</p>",
        "id": 222010174,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610058113
    },
    {
        "content": "<p>That said, <code>poll_drop</code> leaves the other issues unresolved. Me and Tyler talked about this recently. There are numerous issues related:</p>\n<ul>\n<li>scoped threads, was removed from Rust because you can create a reference cycle of join handles, which can be unsafe: <a href=\"https://github.com/rust-lang/rust/issues/24292\">https://github.com/rust-lang/rust/issues/24292</a></li>\n<li>mutex guards (even synchronous) can have their critical section interrupted in the case of early returns.</li>\n</ul>\n<p>Both of these issues can be mitigated with an extra closure (see <a href=\"https://docs.rs/crossbeam/0.8.0/crossbeam/thread/fn.scope.html\">https://docs.rs/crossbeam/0.8.0/crossbeam/thread/fn.scope.html</a>). Crossbeam also provides a more general scope util: <a href=\"https://docs.rs/crossbeam/0.8.0/crossbeam/fn.scope.html\">https://docs.rs/crossbeam/0.8.0/crossbeam/fn.scope.html</a></p>\n<p>I think what we need, generally, is types that cannot be dropped implicitly -- a way to enforce that destruction is explicit and covered on every code path, except while panicking. In that case you _only_ want to clean up resources, and possibly poison some resource. But panicking is not the typical case.</p>",
        "id": 222013455,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610060038
    },
    {
        "content": "<p>A type that must be destructed explicitly could not be inserted into an Rc/Arc - that follows naturally. It solves the scoped thread problem.</p>",
        "id": 222013634,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610060150
    },
    {
        "content": "<p>I had quite different impression with regards to backward compatibility, and think that <code>poll_drop</code> as proposed would be significant breaking change due to extra yield points it introduces. I consider this aspect to be major unresolved issue.</p>",
        "id": 222014553,
        "sender_full_name": "tm",
        "timestamp": 1610060663
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"352985\">@tm</span> Yes, but at least it only applies to manual future impls and combinators, right?</p>",
        "id": 222019280,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610064222
    },
    {
        "content": "<p>BTW When I say _destructed explicitly_, I mean that one must use a <code>fn foo(self, ..)</code> method under normal (non-panic) circumstances. I don't have a proposal for how it would interact with <code>Drop</code>.</p>",
        "id": 222019446,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610064338
    },
    {
        "content": "<p>It is part of Drop so it applies to everything not known to be Copy.</p>",
        "id": 222019520,
        "sender_full_name": "tm",
        "timestamp": 1610064377
    },
    {
        "content": "<p>In async context dropping a generic T would introduce a yield point. It is not even clear why dropping a String or Vec&lt;u8&gt; wouldn't introduce one.</p>",
        "id": 222020434,
        "sender_full_name": "tm",
        "timestamp": 1610065116
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"352985\">tm</span> <a href=\"#narrow/stream/187312-wg-async-foundations/topic/run.20to.20completion.20async.20fn/near/222014553\">said</a>:</p>\n<blockquote>\n<p>I had quite different impression with regards to backward compatibility, and think that <code>poll_drop</code> as proposed would be significant breaking change due to extra yield points it introduces. I consider this aspect to be major unresolved issue.</p>\n</blockquote>\n<p>The number of yield points of an async fn shouldn't be considered stable, imo</p>",
        "id": 222020705,
        "sender_full_name": "tmandry",
        "timestamp": 1610065388
    },
    {
        "content": "<p>The presence of absence of yield points influences what becomes part of generator, and whether resulting future is Send etc.</p>",
        "id": 222020867,
        "sender_full_name": "tm",
        "timestamp": 1610065505
    },
    {
        "content": "<p>I see. In theory I <em>think</em> we can solve this with better analysis</p>",
        "id": 222020963,
        "sender_full_name": "tmandry",
        "timestamp": 1610065586
    },
    {
        "content": "<p>but I'll have to think about it more</p>",
        "id": 222020978,
        "sender_full_name": "tmandry",
        "timestamp": 1610065601
    },
    {
        "content": "<p>though I can see how generics would be a problem, hm</p>",
        "id": 222021007,
        "sender_full_name": "tmandry",
        "timestamp": 1610065637
    },
    {
        "content": "<p>Hmm, does this illustrate the concern?</p>\n<div class=\"codehilite\"><pre><span></span><code>async fn foo&lt;T&gt;() -&gt; bool {\n  let t = T;\n  true\n  // implicit yield point here, so the generator must store a ref to t, which can affect sendness\n}\n</code></pre></div>",
        "id": 222022221,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610066712
    },
    {
        "content": "<p>right</p>",
        "id": 222026104,
        "sender_full_name": "tmandry",
        "timestamp": 1610070870
    },
    {
        "content": "<p>found the original thread: <a href=\"https://github.com/rust-lang/rfcs/pull/2958#discussion_r457294076\">https://github.com/rust-lang/rfcs/pull/2958#discussion_r457294076</a></p>",
        "id": 222029363,
        "sender_full_name": "tmandry",
        "timestamp": 1610074765
    },
    {
        "content": "<p>I don't think async drop necessarily had a backward compatibility problem. But it also provided zero guarantees that it actually solves any issue. If someone had any manual implemented future in their code (e.g. <code>select!</code> or just <code>FutureExt::fuse</code>), the drop feature might have been lost without anyone getting aware about it. You can't really expect every developer to remember which combinators or functions support async drop and which not.</p>\n<p>This proposal avoids the issue. And it also allows proper scoped tasks (like the crossbeam ones) in the async world.</p>",
        "id": 222040848,
        "sender_full_name": "Matthias247",
        "timestamp": 1610085272
    },
    {
        "content": "<p>I also don't think this proposal is less backward compatible. Every existing code will still work. New code (using  <code>async completion fn</code> or however its called) can continue to use all existing code out there. The only thing which is required is new executors which can support spawning such a function. And this shouldn't be a huge change (for a runtime like tokio it mainly means the runtime would need to block until tasks run to completion in the destructor and wait for the finish, which it partially already does since not all tasks are cancellable)</p>",
        "id": 222040995,
        "sender_full_name": "Matthias247",
        "timestamp": 1610085509
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"204219\">@Matthias247</span> I will read your proposal again. I came from a slightly different perspective -- this lack of customizable destruction in Rust has bothered me also outside of async. I wrote up a very drafty vision: <a href=\"https://hackmd.io/gVMh_ZC_Qcm9Y4x2D6hE-g\">https://hackmd.io/gVMh_ZC_Qcm9Y4x2D6hE-g</a></p>",
        "id": 222128114,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610141176
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"204219\">Matthias247</span> <a href=\"#narrow/stream/187312-wg-async-foundations/topic/run.20to.20completion.20async.20fn/near/222040995\">said</a>:</p>\n<blockquote>\n<p>I also don't think this proposal is less backward compatible. Every existing code will still work. New code (using  <code>async completion fn</code> or however its called) can continue to use all existing code out there. The only thing which is required is new executors which can support spawning such a function. And this shouldn't be a huge change (for a runtime like tokio it mainly means the runtime would need to block until tasks run to completion in the destructor and wait for the finish, which it partially already does since not all tasks are cancellable)</p>\n</blockquote>\n<p>It would also require combinators to support it, or they wouldn't be usable from an <code>async completion</code> context, as I understand it.</p>",
        "id": 222132662,
        "sender_full_name": "tmandry",
        "timestamp": 1610143691
    },
    {
        "content": "<p>Ok, I published my comments now.</p>",
        "id": 222139039,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610148363
    },
    {
        "content": "<p>Thanks Matthias.</p>",
        "id": 222139046,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610148369
    },
    {
        "content": "<p>I'll paste my biggest concern here:</p>",
        "id": 222139076,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610148400
    },
    {
        "content": "<p>Unfortunately combinators are so deeply affected that the proposal becomes infeasible in its current state:</p>\n<p>Say a combinator like select: once returned from it, what happens to the unfinished future? Return to caller just like today? Who ensures the future is polled again before dropped?</p>\n<p>Same for FuturesUnordered: Poll a couple of items out, but leave some inside, then drop it - compiler is none the wiser -- and the invariant is broken.</p>\n<p><strong>In general: A combinator that accepts completion futures must poll all of its inner futures to completion before returning from any of its async functions. It can neither store or return any incomplete futures because then they can be arbitrarily dropped.</strong></p>\n<p>Unfortunately, this gives us three bad options:</p>\n<ul>\n<li>Combinators disallow this - severely degrading their utility.</li>\n<li>Combinators allow this, but lose most of the guarantees of this proposal</li>\n<li>Drop-bombs - panic at runtime if futures and combinators are not polled to completion at drop-time.</li>\n</ul>\n<p>It all boils down to this existing drop-semantics we have today - whether we're in async or not. Hence, some rudimentary linear type features are necessary, as far as I can tell.</p>",
        "id": 222139091,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610148415
    },
    {
        "content": "<p>You can see combinators from 2 angles:</p>\n<ol>\n<li>Combinators which exist today (there is a lot in futures-rs, which was carried over from futures 1.0)</li>\n<li>Combinators which users really need in combination with run to completion functions.</li>\n</ol>\n<p>First of all users can continue to use all existing combinators, but not use them run to completion functions. That's ok - they can e.g. still use <code>futures::select</code> or <code>tokio::select</code> to wait on a socket and a timeout in parallel. Or on a channel. They just can't use it for combinating a completion fn with something else (like a timeout).</p>\n<p>For those combinations, I see 2 major use-cases -&gt; timeouts and cancellations. Where one is a particular use-case of the other.<br>\nFor thus, we would have specialized new combinator, like the timeout wrapper which does graceful cancellation.</p>\n<p>An improved verison of <code>FuturesUnordered</code> which is compatible with completion functions would be the structured concurrency Scope/WaitGroup/Nursery or however we call it. It allows to spawn N tasks, and when going out of scope does trigger a graceful cancellation and waits for all of them to complete. This was already implemented in <a href=\"https://github.com/tokio-rs/tokio/issues/1879\">https://github.com/tokio-rs/tokio/issues/1879</a> and <a href=\"https://github.com/tokio-rs/tokio/pull/2579\">https://github.com/tokio-rs/tokio/pull/2579</a> and can be easily carried over to support run to completion tasks.</p>\n<p>Swift really wants to do the same now with <a href=\"https://github.com/DougGregor/swift-evolution/blob/structured-concurrency/proposals/nnnn-structured-concurrency.md\">https://github.com/DougGregor/swift-evolution/blob/structured-concurrency/proposals/nnnn-structured-concurrency.md</a>. <code>Task.withGroup</code> is more or less just <code>FuturesUnordered</code> with run to completion tasks and graceful cancellation signalling.</p>",
        "id": 222140636,
        "sender_full_name": "Matthias247",
        "timestamp": 1610149881
    },
    {
        "content": "<p>I see, yes that could work -- need to take a look at that code, but the extra scope makes it pretty unergonomic - it's a critique I have against these articficial scopes in general, not just in this case. Brb, need to go to a meeting</p>",
        "id": 222141015,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610150243
    },
    {
        "content": "<p>Yeah, I think the scoping here is my main gripe - I think we can't predict what combinators are gonna be useful in the future, so it could be a large overhead. The scoping enforces a lexical structure -- which limits the use cases.</p>\n<p>Say I want to have a task that is owned by a type - created at construction and awaited during destruction.</p>",
        "id": 222144241,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610153625
    },
    {
        "content": "<p>Select could be used to multiplex over channels too (like in Go). The async stream next method should probably be a completion future?</p>",
        "id": 222144313,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610153705
    },
    {
        "content": "<p>But of course, +1 on structured concurrency in general.</p>",
        "id": 222144325,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610153729
    },
    {
        "content": "<p>And +1 on that futures should not be arbitrarily cancelled, like today.</p>",
        "id": 222144333,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610153755
    },
    {
        "content": "<p>If you have time, please check out the draft proposal I posted for ImplicitDrop (linear type support). There's quite some overlap. My hope is that the lexical scoping boilerplate and restriction can be avoided for improved flexibility. Happy to add more examples.</p>",
        "id": 222144530,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610153974
    },
    {
        "content": "<blockquote>\n<p>Select could be used to multiplex over channels too (like in Go).</p>\n</blockquote>\n<p>You can already do that! And you will continue to do so. There is no need for async channels/semaphores/mutexes/etc to become completion functions. They work fine the way they currently do, and support synchronous cancellation as expected. My challenges are really more on a higher layer, like cancelling a transaction in a distributed system which still has to do some (async) cleanup work. This isn't very well supported at the moment.</p>\n<blockquote>\n<p>The scoping enforces a lexical structure -- which limits the use cases.</p>\n</blockquote>\n<p>If you are concerned about the <code>.await</code> on the scope itself - I agree its not nice. If the language offered a <code>defer</code> it could probably be avoided - but I think this is an orthogonal effort to this one. <br>\nThe challenge without scopes is that leaks (either via <code>std::mem::forget</code> or implicit ones) prevent memory safety purely based on destructors. That's the same reason crossbeam scoped threads work, and the old <code>std</code> scoped threads have been removed. The whole leak/mem::forget topic is a terribly complex one and has been discussed to death - therefore I don't think we should get back to it :-) </p>\n<p>But I will take a look at your doc once I find some time</p>",
        "id": 222151770,
        "sender_full_name": "Matthias247",
        "timestamp": 1610164034
    },
    {
        "content": "<blockquote>\n<p>The whole leak/mem::forget topic is a terribly complex one and has been discussed to death - therefore I don't think we should get back to it :-)</p>\n</blockquote>\n<p>Heh, I know. However, I dug around in those threads and the decision was (a) in one case rushed, because of a 1.0 release and (b) there were many good arguments on both sides, and in the end the status quo won, to my understanding, <em>because</em> there weren't enough use cases. At the time you <em>could</em> argue that scoped threads were niche, perhaps... Today, with async present, that's no longer possible.</p>",
        "id": 222342495,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610391950
    },
    {
        "content": "<p>The closure scope workaround worked only because it hijacked the entire parent thread. That won't work for async in general (is this why your scoped tasks were rejected in the end by tokio?), <em>even if we're ok with the extra closure</em>.</p>",
        "id": 222342894,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610392122
    },
    {
        "content": "<p>I view this as important not just because futures are hard to use, but also because we can't have any shared references across tasks or threads. I don't know if you're as bothered as I am, but our code base is just full of refcounts. Arcs everywhere. Aside from the boilerplate, it's not zero-cost and its lack of a clear ownership structure is error prone -- the resulting leaks can lead to logical bugs..</p>",
        "id": 222343533,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610392454
    },
    {
        "content": "<p>Changed the semantics slightly and published pre-rfc here: <a href=\"https://internals.rust-lang.org/t/pre-rfc-leave-auto-trait-for-reliable-destruction/13825\">https://internals.rust-lang.org/t/pre-rfc-leave-auto-trait-for-reliable-destruction/13825</a></p>",
        "id": 222655444,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1610576620
    },
    {
        "content": "<p>Linking this here, because it's pretty cool. Kai Jewsen implemented the RFC contents via proc macros:<br>\n<a href=\"https://github.com/Matthias247/rfcs/pull/1#issuecomment-761803914\">https://github.com/Matthias247/rfcs/pull/1#issuecomment-761803914</a><br>\n<a href=\"https://docs.rs/completion/0.1.0/completion/index.html\">https://docs.rs/completion/0.1.0/completion/index.html</a></p>\n<p>And it's not just the Future, it's a complete ecosystem around it (with completion async traits, IO methods, streams, etc) <span aria-label=\"astonished\" class=\"emoji emoji-1f632\" role=\"img\" title=\"astonished\">:astonished:</span></p>",
        "id": 223059546,
        "sender_full_name": "Matthias247",
        "timestamp": 1610912751
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"137147\">@Didrik Nordstrom</span> </p>\n<blockquote>\n<p>I don't know if you're as bothered as I am, but our code base is just full of refcounts. Arcs everywhere. Aside from the boilerplate, it's not zero-cost and its lack of a clear ownership structure is error prone -- the resulting leaks can lead to logical bugs..</p>\n</blockquote>\n<p>It definitely happens with the current model. Even if they are not directly visible, they might be in the library types (e.g. FD handles, channels, timer handles, etc). I'm however only half worried about them being refcounts in general, and a bit more wary about the requirement for atomic refcounts everywhere since single-threaded (non-synchronized) <code>Future</code>s are not exactly the preferred and easy way. But that's a different story than this one :-) </p>\n<p>I will comment on the internals thread regarding your RFC. Overall I feel like it's wider and more general change, which comes with the usual challenges of these types of changes:</p>\n<ul>\n<li>It might be harder to understand on how it works and it can be used for the average user</li>\n<li>It's harder to predict whether it solves a specific problem very well. In this case I e.g. can't yet see how it solves <code>TaskGroup</code>s , since <code>panic!</code>s  are not yet covered.</li>\n</ul>",
        "id": 223060259,
        "sender_full_name": "Matthias247",
        "timestamp": 1610913738
    },
    {
        "content": "<p>Yeah, the atomics worry me too. But even without atomics, refcounts invalidates the cache lines.</p>",
        "id": 223169889,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1611009476
    },
    {
        "content": "<p>Thanks for the feedback on the pre-RFC. My focus now is to drive it to its best possible state. Once we have reviewed all relevant proposals, we could start a collaborative summary doc and involve a wider audience.</p>",
        "id": 223169963,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1611009569
    },
    {
        "content": "<p>The panic-unwind issues were introducing a lot of complexity indeed. Just updated the proposal. Now, panics work as usual.</p>",
        "id": 223170054,
        "sender_full_name": "Didrik Nordstrom",
        "timestamp": 1611009652
    }
]