[
    {
        "content": "<p>Hey <span class=\"user-mention\" data-user-id=\"312719\">@Xavier Denis</span> <span aria-label=\"wave\" class=\"emoji emoji-1f44b\" role=\"img\" title=\"wave\">:wave:</span></p>",
        "id": 204429332,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595255535
    },
    {
        "content": "<p><span aria-label=\"wave\" class=\"emoji emoji-1f44b\" role=\"img\" title=\"wave\">:wave:</span></p>",
        "id": 204429354,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595255548
    },
    {
        "content": "<p>this is mostly a reiteration of the questions i was raising in <a href=\"#narrow/stream/189540-t-compiler.2Fwg-mir-opt/topic/const.20prop.20into.20operands\">https://rust-lang.zulipchat.com/#narrow/stream/189540-t-compiler.2Fwg-mir-opt/topic/const.20prop.20into.20operands</a> and with <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span>  in DMs. But I'm curious how propagating constants into operands would cause partitioning changes that lead to 12% increase in build times</p>",
        "id": 204429399,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595255571
    },
    {
        "content": "<p>Yeah, it's a really interesting question!</p>",
        "id": 204429487,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595255610
    },
    {
        "content": "<p>and more specifically how can we debug this? It'd be interesting to see how the groups are generated</p>",
        "id": 204429489,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595255611
    },
    {
        "content": "<p>I'll try to explain what I've seen happen and why I think it's happening</p>",
        "id": 204429528,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595255630
    },
    {
        "content": "<p>because I fail to see how operand propagation would make a <code>println!</code> affect partitioning</p>",
        "id": 204429530,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595255631
    },
    {
        "content": "<p>the two seem... orthogonal</p>",
        "id": 204429595,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595255645
    },
    {
        "content": "<p>So, to give some back story, there are kind of two main factors to the partitioning system currently: what goes in a CGU and how big is the CGU. Initially what goes in the CGU is based on the Rust module. IIRC, for each module in the crate we generate two CGUs: one for code which is monomorphic to start with and one for monomorphic instantiations of polymorphic functions (ie, generic code). As for how big the CGU is, this is just the sum of the cost estimates for each item in the CGU. I believe currently, this just boils down to a \"count of MIR statements in the function\".</p>",
        "id": 204429951,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595255839
    },
    {
        "content": "<p>However, the actual number of CGUs we're limited to is fixed. I believe you can control this via a <code>-C</code> flag but the default is like <code>128</code> or something. So when we have more CGUs than we're supposed to, we order all the CGUs by their size and start merging the smallest ones together until we're under the limit.</p>",
        "id": 204430116,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595255912
    },
    {
        "content": "<p>it'd be interesting to see if that change to mir-opt causing a regression was just 'bad luck' ie the CGU in question was just at the limit and adding a println just pushed things over the edge but then these benchmarks seem quite limiting and don't seem to capture interesting properties when we're making changes to code being generated!</p>",
        "id": 204430972,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595256294
    },
    {
        "content": "<p>That's the part that's causing some of our MIR-opts issues I believe. Let me show an example:</p>\n<p>Suppose we have a crate that ends up with CGUs like this:</p>\n<ul>\n<li>CGU 0: Size 10,000</li>\n<li>CGU 1: Size 8,000</li>\n<li>CGU 2: Size 5,000</li>\n<li>CGU 3: Size 500</li>\n<li>CGU 4: Size 400</li>\n<li>CGU 5: Size 300</li>\n</ul>\n<p>Now suppose we have limit of 5 CGUs, we'd get a merged CGU result of:</p>\n<ul>\n<li>CGU 0: Size 10,000</li>\n<li>CGU 1: Size 8,000</li>\n<li>CGU 2: Size 5,000</li>\n<li>CGU (4 + 5): Size 700</li>\n<li>CGU 3: Size 500</li>\n</ul>\n<p>And we have some function that is eligible for the new MIR-opt we're adding. Currently, this function might be getting included in CGU 3. But now since we've optimized that function (maybe a lot) it has a smaller cost which means its initial CGU partition does as well:</p>\n<ul>\n<li>CGU 0: Size 10,000</li>\n<li>CGU 1: Size 8,000</li>\n<li>CGU 2: Size 5,000</li>\n<li>CGU 3: Size <del>500</del> 399</li>\n<li>CGU 4: Size 400</li>\n<li>CGU 5: Size 300</li>\n</ul>\n<p>Well now, since we order by the size and merge the smallest, CGU 3 and CGU 5 are going to be merged:</p>\n<ul>\n<li>CGU 0: Size 10,000</li>\n<li>CGU 1: Size 8,000</li>\n<li>CGU 2: Size 5,000</li>\n<li>CGU (3 + 5): Size 699</li>\n<li>CGU 4: Size 400</li>\n</ul>\n<p>So the end result CGU that our function ended up in actually grew from <code>500</code> to <code>699</code> which means it will probably take LLVM longer to compile that. Even though our function decreased in size, the module it was a part of changed and got bigger!</p>",
        "id": 204431536,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595256530
    },
    {
        "content": "<p>But notice too, the total amount of work went down: 10,000 + 8,000 + 5,000 + 500 + 400 + 300 =&gt; 24,200. But in the new version it's only 24,099.</p>",
        "id": 204431807,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595256644
    },
    {
        "content": "<p>yea but to be clear: this is already the case with no opts</p>",
        "id": 204431811,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595256646
    },
    {
        "content": "<p>we could engineer a testcase that looks exactly like the optimized one you gave</p>",
        "id": 204431858,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595256665
    },
    {
        "content": "<p>Yes, for sure!</p>",
        "id": 204431870,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595256672
    },
    {
        "content": "<p>so that adding a <code>println!</code> also pushes it over the edge</p>",
        "id": 204431874,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595256674
    },
    {
        "content": "<p>Yep!</p>",
        "id": 204431888,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595256679
    },
    {
        "content": "<p>I guess more broadly: how valuable are these tests when looking at changes which change the code being generated</p>",
        "id": 204431922,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595256698
    },
    {
        "content": "<p>/ should we be benchmarking something else?</p>",
        "id": 204431942,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595256712
    },
    {
        "content": "<p>But perf.rlo isn't measuring the cost of adding the <code>println!()</code> per say, it's measuring how expensive that change is relative from one compiler to another.</p>",
        "id": 204431947,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595256716
    },
    {
        "content": "<p>maybe.. a sequence of changes?</p>",
        "id": 204431956,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595256719
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/cgu.20partitioning.20questions/near/204431947\">said</a>:</p>\n<blockquote>\n<p>But perf.rlo isn't measuring the cost of adding the <code>println!()</code> per say, it's measuring how expensive that change is relative from one compiler to another.</p>\n</blockquote>\n<p>yes agreed, but in this case the compilers aren't generating the same mir!</p>",
        "id": 204432065,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595256751
    },
    {
        "content": "<p>those tests make sense to me if we're generating the same mir code but measuring how fast we can generate the same code</p>",
        "id": 204432106,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595256773
    },
    {
        "content": "<p>Yeah, there's a bit of discussion about that idea here <a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/brainstorming.3A.20mission.20statement.2C.20goals.2C.20design.20constraints/near/203851817\">https://rust-lang.zulipchat.com/#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/brainstorming.3A.20mission.20statement.2C.20goals.2C.20design.20constraints/near/203851817</a> and probably else where as well</p>",
        "id": 204432200,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595256803
    },
    {
        "content": "<p>In some sense, it's true that perf.rlo isn't \"pure\" or whatever because what it's measuring changes but on the other hand, that's also kind of the point. If we're making changes that are theoretically faster but in practice slower, those are bad changes.</p>",
        "id": 204432493,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595256938
    },
    {
        "content": "<p>What we're seeing right now are just the benchmarks being flawed.</p>",
        "id": 204432526,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595256953
    },
    {
        "content": "<p>Which is why we are willing to land changes that look bad in the benchmarks if there's solid evidence to show they aren't bad in the real world.</p>",
        "id": 204432642,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595256993
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/cgu.20partitioning.20questions/near/204432493\">said</a>:</p>\n<blockquote>\n<p>If we're making changes that are theoretically faster but in practice slower, those are bad changes.</p>\n</blockquote>\n<p>Agreed, but with changes like this how do we know if it's just 'bad luck' wrt to getting unlucky partitioning changes or reflective of a real slowdown</p>",
        "id": 204432942,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595257115
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"312719\">Xavier Denis</span> <a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/cgu.20partitioning.20questions/near/204431858\">said</a>:</p>\n<blockquote>\n<p>we could engineer a testcase that looks exactly like the optimized one you gave</p>\n</blockquote>\n<p>This is another reason why we've landed a number of those changes which show \"regressions\". If the regressions are only appearing because of where the test suite happens to insert the <code>println!()</code> then we're often ok with landing it.</p>",
        "id": 204432986,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595257141
    },
    {
        "content": "<p>semi-related: would it make sense for incr compilation to not change CGUs?</p>",
        "id": 204433156,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595257204
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"312719\">Xavier Denis</span> <a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/cgu.20partitioning.20questions/near/204432942\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/cgu.20partitioning.20questions/near/204432493\">said</a>:</p>\n<blockquote>\n<p>If we're making changes that are theoretically faster but in practice slower, those are bad changes.</p>\n</blockquote>\n<p>Agreed, but with changes like this how do we know if it's just 'bad luck' wrt to getting unlucky partitioning changes or reflective of a real slowdown</p>\n</blockquote>\n<p>Great question! Here's some of the things I look for to tell if it's the CGU issue:</p>\n<ul>\n<li>\n<p>Are all or nearly all of the regressions isolated to incremental tests? If we see improvements or least no regressions to the non-incremental builds, this is often an indicator.</p>\n</li>\n<li>\n<p>In the detailed report for the incremental tests, is the time being taken up because of more CGUs getting code gen'd? Look for an increase in the number of executions for queries/functions like <code>LLVM_module_codegen</code>.</p>\n</li>\n</ul>",
        "id": 204433524,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595257378
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"312719\">Xavier Denis</span> <a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/cgu.20partitioning.20questions/near/204433156\">said</a>:</p>\n<blockquote>\n<p>semi-related: would it make sense for incr compilation to not change CGUs?</p>\n</blockquote>\n<p>I'm not sure I've thought about it enough to have a good opinion but I'm skeptical in general of making the perf test environment too different from what users would normally run themselves.</p>",
        "id": 204433812,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595257494
    },
    {
        "content": "<p>oh i mean in general not change CGUs during incremental compilation :P</p>",
        "id": 204433924,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595257555
    },
    {
        "content": "<p>or basically say 'only change them if something has majorly changed'</p>",
        "id": 204434002,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595257571
    },
    {
        "content": "<p>basically make incremental compilation say 'if CGUs are less than 50% out of balance don't bother changing them'</p>",
        "id": 204434122,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595257619
    },
    {
        "content": "<p>Oh gotcha</p>",
        "id": 204434164,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595257644
    },
    {
        "content": "<p>basically under the hypothesis that when doing things incrementally changing cgus is not useful and it's better to deal with a single slightly larger / lighter unit than rebalance</p>",
        "id": 204434279,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595257691
    },
    {
        "content": "<p>IIRC <span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span> had a similar idea around here <a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/brainstorming.3A.20mission.20statement.2C.20goals.2C.20design.20constraints/near/203736391\">https://rust-lang.zulipchat.com/#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/brainstorming.3A.20mission.20statement.2C.20goals.2C.20design.20constraints/near/203736391</a> (you might have to scroll a bit further back to see all of the relevant info).</p>",
        "id": 204434322,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595257717
    },
    {
        "content": "<p>(btw i checked the operand opt and the worst test case +12% for an incr rebuild has 5 more calls to <code>LLVM_module_codegen</code>)</p>",
        "id": 204434368,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595257746
    },
    {
        "content": "<p>Yeah seems likely it's the CGU issue then</p>",
        "id": 204434389,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595257759
    },
    {
        "content": "<p>I've got run but if you have more thoughts, feel free to leave them here and I'll try to reply when I'm back later</p>",
        "id": 204434447,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595257797
    },
    {
        "content": "<p>yea no worries! I just want to better understand how we rule out opts from normal compilation</p>",
        "id": 204434623,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595257892
    },
    {
        "content": "<p>and it's sad that we could lose an opt like this which should cause many other opts to unblock</p>",
        "id": 204434697,
        "sender_full_name": "Xavier Denis",
        "timestamp": 1595257920
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> two questions:</p>\n<ul>\n<li>Since merging CGUs is what makes the times change in strange ways for incremental comp, would it make sense to not merge CGUs <em>at all</em> during incremental compilation?</li>\n<li>Ideally one would want the time needed for recompilation after a small change to be constant. For it to be independent of the rest of the crate, and only depend on the size of the change. Could we generate enough CGUs that we get this level of fine-grained behavior on incremental compilation?</li>\n</ul>",
        "id": 204464142,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1595272727
    },
    {
        "content": "<p>Oh, btw, in this context I mean \"incremental compilation for debug builds\". Release builds are another story entirely :P</p>",
        "id": 204464211,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1595272783
    },
    {
        "content": "<blockquote>\n<p>Since merging CGUs is what makes the times change in strange ways for incremental comp, would it make sense to not merge CGUs at all during incremental compilation?</p>\n</blockquote>\n<p>That seems like a good experiment to try! I think <code>pnkfelix</code> even suggested splitting large CGUs which also makes a lot of sense. One other thing we've talked about would be scaling the number of CGUs targeted by the size of the crate. </p>\n<blockquote>\n<p>Ideally one would want the time needed for recompilation after a small change to be constant. For it to be independent of the rest of the crate, and only depend on the size of the change. Could we generate enough CGUs that we get this level of fine-grained behavior on incremental compilation?</p>\n</blockquote>\n<p>Hopefully yes! We will probably have to change our visibility and linkage code to accommodate having code spread across many CGUs and not clustered together.</p>",
        "id": 204503526,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1595293947
    }
]