[
    {
        "content": "<p>Hey <span class=\"user-mention\" data-user-id=\"212698\">@FÃ©lix Fischer</span>! <span aria-label=\"wave\" class=\"emoji emoji-1f44b\" role=\"img\" title=\"wave\">:wave:</span></p>",
        "id": 206139266,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596720039
    },
    {
        "content": "<p>So I guess the thing to start with is this PR <a href=\"https://github.com/rust-lang/rust/pull/74275\">https://github.com/rust-lang/rust/pull/74275</a> which is relatively straightforward refactoring of the <code>partitioning</code> module.</p>",
        "id": 206139585,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596720204
    },
    {
        "content": "<p>My main goal here was to make it easier for us to add new partitioning schemes for testing purposes. I'm not sure if we actually want different schemes in the future but making changes to the existing one just to test things out can be tricky because you can break the bootstrap and get much more complex errors than when you're testing simpler crates.</p>",
        "id": 206139741,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596720274
    },
    {
        "content": "<p>Locally, I have a new scheme that is quite a bit simpler than the current one. Instead of partitioning the code initially by module/crate/etc (see <a href=\"https://doc.rust-lang.org/nightly/nightly-rustc/rustc_middle/ty/print/fn.characteristic_def_id_of_type.html\"><code>characteristic_def_id_of_type</code></a>, it first looks at the <code>InliningMap</code> to see what monomorphic instantiations each item will bring in. It then uses the cost of the item and all of it's dependencies to create CGUs which are (hopefully) close in size. After that, we do the standard merge process where we take the two smallest and merge those together until we have the correct number of CGUs.</p>",
        "id": 206140387,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596720558
    },
    {
        "content": "<p>I was hoping to see an improvement over the current algorithm for debug builds, but unfortunately it's slower. I've mostly been testing by building a copy of the <code>regex</code> crate locally and I think it's currently about 15 - 20% slower than the regular scheme.</p>",
        "id": 206140607,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596720648
    },
    {
        "content": "<p>The code is quite a bit simpler IMO so this may just mean we need to do some additional tuning to close the gap.</p>",
        "id": 206140710,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596720697
    },
    {
        "content": "<p>So, some ideas I have that might be worth exploring:</p>",
        "id": 206140804,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596720731
    },
    {
        "content": "<ul>\n<li>In addition to merging small CGUs, we should consider splitting large CGUs.<br>\n    - I think this is our best bet for keeping incremental times consistent per crate.</li>\n</ul>",
        "id": 206141046,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596720847
    },
    {
        "content": "<ul>\n<li>It looks like right now <code>#[inline]</code> items are instantiated in downstream crates (or perhaps each CGU that uses them?) even in debug mode.<ul>\n<li>I think changing this so that we only have one instantiation of the inline item in the downstream crate (or perhaps we should even use an upstream instantiation?) is likely going to be a win even for the current algorithm.</li>\n</ul>\n</li>\n</ul>",
        "id": 206141352,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596720990
    },
    {
        "content": "<ul>\n<li>If I understand the current algorithm correctly, each CGU gets copies of every <code>MonoItem</code> it uses. In debug mode, we should ideally be sharing those with our other CGUs. <ul>\n<li>I think we may even want to have a way to calculate how much \"duplication\" of MonoItems is in a given compilation. This may be an important metric to know since it directly affects how much code we're handing to LLVM. (I've started working on some code to do this)</li>\n</ul>\n</li>\n</ul>",
        "id": 206141582,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596721093
    },
    {
        "content": "<ul>\n<li>It would be great if, when partitioning, we could group together things that use the same MonoItems. <ul>\n<li>This is another way to reduce the duplication but this might be suitable for release mode as well.</li>\n</ul>\n</li>\n</ul>",
        "id": 206141827,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596721206
    },
    {
        "content": "<ul>\n<li>Partitioning relies pretty heavily on our code-size estimates being accurate. I know there are deficiencies here and we've tried to improve them in the past but sometimes we hit partitioning issues. (LOL)<ul>\n<li>Doing a study here to find out approximately how many LLVM IR instructions each MIR statement actually generates and how that compares to our current estimates might be very useful. There is likely to be a trade off here on accuracy vs time spent generating the estimates. </li>\n<li>Speaking of LLVM, I'm thinking we should actually leave estimating these costs up to the backend (which is pluggable) since cg_lift uses an entirely different IR. They might like to be able to provide better estimates for their backend (which potentially means there's more wins to be had from using cg_lift <span aria-label=\"tada\" class=\"emoji emoji-1f389\" role=\"img\" title=\"tada\">:tada:</span> )</li>\n</ul>\n</li>\n</ul>",
        "id": 206142492,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596721514
    },
    {
        "content": "<p>So that's some ideas</p>",
        "id": 206142829,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596721649
    },
    {
        "content": "<p>Um</p>",
        "id": 206142847,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596721659
    },
    {
        "content": "<p>I guess there's still somethings I'm not sure about which would be worth understanding more thoroughly and (ideally) we could feed that back into the rustc dev guide.</p>",
        "id": 206142960,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596721698
    },
    {
        "content": "<p>I have general ideas about what the partitioning (minus merging) will do but it would be great to have some basic examples that show exactly what's going on.</p>",
        "id": 206143019,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596721731
    },
    {
        "content": "<p>For example, I'd love to have documented what the behavior is when you have:</p>\n<table>\n<thead>\n<tr>\n<th>Crate a</th>\n<th>Crate b</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Non-generic function</td>\n<td>Uses once in a module</td>\n</tr>\n<tr>\n<td>Non-generic function</td>\n<td>Uses in two different modules</td>\n</tr>\n<tr>\n<td>Non-generic <code>#[inline]</code> function</td>\n<td>Uses once in a module</td>\n</tr>\n<tr>\n<td>Non-generic <code>#[inline]</code> function</td>\n<td>Uses in two different modules</td>\n</tr>\n<tr>\n<td>Generic function</td>\n<td>Uses once in a module</td>\n</tr>\n<tr>\n<td>Generic function</td>\n<td>Uses in two different modules</td>\n</tr>\n<tr>\n<td>Generic <code>#[inline]</code> function</td>\n<td>Uses once in a module</td>\n</tr>\n<tr>\n<td>Generic <code>#[inline]</code> function</td>\n<td>Uses in two different modules</td>\n</tr>\n</tbody>\n</table>",
        "id": 206143871,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596722154
    },
    {
        "content": "<p>Other random things I'm just now thinking of:</p>\n<ul>\n<li>We should have a flag that dumps some diagnostic data after partitioning.<ul>\n<li>Things I want to see:<ul>\n<li>Stats about cgu sizes: what's the biggest? what's the smallest? what's the size distribution look like?</li>\n<li>Are the cgus that are taking much longer or much shorter than we think they should? (are our estimates bad for some reason?) </li>\n<li>Which cgus needed to be compiled? (Useful when doing incremental stuff)</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>",
        "id": 206144653,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596722508
    },
    {
        "content": "<ul>\n<li>We should add cost estimates to the <code>self-profiler</code> data collection for each cgu.</li>\n</ul>",
        "id": 206144776,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596722543
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/cgu.20partitioning.20brain.20dump/near/206142492\">said</a>:</p>\n<blockquote>\n<ul>\n<li>Speaking of LLVM, I'm thinking we should actually leave estimating these costs up to the backend (which is pluggable) since cg_lift uses an entirely different IR. They might like to be able to provide better estimates for their backend (which potentially means there's more wins to be had from using cg_lift <span aria-label=\"tada\" class=\"emoji emoji-1f389\" role=\"img\" title=\"tada\">:tada:</span> )</li>\n</ul>\n</blockquote>\n<p>I think the main difference between cg_clif and cg_llvm is that cg_llvm seems to force stack usage a bit more and then expects the mem2reg LLVM pass to cleanup after it. cg_clif tries hard to prevent the stack usage during ir generation, because it doesn't have a mem2reg like pass. This doesn't affect ir size that much I think and the current size estimator doesn't account for this (<a href=\"https://github.com/rust-lang/rust/blob/6e87bacd37539b7e7cd75152dffd225047fa983a/src/librustc_ty/ty.rs#L306\">https://github.com/rust-lang/rust/blob/6e87bacd37539b7e7cd75152dffd225047fa983a/src/librustc_ty/ty.rs#L306</a>) in any way.</p>",
        "id": 206144900,
        "sender_full_name": "bjorn3",
        "timestamp": 1596722601
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"133247\">@bjorn3</span>, that's good info!</p>",
        "id": 206145306,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596722785
    },
    {
        "content": "<p>I would like to know what kinds of tradeoffs there are between &lt;size of CGUs&gt; and &lt;incremental compile times&gt;</p>",
        "id": 206158335,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596728328
    },
    {
        "content": "<p>Like I wonder what would happen if in debug mode for example, we lifted the restriction in number of CGUs</p>",
        "id": 206158576,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596728431
    },
    {
        "content": "<p>And just decided to skip the part where we \"merge them based on the total number of CGUs\"</p>",
        "id": 206158648,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596728464
    },
    {
        "content": "<p>I think this could be useful for two reasons:</p>",
        "id": 206158812,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596728535
    },
    {
        "content": "<ul>\n<li>More fine-grained CGUs means less recompilation of code that was not changed.</li>\n</ul>",
        "id": 206158909,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596728579
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/cgu.20partitioning.20brain.20dump/near/206142492\">said</a>:</p>\n<blockquote>\n<ul>\n<li>Partitioning relies pretty heavily on our code-size estimates being accurate. I know there are deficiencies here and we've tried to improve them in the past but sometimes we hit partitioning issues. (LOL)<ul>\n<li>Doing a study here to find out approximately how many LLVM IR instructions each MIR statement actually generates and how that compares to our current estimates might be very useful. There is likely to be a trade off here on accuracy vs time spent generating the estimates. </li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<p>By the way, <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> , do we currently gather <em>any</em> data on how (in)accurate our code size estimates are overall? For example, is there a debugflag one could use to get a table with a row for each function (or maybe each cgu?) and the columns are 1. estimated-code-size, 2. actual-code size in LLVM IR instructions, and 3. actual code size in machine instructions and/or bytes?</p>",
        "id": 206158943,
        "sender_full_name": "pnkfelix",
        "timestamp": 1596728593
    },
    {
        "content": "<p>I don't think we think we do, but we certainly should!</p>",
        "id": 206159189,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596728702
    },
    {
        "content": "<p>(Cont.)</p>\n<ul>\n<li>When code changes, so do the sizes of the CGUs. This affects the merging step in a manner that the user cannot predict. This induces &lt;compile times&gt; changes that are hard to predict.</li>\n</ul>",
        "id": 206159258,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596728734
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> does that seem reasonable? I don't know what other tradeoffs are between merging and not merging CGUs, but maybe in debug builds we could do without the merging step, and make incr-comp both more fine grained (ie more efficient) as well as more predictable</p>",
        "id": 206160091,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596729118
    },
    {
        "content": "<p>It does seem reasonable overall (or, at least, for some experiments). A few thoughts:</p>\n<p>Smaller CGUs does give increased opportunity for incremental recompilation to be fast (as there is less extra code being recompiled). </p>\n<p>I don't think there's any fundamental reason why we have to merge CGUs, I think it's just an improvement (mostly) over the original partitioning we have now. </p>\n<p>At least with the current scheme, every CGU has to have all the mono items it needs to call (or for them to be available upstream). Having more CGUs will currently (I believe) increase the amount of mono item duplication.</p>",
        "id": 206161278,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596729626
    },
    {
        "content": "<p>Interesting</p>",
        "id": 206161884,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596729877
    },
    {
        "content": "<p>I think it's fine to have mono item duplication in cases where it helps compilation times</p>",
        "id": 206161983,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596729937
    },
    {
        "content": "<p>I would still merge those if it turns out that merging is better for their times</p>",
        "id": 206162087,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596729977
    },
    {
        "content": "<p>I think that in the general case, merging makes sense when you want to have a certain level of optimization across big swaths of code (because LLVM can optimize as much as it wants inside one CGU). For incr-comp, this would mean that <code>release</code> mode can be tuned to have more or less CGUs, and therefore less or more optimizations.</p>",
        "id": 206162385,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596730133
    },
    {
        "content": "<p>Because in <code>release</code> mode we could want to have more LLVM optimizations available</p>",
        "id": 206162484,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596730191
    },
    {
        "content": "<p>(Even at the cost of compile times)</p>",
        "id": 206162527,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596730202
    },
    {
        "content": "<p>(Depending on how performant we want incremental <code>release</code> binaries to be)</p>",
        "id": 206162569,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596730224
    },
    {
        "content": "<p>For <code>debug</code> builds I would disable any merging that does not help with compile times, however :3</p>",
        "id": 206162683,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596730296
    },
    {
        "content": "<p>Yeah, there's a lot of complexity here so I think we certainly want our changes to be well motivated both from the theoretical perspective as well as concrete performance benchmarks.</p>",
        "id": 206291485,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596824021
    },
    {
        "content": "<p>Indeed</p>",
        "id": 206319468,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596842467
    },
    {
        "content": "<p>Mmm, now I want to make more performance tests</p>",
        "id": 206319488,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596842505
    },
    {
        "content": "<p>But I don't know how much I should, since I cannot focus in both this and in helping nick with the bench suite</p>",
        "id": 206319537,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596842558
    },
    {
        "content": "<p>(Specially after uni is done processing my thesis application)</p>",
        "id": 206319550,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596842575
    },
    {
        "content": "<p>(I think I'll have space for just one of the two then)</p>",
        "id": 206319557,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596842589
    },
    {
        "content": "<p>That's fine! Is there anything in particular you'd like to work on next so I don't start on that? If you're busy with other stuff right now, that's totally fine too <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 206320585,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1596843796
    },
    {
        "content": "<p>I think I'm currently busy with other stuff to start programming right away, but maybe I could start reading the relevant bits of the CGU partitioning stuff</p>",
        "id": 206324198,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596848427
    },
    {
        "content": "<p>How big is that code?</p>",
        "id": 206324203,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1596848451
    },
    {
        "content": "<p>Also which files should one read? <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> :)</p>",
        "id": 206470898,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597071698
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"212698\">@FÃ©lix Fischer</span> <a href=\"https://github.com/rust-lang/rust/blob/master/src/librustc_mir/monomorphize/partitioning.rs\">https://github.com/rust-lang/rust/blob/master/src/librustc_mir/monomorphize/partitioning.rs</a></p>\n<p>The doc comment is 93 lines but the total file is about 1000 lines.</p>",
        "id": 206485626,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597079018
    },
    {
        "content": "<p>Is everything in that file?</p>",
        "id": 206485728,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597079063
    },
    {
        "content": "<p>:3</p>",
        "id": 206485738,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597079065
    },
    {
        "content": "<p>Most everything related to cgu partitioning yeah</p>",
        "id": 206485808,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597079109
    },
    {
        "content": "<p>A thought Iâve just had - can we leverage knowledge about the circumstances in which compiler shims are generated to put those mono items in compilation units that make more sense? (e.g. maybe drop shims donât change much and arenât often removed or replaced, so should be in their own codegen unit; but function pointer shims on the other hand are often changed alongside the mono item which spawned them?)</p>",
        "id": 206486484,
        "sender_full_name": "davidtwco",
        "timestamp": 1597079500
    },
    {
        "content": "<p>What is a shim in this context?</p>",
        "id": 206487284,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597079954
    },
    {
        "content": "<p>rustc generates MIR bodies in some contexts, for example: implementations of <code>drop_in_place&lt;T&gt;</code>, or of <code>Fn*</code> trait functions for a given function pointer.</p>",
        "id": 206488162,
        "sender_full_name": "davidtwco",
        "timestamp": 1597080415
    },
    {
        "content": "<p>We know the context in which these shims get created, and that information might be leveraged by the partitioning.</p>",
        "id": 206488214,
        "sender_full_name": "davidtwco",
        "timestamp": 1597080446
    },
    {
        "content": "<p>would moving all <code>drop_in_place</code> into one cgu result in recompiles of the whole cgu if we use a new instance of a generic type?</p>",
        "id": 206490439,
        "sender_full_name": "lcnr",
        "timestamp": 1597081513
    },
    {
        "content": "<p>without polymorphization we need seperate <code>drop_in_place</code> for <code>Vec&lt;u32&gt;</code> and <code>Vec&lt;u16&gt;</code>, don't we?</p>",
        "id": 206490614,
        "sender_full_name": "lcnr",
        "timestamp": 1597081585
    },
    {
        "content": "<p>Yeah - my examples were very much artificial, I havenât thought much about what useful partitioning we could do if we leveraged this information, just that we could leverage that information.</p>",
        "id": 206491342,
        "sender_full_name": "davidtwco",
        "timestamp": 1597081967
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"216206\">@lcnr</span> that feels accurate to me</p>",
        "id": 206491360,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597081979
    },
    {
        "content": "<p>Ahh, okay, I understand the context now, <span class=\"user-mention\" data-user-id=\"116107\">@davidtwco</span> :3</p>",
        "id": 206491409,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082013
    },
    {
        "content": "<p>I think it is a good idea to keep in the list</p>",
        "id": 206491548,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082079
    },
    {
        "content": "<p>Do we have a list?</p>",
        "id": 206491561,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082087
    },
    {
        "content": "<p>(Like a hackmd)</p>",
        "id": 206491590,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082105
    },
    {
        "content": "<p>Itâs possible though that because those shims are constructed from just a type that much of the compiler wouldnât need to be invoked - so even if they were recompiled more often, it might be really quick every time. Again, just speculation, but <span aria-label=\"shrug\" class=\"emoji emoji-1f937\" role=\"img\" title=\"shrug\">:shrug:</span></p>",
        "id": 206491591,
        "sender_full_name": "davidtwco",
        "timestamp": 1597082105
    },
    {
        "content": "<p>Yeah we need more measurement to really know without fiddling with the partitioning and seeing what happens</p>",
        "id": 206491677,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082159
    },
    {
        "content": "<p>But I think it 100% makes sense</p>",
        "id": 206491740,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082173
    },
    {
        "content": "<p>And also it would seem to me that it's closely related to polymorphization</p>",
        "id": 206491764,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082192
    },
    {
        "content": "<p>As <span class=\"user-mention\" data-user-id=\"216206\">@lcnr</span> said</p>",
        "id": 206491797,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082211
    },
    {
        "content": "<p>are we trying to polymorphize shims rn? <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> from what I can tell we aren't doing so rn...</p>",
        "id": 206491839,
        "sender_full_name": "lcnr",
        "timestamp": 1597082238
    },
    {
        "content": "<p>Like maybe with PM enabled, most of this optimization would not be needed, I think</p>",
        "id": 206491843,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082240
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"216206\">@lcnr</span> is polimorphization already in-tree?</p>",
        "id": 206491995,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082308
    },
    {
        "content": "<p>ye, but off by default</p>",
        "id": 206492004,
        "sender_full_name": "lcnr",
        "timestamp": 1597082316
    },
    {
        "content": "<p><code>-Zpolymorphize=on</code></p>",
        "id": 206492024,
        "sender_full_name": "lcnr",
        "timestamp": 1597082323
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"216206\">@lcnr</span> we do, theyâre not treated separately but weâve made changes in the past to shim building (e.g. <a href=\"https://github.com/rust-lang/rust/issues/75346\">#75346</a>) that enables them to be polymorphic.</p>",
        "id": 206492043,
        "sender_full_name": "davidtwco",
        "timestamp": 1597082336
    },
    {
        "content": "<p>I seem to remember that last week it was not enabled... ahh, you're right. In-tree but off by default, yas</p>",
        "id": 206492045,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082337
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116107\">@davidtwco</span> nice! :D</p>",
        "id": 206492208,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082407
    },
    {
        "content": "<p>ahh, the reason why <code>drop_in_place</code> isn't polymorphized is then because it always uses a pointer to <code>T</code>?</p>",
        "id": 206492214,
        "sender_full_name": "lcnr",
        "timestamp": 1597082409
    },
    {
        "content": "<p>I assume so, Iâve never dug into the MIR for it.</p>",
        "id": 206492239,
        "sender_full_name": "davidtwco",
        "timestamp": 1597082427
    },
    {
        "content": "<p>So assuming all shims are eventually captured by polimorphization, this optimization would mainly be useful for when compiling in <code>release</code> mode, right? Since (I'm assuming) <code>release</code> would turn off PM in order to get the most runtime performance available</p>",
        "id": 206492443,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082538
    },
    {
        "content": "<p>PM does not have a negative runtime impact</p>",
        "id": 206492704,
        "sender_full_name": "lcnr",
        "timestamp": 1597082683
    },
    {
        "content": "<p>we actually get some benefits because the binary is smaller (depending on how clever llvm is I guess <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span> )</p>",
        "id": 206492767,
        "sender_full_name": "lcnr",
        "timestamp": 1597082720
    },
    {
        "content": "<p>We do not virtualize function calls with polymorphization</p>",
        "id": 206492800,
        "sender_full_name": "lcnr",
        "timestamp": 1597082745
    },
    {
        "content": "<p>Polymorphization just generates fewer copies of functions, if shouldnât impact runtime performance. Polymorphization is run on all shims but thatâs not to say that they will be polymorphized - depends how they use their generic parameters (if they have any). </p>\n<p>If you have more questions, we can chat in <a class=\"stream\" data-stream-id=\"216091\" href=\"/#narrow/stream/216091-t-compiler.2Fwg-polymorphization\">#t-compiler/wg-polymorphization</a> to keep this chat on-topic.</p>",
        "id": 206492871,
        "sender_full_name": "davidtwco",
        "timestamp": 1597082766
    },
    {
        "content": "<blockquote>\n<p>We do not virtualize function calls with polymorphization</p>\n</blockquote>\n<p>Holy cow. I do not understand how did you pull it off, then, David. I will surely go ask! Thanks for the time <span aria-label=\"heart\" class=\"emoji emoji-2764\" role=\"img\" title=\"heart\">:heart:</span></p>",
        "id": 206492969,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597082840
    },
    {
        "content": "<p>Okay now I understand. We'd never disable polymorphization for runtime performance reasons :D</p>",
        "id": 206495767,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597084327
    },
    {
        "content": "<p>And at the same time, there are shims that will definitely not be polymorphisized</p>",
        "id": 206495884,
        "sender_full_name": "FÃ©lix Fischer",
        "timestamp": 1597084388
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"216206\">@lcnr</span> I just realised - I donât think we do actually polymorphize shims. Iâm misremembering because we did have to make them capable of dealing with generic params (if the instance that spawned them was polymorphized). <code>Instance::polymorphize</code> has a check for <code>InstanceDef::Item</code> (ought to look into if that is necessary). Thatâs the last Iâll say about polymorphization here though to avoid going off topic.</p>",
        "id": 206498238,
        "sender_full_name": "davidtwco",
        "timestamp": 1597085468
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116107\">@davidtwco</span> There is one way in which polymorphization would impact runtime performance: it reduces code size and thus instruction cache footprint.</p>",
        "id": 207111228,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1597646607
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/241847-t-compiler.2Fwg-incr-comp/topic/cgu.20partitioning.20brain.20dump/near/206143871\">said</a>:</p>\n<blockquote>\n<p>For example, I'd love to have documented what the behavior is when you have:</p>\n<table>\n<thead>\n<tr>\n<th>Crate a</th>\n<th>Crate b</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Non-generic function</td>\n<td>Uses once in a module</td>\n</tr>\n<tr>\n<td>Non-generic function</td>\n<td>Uses in two different modules</td>\n</tr>\n<tr>\n<td>Non-generic <code>#[inline]</code> function</td>\n<td>Uses once in a module</td>\n</tr>\n<tr>\n<td>Non-generic <code>#[inline]</code> function</td>\n<td>Uses in two different modules</td>\n</tr>\n<tr>\n<td>Generic function</td>\n<td>Uses once in a module</td>\n</tr>\n<tr>\n<td>Generic function</td>\n<td>Uses in two different modules</td>\n</tr>\n<tr>\n<td>Generic <code>#[inline]</code> function</td>\n<td>Uses once in a module</td>\n</tr>\n<tr>\n<td>Generic <code>#[inline]</code> function</td>\n<td>Uses in two different modules</td>\n</tr>\n</tbody>\n</table>\n</blockquote>\n<p>Sorry I got occupied last week. <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span>  can you comment on how I can verify the behavior for these?</p>",
        "id": 208609704,
        "sender_full_name": "Aman Arora",
        "timestamp": 1598904939
    },
    {
        "content": "<p>would be great to keep filling rustc-dev-guide with more info ;)</p>",
        "id": 208610136,
        "sender_full_name": "Santiago Pastorino",
        "timestamp": 1598905150
    },
    {
        "content": "<p>Where part of the dev guide should I add results of this testing to? I can't seem to find a particular section dedicated to incremental compile (there is a section in the query system) and the only detail I could find about partitioning was a comment on this <a href=\"https://rustc-dev-guide.rust-lang.org/backend/monomorph.html?highlight=partition#collection\">page</a></p>",
        "id": 208935186,
        "sender_full_name": "Aman Arora",
        "timestamp": 1599121669
    },
    {
        "content": "<p>About the actual results I added more details on the issue itself: <a href=\"https://github.com/rust-lang/wg-incr-comp/issues/2\">https://github.com/rust-lang/wg-incr-comp/issues/2</a></p>",
        "id": 208935250,
        "sender_full_name": "Aman Arora",
        "timestamp": 1599121698
    },
    {
        "content": "<p>Apologies to everyone trying to get a hold of me the last few days. I've been feeling a bit sick and haven't spent much time on Rust stuff. I'm feeling better now so hopefully I can dig out of the pile of Zulip and GitHub notifications over the next day or two! <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 208981202,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1599145514
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"281950\">@Aman Arora</span> Sorry, I'll take a look at what you wrote on GitHub later today.</p>",
        "id": 208981299,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1599145554
    },
    {
        "content": "<p>rustc-dev-guide merged <a href=\"https://github.com/rust-lang/rustc-dev-guide/pull/847\">https://github.com/rust-lang/rustc-dev-guide/pull/847</a>. <a href=\"https://github.com/rust-lang/wg-incr-comp/issues/2\">https://github.com/rust-lang/wg-incr-comp/issues/2</a> can be closed.</p>",
        "id": 209437214,
        "sender_full_name": "Aman Arora",
        "timestamp": 1599595570
    },
    {
        "content": "<p>The information can be found here: <a href=\"https://rustc-dev-guide.rust-lang.org/backend/monomorph.html?highlight=mono#codegen-unit-cgu-partitioning\">https://rustc-dev-guide.rust-lang.org/backend/monomorph.html?highlight=mono#codegen-unit-cgu-partitioning</a></p>",
        "id": 209437231,
        "sender_full_name": "Aman Arora",
        "timestamp": 1599595579
    },
    {
        "content": "<p>Great work! <span aria-label=\"tada\" class=\"emoji emoji-1f389\" role=\"img\" title=\"tada\">:tada:</span></p>",
        "id": 209458384,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1599609612
    }
]