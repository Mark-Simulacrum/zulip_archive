[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211871\">@Hadrien Grasland</span> </p>\n<blockquote>\n<p>Using volatile loads and stores to engage in a data race on a *mut u8 which is only accessed via volatiles loads and stores and has no Rust references to it is okay, because this memory location does not interact with the Rust abstract machine and memory operations affecting it are therefore not subjected to the rules of said abstract machine.</p>\n</blockquote>\n<p>I'm not sure what you mean by \"this memory location does not interact with the Rust abstract machine\".</p>",
        "id": 178005196,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570912192
    },
    {
        "content": "<p>E.g., if the memory behind the <code>*mut u8</code> is \"owned\" by Rust, e.g., because it was allocated by it, then accesses through the pointer do alter the state of the abstract machine</p>",
        "id": 178005257,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570912247
    },
    {
        "content": "<p>OTOH if the pointer was obtained by Rust from some unknown code, and Rust never accesses it, then that sounds reasonable</p>",
        "id": 178005273,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570912284
    },
    {
        "content": "<p>What I was trying to express is that under these conditions, hardware stores cannot cause any observable harm.</p>",
        "id": 178005898,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570913383
    },
    {
        "content": "<p>But I need some more spec-friendly language to spell it out ;)</p>",
        "id": 178005964,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570913491
    },
    {
        "content": "<p>This reminds me of the notion of non-interference (from lang-sec / information-flow control)</p>",
        "id": 178006014,
        "sender_full_name": "centril",
        "timestamp": 1570913539
    },
    {
        "content": "<p>If I try to go into more details...</p>\n<ol>\n<li>If we restrict ourselves to loads and stores, as volatile does, only hardware stores may harm Rust. Hardware loads can safely be considered not to be observable by Rust (even if that's technically not 100% true).</li>\n<li>A hardware store may only cause harm by writing an invalid value in memory that Rust can read or writing data at the wrong time according to Rust's data access protocol (e.g. reference aliasing rules, Rust-visible data race).</li>\n</ol>",
        "id": 178006107,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570913759
    },
    {
        "content": "<p>If the data has no validity invariant besides initialized-ness, then any value that hardware can write is fine. At the hardware level, un-initializing data in RAM by writing <code>mem::uninitialized()</code> to it is not possible (to the point where it would actually be interesting to see what a volatile store of that compiles down to in LLVM).</p>",
        "id": 178006163,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570913845
    },
    {
        "content": "<p>If the data is only accessed via hardware loads (volatile or assembly), and accessible via raw pointer, then Rust's memory access protocol never really comes into play, as with pure raw pointer based access the only data access protocol restriction that remains at the Rust level is \"no data race\", and hardware loads and stores have their own semantic of a data race which \"just\" produces garbage data, which is fine by Rust as long as there's no data validity invariant to be upheld.</p>",
        "id": 178006220,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570913939
    },
    {
        "content": "<p>No reference = no aliasing assumptions, no \"dereferenceable\" allowing auto-caching<br>\nNo non-volatile pointer accesses = all accesses have hardware load semantics, so Rust's load semantics don't come into play</p>",
        "id": 178006230,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570913988
    },
    {
        "content": "<p>At least that's my theory. Now I need to do a 2-year postdoc in <span class=\"user-mention\" data-user-id=\"120791\">@RalfJ</span>'s team to see how well it holds :P</p>",
        "id": 178006353,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570914161
    },
    {
        "content": "<p>lol^^</p>",
        "id": 178007396,
        "sender_full_name": "RalfJ",
        "timestamp": 1570915924
    },
    {
        "content": "<blockquote>\n<p>hardware loads and stores have their own semantic of a data race which \"just\" produces garbage data, which is fine by Rust as long as there's no data validity invariant to be upheld.</p>\n</blockquote>\n<p>unfortunately LLVM devs <a href=\"https://bugs.llvm.org/show_bug.cgi?id=42435\" target=\"_blank\" title=\"https://bugs.llvm.org/show_bug.cgi?id=42435\">refuse to guarantee</a> things like \"volatile loads can never return <code>undef</code>\"</p>",
        "id": 178007408,
        "sender_full_name": "RalfJ",
        "timestamp": 1570915986
    },
    {
        "content": "<p>so, while I could certainly imagine a spec of <code>volatile</code> where you are right, I don't dare say that that's what LLVM implements :(</p>",
        "id": 178007453,
        "sender_full_name": "RalfJ",
        "timestamp": 1570916043
    },
    {
        "content": "<p>(also: oh no, now that long long volatile thread that lay dormant for some time is alive again and will be even harder to summarize, if/when some dares to take on that task^^)</p>",
        "id": 178007528,
        "sender_full_name": "RalfJ",
        "timestamp": 1570916222
    },
    {
        "content": "<p>Meh. Nasty LLVM devs. You have to admit, it would be super-tempting to be able to process inline assembly, FFI and volatile under a single unified \"hardware memory model and its interactions with Rust's memory model\" framework.</p>\n<p>Three difficult memory model problems addressed for the price of one!</p>",
        "id": 178007734,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570916621
    },
    {
        "content": "<p>If we only allow unknown code to do what sound Rust code would be able to do, then we are already there</p>",
        "id": 178007785,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570916688
    },
    {
        "content": "<p>The problem is people wanting to call unknown code that can do things that Rust cannot do <span aria-label=\"laughter tears\" class=\"emoji emoji-1f602\" role=\"img\" title=\"laughter tears\">:laughter_tears:</span></p>",
        "id": 178007800,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570916720
    },
    {
        "content": "<p>Yeah, or writing an OS kernel in Rust.</p>",
        "id": 178007807,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570916741
    },
    {
        "content": "<p>Low-level hardware generally doesn't care much about what languages think of as the right way to access memory.</p>",
        "id": 178007857,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570916770
    },
    {
        "content": "<p>Unless your hardware is \"valgrind\"</p>",
        "id": 178007862,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570916787
    },
    {
        "content": "<p>or something similar</p>",
        "id": 178007864,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570916795
    },
    {
        "content": "<p>Truly, it would be nice if every CPU were like valgrind... but without the 30x slowdown.</p>",
        "id": 178007879,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570916840
    },
    {
        "content": "<p>Jokes aside, I think that Rust can guarantee that volatile loads do not generate <code>undef</code> even if LLVM doesn't</p>",
        "id": 178007932,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570916907
    },
    {
        "content": "<p>I'd be fine to defer fixing that LLVM bug until somebody hits it</p>",
        "id": 178007938,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570916938
    },
    {
        "content": "<p>volatile and inline assembly are related but not the same though ;)</p>",
        "id": 178007949,
        "sender_full_name": "RalfJ",
        "timestamp": 1570916949
    },
    {
        "content": "<p>In a hardware-specific way, that's trivial: just write a one-line inline assembly snippet with your favorite LOAD instruction.</p>",
        "id": 178007950,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570916959
    },
    {
        "content": "<p>and FFI... together with xLTO I'm afraid this framework is not going to be any good for that</p>",
        "id": 178007951,
        "sender_full_name": "RalfJ",
        "timestamp": 1570916965
    },
    {
        "content": "<p>In a portable way, that may be harder</p>",
        "id": 178007952,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570916968
    },
    {
        "content": "<p>but yes, the better I (think I) understand volatile the more I think a variant of that can also be used for inline assembly</p>",
        "id": 178008006,
        "sender_full_name": "RalfJ",
        "timestamp": 1570917016
    },
    {
        "content": "<p>and the framework for that even exists already, it's called \"syscalls\" or \"externally observable events\"</p>",
        "id": 178008013,
        "sender_full_name": "RalfJ",
        "timestamp": 1570917041
    },
    {
        "content": "<p>I think we should group them all under that framework</p>",
        "id": 178008018,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570917060
    },
    {
        "content": "<p>The question is still: what is unknown code allowed to do? I don't think the possibility of xLTO happening should affect the answer</p>",
        "id": 178008038,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570917120
    },
    {
        "content": "<p>the hard part is bounding what the effect of a volatile / inline assembly can be <em>in terms of the Rust Abstract Machine</em> in a way that's actually both sound and useful</p>",
        "id": 178008039,
        "sender_full_name": "RalfJ",
        "timestamp": 1570917122
    },
    {
        "content": "<p>I asked whether an <code>asm!</code> statement with a memory <code>clobber</code> is a data-race, and I wasn't joking there</p>",
        "id": 178008085,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570917160
    },
    {
        "content": "<blockquote>\n<p>I'd be fine to defer fixing that LLVM bug until somebody hits it</p>\n</blockquote>\n<p>I am doubtful we'd ever realize that this is the cause of the bug. It'll just be someone's Heisenbug and make their life miserable.</p>",
        "id": 178008086,
        "sender_full_name": "RalfJ",
        "timestamp": 1570917160
    },
    {
        "content": "<blockquote>\n<p>The question is still: what is unknown code allowed to do? I don't think the possibility of xLTO happening should affect the answer</p>\n</blockquote>\n<p>I'd like to keep FFI and xLTO out of the equation until we solved the \"easier\" cases^^</p>",
        "id": 178008099,
        "sender_full_name": "RalfJ",
        "timestamp": 1570917205
    },
    {
        "content": "<blockquote>\n<p>I asked whether an <code>asm!</code> statement with a memory <code>clobber</code> is a data-race, and I wasn't joking there</p>\n</blockquote>\n<p>yeah it's a good question ;)</p>",
        "id": 178008103,
        "sender_full_name": "RalfJ",
        "timestamp": 1570917226
    },
    {
        "content": "<p>it goes back to another issue I have with the C++ memory model: it's definition of a data race is utterly broken</p>",
        "id": 178008149,
        "sender_full_name": "RalfJ",
        "timestamp": 1570917244
    },
    {
        "content": "<p>I think we need an <em>operational</em> model to make sense of all of that</p>",
        "id": 178008156,
        "sender_full_name": "RalfJ",
        "timestamp": 1570917258
    },
    {
        "content": "<p>So... I have another question on this topic.</p>",
        "id": 178027446,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570954989
    },
    {
        "content": "<p>What if we defined Rust's volatile to compile down to LLVM's atomic volatile with Relaxed or Unordered ordering?</p>",
        "id": 178027452,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570955018
    },
    {
        "content": "<p>As far as I know, this would change almost nothing from a codegen point of view (since volatile loads and stores already cannot be eliminated or reordered).</p>",
        "id": 178027514,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570955138
    },
    {
        "content": "<p>But it would have the interesting side-effect of making data races of volatile accesses on the Rust side well-defined.</p>",
        "id": 178027564,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570955208
    },
    {
        "content": "<p>(Since they wouldn't be data races anymore from LLVM's point of view, and rustc itself never cared either way)</p>",
        "id": 178027578,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570955269
    },
    {
        "content": "<p>As for the use case of sharing memory with untrusted code, data races of atomic reads with non-atomic writes would remain UB from a specification point of view... but on any platform that I am aware of, this UB could have no observable consequence, as long as the compiler never does LTO between the untrusted code and the trusted code (and doing that could go wrong in plenty of other ways, so security-conscious people just won't)</p>",
        "id": 178027687,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570955469
    },
    {
        "content": "<p>I guess my question is, if volatile is meant to mean \"defer to hardware semantics\", and the semantics of all known hardware guarantees Relaxed atomics-like semantics on loads and store... do we really gain anything by using non-atomic volatile accesses?</p>",
        "id": 178027740,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570955582
    },
    {
        "content": "<p>Given volatile's restrictions, is there really any optimization that LLVM can perform on non-atomic volatile accesses, that it cannot perform on atomic volatile accesses?</p>",
        "id": 178027792,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570955662
    },
    {
        "content": "<p>Do we really care about LLVM's weird notion of racey volatile accesses, or could we just do without by telling LLVM to shut up and consider \"our\" volatile to be a strict superset of relaxed atomic?</p>",
        "id": 178027801,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570955713
    },
    {
        "content": "<p>There is admittedly one backwards compatibility wrinkle: Making volatile atomic would break compilation of volatile accesses larger than pointer-sized. Many would argue that this is actually desirable. But breaking backwards compatibility is never okay.</p>",
        "id": 178027849,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570955819
    },
    {
        "content": "<p>To address this, we would probably need to add ptr::read_atomic_volatile(), as opposed to changing ptr::read_volatile()'s semantics. Which would, as an extra benefit, allow us to add an Ordering parameter.</p>",
        "id": 178027900,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570955898
    },
    {
        "content": "<p>After that, if everyone agrees with me that non-atomic volatile is a footgun, we could _consider_ deprecating it... But we don't really have to, we can just add a note on non-atomic volatile's documentation suggesting use of atomic volatile in concurrent scenarios.</p>",
        "id": 178027915,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570955990
    },
    {
        "content": "<p>(OTOH, defaulting to relaxed/unordered volatile semantics would be the right choice in the case of inline assembly, where there's no room for an atomic ordering parameter in the syntax and hardware doesn't allow non-native-width load/store anyhow)</p>",
        "id": 178027968,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570956081
    },
    {
        "content": "<p>One issue might be if there were some <em>very hypothetical</em> platform where (a) relaxed atomics use a different instruction from normal accesses and (b) MMIO accesses want the normal instruction.</p>",
        "id": 178028092,
        "sender_full_name": "comex",
        "timestamp": 1570956353
    },
    {
        "content": "<p>That would mean a multiprocessor platform without guaranteed cache coherence... ew, poor devs.</p>",
        "id": 178028155,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570956433
    },
    {
        "content": "<p>But such a use case could be served by not deprecating read_volatile/write_volatile, and instead warning people that these are aimed at very niche scenarios and should not be used as their everyday tool, even for MMIO.</p>",
        "id": 178028206,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570956500
    },
    {
        "content": "<p>condition A might be satisfied by VMs such as WebAssembly... I took a quick look but I can't figure out exactly what they're guaranteeing about data races</p>",
        "id": 178028313,
        "sender_full_name": "comex",
        "timestamp": 1570956722
    },
    {
        "content": "<p>but then WebAssembly has no MMIO</p>",
        "id": 178028343,
        "sender_full_name": "comex",
        "timestamp": 1570956729
    },
    {
        "content": "<p>It does have I/O with the host platform, that's what hsivonen had in mind when starting this topic many months ago... but that form of MMIO is not picky about the exact choice of hardware instruction ;)</p>",
        "id": 178028435,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570956926
    },
    {
        "content": "<p>\u0011\u0011\u0011\u0011\u0011\u0011\u0011by the way, one fun thing about volatile with memory orderings</p>",
        "id": 178028507,
        "sender_full_name": "comex",
        "timestamp": 1570957057
    },
    {
        "content": "<p>on some platforms, there is more than one way to implement atomics in terms of barriers <a href=\"https://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html\" target=\"_blank\" title=\"https://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html\">https://www.cl.cam.ac.uk/~pes20/cpp/cpp0xmappings.html</a></p>",
        "id": 178028509,
        "sender_full_name": "comex",
        "timestamp": 1570957075
    },
    {
        "content": "<p>if you're using it for IPC in shared memory... in theory the process you're communicating with could be using a different choice</p>",
        "id": 178028554,
        "sender_full_name": "comex",
        "timestamp": 1570957106
    },
    {
        "content": "<p>(it probably won't be, since it's part of the ABI and other processes are probably not using a different ABI, but you never know <em>shrug</em>)</p>",
        "id": 178028562,
        "sender_full_name": "comex",
        "timestamp": 1570957131
    },
    {
        "content": "<p>You're right! In that case, it would probably make more sense to only allow relaxed and unordered ordering on atomic volatile.</p>",
        "id": 178028573,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570957153
    },
    {
        "content": "<p>...that said, I have actual use cases for atomics in shared memory with non-relaxed orderings</p>",
        "id": 178028582,
        "sender_full_name": "comex",
        "timestamp": 1570957194
    },
    {
        "content": "<p>so I have no idea what the best policy is :p</p>",
        "id": 178028633,
        "sender_full_name": "comex",
        "timestamp": 1570957219
    },
    {
        "content": "<p>Probably start with Relaxed, and consider adding other memory barriers as a later step.</p>",
        "id": 178028642,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570957258
    },
    {
        "content": "<p>perhaps</p>",
        "id": 178028663,
        "sender_full_name": "comex",
        "timestamp": 1570957293
    },
    {
        "content": "<p>We don't really need to solve the problem of defining an ABI for atomic memory barriers urgently, I think.</p>",
        "id": 178028666,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570957299
    },
    {
        "content": "<p>And that would likely entail quite a bit of extra work, e.g. getting it engraved in the SYSV ABI for example.</p>",
        "id": 178028714,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570957329
    },
    {
        "content": "<p>it's already part of the ABI, isn't it?  you can link together multiple C programs that use C11 atomics</p>",
        "id": 178028719,
        "sender_full_name": "comex",
        "timestamp": 1570957348
    },
    {
        "content": "<p>although I don't know if it's literally specified in the document</p>",
        "id": 178028730,
        "sender_full_name": "comex",
        "timestamp": 1570957364
    },
    {
        "content": "<p>Actually, that's an excellent point. I have no idea how that works.</p>",
        "id": 178028735,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570957382
    },
    {
        "content": "<p>it's just that in general, a process you're communicating with over IPC may not be something you could link with</p>",
        "id": 178028739,
        "sender_full_name": "comex",
        "timestamp": 1570957386
    },
    {
        "content": "<p>that said, this is usually an issue only for SeqCst (although I can't say it couldn't theoretically apply to other orderings)</p>",
        "id": 178028743,
        "sender_full_name": "comex",
        "timestamp": 1570957398
    },
    {
        "content": "<p>One potentially interesting middle ground could be to treat non-Relaxed atomics in shared memory like any other repr(Rust) concern: we only guarantee that it works when linking two binaries produced by the same version of rustc and in the same configuration.</p>",
        "id": 178028892,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570957622
    },
    {
        "content": "<p>Not sure how that idea translates into standardese, tho</p>",
        "id": 178028903,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570957636
    },
    {
        "content": "<p>If we map Rust atomics to C11 atomics we can just provide the guarantees when libc is linked</p>",
        "id": 178032244,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570962193
    },
    {
        "content": "<p>e.g. \"if all processes involved in the IPC use the same ABI\"/\"libc\", then...</p>",
        "id": 178032311,
        "sender_full_name": "gnzlbg",
        "timestamp": 1570962290
    },
    {
        "content": "<p>I posted some report of this discussion at <a href=\"https://github.com/rust-lang/unsafe-code-guidelines/issues/152\" target=\"_blank\" title=\"https://github.com/rust-lang/unsafe-code-guidelines/issues/152\">https://github.com/rust-lang/unsafe-code-guidelines/issues/152</a> with a link back here for extra visibility.</p>",
        "id": 178033072,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1570963523
    }
]