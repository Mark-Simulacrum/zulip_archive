[
    {
        "content": "<p>So apparently <code>crossbeam-deque</code> may perform racing reads, but then discard the result in case a race has occurred: <a href=\"https://github.com/crossbeam-rs/crossbeam/issues/589\">https://github.com/crossbeam-rs/crossbeam/issues/589</a><br>\nIs that legal? If not, how bad is it? This might be a good addition to the \"UB used in practice\" collection...</p>",
        "id": 217343193,
        "sender_full_name": "Shnatsel",
        "timestamp": 1605827254
    },
    {
        "content": "<p>I'd definitely put that under undefined, especially since it's volatile, as each volatile access is a side effect(?) on any affected scalar? Rust's memory model steal's Cs, but since rust doesn't have objects, and the C11 model is defined in terms of objects, it can actually be very difficult to reason about the memory model. <br>\nTo whether or not it could actively cause harm? <span aria-label=\"shrug\" class=\"emoji emoji-1f937\" role=\"img\" title=\"shrug\">:shrug:</span>, seems to me like it may not. Though as always, I feel obliged to point out that justifying UB is a great way to start justifying other UB, even if you are probably fine in this case at this time.</p>",
        "id": 217347014,
        "sender_full_name": "Connor Horman",
        "timestamp": 1605830235
    },
    {
        "content": "<p>Yeah, optimistic concurrency stuff like this is tricky. at one point i wrote a blog post about a thread-safe cell type whose loads could tear (<a href=\"https://shift.click/blog/tearcell/\">https://shift.click/blog/tearcell/</a>). I meant to follow up with a post about example use cases but never got around to it — this sort of optimistic concurrency (also seqlocks, etc) are candidates of it. in theory if LLVM did a better job with optimizing that sort of thing, you could recommend it for that... in practice IIRC volatile read tends to generate much better code though, even than the more production-ready version of TearCell (which uses larger loads if possible).</p>",
        "id": 217347504,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1605830565
    },
    {
        "content": "<p>Hmm, how does it check that it raced?  I would assume that a racing read just gives poison, so you can perform it, you just can't use the value afterwards.</p>",
        "id": 217368858,
        "sender_full_name": "scottmcm",
        "timestamp": 1605856704
    },
    {
        "content": "<p>A common way is to read a monotonically increasing write counter before and after. If the value is (even and) the same both times, then no race occurred.</p>",
        "id": 217416980,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1605886934
    },
    {
        "content": "<p><a href=\"http://llvm.org/docs/LangRef.html#memmodel\">Looks like</a> the LLVM semantic is that a racing read produces <code>undef</code>.</p>\n<p>So I don't know whether Rust adds any additional requirements atop it, but there's probably a version we could make allowed where reading it as <code>ManuallyUninit&lt;T&gt;</code> is fine and then only <code>assume_init</code>ed if some external thing says it didn't race.</p>\n<p>Of course, it couldn't just be a normal <code>&amp;T</code> read of a non-<code>UnsafeCell</code> thing, since a read of that could definitely move earlier.</p>",
        "id": 217453928,
        "sender_full_name": "scottmcm",
        "timestamp": 1605903551
    },
    {
        "content": "<p>Rust uses C/C++ semantics for concurrency</p>",
        "id": 217503131,
        "sender_full_name": "RalfJ",
        "timestamp": 1605967504
    },
    {
        "content": "<p>this means racy reads are UB</p>",
        "id": 217503136,
        "sender_full_name": "RalfJ",
        "timestamp": 1605967511
    },
    {
        "content": "<p>the two models are incompatible in that for each of the two, there are optimizations that work in one but not in the other (where \"not work\" = they are incorrect). LLVM actually used to have a bug where it did an optimization that is only correct under C++ concurrency semantics, which lead to miscompilations...</p>",
        "id": 217503148,
        "sender_full_name": "RalfJ",
        "timestamp": 1605967538
    },
    {
        "content": "<p>The issue with the LLVM memory model is that it has seen hardly any formal scrutiny. the C/C++ model was broken in various ways until people started formalizing it properly and doing proofs about it (and the committee then adjusted the standard), so I'd expect the same to be true for the LLVM model.</p>",
        "id": 217503222,
        "sender_full_name": "RalfJ",
        "timestamp": 1605967621
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/136281-t-lang.2Fwg-unsafe-code-guidelines/topic/avoiding.20UB.20due.20to.20races.20by.20discarding.20result.3F/near/217416980\">said</a>:</p>\n<blockquote>\n<p>A common way is to read a monotonically increasing write counter before and after. If the value is (even and) the same both times, then no race occurred.</p>\n</blockquote>\n<p>due to what I said above, unfortunately such code is incorrect in Rust (just <a href=\"http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf\">like it is in C/C++</a>)</p>",
        "id": 217503358,
        "sender_full_name": "RalfJ",
        "timestamp": 1605967804
    },
    {
        "content": "<p>Such code in C is running in the Linux kernel, on myriad systems.</p>",
        "id": 217512764,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1605983336
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 217512772,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1605983359
    },
    {
        "content": "<p>Right, I wasn't disagreeing that it was UB, just giving a possible answer for  \"how does it check that it raced?\".</p>\n<p>But yes, seqlocks are very common in the linux kernel.</p>",
        "id": 217513106,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1605983939
    },
    {
        "content": "<p>I am curious whether the kernel is doing something to make it not UB, or whether this is just a case of \"in practice compilers handle it just fine\".</p>",
        "id": 217513121,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1605983978
    },
    {
        "content": "<p>(Neither of those two would surprise me if it were the case.)</p>",
        "id": 217513132,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1605983995
    },
    {
        "content": "<p>I read through their seqlock code in the last couple months to answer that question for myself (and make sure a seqlock of my own (which used relaxed reads to avoid UB) had appropriate fencing) and it seemed that it was \"in practice it's fine\".</p>\n<p>I mean, it seems hard for a compiler to miscompile in practice.</p>",
        "id": 217513343,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1605984275
    },
    {
        "content": "<p><a href=\"https://github.com/torvalds/linux/blob/672f8871261597894d46454b8fa1660d6c952af6/include/linux/seqlock.h\">https://github.com/torvalds/linux/blob/672f8871261597894d46454b8fa1660d6c952af6/include/linux/seqlock.h</a> and <a href=\"https://github.com/torvalds/linux/blob/v3.13/arch/x86/vdso/vclock_gettime.c#L180-L187\">https://github.com/torvalds/linux/blob/v3.13/arch/x86/vdso/vclock_gettime.c#L180-L187</a> are in my history for this if you're curious, although i now notice v3.13 is kinda old and maybe the code has changed since thhen (certainly it seems to have moved)</p>",
        "id": 217513412,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1605984368
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/136281-t-lang.2Fwg-unsafe-code-guidelines/topic/avoiding.20UB.20due.20to.20races.20by.20discarding.20result.3F/near/217513121\">said</a>:</p>\n<blockquote>\n<p>I am curious whether the kernel is doing something to make it not UB, or whether this is just a case of \"in practice compilers handle it just fine\".</p>\n</blockquote>\n<p>to my knowledge, the kernel doesn't use the C concurrency primitives, it does it's own hand-rolled thing</p>",
        "id": 217513428,
        "sender_full_name": "RalfJ",
        "timestamp": 1605984414
    },
    {
        "content": "<p>also, this question (C++ vs LLVM concurrency) comes up again and again and I keep saying the same things^^ I wonder what would be a good place to write them down? (not that I have the time to actually do a writeup)</p>",
        "id": 217513450,
        "sender_full_name": "RalfJ",
        "timestamp": 1605984472
    },
    {
        "content": "<p>The docs are very clear about it IMO, that we follow C++'s model.</p>",
        "id": 217513517,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1605984540
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/136281-t-lang.2Fwg-unsafe-code-guidelines/topic/avoiding.20UB.20due.20to.20races.20by.20discarding.20result.3F/near/217513343\">said</a>:</p>\n<blockquote>\n<p>I read through their seqlock code in the last couple months to answer that question for myself (and make sure a seqlock of my own (which used relaxed reads to avoid UB) had appropriate fencing) and it seemed that it was \"in practice it's fine\".</p>\n<p>I mean, it seems hard for a compiler to miscompile in practice.</p>\n</blockquote>\n<p>Section 2.3 of <a href=\"https://plv.mpi-sws.org/validc/paper.pdf\">this paper</a> describes how code could be miscompiled when LLVM does optimizations both following the C++ model and following the LLVM model. That's not the same as miscompiling seqlock, clearly, but it could still be interesting to you.</p>",
        "id": 217513533,
        "sender_full_name": "RalfJ",
        "timestamp": 1605984576
    },
    {
        "content": "<p>LLVM goes even further and makes write-write races not UB, but write <code>poison</code> instead.<br>\nFWIW, I actually like this model, it seems nicer (for an IR, at least) than full UB on data races. But unfortunately, from what I understand, it does not fit very well the usual axiomatic \"candidate execution\" style of weak memory concurrency models. I anyway prefer operational models, but the main thrust of weak memory research is in the axiomatic style -- and the few people doing operational models have to compare with C++ as the gold standard, so little time is spent considering the LLVM approach. :/</p>",
        "id": 217513657,
        "sender_full_name": "RalfJ",
        "timestamp": 1605984759
    },
    {
        "content": "<p>Hm, interesting, I'll give it a read.</p>\n<p>And I think the misconception is the same misconception here are the same as the misconceptions in another thread about volitile reads being a way to dodge UB. (Since crossbeam reads this with a volatile read).</p>\n<p>Using something like <code>TearCell</code> (linked before) would avoid this, and an actually-good implementation of it would probably even avoid performance issues, but I don't think you can define an efficient TearCell for non <code>bytemuck::Pod</code> types due issues with reading padding bytes causing a wider read to be entirely undef (or poison? I don't know), as opposed to only the bytes in question being poison.</p>\n<p>LLVM's <code>atomic_element_unordered_copy_memory</code> stuff might help here but I suspect it's undesirable in Rust (unordered isn't part of the C memory model) and even then currently it is not efficient at all.</p>",
        "id": 217513733,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1605984882
    },
    {
        "content": "<blockquote>\n<p>(Since crossbeam reads this with a volatile read).</p>\n</blockquote>\n<p>the crossbeam authors are aware that <code>volatile</code> doesn't fix the UB. they did this to reduce the chance of miscompilation.</p>",
        "id": 217513751,
        "sender_full_name": "RalfJ",
        "timestamp": 1605984922
    },
    {
        "content": "<p>I see. You see the same issue in the seqlock crate: <a href=\"https://github.com/Amanieu/seqlock/blob/master/src/lib.rs#L147\">https://github.com/Amanieu/seqlock/blob/master/src/lib.rs#L147</a> . Admittedly, the only use of that code I know of is in the crossbeam benchmarks, but it's plausible there are others.</p>",
        "id": 217513838,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1605985071
    },
    {
        "content": "<p>My recommendation for such cases would be to acknowledge in the comment that this is not standard-compliant, and to remain on the look (via testing etc) for actual issues arising from this</p>",
        "id": 217514715,
        "sender_full_name": "RalfJ",
        "timestamp": 1605986243
    },
    {
        "content": "<p>What would the missed optimization consequences be for moving to the \"candidate execution\" model for racing memory operations, compatible with algorithms that assume a read racing with a write will obtain either the old or new value, and two writes racing will happen in one or the other order?</p>",
        "id": 217514912,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1605986566
    },
    {
        "content": "<p>What optimization opportunities does LLVM gain with its model?</p>",
        "id": 217514924,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1605986615
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/136281-t-lang.2Fwg-unsafe-code-guidelines/topic/avoiding.20UB.20due.20to.20races.20by.20discarding.20result.3F/near/217514912\">said</a>:</p>\n<blockquote>\n<p>What would the missed optimization consequences be for moving to the \"candidate execution\" model for racing memory operations, compatible with algorithms that assume a read racing with a write will obtain either the old or new value, and two writes racing will happen in one or the other order?</p>\n</blockquote>\n<p>I'm the wrong person to ask this... I have explicitly avoided becoming a weak memory expert.^^ but there definitely are optimizations that rely on read-write races not just returning the old or the new value.</p>",
        "id": 217515275,
        "sender_full_name": "RalfJ",
        "timestamp": 1605987167
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/136281-t-lang.2Fwg-unsafe-code-guidelines/topic/avoiding.20UB.20due.20to.20races.20by.20discarding.20result.3F/near/217514924\">said</a>:</p>\n<blockquote>\n<p>What optimization opportunities does LLVM gain with its model?</p>\n</blockquote>\n<p>see <a href=\"https://plv.mpi-sws.org/validc/paper.pdf\">section 2.3 of this paper</a>, which discusses two optimizations: one allowed in LLVM and not allowed in GCC (as GCC uses the C++ model all the way though), and one vice versa.</p>",
        "id": 217515298,
        "sender_full_name": "RalfJ",
        "timestamp": 1605987203
    },
    {
        "content": "<p>basically, LLVM can introduce speculative reads, while GCC cannot</p>",
        "id": 217515381,
        "sender_full_name": "RalfJ",
        "timestamp": 1605987337
    },
    {
        "content": "<blockquote>\n<p>due to what I said above, unfortunately such code is incorrect in Rust (just <a href=\"http://www.hpl.hp.com/techreports/2012/HPL-2012-68.pdf\">like it is in C/C++</a>)</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"120791\">@RalfJ</span>  is figure 2 on this paper correct ? I thought atomics would only sync between themselves, they even talk about this in section 4</p>",
        "id": 221369080,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609535501
    },
    {
        "content": "<p>The default synchronization of <code>atomic&lt;T&gt;</code> in C++ is <code>SeqCst</code>, so they can be used to synchronize other variables</p>",
        "id": 221369475,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1609536075
    },
    {
        "content": "<p>I thought that wasn't the case for any memory ordering, even SeqCst</p>",
        "id": 221369490,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609536113
    },
    {
        "content": "<p>See Section 4 of the same paper</p>",
        "id": 221369539,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609536140
    },
    {
        "content": "<p>With sequential consistency as traditionally conceived, you know that the write to <code>x</code> happens before <code>y = 1</code>, which happens before the while loop fails, which happens before the read in the assert</p>",
        "id": 221369561,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1609536186
    },
    {
        "content": "<p>But what prevents the load being moved to after the store with SeqCst ?</p>",
        "id": 221369571,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609536212
    },
    {
        "content": "<p>The happens before relations I just described</p>",
        "id": 221369619,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1609536253
    },
    {
        "content": "<p>Like I said before, I thought that for atomics that would only guarantee ordering between the same variable</p>",
        "id": 221369638,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609536301
    },
    {
        "content": "<p>And in my mind that was the difference between ordering in atomics and fences</p>",
        "id": 221369651,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609536326
    },
    {
        "content": "<p>SeqCst talks about a global order though, that is consistent with happens-before</p>",
        "id": 221369652,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1609536330
    },
    {
        "content": "<p>So, is section 4 of the same paper wrong ?</p>",
        "id": 221369659,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609536349
    },
    {
        "content": "<p>In</p>\n<div class=\"codehilite\" data-code-language=\"C++\"><pre><span></span><code><span class=\"kt\">int</span> <span class=\"n\">r2</span> <span class=\"o\">=</span> <span class=\"n\">data2</span><span class=\"p\">;</span>\n<span class=\"n\">seq1</span> <span class=\"o\">=</span> <span class=\"n\">seq</span><span class=\"p\">;</span>\n</code></pre></div>\n<p>(where I guess the <code>seq</code> variables are atomic), the load happens-before the other load but that doesn't mean anything in particular in this example because nothing reads <code>r2</code></p>",
        "id": 221369842,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1609536580
    },
    {
        "content": "<p>I'm not sure what specifically you are pointing to that you think is wrong</p>",
        "id": 221369922,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1609536680
    },
    {
        "content": "<blockquote>\n<p>The second statement performs a “sequentially consistent” atomic load from seq. But that is not required to<br>\nprevent the processor or compiler from reordering the two<br>\nloads.</p>\n</blockquote>",
        "id": 221369940,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609536715
    },
    {
        "content": "<p>Hmm, I think I know what I got wrong</p>",
        "id": 221369988,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609536767
    },
    {
        "content": "<p>that's true. I said that it \"happens-before\" but that doesn't mean that the processor or compiler actually has to put them in order unless this hb relation is used to deduce that a read sees a write</p>",
        "id": 221370020,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1609536805
    },
    {
        "content": "<p>because that's the only \"observable content\" of the happens before relation</p>",
        "id": 221370074,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1609536849
    },
    {
        "content": "<p>Hmm, I read the docs again and I think I had some misconceptions about the ordering on atomics</p>",
        "id": 221370099,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609536926
    },
    {
        "content": "<p>They are stronger than I thought</p>",
        "id": 221370108,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609536942
    },
    {
        "content": "<p>in particular, <code>Release</code> and <code>Acquire</code> orderings are specifically intended to be able to synchronize variables other than the atomic itself</p>",
        "id": 221370162,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1609536988
    },
    {
        "content": "<p>and <code>SeqCst</code> is viewed as implying both of these (although I think it is disputed whether this is actually true in the C++11 memory model)</p>",
        "id": 221370173,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1609537025
    },
    {
        "content": "<p>Yeah, I get it now, I just got a bit confused with some wording I guess</p>",
        "id": 221370233,
        "sender_full_name": "Thales Fragoso",
        "timestamp": 1609537095
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"271719\">Mario Carneiro</span> <a href=\"#narrow/stream/136281-t-lang.2Fwg-unsafe-code-guidelines/topic/avoiding.20UB.20due.20to.20races.20by.20discarding.20result.3F/near/221370173\">said</a>:</p>\n<blockquote>\n<p>and <code>SeqCst</code> is viewed as implying both of these (although I think it is disputed whether this is actually true in the C++11 memory model)</p>\n</blockquote>\n<p>no, that's not disputed. there were bugs in the model but I think the bugs had a different effect than this. and anyway they are fixed in c++2x</p>",
        "id": 221398548,
        "sender_full_name": "RalfJ",
        "timestamp": 1609591489
    }
]