[
    {
        "content": "<p>for embedded sometimes you need a non-tearing non-coalescing store, is there a way to do this in rust currently? volatile can be tearing afaik, and atomics can be coalesced so i’m not sure how to proceed</p>",
        "id": 171724599,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564086470
    },
    {
        "content": "<p>specifically for memory-mapped I/O, e.g if you’re programming the LAPIC on x86 you need such a store</p>",
        "id": 171724677,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564086515
    },
    {
        "content": "<p>no there is not -- the intended way is to use volatile, but we need a way to express when those can tear and when not</p>",
        "id": 171724861,
        "sender_full_name": "RalfJ",
        "timestamp": 1564086650
    },
    {
        "content": "<p>the two proposals I have seen for that are to either expose some kind of intrinsic or trait that lets you test if volatile accesses for type <code>T</code> can tear, or alternatively <span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span> proposed to deprecate <code>read/write_volatile</code> in favor of a whole bunch of non-tearing intrinsics of various sizes (similar to how we have atomic intrinsics of various sizes)</p>",
        "id": 171724972,
        "sender_full_name": "RalfJ",
        "timestamp": 1564086726
    },
    {
        "content": "<p>I think this has stalled mostly because nobody pushed for it</p>",
        "id": 171725024,
        "sender_full_name": "RalfJ",
        "timestamp": 1564086773
    },
    {
        "content": "<p>i see. seems like something that a lot of embedded people would actually need in theory, although in practice i guess volatile will be fine (if it’s aligned)</p>",
        "id": 171725102,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564086819
    },
    {
        "content": "<p>in practice \"small\" aligned volatile accesses (unaligned ones are not even possible on stable Rust) will not tear</p>",
        "id": 171725225,
        "sender_full_name": "RalfJ",
        "timestamp": 1564086895
    },
    {
        "content": "<p>but I dont know what \"small\" is. I expect <code>usize</code> to be \"small\".</p>",
        "id": 171725250,
        "sender_full_name": "RalfJ",
        "timestamp": 1564086909
    },
    {
        "content": "<p>if you do anything at all mmio you need to check your hardware manual to read the mmio section, so it's not a huge deal that you also have to check the instruction set to see what the allowed read and write sizes are. then you'll know which volatile actions are non-tearing</p>",
        "id": 171737519,
        "sender_full_name": "Lokathor",
        "timestamp": 1564099086
    },
    {
        "content": "<p>the problem, afaik, is more that you can tell the compiler to emit a 64-bit write and it just decides to emit two 32-bit writes for whatever reason, even if 64-bit is the native word size</p>",
        "id": 171768204,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564143196
    },
    {
        "content": "<p>although in practice i can’t think of a reason why llvm would do that</p>",
        "id": 171768234,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564143241
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228354\">@Matt Taylor</span> I suppose that depends on how you tell the compiler</p>",
        "id": 171771713,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146314
    },
    {
        "content": "<p>if you tell it via a <code>*ptr</code> or <code>ptr.write</code> or similar generic methods that will work for all sizes, the compiler might do whatever, from emitting a single instruction, to two instructions, or even calling <code>memcpy</code></p>",
        "id": 171771761,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146357
    },
    {
        "content": "<p>if you want the compiler to use a particular instruction to perform a write, AFAICT your only option right now is to use inline assembly</p>",
        "id": 171771832,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146385
    },
    {
        "content": "<p>yeah, exactly</p>",
        "id": 171771841,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146394
    },
    {
        "content": "<p>you can do a bit better with atomics</p>",
        "id": 171771905,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146436
    },
    {
        "content": "<p>but if you want to do mmio you probably need volatile as well</p>",
        "id": 171771929,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146455
    },
    {
        "content": "<p>otherwise the write might be optimized in subtle ways</p>",
        "id": 171771958,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146477
    },
    {
        "content": "<p>i think in c++ you could use something like volatile std::atomic&lt;T&gt; but since the volatile ops are functions, can’t be done in rust</p>",
        "id": 171772021,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146505
    },
    {
        "content": "<p>although it might be worth mentioning that the proposal for the new volatile_load / volatile_store in c++ do guarantee non-tearing if it’s available</p>",
        "id": 171772061,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146540
    },
    {
        "content": "<p>Are there <code>volatile</code>-qualified overloads of the <code>std::atomic</code> methods in C++ ?</p>",
        "id": 171772072,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146548
    },
    {
        "content": "<p>we could add <code>volatile_load</code>/<code>volatile_store</code> methods to the atomic types in Rust</p>",
        "id": 171772107,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146578
    },
    {
        "content": "<p>but the \"non-tearing if its available\" is not enough if you require non-tearing for correctness</p>",
        "id": 171772126,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146599
    },
    {
        "content": "<p>you’d also need a way to test for it i guess</p>",
        "id": 171772184,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146619
    },
    {
        "content": "<p>or get a compiler error</p>",
        "id": 171772192,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146629
    },
    {
        "content": "<p>how would you even tell llvm to emit a non-tearing volatile access</p>",
        "id": 171772216,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146662
    },
    {
        "content": "<p>right now, the <code>ptr.write_volatile</code> methods are non-tearing, if possible</p>",
        "id": 171772233,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146674
    },
    {
        "content": "<p>because llvm won't tear for fun</p>",
        "id": 171772238,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146684
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228354\">@Matt Taylor</span> you use a volatile+atomic load/store</p>",
        "id": 171772243,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146700
    },
    {
        "content": "<p>ok i see</p>",
        "id": 171772254,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146720
    },
    {
        "content": "<p>atomic load/stores are non-tearing (they are \"atomic\"), and you just need to also prevent llvm from optimizing them in certain ways, which you can do by making them volatile</p>",
        "id": 171772303,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146741
    },
    {
        "content": "<p>i mean the closest reason i can think to why it might tear is if you have something like a mul which can spit out a 64-bit operand in two regs</p>",
        "id": 171772305,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146743
    },
    {
        "content": "<p>unaligned load/stores often tear</p>",
        "id": 171772316,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146759
    },
    {
        "content": "<p>but as ralf said those are curently not allowed anyway</p>",
        "id": 171772328,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146773
    },
    {
        "content": "<p>e.g. if the memory goes across a cache line or page boundary</p>",
        "id": 171772330,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146777
    },
    {
        "content": "<p>yep I don't think we have any API for those</p>",
        "id": 171772349,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146795
    },
    {
        "content": "<p>i mean does llvm actually provide any documented guarantees that it will not tear?</p>",
        "id": 171772362,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146819
    },
    {
        "content": "<p>for atomics? yes</p>",
        "id": 171772371,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146830
    },
    {
        "content": "<p>for non-atomics</p>",
        "id": 171772419,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146843
    },
    {
        "content": "<p>you said ptr.write_volatile will not tear ‘if possible’</p>",
        "id": 171772425,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146851
    },
    {
        "content": "<p>no</p>",
        "id": 171772426,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146852
    },
    {
        "content": "<p>\"if possible\" is not a guarantee</p>",
        "id": 171772432,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146861
    },
    {
        "content": "<p>fair enough</p>",
        "id": 171772470,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564146901
    },
    {
        "content": "<p>the difference is that atomics will fail to compile if the target doesn't support a particular size</p>",
        "id": 171772483,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146910
    },
    {
        "content": "<p>so LLVM knows that there is an instruction for doing the thing correctly</p>",
        "id": 171772496,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146925
    },
    {
        "content": "<p>I think we could add <code>volatile_load</code>/<code>volatile_store</code> methods to the atomic types, and that might work for you - if the target supports that atomic type that is</p>",
        "id": 171772574,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564146976
    },
    {
        "content": "<p>i think that would be a pretty good way to proceed</p>",
        "id": 171772602,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564147014
    },
    {
        "content": "<p>although since MMIO is usually done through hardcoded addresses, it could be a bit weird to have a pointer to an atomic type at that location, no?</p>",
        "id": 171774145,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564148388
    },
    {
        "content": "<p>FWIW I never understood why we need <code>AtomicXY</code> types, instead of having <code>ptr.atomic_load(...)</code> methods.</p>",
        "id": 171776212,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564149928
    },
    {
        "content": "<p>Sure an atomic type wrapper can be built on top of the pointer methods, but the opposite is not true I think. </p>\n<p>If you want to do an atomic relaxed load of some memory address in rust today, AFAICT, there is no easy way for you to do that</p>",
        "id": 171776295,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564149976
    },
    {
        "content": "<p>You would need to somehow construct an <code>AtomicXY</code> at that address</p>",
        "id": 171776318,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564149994
    },
    {
        "content": "<p>Well not construct, but go from the address as an <code>usize</code> to a <code>&amp;AtomicXY</code> that you can then operate on - doable, but weird</p>",
        "id": 171776355,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564150049
    },
    {
        "content": "<p><code>*mut AtomicT</code> is the oposite you’re looking for.</p>",
        "id": 171778185,
        "sender_full_name": "nagisa",
        "timestamp": 1564151306
    },
    {
        "content": "<p>AtomicT is guaranteed to be layout-compatible to T so you can just cast the pointer.</p>",
        "id": 171778229,
        "sender_full_name": "nagisa",
        "timestamp": 1564151339
    },
    {
        "content": "<p>it’s just a bit trickier than having a method on the pointer itself. also i think you can still swap / replace the AtomicT non-atomically, which is a bit odd</p>",
        "id": 171779848,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564152525
    },
    {
        "content": "<p>also you will have to go around casting your types to integers (or bool) in order to write them out with this design</p>",
        "id": 171780056,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564152633
    },
    {
        "content": "<p>You can write an extension trait presumably that casts under the hood to the appropriate atomic and calls the appropriate function</p>",
        "id": 171780187,
        "sender_full_name": "simulacrum",
        "timestamp": 1564152727
    },
    {
        "content": "<p>oh and there might be another issue - the methods for these would probably require taking &amp;self, but to my knowledge references must be dereferenceable at all times, and if you’re accessing some memory region that’s writable but not readable then it would be invalid to create a reference to this address</p>",
        "id": 171780397,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564152865
    },
    {
        "content": "<p>i can’t think of any instance where this is actually the case in practice (writable but not readable mem), but there probably are cases</p>",
        "id": 171780467,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564152947
    },
    {
        "content": "<p>I'm not sure why/how that would be a problem? I'm envisioning the methods on the trait taking <code>self</code> by-value so there's no references to speak of here</p>",
        "id": 171780782,
        "sender_full_name": "simulacrum",
        "timestamp": 1564153170
    },
    {
        "content": "<p>We might want <code>AtomicT</code> and such to be defined on <code>*const T</code> instead of <code>&amp;self</code>, though</p>",
        "id": 171780797,
        "sender_full_name": "simulacrum",
        "timestamp": 1564153189
    },
    {
        "content": "<p>and/or <code>*mut T</code></p>",
        "id": 171780803,
        "sender_full_name": "simulacrum",
        "timestamp": 1564153196
    },
    {
        "content": "<p>I think there might be an open issue about that</p>",
        "id": 171780879,
        "sender_full_name": "simulacrum",
        "timestamp": 1564153219
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> sorry, i was talking about <code>fn volatile_load(&amp;self, ...)</code> method on the AtomicT itself</p>",
        "id": 171780891,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564153233
    },
    {
        "content": "<p>what gnzlbg proposed</p>",
        "id": 171780919,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564153254
    },
    {
        "content": "<p>Yeah, we'd probably want that to be <code>fn volatile_load(*const Self, ...)</code></p>",
        "id": 171780944,
        "sender_full_name": "simulacrum",
        "timestamp": 1564153269
    },
    {
        "content": "<p>then there should be no problem</p>",
        "id": 171780956,
        "sender_full_name": "simulacrum",
        "timestamp": 1564153280
    },
    {
        "content": "<p>(though I guess we'd need that to be <code>unsafe fn</code>)</p>",
        "id": 171780972,
        "sender_full_name": "simulacrum",
        "timestamp": 1564153291
    },
    {
        "content": "<p>ok cool</p>",
        "id": 171780975,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564153292
    },
    {
        "content": "<p>does sound a bit tricky overall but i can’t think of a better way and it is niche anyway</p>",
        "id": 171781018,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564153320
    },
    {
        "content": "<p>i guess this would need an RFC? i’m down to draft something up, but OTOH if people want to make other changes to ptr::volatile_load and such as ralf implied, then it may be better to do it all at once</p>",
        "id": 171781155,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564153407
    },
    {
        "content": "<p>hm, not sure. I would lean towards yes since it deals with UCG stuff</p>",
        "id": 171781418,
        "sender_full_name": "simulacrum",
        "timestamp": 1564153567
    },
    {
        "content": "<blockquote>\n<p>i can’t think of any instance where this is actually the case in practice (writable but not readable mem), but there probably are cases</p>\n</blockquote>\n<p>Some embedded microcontrollers have memory-mapped I/O where a read-after-write returns a different value for the read than what was just written (e.g., writing bits that trigger actions, returning instead bits that reflect current state).</p>",
        "id": 171784622,
        "sender_full_name": "Tom Phinney",
        "timestamp": 1564156110
    },
    {
        "content": "<p>i am thinking more of cases where an unnecessary read triggers an actual action, like crashing. i’m told that for the pci ide controller a read to some address indicates that you’ve handled an IRQ (presumably allowing it to send another one), which can be bad</p>",
        "id": 171785645,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564156959
    },
    {
        "content": "<p>and again, i see absolutely no reason why this would even happen in practice, but if we’re being pedantic about non-tearing accesses it seems reasonable to be pedantic about this too</p>",
        "id": 171785808,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564157082
    },
    {
        "content": "<blockquote>\n<p>for the pci ide controller a read to some address indicates that you’ve handled an IRQ (presumably allowing it to send another one)</p>\n</blockquote>\n<p>I've encountered that situation in memory-mapped I/O. It tends to show up more frequently in 8/16-bit data, 16/24-bit <code>usize</code> microcontrollers, which Rust currently doesn't support (because the current minimum <code>usize</code> is 32). IMO this \"feature\" is often a hold-over from those earlier designs for small-bit-width word sizes. However, in cases like IRQ it may also be a timing optimization for performance-critical code that runs in a protected state (such as with interrupts disabled) whose duration needs to be minimized.</p>",
        "id": 171787099,
        "sender_full_name": "Tom Phinney",
        "timestamp": 1564158256
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span> </p>\n<blockquote>\n<p>atomic load/stores are non-tearing (they are \"atomic\"), and you just need to also prevent llvm from optimizing them in certain ways, which you can do by making them volatile</p>\n</blockquote>\n<p><code>atomic</code> has two aspects, non-tearing and the <code>Ordering</code> thing. So I don't think you want \"atomic volatile\", you just want \"non-tearing volatile\".</p>",
        "id": 171787426,
        "sender_full_name": "RalfJ",
        "timestamp": 1564158569
    },
    {
        "content": "<p>what is the difference between a Relaxed volatile atomic access and a non-tearing volatile access? <span class=\"user-mention\" data-user-id=\"120791\">@RalfJ</span></p>",
        "id": 171787565,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564158663
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228354\">@Matt Taylor</span> also for your questions around volatile and MMIO, some further reading material:<br>\n- <a href=\"https://internals.rust-lang.org/t/volatile-and-sensitive-memory/3188/49?u=ralfjung\" target=\"_blank\" title=\"https://internals.rust-lang.org/t/volatile-and-sensitive-memory/3188/49?u=ralfjung\">https://internals.rust-lang.org/t/volatile-and-sensitive-memory/3188/49?u=ralfjung</a><br>\n- <a href=\"https://github.com/rust-lang/unsafe-code-guidelines/issues/33\" target=\"_blank\" title=\"https://github.com/rust-lang/unsafe-code-guidelines/issues/33\">https://github.com/rust-lang/unsafe-code-guidelines/issues/33</a><br>\n- <a href=\"https://github.com/rust-lang/unsafe-code-guidelines/issues/152\" target=\"_blank\" title=\"https://github.com/rust-lang/unsafe-code-guidelines/issues/152\">https://github.com/rust-lang/unsafe-code-guidelines/issues/152</a></p>",
        "id": 171787598,
        "sender_full_name": "RalfJ",
        "timestamp": 1564158710
    },
    {
        "content": "<blockquote>\n<p>what is the difference between a Relaxed volatile atomic access and a non-tearing volatile access? <span class=\"user-mention silent\" data-user-id=\"120791\">RalfJ</span></p>\n</blockquote>\n<p>the difference is in whether it is UB for such an access to be in a data race with other accesses</p>",
        "id": 171787655,
        "sender_full_name": "RalfJ",
        "timestamp": 1564158734
    },
    {
        "content": "<p>and there's also a difference in whether a happens-before relationship can be established when this access is combined the right way with a fence</p>",
        "id": 171787669,
        "sender_full_name": "RalfJ",
        "timestamp": 1564158762
    },
    {
        "content": "<p>I had a long discussion with <span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span> about that once, but I am not sure where... we should find some place to write down the conclusions of that discussion</p>",
        "id": 171787700,
        "sender_full_name": "RalfJ",
        "timestamp": 1564158798
    },
    {
        "content": "<blockquote>\n<p>atomic has two aspects, non-tearing and the Ordering thing. So I don't think you want \"atomic volatile\", you just want \"non-tearing volatile\".</p>\n</blockquote>\n<p>Wasn't one of the ordering for atomics in LLVM <code>Unordered</code> ? (I'm not sure how that differed from <code>Relaxed</code> since <code>Relaxed</code> is defined as \"no ordering\")</p>",
        "id": 171787785,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564158877
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228354\">@Matt Taylor</span> I am not sure how familiar you are with the C/C++ concurrency memory model(s)?</p>",
        "id": 171787793,
        "sender_full_name": "RalfJ",
        "timestamp": 1564158882
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span> yeah LLVM has an \"even weaker than <code>Relaxed</code>\" thing. IIRC it does not even guarantee coherence (i.e. it can first see a new write and then an old write). no idea how that relates to volatile or \"normal\" accesses though.</p>",
        "id": 171787840,
        "sender_full_name": "RalfJ",
        "timestamp": 1564158925
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228354\">@Matt Taylor</span> ah here is the public part of that discussion: <a href=\"https://internals.rust-lang.org/t/add-volatile-operations-to-core-x86-64/10480\" target=\"_blank\" title=\"https://internals.rust-lang.org/t/add-volatile-operations-to-core-x86-64/10480\">https://internals.rust-lang.org/t/add-volatile-operations-to-core-x86-64/10480</a></p>",
        "id": 171787931,
        "sender_full_name": "RalfJ",
        "timestamp": 1564158991
    },
    {
        "content": "<p>but there's also a long private chat thread between <span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span> and me</p>",
        "id": 171787935,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159000
    },
    {
        "content": "<p>I don't remember what the value was in doing something less than relaxed</p>",
        "id": 171788098,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159156
    },
    {
        "content": "<p>relaxed-&gt;fence-&gt;fence-&gt;relaxed can imply happens-before</p>",
        "id": 171788110,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159176
    },
    {
        "content": "<p>Sure, using relaxed allows for some synchronization if the proper fences and other atomic operations are used</p>",
        "id": 171788115,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159179
    },
    {
        "content": "<p>which I dont think we want for volatile</p>",
        "id": 171788121,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159183
    },
    {
        "content": "<p>i mean, it can, if one uses the fences</p>",
        "id": 171788191,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159211
    },
    {
        "content": "<p>but then one wanted synchronization of some sort I guess, otherwise why use the fences</p>",
        "id": 171788208,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159227
    },
    {
        "content": "<p>yes. but the key thing is if you replace <code>Relaxed</code> by a \"normal\" access, it does not imply anything, even with the fences</p>",
        "id": 171788219,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159237
    },
    {
        "content": "<p>yes that's right, a volatile atomic relaxed is not the same as a normal volatile load / store because of the fence interaction</p>",
        "id": 171788246,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159270
    },
    {
        "content": "<p>so without a very careful study I'd argue it should also not imply anything for volatile accesses</p>",
        "id": 171788261,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159287
    },
    {
        "content": "<p>maybe <code>Unordered</code> is enough for that, not sure</p>",
        "id": 171788274,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159296
    },
    {
        "content": "<p><a href=\"https://llvm.org/docs/Atomics.html#unordered\" target=\"_blank\" title=\"https://llvm.org/docs/Atomics.html#unordered\">https://llvm.org/docs/Atomics.html#unordered</a></p>",
        "id": 171788350,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159352
    },
    {
        "content": "<p>\"These operations are required to be atomic in the sense that if you use unordered loads and unordered stores, a load cannot see a value which was never stored. \"</p>",
        "id": 171788493,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159450
    },
    {
        "content": "<p>\"This cannot be used for synchronization\"</p>",
        "id": 171788510,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159461
    },
    {
        "content": "<p>seems reasonable</p>",
        "id": 171788514,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159466
    },
    {
        "content": "<p>\"can be expensive or unavailable for wider loads\"</p>",
        "id": 171788523,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159475
    },
    {
        "content": "<p>It appears that it fails to compile if there isn't a native instruction that performs the operation atomically.</p>",
        "id": 171788555,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159506
    },
    {
        "content": "<p>probably volatile already acts like unordered, except for the tearing aspect</p>",
        "id": 171788562,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159514
    },
    {
        "content": "<p>\"an unordered load or store cannot be split into multiple instructions \"</p>",
        "id": 171788579,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159525
    },
    {
        "content": "<p>but based on the feedback we got so far, it seems unlikely LLVM will want to guarantee that to us :/</p>",
        "id": 171788587,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159530
    },
    {
        "content": "<p>FWIW on IRC they did recommend looking into atomic unordered instead if we wanted guaranteed no tearing</p>",
        "id": 171788619,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159557
    },
    {
        "content": "<p>we want no tearing <em>and</em> volatile though</p>",
        "id": 171788680,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159580
    },
    {
        "content": "<p>but then these operations can be marked with <code>volatile</code></p>",
        "id": 171788700,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159591
    },
    {
        "content": "<p>unordered can be dead-read-eliminated, for example</p>",
        "id": 171788708,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159594
    },
    {
        "content": "<p>LLVM lets you combine atomic orderings with <code>volatile</code>?</p>",
        "id": 171788731,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159605
    },
    {
        "content": "<p>yes it would be volatile+unordered</p>",
        "id": 171788732,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159606
    },
    {
        "content": "<p>yes it does, for all atomic orderings!</p>",
        "id": 171788747,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159613
    },
    {
        "content": "<p>oh wow</p>",
        "id": 171788754,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159617
    },
    {
        "content": "<p>whatever the heck that means in terms of semantics^^</p>",
        "id": 171788763,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159629
    },
    {
        "content": "<p>so that's what I meant that volatile+relaxed might have done the trick</p>",
        "id": 171788767,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159634
    },
    {
        "content": "<p>even though it might be a bit footguny if it can imply a happens before</p>",
        "id": 171788786,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159652
    },
    {
        "content": "<p>I think if you <code>s/Relaxed/Unordered/</code>, I can live with that</p>",
        "id": 171788789,
        "sender_full_name": "RalfJ",
        "timestamp": 1564159653
    },
    {
        "content": "<p>we could add unstable <code>volatile_unordered_load</code>/<code>store</code> methods to the Atomic types and see if those solve the problems that people have</p>",
        "id": 171788882,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159709
    },
    {
        "content": "<p>most are already doing what works for them, whatever that might be</p>",
        "id": 171788901,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159725
    },
    {
        "content": "<p>wow, this is a much bigger mess than i originally thought ^_^ thanks for the links, reading now</p>",
        "id": 171788922,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564159753
    },
    {
        "content": "<p>we could also add generic <code>volatile_load</code>/<code>store</code> methods to the atomic types that take an Ordering <span aria-label=\"laughter tears\" class=\"emoji emoji-1f602\" role=\"img\" title=\"laughter tears\">:laughter_tears:</span> <br>\nI really have no idea why would one to use volatile with the other orderings</p>",
        "id": 171789037,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564159830
    },
    {
        "content": "<blockquote>\n<p>wow, this is a much bigger mess than i originally thought ^_^ thanks for the links, reading now</p>\n</blockquote>\n<p>why is that the reaction I get almost every time I answer a question? <span aria-label=\"rofl\" class=\"emoji emoji-1f923\" role=\"img\" title=\"rofl\">:rofl:</span></p>",
        "id": 171789397,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160135
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span> or we could just make our existing intrinsics be <code>volatile unordered</code></p>",
        "id": 171789492,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160173
    },
    {
        "content": "<p>then we can entirely side-step the question of \"what are the semantics of non-atomic volatile accesses\" :D</p>",
        "id": 171789514,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160197
    },
    {
        "content": "<p>I think that wouldn't work, it would fail to compile if the load can tear</p>",
        "id": 171789517,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160201
    },
    {
        "content": "<p>oh dang</p>",
        "id": 171789531,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160213
    },
    {
        "content": "<p>I'd like a version of <code>Unordered</code> that permits tearing but still does not have data race problems...</p>",
        "id": 171789566,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160243
    },
    {
        "content": "<p>I think the tearing loads are not atomic</p>",
        "id": 171789606,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160269
    },
    {
        "content": "<p>you can probably implement them on top of the atomic unordered ones</p>",
        "id": 171789665,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160283
    },
    {
        "content": "<p>the ordering annotations make sense even with tearing</p>",
        "id": 171789672,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160287
    },
    {
        "content": "<p>they would say that all the individual \"tears\" would have that ordering</p>",
        "id": 171789719,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160312
    },
    {
        "content": "<p>the ordering annotations explicitly say that one cannot observe values that haven't been written to I think</p>",
        "id": 171789735,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160322
    },
    {
        "content": "<p>I don't think there is an ordering that doesn't say that</p>",
        "id": 171789751,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160336
    },
    {
        "content": "<p>this would still apply \"per-fragment\" for the teared ones</p>",
        "id": 171789765,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160344
    },
    {
        "content": "<p>in fact we could just say it applies per byte</p>",
        "id": 171789782,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160363
    },
    {
        "content": "<p>sure, but I don't know what would LLVM win from exposing them as intrinsics</p>",
        "id": 171789793,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160371
    },
    {
        "content": "<p>coalescing adjacent atomic accesses is sound, AFAIK</p>",
        "id": 171789794,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160372
    },
    {
        "content": "<p>basically I want to not ever have to think about non-atomic volatile accesses again</p>",
        "id": 171789876,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160405
    },
    {
        "content": "<p>the question \"how do volatile and atomic interact\" comes up all the time</p>",
        "id": 171789895,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160417
    },
    {
        "content": "<p>if the answer is \"like unordered but bytewise\", that would be a big step IMO</p>",
        "id": 171789907,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160427
    },
    {
        "content": "<p>I think we should just deprecate the volatile reads/writes  if the volatile atomic unordered intrinsics solve the problem</p>",
        "id": 171789919,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160438
    },
    {
        "content": "<p>people that want tearing should just call those in a loop or something</p>",
        "id": 171789931,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160454
    },
    {
        "content": "<p>I don't know what problem tearing volatile load / stores solve</p>",
        "id": 171789964,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160478
    },
    {
        "content": "<p>(a) deprecation does not absolve us from defining their semantics, (b) we probably should still provide arbitrarily-sized volatile accesses \"because C does\"</p>",
        "id": 171789971,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160483
    },
    {
        "content": "<p>we can just wrap them to loop over the memory doing 1-byte wide volatile atomic unordered operations</p>",
        "id": 171790002,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160511
    },
    {
        "content": "<p>maybe something cleverer than that, like using the largest possible size or something</p>",
        "id": 171790073,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160536
    },
    {
        "content": "<p>very inefficient. but probably good enough for something deprecated.</p>",
        "id": 171790084,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160544
    },
    {
        "content": "<p>i mean, huge volatile load / stores generate horrible code already today</p>",
        "id": 171790125,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160584
    },
    {
        "content": "<p>yeah</p>",
        "id": 171790145,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160606
    },
    {
        "content": "<p>sounds like a solid plan to me</p>",
        "id": 171790151,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160612
    },
    {
        "content": "<p>i think there was an example of using one on an array of 4096 bytes and getting horrible assembly</p>",
        "id": 171790153,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564160614
    },
    {
        "content": "<p>you would probably have to avoid doing it in 1 byte chunks not for performance but also just the fact that many people seem to erroneously rely on them for non-tearing for small types anyway</p>",
        "id": 171790249,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564160684
    },
    {
        "content": "<ul>\n<li>find a way to provide one uniform API for \"non-tearing\" accesses</li>\n<li>use that to provide atomic and volatile accesses (the volatile ones being unordered implicitly)</li>\n<li>remove the old intrinsics and implement everything in terms of the new shiny ones</li>\n</ul>\n<p>the user-visible API for non-tearing volatile accesses is still open I think?</p>",
        "id": 171790283,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160723
    },
    {
        "content": "<p>also <span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span> <a href=\"https://github.com/rust-lang/rfcs/pull/2728\" target=\"_blank\" title=\"https://github.com/rust-lang/rfcs/pull/2728\">https://github.com/rust-lang/rfcs/pull/2728</a> has been proposed, so the longer we wait the more messy volatile stuff already exists...</p>",
        "id": 171790295,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160749
    },
    {
        "content": "<blockquote>\n<p>you would probably have to avoid doing it in 1 byte chunks not for performance but also just the fact that many people seem to erroneously rely on them for non-tearing for small types anyway</p>\n</blockquote>\n<p>shouldn't be too hard to do something like</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"k\">match</span><span class=\"w\"> </span><span class=\"n\">size_of</span>::<span class=\"o\">&lt;</span><span class=\"n\">T</span><span class=\"o\">&gt;</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"mi\">1</span><span class=\"w\"> </span><span class=\"o\">=&gt;</span><span class=\"w\"> </span><span class=\"p\">...</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"o\">=&gt;</span><span class=\"w\"> </span><span class=\"p\">...</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"mi\">4</span><span class=\"w\"> </span><span class=\"o\">=&gt;</span><span class=\"w\"> </span><span class=\"p\">...</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"mi\">8</span><span class=\"w\"> </span><span class=\"o\">=&gt;</span><span class=\"w\"> </span><span class=\"p\">...</span><span class=\"w\"></span>\n<span class=\"w\">  </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"o\">=&gt;</span><span class=\"w\"> </span><span class=\"c1\">// fallback, loop with largest power of 2 that is a factor of n</span>\n<span class=\"w\">  </span><span class=\"p\">...</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</pre></div>",
        "id": 171790373,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160794
    },
    {
        "content": "<p>in fact if we \"loop with largest power of 2 &lt;= size_of::&lt;usize&gt;() that is a factor of n\", we'd get the expected behavior for sizes 2, 4, and on 64bit also size 8</p>",
        "id": 171790482,
        "sender_full_name": "RalfJ",
        "timestamp": 1564160892
    },
    {
        "content": "<p>This would obviously be RFC material. I don't know who should give this idea some thought before we do that</p>",
        "id": 171791850,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564161989
    },
    {
        "content": "<p>even if it’s only exposed via arch-dependent intrinsics, i believe it’s still worth considering volatile ops other than just load and store. for example on x86 i believe you need to use an OR when updating certain bits of page tables, and this strictly speaking should be done through volatile</p>",
        "id": 171793040,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564162931
    },
    {
        "content": "<p>i’m not even sure if there are ways of doing this in rust currently</p>",
        "id": 171793057,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564162951
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228354\">@Matt Taylor</span> but what is the problem with doing read, OR, store?</p>",
        "id": 171798089,
        "sender_full_name": "RalfJ",
        "timestamp": 1564165516
    },
    {
        "content": "<p>is it because the CPU itself might concurrently modify the page table when the program does something?</p>",
        "id": 171798119,
        "sender_full_name": "RalfJ",
        "timestamp": 1564165549
    },
    {
        "content": "<p>in this case it’s that the cpu can set a flag after you read</p>",
        "id": 171798122,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564165549
    },
    {
        "content": "<p>yeah</p>",
        "id": 171798127,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564165554
    },
    {
        "content": "<p>ah makes sense</p>",
        "id": 171798130,
        "sender_full_name": "RalfJ",
        "timestamp": 1564165556
    },
    {
        "content": "<p>what do people do in C? I dont think it has volatile RMW operations</p>",
        "id": 171798193,
        "sender_full_name": "RalfJ",
        "timestamp": 1564165572
    },
    {
        "content": "<p>(RMW = read-modify-write, i.e., all these atomic_and, atomic_add, atomic_or, compare_exchange, ...)</p>",
        "id": 171798208,
        "sender_full_name": "RalfJ",
        "timestamp": 1564165588
    },
    {
        "content": "<p>it’s probably broken in C too lol</p>",
        "id": 171798241,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564165616
    },
    {
        "content": "<p>that’s a good question though</p>",
        "id": 171798245,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564165622
    },
    {
        "content": "<p>i mean <code>*some_volatile_var |= foo</code> is probably as close as it gets, but i guess at some point you just go for inline assembly</p>",
        "id": 171798365,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564165683
    },
    {
        "content": "<p>i’ll try and find out what people are doing for this instance</p>",
        "id": 171798425,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564165736
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span> maybe instead of duplicating the entire API for volatile (with RMWs etc), we should have <code>Ordering::Volatile</code>?</p>",
        "id": 171798799,
        "sender_full_name": "RalfJ",
        "timestamp": 1564165974
    },
    {
        "content": "<p>the problem is that the current API goes through &amp;self</p>",
        "id": 171799049,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564166165
    },
    {
        "content": "<p>and since references are dereferenceable, it’s not going to work for MMIO i think?</p>",
        "id": 171799065,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564166192
    },
    {
        "content": "<p>ah</p>",
        "id": 171799597,
        "sender_full_name": "RalfJ",
        "timestamp": 1564166595
    },
    {
        "content": "<p>but there are problems for that even with atomic usage</p>",
        "id": 171799598,
        "sender_full_name": "RalfJ",
        "timestamp": 1564166595
    },
    {
        "content": "<p>see <a href=\"https://github.com/rust-lang/rust/issues/55005\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/issues/55005\">https://github.com/rust-lang/rust/issues/55005</a></p>",
        "id": 171799611,
        "sender_full_name": "RalfJ",
        "timestamp": 1564166607
    },
    {
        "content": "<p>(you didnt think we were already done with the messy parts, did you?^^)</p>",
        "id": 171799629,
        "sender_full_name": "RalfJ",
        "timestamp": 1564166624
    },
    {
        "content": "<p>oh dear</p>",
        "id": 171799763,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564166717
    },
    {
        "content": "<p>i think i need to have a lie down</p>",
        "id": 171799781,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564166735
    },
    {
        "content": "<p>so <span class=\"user-mention\" data-user-id=\"228354\">@Matt Taylor</span> one proposal here is to make <code>UnsafeCell</code> not dereferencable. That would help with some things. An interesting open question is what to do about cases like <code>&amp;(i32, Cell&lt;i32&gt;)</code>; seems like at best we could mark the first 4 bytes dereferencable then. Though it would be nice if e.g. <code>Cell</code> could opt-back-in to <code>dereferencable</code>.<br>\nBut also see <a href=\"https://github.com/rust-lang/unsafe-code-guidelines/issues/88\" target=\"_blank\" title=\"https://github.com/rust-lang/unsafe-code-guidelines/issues/88\">https://github.com/rust-lang/unsafe-code-guidelines/issues/88</a>.</p>",
        "id": 171809110,
        "sender_full_name": "RalfJ",
        "timestamp": 1564174385
    },
    {
        "content": "<p>TANSTAAFL, or you didn't think you'd solve the problem that easily, did you? <span aria-label=\"rofl\" class=\"emoji emoji-1f923\" role=\"img\" title=\"rofl\">:rofl:</span></p>",
        "id": 171810426,
        "sender_full_name": "Tom Phinney",
        "timestamp": 1564175531
    },
    {
        "content": "<p>well I am just at the beginning of my research career, what would I do all day if there wouldn't be a large pool and a steady supply of open problems? ;)</p>",
        "id": 171811431,
        "sender_full_name": "RalfJ",
        "timestamp": 1564176531
    },
    {
        "content": "<p>What would you do? I'm reminded of an old joke about a mathematician. I couldn't find that precise one online, but <a href=\"https://www.reddit.com/r/Jokes/comments/1kid90/the_mathematicians_interview/\" target=\"_blank\" title=\"https://www.reddit.com/r/Jokes/comments/1kid90/the_mathematicians_interview/\">https://www.reddit.com/r/Jokes/comments/1kid90/the_mathematicians_interview/</a> comes close. <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span></p>",
        "id": 171815994,
        "sender_full_name": "Tom Phinney",
        "timestamp": 1564180238
    },
    {
        "content": "<p>so I guess it's good for y'all that I don't have to create <em>new</em> problems to solve then :D</p>",
        "id": 171817499,
        "sender_full_name": "RalfJ",
        "timestamp": 1564182025
    },
    {
        "content": "<blockquote>\n<p>This would help with some things</p>\n</blockquote>\n<p>what things does it not solve here? seems like with a non-dereferenceable UnsafeCell and Ordering::Volatile that uses LLVM Unordered underneath, we’re set (in terms of soundness)</p>",
        "id": 171818446,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564183219
    },
    {
        "content": "<p>what is it that i’ve neglected this time :p</p>",
        "id": 171818620,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564183445
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228354\">@Matt Taylor</span> I think for MMIO that would be all, I was thinking of other problems around <code>dereferencable</code>, like the <code>Arc</code> one</p>",
        "id": 171833878,
        "sender_full_name": "RalfJ",
        "timestamp": 1564212205
    },
    {
        "content": "<p>right</p>",
        "id": 171833920,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564212249
    },
    {
        "content": "<p>another potential problem with this route is that it blocks people from using different Orderings than the one we choose for Volatile (Unordered)</p>",
        "id": 171833935,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564212316
    },
    {
        "content": "<p>see <span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span>'s question in the thread: what is the use-case for an access that is <em>both</em> synchronizing and volatile?</p>",
        "id": 171834328,
        "sender_full_name": "RalfJ",
        "timestamp": 1564213030
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 171841923,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564227390
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 171841939,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564227460
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 171841986,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564227493
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 171841989,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564227504
    },
    {
        "content": "<p>volatile is orthogonal to atomics: it says that the reads and writes to memory must happen exactly has written in the code, e.g., if you read the same memory twice, those two reads must happen, if you read from memory once, only one read can happen, etc.</p>",
        "id": 171842000,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564227541
    },
    {
        "content": "<p>the compiler must assume that the reads and writes have side-effects like unknown function calls, etc.</p>",
        "id": 171842007,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564227580
    },
    {
        "content": "<p>That pretty much inhibits all optimizations, so why would want to on top of that combine the volatile reads / writes with atomics ?</p>",
        "id": 171842056,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564227606
    },
    {
        "content": "<p>No idea. If you have volatile and atomic operations, the compiler might be able to re-order the atomic ones across the volatile ones in certain ways. By making the atomic ones volatile, you inhibit that.</p>",
        "id": 171842064,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564227640
    },
    {
        "content": "<p>Somebody on LLVM IRC mentioned that \"volatile synchronizes with volatile\" because you can't reorder volatile operations across each other</p>",
        "id": 171842134,
        "sender_full_name": "gnzlbg",
        "timestamp": 1564227840
    },
    {
        "content": "<blockquote>\n<p>volatile is orthogonal to atomics: it says that the reads and writes to memory must happen exactly has written in the code, e.g., if you read the same memory twice, those two reads must happen, if you read from memory once, only one read can happen, etc.</p>\n</blockquote>\n<p>agreed. slightly more formally speaking: it makes reads and write observable events, and thus part of the program behavior that must be preserved.</p>",
        "id": 171880773,
        "sender_full_name": "RalfJ",
        "timestamp": 1564303464
    },
    {
        "content": "<blockquote>\n<p>Somebody on LLVM IRC mentioned that \"volatile synchronizes with volatile\" because you can't reorder volatile operations across each other</p>\n</blockquote>\n<p>I think that's very wrong. \"synchronizes with\" also means that <em>other</em> instructions cannot be reordered around this. that is explicitly <em>not</em> true for <code>volatile</code>.</p>",
        "id": 171880777,
        "sender_full_name": "RalfJ",
        "timestamp": 1564303494
    },
    {
        "content": "<p>IOW, the following code is wrong:</p>\n<div class=\"codehilite\"><pre><span></span>static int DATA = 0;\nvolatile int FLAG = 0;\n</pre></div>\n\n\n<p>thread A:</p>\n<div class=\"codehilite\"><pre><span></span>DATA = 42;\nFLAG = 1;\n</pre></div>\n\n\n<p>thread B:</p>\n<div class=\"codehilite\"><pre><span></span>while (FLAG == 0) {}\nprintf(&quot;%d&quot;, DATA);\n</pre></div>",
        "id": 171880809,
        "sender_full_name": "RalfJ",
        "timestamp": 1564303562
    },
    {
        "content": "<p>if volatile synced-with volatile, then that code would be fine, but in fact the compiler is allowed to reorder the two writes in thread A</p>",
        "id": 171880834,
        "sender_full_name": "RalfJ",
        "timestamp": 1564303593
    },
    {
        "content": "<p>isn’t their point that you can’t reorder a volatile around <em>other volatiles</em>? in your case, there is only one volatile, but if you make data volatile then it would be forced to not reorder the writes</p>",
        "id": 171881060,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564304078
    },
    {
        "content": "<p>yes, they are saying \"X and X implies Y, hence Y\" where X = \"volatiles cannot be reodered with each other\" and Y = \"volatiles sync with each other\"</p>",
        "id": 171881284,
        "sender_full_name": "RalfJ",
        "timestamp": 1564304495
    },
    {
        "content": "<p>I agree with \"X\" but I do not agree with \"X implies Y\", and hence I do not agree with \"Y\"</p>",
        "id": 171881286,
        "sender_full_name": "RalfJ",
        "timestamp": 1564304509
    },
    {
        "content": "<p>\"sync withe each other\" has a very precise meaning in concurrent memory models. it's what release/acquire accesses (amongst other things do)</p>",
        "id": 171881341,
        "sender_full_name": "RalfJ",
        "timestamp": 1564304562
    },
    {
        "content": "<p>if you replace the volailte load/store in my example by release/acquire load store, it becomes correct</p>",
        "id": 171881344,
        "sender_full_name": "RalfJ",
        "timestamp": 1564304576
    },
    {
        "content": "<p>yep, it's definitely wrong that volatile synchronizes-with volatile in that sense</p>",
        "id": 171881349,
        "sender_full_name": "comex",
        "timestamp": 1564304583
    },
    {
        "content": "<p>it becomes correct because you cannot move the store to DATA down below the release-store to FLAG</p>",
        "id": 171881355,
        "sender_full_name": "RalfJ",
        "timestamp": 1564304608
    },
    {
        "content": "<p><em>that</em> is what it means for accesses to synchronize</p>",
        "id": 171881357,
        "sender_full_name": "RalfJ",
        "timestamp": 1564304610
    },
    {
        "content": "<p>i think they were just using it too loosely. either way, i think we’re in agreement here</p>",
        "id": 171881360,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564304627
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228354\">@Matt Taylor</span> I agree that we two are in agreement. they might \"just\" have said it to loosely but the business of specifying a language it not one where you can permit yourself to be loose about your terminology.</p>",
        "id": 171881403,
        "sender_full_name": "RalfJ",
        "timestamp": 1564304662
    },
    {
        "content": "<p>yeah, absolutely</p>",
        "id": 171881405,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564304693
    },
    {
        "content": "<p>so, I am not being nitpicky to annoy people, and I dont think they are being a bad person by being loose about terminology, I just try to make sure we all use the same terms to mean the same things, in particular terms that actually <em>do</em> have a precise meaning :)</p>",
        "id": 171881421,
        "sender_full_name": "RalfJ",
        "timestamp": 1564304754
    },
    {
        "content": "<p>I should probably read up a bit more on C’s concurrent memory model</p>",
        "id": 171881489,
        "sender_full_name": "Matt Taylor",
        "timestamp": 1564304871
    },
    {
        "content": "<p>are you sure you want that? hint: if you thought <code>volatile</code> was messy...</p>",
        "id": 171881914,
        "sender_full_name": "RalfJ",
        "timestamp": 1564305725
    },
    {
        "content": "<p>the good news is that the concurrency mess is different :P</p>",
        "id": 171881916,
        "sender_full_name": "RalfJ",
        "timestamp": 1564305780
    },
    {
        "content": "<p>the problem is not that we have no formal model, the problem is we have a dozen of them that all have different flaws</p>",
        "id": 171881922,
        "sender_full_name": "RalfJ",
        "timestamp": 1564305793
    }
]