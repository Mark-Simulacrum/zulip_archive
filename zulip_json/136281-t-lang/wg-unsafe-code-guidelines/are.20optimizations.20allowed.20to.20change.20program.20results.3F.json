[
    {
        "content": "<p>In some Rust targets, like <code>i586</code>, optimizations currently change the program results, e.g., when FP arithmetic is involved</p>",
        "id": 164443902,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556537468
    },
    {
        "content": "<p>For example, when the x87 FPU is used, and the precision of the FPU registers is not appropriately set, which is expensive, at different optimization levels (e.g. <code>-C opt-level=0</code> vs <code>-C opt-level=3</code>) sample programs produce different results.</p>",
        "id": 164443972,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556537531
    },
    {
        "content": "<p><a href=\"https://github.com/rust-lang/unsafe-code-guidelines/issues/123\" target=\"_blank\" title=\"https://github.com/rust-lang/unsafe-code-guidelines/issues/123\">https://github.com/rust-lang/unsafe-code-guidelines/issues/123</a></p>",
        "id": 164443982,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556537565
    },
    {
        "content": "<p>The very definition of a correct optimization is that it does not change what the program does. Or rather, more carefully stated: every behavior of the optimized program must have been a possible behavior of the source program.</p>",
        "id": 164444010,
        "sender_full_name": "RalfJ",
        "timestamp": 1556537607
    },
    {
        "content": "<p>So the way I see it, either whatever happens on x87 is unsound, or the semantics are not what we think they are.</p>",
        "id": 164444011,
        "sender_full_name": "RalfJ",
        "timestamp": 1556537607
    },
    {
        "content": "<p>Debug builds and release builds behaving differently is not an issue <em>per se</em>, it just means that the program is non-deterministic and the compiler chose different executions.</p>",
        "id": 164444012,
        "sender_full_name": "RalfJ",
        "timestamp": 1556537607
    },
    {
        "content": "<p>I think it might make sense to, as part of the glossary of the UCGs, define what an optimization is, because we already guarantee some (e.g. niche Optimizations)</p>",
        "id": 164444015,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556537615
    },
    {
        "content": "<p>niche optimizations isnt really an optimization in this sense, yeah</p>",
        "id": 164444023,
        "sender_full_name": "RalfJ",
        "timestamp": 1556537637
    },
    {
        "content": "<p>it's more part of the data layout stuff that is partially unspecified</p>",
        "id": 164444068,
        "sender_full_name": "RalfJ",
        "timestamp": 1556537650
    },
    {
        "content": "<p>and maybe answer the fundamental question of whether rust optimizations are allowed to change rust program semantics or not (without going into FP), and maybe RFCing that</p>",
        "id": 164444070,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556537654
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"120791\">@RalfJ</span> indeed, niche optimizations are a bad example</p>",
        "id": 164444077,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556537679
    },
    {
        "content": "<blockquote>\n<p>and maybe answer the fundamental question of whether rust optimizations are allowed to change rust program semantics or not (without going into FP), and maybe RFCing that</p>\n</blockquote>\n<p>uh. of course they are not. that's like asking if the rust compiler is allowed to erase your hard disk. we dont need an RFC for that, there is decades of research on what is a compiler.^^</p>",
        "id": 164444082,
        "sender_full_name": "RalfJ",
        "timestamp": 1556537690
    },
    {
        "content": "<p>it might be worth repeating that here to have it documented, but having an RFC on this to me feels like having an RFC on the value of pi.^^</p>",
        "id": 164444111,
        "sender_full_name": "RalfJ",
        "timestamp": 1556537727
    },
    {
        "content": "<p>indeed | EDIT: this was part of a private thread, so what follows does not make much sense here - the idea being explored here was how miri could implement fp non-determinism, e.g, by storing multiple values per float (e.g. an f64 and an f80 one)</p>",
        "id": 164444797,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556538478
    },
    {
        "content": "<p>so per FP stack you don't only need two values, f64 and f80, you need all possible values</p>",
        "id": 164444869,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556538536
    },
    {
        "content": "<p>\"FP stack\"?</p>",
        "id": 164444889,
        "sender_full_name": "RalfJ",
        "timestamp": 1556538555
    },
    {
        "content": "<p>e.g. if you want to diagnose <code>if x &gt; y { unsafe { foo() }</code> and see if that can be called, where x and y have arrived from a chain of N and M FP arithmetic operations</p>",
        "id": 164444903,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556538574
    },
    {
        "content": "<p>each of which individual operation could have been performed with a different precision, you have many x and many y possible values</p>",
        "id": 164444922,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556538596
    },
    {
        "content": "<p>and are probably interested in \"will this branch always or never be taken\"</p>",
        "id": 164444983,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556538614
    },
    {
        "content": "<p>that is, if you want to avoid executing the program an infinite amount of times, you'd have to track all FP values that are getting accumulated</p>",
        "id": 164445014,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556538665
    },
    {
        "content": "<p>sure, the usual problem with non-determinism is that it can be infeasible to explore all possible executions</p>",
        "id": 164445087,
        "sender_full_name": "RalfJ",
        "timestamp": 1556538725
    },
    {
        "content": "<p>so I asked on #llvm in IRC and it seems that fixing this for i586 would be too expensive, and even then might not work properly</p>",
        "id": 164446963,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556540676
    },
    {
        "content": "<p>the best bet would be to make all loads and stores of f32 and f64 in i586 volatile, instead of playing with rounding modes</p>",
        "id": 164447018,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556540731
    },
    {
        "content": "<p>that would not produce the same results as SSE, but that's actually something we could implement in miri</p>",
        "id": 164447565,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556541200
    },
    {
        "content": "<p>Yes, it's not fundamentally difficult to force some arbitrary deterministic behavior out of x87 if you accept a big performance hit. But that doesn't solve the actual underlying question for UCG: what degree of non-determinism in floating point is possible (and hence, how much can results vary between different executions). Some amount is clearly needed to account for platform differences and compiler optimizations (see above, also: NaN bit patterns) but presumably there should be some limits even in the worst case?</p>",
        "id": 164484215,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1556568463
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"132920\">@gnzlbg</span>  FP arithmetic is imprecise: optimizations can and often do change program results. You don't have to conditionally-invoke <code>unsafe</code> behavior to show this; all you need do is apply the associative and distributive laws of arithmetic to reorder the terms and/or factors in a computation, which is something that LLVM-like optimizers do. Often such reordering will lead to slightly different FP numeric results, which when compared with an \"expected\" result can lead to taking different branches in a program.</p>",
        "id": 164491751,
        "sender_full_name": "Tom Phinney",
        "timestamp": 1556574391
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"132894\">@Tom Phinney</span> we dont do those optimizations, and llvm doesn’t do them by default either</p>",
        "id": 164491824,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556574469
    },
    {
        "content": "<p>One needs to opt-into -ffast-math in llvm and clang because of that</p>",
        "id": 164491891,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556574502
    },
    {
        "content": "<p>So AFAICT the x87 situation is an LLVM bug</p>",
        "id": 164491909,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556574535
    },
    {
        "content": "<p>On IRC some devs mentioned they would accept patches for that target, even if they make things much slower for the target by default</p>",
        "id": 164491961,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556574597
    },
    {
        "content": "<p>I don’t know whether that would really end up happening, but optimizations should not change your program results</p>",
        "id": 164492062,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556574662
    },
    {
        "content": "<p>At least not without explicitly opting into unsound optimizations</p>",
        "id": 164492089,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556574700
    },
    {
        "content": "<blockquote>\n<p>So AFAICT the x87 situation is an LLVM bug</p>\n</blockquote>\n<p>I think this is quite arguable. The behavior of LLVM's codegen on x87 is closer to what FLT_EVAL_METHOD in standard C blesses as an implementation choice (only that the extra precision is not stripped at source-level assignments and casts but at ill-defined other points) than to the decidedly more shaky -ffast-math. You could argue LLVM IR should have stricter semantics by default and make the current behavior opt-in but AFAICT it deliberately doesn't (it's important for many targets, including very modern ones, to have some leeway in IEEE conformance). An option for more determinism would be great, but I think we can only seriously contemplate this in 2019 because nobody really cares about non-SSE2 hardware any more, and for the very same reason it'll be hard to get people to care enough to even classify this as a bug that needs fixing instead of sweeping it under the rug as being covered by the lack of guarantees about IEEE conformance.</p>",
        "id": 164494923,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1556577586
    },
    {
        "content": "<p>Which other modern targets have this particular behavior?</p>",
        "id": 164514396,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556604811
    },
    {
        "content": "<p>Most / all LLVM FP intrinsics do mention IEEE conformance in the LangRef (and the standard is exact for many operations, e.g., +-*...), and there are fast-math flags in place to enable this kind of behavior already AFAICT</p>",
        "id": 164516316,
        "sender_full_name": "gnzlbg",
        "timestamp": 1556607583
    },
    {
        "content": "<p>Various embedded platforms and GPUs have settings like \"flush denormals to zero\". Even when those are optional settings, they are commonly enabled and compilers want to be able to Just Work in their presence (unlike e.g. access to floating point exceptions and changes to rounding mode, which need special accomodation). And then there's the fact that some operations may be lowered to libcalls that are, in practice, not as accurate as IEEE mandates, but LLVM still wants to be able to generate code for those targets.</p>",
        "id": 164516897,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1556608291
    },
    {
        "content": "<p>I just took another look at LangRef and indeed some intrinsics make reference to the corresponding libm function, but fadd/fsub/fmul/fdiv notably don't refer to IEE 754!</p>",
        "id": 164516984,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1556608390
    }
]