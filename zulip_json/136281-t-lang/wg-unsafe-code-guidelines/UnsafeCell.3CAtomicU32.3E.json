[
    {
        "content": "<p>Hi, I'm not sure if this is the best place to ask (or even how to use zulip). I've used UnsafeCell&lt;AtomicU32&gt; in order to perform unsynchronized loads when I can guarantee that other threads <em>only</em> load from that atomic (never store). Is this safe? <a href=\"https://github.com/tokio-rs/tokio/blob/3a941e99a112f0058d2ac1f295da29491ba4b232/tokio-executor/src/loom/atomic_u32.rs#L25-L27\" target=\"_blank\" title=\"https://github.com/tokio-rs/tokio/blob/3a941e99a112f0058d2ac1f295da29491ba4b232/tokio-executor/src/loom/atomic_u32.rs#L25-L27\">https://github.com/tokio-rs/tokio/blob/3a941e99a112f0058d2ac1f295da29491ba4b232/tokio-executor/src/loom/atomic_u32.rs#L25-L27</a></p>",
        "id": 178132940,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571082607
    },
    {
        "content": "<p>I am pretty sure it is, but got a comment on HN and i was not sure how to respond: <a href=\"https://news.ycombinator.com/item?id=21251778\" target=\"_blank\" title=\"https://news.ycombinator.com/item?id=21251778\">https://news.ycombinator.com/item?id=21251778</a></p>",
        "id": 178132954,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571082624
    },
    {
        "content": "<p>It is UB, and I got some actual miscompilation on one of my programs while trying something similar so it's not a theoretical concern.</p>",
        "id": 178133319,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571082928
    },
    {
        "content": "<p>Further, <code>UnsafeCell&lt;AtomicXyz&gt;</code> is redundant because <code>AtomicXyz</code> already contains an <code>UnsafeCell&lt;Xyz&gt;</code>.</p>",
        "id": 178133446,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083012
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211871\">@Hadrien Grasland</span> what part is UB?</p>",
        "id": 178133480,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571083028
    },
    {
        "content": "<p>Loading from an UnsafeCell some data which may have ever been touched by another thread.</p>",
        "id": 178133512,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083053
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211871\">@Hadrien Grasland</span> by touched, you mean mutated? In this case, there are no mutations from other threads</p>",
        "id": 178133547,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571083081
    },
    {
        "content": "<p>The problem is that even with UnsafeCell, the compiler can assume that if it knows about all memory accesses in the current thread, it knows about all memory accesses, period.</p>",
        "id": 178133589,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083084
    },
    {
        "content": "<p>So it can optimize out \"redundant\" loads and so on.</p>",
        "id": 178133612,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083098
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211871\">@Hadrien Grasland</span> in this case, it does know about all stores in the thread</p>",
        "id": 178133626,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571083115
    },
    {
        "content": "<p>And there are no stores from other threads and have never been?</p>",
        "id": 178133655,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083136
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211871\">@Hadrien Grasland</span> all stores are guarded by locks and the unsync_load happens within the lock</p>",
        "id": 178133688,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571083156
    },
    {
        "content": "<p>Oh, if you have a lock, then that is your synchronization.</p>",
        "id": 178133711,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083181
    },
    {
        "content": "<p>In that case, you don't need Atomic, you could use UnsafeCell&lt;u32&gt; directly.</p>",
        "id": 178133726,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083197
    },
    {
        "content": "<p>(unless you sometimes want to access the atomic without going through the lock)</p>",
        "id": 178133794,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083210
    },
    {
        "content": "<p>By the way, what's wrong with just doing atomic loads and stores with <code>Relaxed</code> ordering?</p>",
        "id": 178133821,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083231
    },
    {
        "content": "<p>100% of mutations are in the lock, only loads are outside of the lock</p>",
        "id": 178133824,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571083234
    },
    {
        "content": "<blockquote>\n<p>100% of mutations are in the lock, only loads are outside of the lock</p>\n</blockquote>\n<p>But how do you make sure that the mutations are propagated to the threads doing the load?</p>",
        "id": 178133879,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083291
    },
    {
        "content": "<p>At the hardware level, <code>load(Relaxed)</code> should compile down to a normal load instructions on all current CPUs. But at the compiler level, it serves as a warning that the value may have changed as a result of another thread modifying it, and the compiler should go check it from time to time.</p>",
        "id": 178134026,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083409
    },
    {
        "content": "<p>(Currently, LLVM pessimistically interprets this as a command to go check the value <em>every single time</em>, but most other experts I know agree with me that this is an LLVM optimizer bug)</p>",
        "id": 178134162,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083482
    },
    {
        "content": "<p>There is heavier synchronization else where that guarantees it</p>",
        "id": 178134255,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571083563
    },
    {
        "content": "<p>When you acquire a lock (or use an atomic with <code>Acquire</code> ordering, which is what the lock implementation does under the hood), the compiler automatically treats every shared variable which you're going to manipulate inside of the lock like this. But without a lock, you need to hint the compiler at the necessity of refreshing its local cache of the shared variable.</p>",
        "id": 178134303,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083589
    },
    {
        "content": "<p>Oh, if you have heavier synchronization then you should probably be fine.</p>",
        "id": 178134327,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083623
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211871\">@Hadrien Grasland</span> the details are in this post: <a href=\"https://tokio.rs/blog/2019-10-scheduler/\" target=\"_blank\" title=\"https://tokio.rs/blog/2019-10-scheduler/\">https://tokio.rs/blog/2019-10-scheduler/</a> (including how other threads are notified)</p>",
        "id": 178134333,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571083625
    },
    {
        "content": "<p>Reading through...</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"c1\">// safety: this is the **only** thread that updates this cell.</span>\n<span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">tail</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">tail</span><span class=\"p\">.</span><span class=\"n\">unsync_load</span><span class=\"p\">();</span><span class=\"w\"></span>\n</pre></div>\n\n\n<p>I agree with the safety note stating that this should work, but I would just use <code>load(Relaxed)</code> unless I have a benchmark proving that there's a performance benefit in not doing so, for the sake of sticking with familiar abstractions.</p>",
        "id": 178134617,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083838
    },
    {
        "content": "<p>If I had to do it, then I would do it by transmuting <code>&amp;AtomicU32</code> into <code>&amp;UnsafeCell&lt;u32&gt;</code> or just plain <code>*const u32</code> (I believe there are some <code>repr(transparent)</code> in the right places that makes those transmutes okay).</p>",
        "id": 178134670,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571083891
    },
    {
        "content": "<p>I've run benchmarks where the unsync load is measurably faster than a relaxed load</p>",
        "id": 178134818,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571084005
    },
    {
        "content": "<p>Most likely the aforementioned LLVM optimizer bug, sigh.</p>",
        "id": 178134845,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571084031
    },
    {
        "content": "<p>there was a previous thread w/ <span class=\"user-mention\" data-user-id=\"120791\">@RalfJ</span> on a similar optimization in the <code>bytes</code> crate</p>",
        "id": 178134846,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571084031
    },
    {
        "content": "<p>:(</p>",
        "id": 178134853,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571084037
    },
    {
        "content": "<p>(the one in bytes was definitely UB though... )</p>",
        "id": 178134909,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571084054
    },
    {
        "content": "<p>Well, then again, casting <code>&amp;AtomicU32</code> to <code>*const u32</code> followed by a ptr::read() should work if you are the only thread writing there. It's ugly, but not UB.</p>",
        "id": 178134940,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571084086
    },
    {
        "content": "<p>The unsync_load() in pop() should work for the same reason.</p>",
        "id": 178135231,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571084293
    },
    {
        "content": "<p>Do you have a pointer to the steal() impl? It's not featured in the blog post...</p>",
        "id": 178135404,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571084404
    },
    {
        "content": "<p>(PS: I agree with what you say in the blog post. Sometimes, people who discover atomics undergo a bit of a \"kid in a candy store\" phase and forget that locking an uncontended mutex is just an atomic swap and unlocking an uncontended mutex is just an atomic store, both of which are <em>really</em> cheap. As the Preshing blog says, well-implemented locks are not slow, contention is.)</p>",
        "id": 178136004,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571084844
    },
    {
        "content": "<p>(Be it contention on the lock, or contention on the CPU cache lines that it protects, which are invalidated on every write)</p>",
        "id": 178136117,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571084938
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211871\">@Hadrien Grasland</span> <a href=\"https://github.com/tokio-rs/tokio/blob/new-scheduler/tokio-executor/src/thread_pool/queue/local.rs#L201-L240\" target=\"_blank\" title=\"https://github.com/tokio-rs/tokio/blob/new-scheduler/tokio-executor/src/thread_pool/queue/local.rs#L201-L240\">https://github.com/tokio-rs/tokio/blob/new-scheduler/tokio-executor/src/thread_pool/queue/local.rs#L201-L240</a></p>",
        "id": 178136318,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571085087
    },
    {
        "content": "<p><code>dst.tail.unsync_load()</code> looks wrong.</p>",
        "id": 178136391,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571085128
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211871\">@Hadrien Grasland</span> it's confusing, but self &amp; dst are probably ordered wrong</p>",
        "id": 178136407,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571085147
    },
    {
        "content": "<p>from an API pov</p>",
        "id": 178136429,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571085166
    },
    {
        "content": "<p><code>dst</code> is owned by the calling thread</p>",
        "id": 178136436,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571085175
    },
    {
        "content": "<p>where as <code>self</code> is the remote thread</p>",
        "id": 178136443,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571085179
    },
    {
        "content": "<p>Yup, that's definitely confusing.</p>",
        "id": 178136483,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571085215
    },
    {
        "content": "<p>Consider changing it so that <code>self</code> is the receiver and the input parameter is an <code>src</code> queue that is being stolen from.</p>",
        "id": 178136563,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571085247
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211871\">@Hadrien Grasland</span> my thought would be to make <code>steal</code> a free fn</p>",
        "id": 178136576,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571085256
    },
    {
        "content": "<p>Works as well.</p>",
        "id": 178136587,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571085269
    },
    {
        "content": "<p>or, it could be <code>steal_from(self, src)</code></p>",
        "id": 178136609,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571085285
    },
    {
        "content": "<p>Also, consider replicating your safety note on this unsync_load() (you did make this function unsafe, right?)</p>",
        "id": 178136659,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571085331
    },
    {
        "content": "<p>unsync_load is unsafe</p>",
        "id": 178136737,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571085379
    },
    {
        "content": "<p>I am a bit surprised by this:</p>\n<div class=\"codehilite\"><pre><span></span><span class=\"w\">            </span><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">src_head</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">head</span><span class=\"p\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">Acquire</span><span class=\"p\">);</span><span class=\"w\"></span>\n<span class=\"w\">            </span><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">src_tail</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">tail</span><span class=\"p\">.</span><span class=\"n\">load</span><span class=\"p\">(</span><span class=\"n\">Acquire</span><span class=\"p\">);</span><span class=\"w\"></span>\n\n<span class=\"w\">            </span><span class=\"c1\">// Number of available tasks to steal</span>\n<span class=\"w\">            </span><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">src_tail</span><span class=\"p\">.</span><span class=\"n\">wrapping_sub</span><span class=\"p\">(</span><span class=\"n\">src_head</span><span class=\"p\">);</span><span class=\"w\"></span>\n<span class=\"w\">            </span><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"o\">-</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"o\">/</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"p\">;</span><span class=\"w\"></span>\n\n<span class=\"w\">            </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"o\">==</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">                </span><span class=\"k\">return</span><span class=\"w\"> </span><span class=\"mi\">0</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"w\">            </span><span class=\"p\">}</span><span class=\"w\"></span>\n\n<span class=\"w\">            </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"n\">n</span><span class=\"w\"> </span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"bp\">self</span><span class=\"p\">.</span><span class=\"n\">buffer</span><span class=\"p\">.</span><span class=\"n\">len</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"k\">as</span><span class=\"w\"> </span><span class=\"kt\">u32</span><span class=\"w\"> </span><span class=\"o\">/</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">                </span><span class=\"n\">atomic</span>::<span class=\"n\">spin_loop_hint</span><span class=\"p\">();</span><span class=\"w\"></span>\n<span class=\"w\">                </span><span class=\"c1\">// inconsistent, try again</span>\n<span class=\"w\">                </span><span class=\"k\">continue</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"w\">            </span><span class=\"p\">}</span><span class=\"w\"></span>\n</pre></div>",
        "id": 178136901,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571085504
    },
    {
        "content": "<p>When do you expect the if to fail?</p>",
        "id": 178136931,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571085542
    },
    {
        "content": "<p>Oh, well, I'm being reminded that I should probably go to sleep because it's getting late here and I have a job interview to take care of early tomorrow.</p>",
        "id": 178137588,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571085965
    },
    {
        "content": "<p>But I would definitely enjoy spending more time reviewing this later on, hopefully will find some time tomorrow.</p>",
        "id": 178137625,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571085998
    },
    {
        "content": "<p>good luck!</p>",
        "id": 178138496,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571086623
    },
    {
        "content": "<p>so the high-level bit is that <em>if</em> all the racing accesses are reads, then all is fine and there's no UB. (I mean, that's a pattern that can even be written in safe code.)</p>",
        "id": 178138860,
        "sender_full_name": "RalfJ",
        "timestamp": 1571086841
    },
    {
        "content": "<p>but you'll need some mechanism to ensure a happens-before edge between any critical section (that mutates the data) and any read</p>",
        "id": 178138911,
        "sender_full_name": "RalfJ",
        "timestamp": 1571086885
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224941\">@Carl Lerche</span>  it'd help if you had a \"minimized example\" (even in pseudo-code) of the kind of pattern you are worried about</p>",
        "id": 178138945,
        "sender_full_name": "RalfJ",
        "timestamp": 1571086911
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"120791\">@RalfJ</span> from a concurrency POV, i'm fairly confident it is correct. The original HN comment was saying that the compiler could insert random data in the field though... which did not sound correct to me.</p>",
        "id": 178140674,
        "sender_full_name": "Carl Lerche",
        "timestamp": 1571088256
    },
    {
        "content": "<p>uh... that sounds weird</p>",
        "id": 178140729,
        "sender_full_name": "RalfJ",
        "timestamp": 1571088327
    },
    {
        "content": "<p>I usually take Reddit comments serious but ignore HN comments. ;)</p>",
        "id": 178140740,
        "sender_full_name": "RalfJ",
        "timestamp": 1571088346
    },
    {
        "content": "<p>Meh. Looks like my stupid stressed out brain doesn't want to sleep tonight :(</p>",
        "id": 178147268,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571095270
    },
    {
        "content": "<p>Then I guess I'll just either a/take a look at this code further or b/try to draft some kind of pre-RFC document for atomic volatile. Hmmm...</p>",
        "id": 178147326,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571095328
    },
    {
        "content": "<p>Got time to take another look. Overall, what you have here looks pretty reasonable, but would probably be better with a bit of documentation here and there so that things need to be inferred less often.</p>",
        "id": 178195263,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571147635
    },
    {
        "content": "<p>For example, Local::mask should be documented as a power-of-2 modulo optimization for head/tail % buffer.len() computations.</p>",
        "id": 178195407,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571147737
    },
    {
        "content": "<p>It is not immediately obvious that the ptr::read(ptr) in pop() isn't racy. It actually is because both push() and pop() may only be called in the local queue's owner thread. The documentation of that ptr::read could just point that out.</p>",
        "id": 178195806,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571147977
    },
    {
        "content": "<p>The concurrent correctness of steal2(), on its side, is also <em>far</em> from obvious. After all, this can happen:</p>\n<p>- Thread A is the owner of the queue, Thread B is the thief.<br>\n- Thread B starts stealing, enters steal2(), reads the head/tail info of thread A's local work queue, then for some strange reason stupid OS task scheduler decides to put it to sleep and schedule something else.<br>\n- Thread A furiously pushes and pops tasks on its local queue until the tail (pushing end) gets close to the point where thread B measured that thread A's head (popping end) was.<br>\n- Thread B wakes up and starts reading what it assumes to be unprocessed thread A tasks, while thread A is simultaneously in the process of overwriting the corresponding memory region. This is a data race.</p>",
        "id": 178196937,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571148611
    },
    {
        "content": "<p>Now, Thread B has a good chance of figuring out that this happened and restarting the transaction later on, when it will try to claim the tasks with a CAS of thread A's head pointer. I say good chance, because there is a tiny odd of an ABA issue masking the problem if thread A managed to make its head counter overflow and do a perfect round trip. With AtomicU32, the odds of this happening are probably too small to bother considering them, but this shows that the size of the head and the tail pointers are correctness-critical in this algorithm, which is not documented currently.</p>",
        "id": 178197458,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571148958
    },
    {
        "content": "<p>And all this does not eliminate the fact that even if thread B eventually figures out that something went wrong and restarts the transaction, a data race has still occured, so the program technically has undefined behavior from the point of view of the Rust spec.</p>",
        "id": 178197572,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571149025
    },
    {
        "content": "<p>My understanding is that you are trying to implement semantics akin to those of a seqlock (try to read, check for race, try again if a race occured), but unfortunately I'm not sure we actually have the right tools for efficiently building those without UB in Rust at this point in time. I believe we'd need something like a well-implemented element-wise atomic memcpy intrinsic, which LLVM has but Rust does not expose right now. And because LLVM is terrible at optimizing Relaxed atomics, naively replacing this intrinsic with an AtomicU8 load/store loop would yield terrible performance at this point in time.</p>\n<p>(I wonder if we could write a decent atomic memcpy implementation in pure Rust, without resorting to weird arch-specific tricks like hand-coded <code>REP MOVQ</code> inline assembly... but that's a crazy idea for another day)</p>",
        "id": 178197635,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571149070
    },
    {
        "content": "<p>Given that this is a super edge case, I would personally be fine with a comment saying \"this is UB, but it has low odds of happening, it is not known to have any observable consequence, and we don't have the right language tools for building the underlying synchronization protocol correctly and efficiently right now\". But again, this comment is missing.</p>",
        "id": 178198023,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571149309
    },
    {
        "content": "<p>Anyhow, overall, good job! I've tried to write a work-stealing scheduler myself in the past, and I'm well aware of how much painful it can get when things like blocking come into play. All I am saying is that perhaps you should document your achievement a little bit better so that future reviewers of the code get a more solid grasp of what's going on and why.</p>",
        "id": 178198879,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571149918
    },
    {
        "content": "<p>maybe not AtomicU8, but an AtomicU64 loop would be decently fast</p>",
        "id": 178251967,
        "sender_full_name": "comex",
        "timestamp": 1571190845
    },
    {
        "content": "<p>I don't understand why atomic memcpy is needed here though</p>",
        "id": 178251978,
        "sender_full_name": "comex",
        "timestamp": 1571190872
    },
    {
        "content": "<p>Because ptr::read racing with ptr::write is generally not allowed, even if you discard the result after the fact. Whereas with a form of atomic memcpy the result is \"well-defined\": you get randomly torn garbage data.</p>",
        "id": 178260198,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571203403
    },
    {
        "content": "<p>(IIUC, it's actually OK at the LLVM layer since they use a \"data race returns undef\" localized UB formalism rather than a messy C-like notion of global UB invalidating the whole program, so another way to handle this would be to integrate similar data race semantics to Rust... but I'm not sure if we are prepared to do that)</p>",
        "id": 178260273,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571203547
    },
    {
        "content": "<p>In a way, this is somewhat related to my thread about padding bytes and memcpy: our current rules have a nasty tendency to turn some specific memory read and write operations into global program UB, and I'm not sure if this is actually fine.</p>",
        "id": 178261623,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571205834
    },
    {
        "content": "<p>(in the padding bytes case, it's more egregious since making it UB to observe padding bytes makes it UB to move a Rust object in an efficient/obvious way... but I think this case is no less interesting)</p>",
        "id": 178261741,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571205963
    },
    {
        "content": "<p>At the same time, it's definitely true that specific load/store operations are global program UB. Dereferencing a null pointer is, for example. So differencing between local and global UB would likely end up making the rules more complex ;)</p>",
        "id": 178262137,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571206583
    },
    {
        "content": "<blockquote>\n<p>Because ptr::read racing with ptr::write is generally not allowed, even if you discard the result after the fact. Whereas with a form of atomic memcpy the result is \"well-defined\": you get randomly torn garbage data.</p>\n</blockquote>\n<p>I dont think we have anything in the Rust semantics that gives you randomly turn garbage data. that would be <code>freeze</code> and we dont have it.</p>",
        "id": 178311265,
        "sender_full_name": "RalfJ",
        "timestamp": 1571247667
    },
    {
        "content": "<p>Let me reformulate. It's not randomly torn. It's the perfectly reasonable result of a sequence of atomic reads targeting different memory locations, which happen tor return the values that were atomically written by different sequences of writes.</p>",
        "id": 178314465,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571249561
    },
    {
        "content": "<p>And from a specification point of view, that's totally different.</p>",
        "id": 178314508,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571249583
    },
    {
        "content": "<p>From a developer's point of view, however, it's randomly torn garbage data.</p>",
        "id": 178314537,
        "sender_full_name": "Hadrien Grasland",
        "timestamp": 1571249602
    },
    {
        "content": "<p>I see. fair :)</p>",
        "id": 178314661,
        "sender_full_name": "RalfJ",
        "timestamp": 1571249651
    }
]