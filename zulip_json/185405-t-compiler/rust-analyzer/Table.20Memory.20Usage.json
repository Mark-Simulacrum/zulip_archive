[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211727\">@Jonas Schievink</span> did a quick patch to drop salsa's tables to see how much space those occupy. That accounts for 200 mb of unaccounted for space:</p>\n<p><a href=\"https://gist.github.com/matklad/adac544d39b540f90c83c7169b1caa46\">https://gist.github.com/matklad/adac544d39b540f90c83c7169b1caa46</a></p>",
        "id": 204683343,
        "sender_full_name": "matklad",
        "timestamp": 1595432541
    },
    {
        "content": "<p>Oof</p>",
        "id": 204683571,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1595432649
    },
    {
        "content": "<p>Not unexpected though</p>",
        "id": 204683590,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1595432657
    },
    {
        "content": "<p>What if we <em>just</em> collect slot keys instead of the entire map? As in, what <a href=\"https://github.com/salsa-rs/salsa/pull/196\">https://github.com/salsa-rs/salsa/pull/196</a> does.<br>\nOr is that already how things work on master? I forgot.</p>",
        "id": 204683801,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1595432758
    },
    {
        "content": "<p>I think if we can just collect slots with rc=1</p>",
        "id": 204684648,
        "sender_full_name": "matklad",
        "timestamp": 1595433118
    },
    {
        "content": "<p>Hm, or is it a bad idea due to slots being re-used...</p>",
        "id": 204684717,
        "sender_full_name": "matklad",
        "timestamp": 1595433137
    },
    {
        "content": "<p>s/re-used/referenced to from many tables/</p>",
        "id": 204684784,
        "sender_full_name": "matklad",
        "timestamp": 1595433170
    },
    {
        "content": "<ul>\n<li><a href=\"https://github.com/salsa-rs/salsa/pull/240\">https://github.com/salsa-rs/salsa/pull/240</a></li>\n<li><a href=\"https://github.com/rust-analyzer/rust-analyzer/pull/5494\">https://github.com/rust-analyzer/rust-analyzer/pull/5494</a></li>\n</ul>",
        "id": 204691449,
        "sender_full_name": "matklad",
        "timestamp": 1595436363
    },
    {
        "content": "<p>This also clears <code>input</code> memory, so we finally see all the things</p>",
        "id": 204691596,
        "sender_full_name": "matklad",
        "timestamp": 1595436453
    },
    {
        "content": "<p><a href=\"https://gist.github.com/matklad/d738eedb04152a96c957f3d341400306\">https://gist.github.com/matklad/d738eedb04152a96c957f3d341400306</a></p>",
        "id": 204691601,
        "sender_full_name": "matklad",
        "timestamp": 1595436455
    },
    {
        "content": "<p>Cool!</p>",
        "id": 204691827,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1595436589
    },
    {
        "content": "<p>Heh, I am forgetting that <code>sweep</code> thing is intended for real garbage collection and not for, you know, measuring memory :D</p>",
        "id": 204691891,
        "sender_full_name": "matklad",
        "timestamp": 1595436611
    },
    {
        "content": "<p>Is <code>MacroArgQuery</code> supposed to be that large?</p>",
        "id": 204692119,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595436726
    },
    {
        "content": "<p>I think we could make it more compact, but, in general, it will be large</p>",
        "id": 204692275,
        "sender_full_name": "matklad",
        "timestamp": 1595436808
    },
    {
        "content": "<p>as in, a lot of code is generated by macros,</p>",
        "id": 204692309,
        "sender_full_name": "matklad",
        "timestamp": 1595436831
    },
    {
        "content": "<p>It looks like it's a token tree representation of the macro parameters?</p>",
        "id": 204692391,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595436848
    },
    {
        "content": "<p>(as opposed to macro-generated code)</p>",
        "id": 204692408,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595436859
    },
    {
        "content": "<p>yes</p>",
        "id": 204692427,
        "sender_full_name": "matklad",
        "timestamp": 1595436869
    },
    {
        "content": "<p>And it's worth caching it instead of computing it on the fly (since we also store the macro expansion result)?</p>",
        "id": 204692712,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595437021
    },
    {
        "content": "<p>It is worth caching because it's a firewall</p>",
        "id": 204692772,
        "sender_full_name": "matklad",
        "timestamp": 1595437049
    },
    {
        "content": "<p>Most syntax changes leave macro args in place</p>",
        "id": 204692793,
        "sender_full_name": "matklad",
        "timestamp": 1595437059
    },
    {
        "content": "<p>though, these all shold be rechecked, I expect ItemTree work might have changed the calculus here</p>",
        "id": 204692901,
        "sender_full_name": "matklad",
        "timestamp": 1595437085
    },
    {
        "content": "<p>Hm....</p>",
        "id": 204693050,
        "sender_full_name": "matklad",
        "timestamp": 1595437151
    },
    {
        "content": "<p>I think I see something which makes zero sense to me</p>",
        "id": 204693075,
        "sender_full_name": "matklad",
        "timestamp": 1595437163
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>   252mb ItemTreeQuery\n   121mb CrateDefMapQueryQuery\n    59mb BodyQuery\n    38mb InferQueryQuery\n</code></pre></div>",
        "id": 204693095,
        "sender_full_name": "matklad",
        "timestamp": 1595437175
    },
    {
        "content": "<p>It's unreasonable that body data occupies less space then top-level data</p>",
        "id": 204693147,
        "sender_full_name": "matklad",
        "timestamp": 1595437200
    },
    {
        "content": "<p>Indeed <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span></p>",
        "id": 204694354,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1595437747
    },
    {
        "content": "<p>note that this is without <code>--with-deps</code>, but still</p>",
        "id": 204694964,
        "sender_full_name": "matklad",
        "timestamp": 1595438043
    },
    {
        "content": "<p>Hmm, in that case my expectation is:</p>\n<ul>\n<li>You get <code>ItemTree</code>s for all files in all dependencies, and for all item-level macro files too =&gt; big</li>\n<li>You get <code>CrateDefMap</code>s for all dependencies, which always contain private items too (and also the known issue around duplicating glob imported items) =&gt; big</li>\n</ul>\n<p>So maybe this makes sense?</p>",
        "id": 204695339,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1595438222
    },
    {
        "content": "<p>A bit, for smaller crates with with deps the ordering is right, but the order of magnitude seems wrong (2x difference or something)</p>",
        "id": 204697132,
        "sender_full_name": "matklad",
        "timestamp": 1595439009
    },
    {
        "content": "<p>this definitelly worth looking into and explaining</p>",
        "id": 204697189,
        "sender_full_name": "matklad",
        "timestamp": 1595439043
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133169\">matklad</span> <a href=\"#narrow/stream/185405-t-compiler.2Fwg-rls-2.2E0/topic/Table.20Memory.20Usage/near/204692793\">said</a>:</p>\n<blockquote>\n<p>Most syntax changes leave macro args in place</p>\n</blockquote>\n<p>Could we track only the text instead? So we don't cache the tt (but recompute it when needed) and cache only the text and the expansion.</p>",
        "id": 204700966,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595441037
    },
    {
        "content": "<p>That sounds like an excellent idea!</p>",
        "id": 204701560,
        "sender_full_name": "matklad",
        "timestamp": 1595441301
    },
    {
        "content": "<p>How would that work? A new <code>macro_arg_syntax</code> query that returns the <code>SyntaxNode</code> and a <code>#[transparent]</code> <code>macro_arg_tt</code> that does the conversion?</p>",
        "id": 204702081,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595441537
    },
    {
        "content": "<p>Hmm, that doesn't seem to work, something about <code>SyntaxNode</code> not being <code>Send</code> (but I put it in an <code>Arc</code>, so dunno)</p>",
        "id": 204704211,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595442548
    },
    {
        "content": "<p>you can use <code>GreenNode</code> instead of <code>SyntaxNode</code></p>",
        "id": 204704352,
        "sender_full_name": "matklad",
        "timestamp": 1595442603
    },
    {
        "content": "<p><code>SyntaxNode</code>s are thread local</p>",
        "id": 204704381,
        "sender_full_name": "matklad",
        "timestamp": 1595442617
    },
    {
        "content": "<p>So <code>SyntaxNode::green</code>? But that returns a reference, so..</p>",
        "id": 204704508,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595442686
    },
    {
        "content": "<p>.clone</p>",
        "id": 204704552,
        "sender_full_name": "matklad",
        "timestamp": 1595442714
    },
    {
        "content": "<p>And it's private</p>",
        "id": 204704634,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595442733
    },
    {
        "content": "<p>Well, let's see</p>",
        "id": 204705266,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595443017
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>   186mb MacroArgQuery\n    60mb MacroArgSyntaxQuery\n</code></pre></div>",
        "id": 204705759,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595443268
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>Item Collection: 18.076997307s, 829mb allocated 0b resident\nTotal expressions: 187802\nExpressions of unknown type: 1480 (0%)\nExpressions of partially unknown type: 700 (0%)\nType mismatches: 466\nInference: 24.968460198s, 1430mb allocated 0b resident\nTotal: 43.045673099s, 1430mb allocated 0b resident\n\nItem Collection: 18.373088111s, 658mb allocated 0b resident\nTotal expressions: 187798\nExpressions of unknown type: 1480 (0%)\nExpressions of partially unknown type: 700 (0%)\nType mismatches: 466\nInference: 25.376398801s, 1234mb allocated 0b resident\nTotal: 43.74958371s, 1234mb allocated 0b resident\n</code></pre></div>",
        "id": 204706466,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595443599
    },
    {
        "content": "<p>I guess it works?</p>",
        "id": 204706510,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595443624
    },
    {
        "content": "<p>Nice!</p>",
        "id": 204706760,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1595443742
    },
    {
        "content": "<p>Idle thought: unresolved items (which store paths) should be heavier than resolved items (which store ids), because a path is a path, and an id is u32. </p>\n<p>I wonder if we need one-step macro expansion and name resolution lowring step. And whether that would hit cyclic queries, where, to resolve associated types, you'd invoke type inference machinery which needs lowred impls...</p>",
        "id": 204797351,
        "sender_full_name": "matklad",
        "timestamp": 1595511296
    },
    {
        "content": "<p>resolving associated types is a separate step</p>",
        "id": 204802283,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1595513584
    },
    {
        "content": "<p>Well yes, that's exactly the issue. </p>\n<p>Like, I imagine that we'd want to lower <code>Self::Item</code> to something which is infailable, and not to a type &amp; <code>Name</code> pair.</p>",
        "id": 204803090,
        "sender_full_name": "matklad",
        "timestamp": 1595513950
    },
    {
        "content": "<p>I mean, lower in a single step, from ItemTree straight to \"we know everything is it to know, except fro child items\"</p>",
        "id": 204803167,
        "sender_full_name": "matklad",
        "timestamp": 1595513992
    },
    {
        "content": "<p>well, it needs to be lowered to <code>&lt;Self as SomeTrait&gt;::Item</code>, but that doesn't need type inference</p>",
        "id": 204804957,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1595514771
    },
    {
        "content": "<p>Where <code>SomeTrair</code> and <code>Item</code> are ids, right?</p>",
        "id": 204806420,
        "sender_full_name": "matklad",
        "timestamp": 1595515364
    },
    {
        "content": "<p>Hm, I guess that makes sense, <code>Foo::Bar::Baz</code> paths are forbidden without disambiguation</p>",
        "id": 204806486,
        "sender_full_name": "matklad",
        "timestamp": 1595515397
    },
    {
        "content": "<p>This makes the idea slightly more realizable...</p>",
        "id": 204806522,
        "sender_full_name": "matklad",
        "timestamp": 1595515418
    },
    {
        "content": "<p>yes</p>",
        "id": 204820456,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1595521776
    },
    {
        "content": "<p>and it's just based on the where clauses in scope</p>",
        "id": 204820478,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1595521792
    },
    {
        "content": "<p>that's basically what happens during lowering to HIR in rustc as well, as I understand it</p>",
        "id": 204820562,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1595521829
    },
    {
        "content": "<p>Uhu. I think we'll need to be careful with laziness here, but I think a simple rule like \"child <em>names</em> are lowered with parent, children are lowered lazy\" should work</p>",
        "id": 204820846,
        "sender_full_name": "matklad",
        "timestamp": 1595521942
    },
    {
        "content": "<p>Ie, we should know functions names in impls, but not necessary functions</p>",
        "id": 204820888,
        "sender_full_name": "matklad",
        "timestamp": 1595521964
    },
    {
        "content": "<blockquote>\n<p>Could we track only the text instead? So we don't cache the tt (but recompute it when needed) and cache only the text and the expansion.</p>\n</blockquote>\n<p>It's interesting that the PR doesn't do exactly that -- it uses green trees, and not token trees. I <em>think</em> memory savings come from the fact that green trees deduplicate nodes, which token trees can't do, because they have identities.</p>",
        "id": 204894367,
        "sender_full_name": "matklad",
        "timestamp": 1595582168
    },
    {
        "content": "<p>Which invites an interesting question -- do we actually <strong>need</strong> token identities?</p>",
        "id": 204894388,
        "sender_full_name": "matklad",
        "timestamp": 1595582198
    },
    {
        "content": "<p>We were caching token trees before, now we're only caching green nodes (text?) and computing the token trees right before macro expansion.</p>",
        "id": 204894418,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595582234
    },
    {
        "content": "<p>But I see your point about green nodes not being necessarily smaller than token trees</p>",
        "id": 204894501,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595582293
    },
    {
        "content": "<p>Still, 60 MB is a lot. Are you sure that storing the text wouldn't be better?</p>",
        "id": 204894584,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595582371
    },
    {
        "content": "<blockquote>\n<p>We were caching token trees before, now we're only caching green nodes (text?) and computing the token trees right before macro expansion.</p>\n</blockquote>\n<p>Exactly, we <em>replaced</em> token trees with green trees. Naively, I'd expect that to have little impact on perf (as both are essentially the same tree structure). I <em>think</em> the diff is due to deduplication of green nodes</p>",
        "id": 204894604,
        "sender_full_name": "matklad",
        "timestamp": 1595582392
    },
    {
        "content": "<p>Text would be better, yeah</p>",
        "id": 204894653,
        "sender_full_name": "matklad",
        "timestamp": 1595582408
    },
    {
        "content": "<p>So, I wonder if we can change the repr of token trees to place hygine info on subtrees in a sidetable, and have nodes in a subtree be identified using only position (w deduplication)</p>",
        "id": 204894690,
        "sender_full_name": "matklad",
        "timestamp": 1595582450
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133169\">matklad</span> <a href=\"#narrow/stream/185405-t-compiler.2Fwg-rls-2.2E0/topic/Table.20Memory.20Usage/near/204894653\">said</a>:</p>\n<blockquote>\n<p>Text would be better, yeah</p>\n</blockquote>\n<p>Um, how do I parse the text into a <code>SyntaxNode</code>? That feels a bit wrong.</p>",
        "id": 204894977,
        "sender_full_name": "Laurențiu",
        "timestamp": 1595582657
    },
    {
        "content": "<p>It might even be impossible</p>",
        "id": 204895161,
        "sender_full_name": "matklad",
        "timestamp": 1595582768
    },
    {
        "content": "<p>For recursive macro expansions, there's no text</p>",
        "id": 204895170,
        "sender_full_name": "matklad",
        "timestamp": 1595582778
    },
    {
        "content": "<p>Latests results (without memory unnacounted for): <a href=\"https://github.com/rust-analyzer/rust-analyzer/pull/5494#issuecomment-669204979\">https://github.com/rust-analyzer/rust-analyzer/pull/5494#issuecomment-669204979</a></p>",
        "id": 206023987,
        "sender_full_name": "matklad",
        "timestamp": 1596635434
    }
]