[
    {
        "content": "<p>I would like to enable proc-macro and build-script in metrics to match the default settings of RA. </p>\n<p>Good idea or not ?</p>",
        "id": 233293115,
        "sender_full_name": "Edwin Cheng",
        "timestamp": 1617702703
    },
    {
        "content": "<p>I'm worried about practically losing the historical measurements</p>",
        "id": 233293224,
        "sender_full_name": "Laurențiu",
        "timestamp": 1617702743
    },
    {
        "content": "<p>I think loosing historical data is fine. We are mostly interested in last week perf, not in the long-term trends.</p>",
        "id": 233294893,
        "sender_full_name": "matklad",
        "timestamp": 1617703648
    },
    {
        "content": "<p>We can always recrated historical data by going back in the git's history.</p>",
        "id": 233294912,
        "sender_full_name": "matklad",
        "timestamp": 1617703667
    },
    {
        "content": "<p><span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> </p>\n<p>I now realize that, in general, if you want to observe historical perf trends, collecting a history of measurements in time is wrong, and instead it's more robust to re-create historical data. That way, you are protected from configuration changes (GitHub actions upgrading VMs)</p>",
        "id": 233295495,
        "sender_full_name": "matklad",
        "timestamp": 1617704011
    },
    {
        "content": "<p>Of course, if you have your own <del>hardware</del> infra it's easier to keep it more consistent. I noticed that GHA has at least two different CPU types.</p>",
        "id": 233295671,
        "sender_full_name": "Laurențiu",
        "timestamp": 1617704114
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>$ git log --merges --oneline | wc -l\n5042\n</code></pre></div>\n<p>That's gonna take a while.</p>",
        "id": 233295858,
        "sender_full_name": "Laurențiu",
        "timestamp": 1617704223
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"203546\">@Laurențiu</span> that depends on how much history you want. Fun fact: the timing infrastructure in IntelliJ reports times in wall-clock machine independent format. That is, the measure is milliseconds, but they are multiplied by the \"scaling factor\": how much the current CPU is faster than a canonical CPU</p>",
        "id": 233296065,
        "sender_full_name": "matklad",
        "timestamp": 1617704362
    },
    {
        "content": "<p>Canonical CPU is Pentium 4</p>",
        "id": 233296085,
        "sender_full_name": "matklad",
        "timestamp": 1617704377
    },
    {
        "content": "<blockquote>\n<p>That's gonna take a while.</p>\n</blockquote>\n<p>You probably don't want to sample the history linearly, and insterad want something more exponential, line 2, 4, 8, 16, 32, 64, 128, 256 commits back</p>",
        "id": 233296214,
        "sender_full_name": "matklad",
        "timestamp": 1617704445
    },
    {
        "content": "<p>or some kind of adaptive sampling.</p>",
        "id": 233296228,
        "sender_full_name": "matklad",
        "timestamp": 1617704458
    },
    {
        "content": "<p>And it's still slow <span aria-label=\"laughter tears\" class=\"emoji emoji-1f602\" role=\"img\" title=\"laughter tears\">:laughter_tears:</span> (sorry for the jab, somehow I never managed to like IntelliJ). But yeah, it's a sensible approach; I imagine it can have problems when you start adding and using more cores, Amdahl's law and all that.</p>",
        "id": 233296230,
        "sender_full_name": "Laurențiu",
        "timestamp": 1617704462
    }
]