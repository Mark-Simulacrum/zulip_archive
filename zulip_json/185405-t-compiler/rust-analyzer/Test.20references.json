[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"133169\">@matklad</span> </p>\n<p>There are two features that I think would be nice to have in RA:</p>\n<ul>\n<li>A mechanism to search all related tests for a function (both unit, and integration)</li>\n<li>Provide a code lens with test references and the ability to run them in one click. Perhaps showing statuses (succeed, running, failed) if it is possible to implement (as I remember, at least VSCode API does not allow updating code lenses dynamically).</li>\n</ul>\n<p>And there are two difficulties:</p>\n<ul>\n<li>relatively slow reference search</li>\n<li>synchronous code lens support. That is, the lenses resolved asynchronously, but the places where they need to be shown calculated synchronously! So, adding a synchronous tests lookup can seriously slow down the UI, which is not good.</li>\n</ul>\n<p>The first problem is not so hard. We can use inverted n-gram index or inverted names (identifiers) index. I guess names index should work faster and would be quite enough as we do not need regex support. But I'll try both approaches.</p>\n<p>The second one is more complicated. LSP allows to add CodeLens asynchronously, but RA does not use this ability, and to my mind, it requires significant internal changes to add it.</p>\n<p>Do you have some thoughts \\ ideas \\ suggestions on this? Thanks.</p>",
        "id": 212607884,
        "sender_full_name": "vsrs",
        "timestamp": 1602099004
    },
    {
        "content": "<p>This all sounds reasonable!</p>\n<p>As usual, if we hide the feature behind a feature toggle, we can refine the impl as we go, no need to make it super fast right of the bat. </p>\n<p>On the first point: We should have trigram index for speeding up reference search, but it requires some engineering effort to implement. We also need to check if trigram index is what actually is slow. My hunch here is that the slow thing is actually the semantic resolve, so it might make sense to profile it. IIRC, there are some low hanging frutits in the semantic resolve space. For example, we coupld classify potential match by syntax (field access, method call, path, pattern) and use that for some syntax-but-not-semantics quick filtering. </p>\n<p>I also think that we effectively are <em>already</em> doing reference search to show \"n references\" code lens? If so, than the additional cost seems to be negligible? </p>\n<p>On the second point: havan't looked into this, but, if there are async code lens, we should land a refactor to enable them!</p>",
        "id": 213006605,
        "sender_full_name": "matklad",
        "timestamp": 1602488645
    },
    {
        "content": "<p>I'm sorry for the late reply.</p>\n<blockquote>\n<p>We also need to check if trigram index is what actually is slow.</p>\n</blockquote>\n<p>If I'm not mistaken at the moment we  do full text search every time for each reference. If so, this can be accelerated.  </p>\n<blockquote>\n<p>My hunch here is that the slow thing is actually the semantic resolve, so it might make sense to profile it.</p>\n</blockquote>\n<p>I'll try, though not sure that I know this part of the code good enough.   </p>\n<blockquote>\n<p>I also think that we effectively are already doing reference search to show \"n references\" code lens?</p>\n</blockquote>\n<p>Actually I just reused existing mechanism, the same is used by rename_reference, etc. It works fast enough for n-references search, even for big projects like RA itself. But it too slow for tests search. I have a prototype and it takes up to 4-7 seconds to find all tests on my notebook. I'm sure it might be much faster.   </p>\n<blockquote>\n<p>but, if there are async code lens, we should land a refactor to enable them!</p>\n</blockquote>\n<p>Perfect. Perhaps, this is where I should start.</p>",
        "id": 213700019,
        "sender_full_name": "vsrs",
        "timestamp": 1603016630
    }
]