[
    {
        "content": "<p>I sometimes get a very slow completion due to documentation being loaded for an item for the first time causing a slow parse_query(137ms) causing an overly long loop turn message. There isn't really much we can do about those is there?</p>\n<div class=\"codehilite\"><pre><span></span><code>  202ms - handle_completion\n      185ms - import_on_the_fly @ pu\n          137ms - render_resolution\n              137ms - render_fn\n                  137ms - parse_query @ FileId(4212)\n                    0   - crate_def_map:wait (1 calls)\n           26ms - import_assets::search_for_imports (1 calls)\n           21ms - render_resolution (2 calls)\n        0   - Semantics::analyze_impl (3 calls)\n       16ms - SourceBinder::to_module_def (3 calls)\n        0   - crate_def_map:wait (1 calls)\n        0   - descend_into_macros (1 calls)\n        0   - item::Builder::build (3 calls)\n</code></pre></div>",
        "id": 256086987,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1633364588
    },
    {
        "content": "<p>Which file is that? 137ms for parsing is quite a lot... But not unheared of - glorious old parser is 250ms on my (fast) machine</p>",
        "id": 256087430,
        "sender_full_name": "matklad",
        "timestamp": 1633364721
    },
    {
        "content": "<p>Anyway for me to figure out what a file id maps to?</p>",
        "id": 256087485,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1633364738
    },
    {
        "content": "<p>might be the AVX512 files</p>",
        "id": 256087491,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1633364740
    },
    {
        "content": "<p>potentially</p>",
        "id": 256087516,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1633364746
    },
    {
        "content": "<p>I do think that we can make the parsing itself X times faster, I think rowan is jokingly slow. Not gonna be easy though</p>",
        "id": 256087631,
        "sender_full_name": "matklad",
        "timestamp": 1633364777
    },
    {
        "content": "<p>But, ideally, completion shouldn't be hitting parsing at all -- doc comments should be in the item tree, as they are attributes. </p>\n<p>Last time I've looked into this, the thing that caused parsing were function parameter names -- they are not stored in an item tree, as they don't have semantic meaning, but they are important for completion</p>",
        "id": 256088327,
        "sender_full_name": "matklad",
        "timestamp": 1633364988
    },
    {
        "content": "<p>Oh okay, I assumed it would be docs since that would've made the most sense to me</p>",
        "id": 256088472,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1633365023
    },
    {
        "content": "<p>But ye, was a bit suprised to see parsing happening there at all in the first place as well</p>",
        "id": 256088557,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1633365050
    },
    {
        "content": "<p>Not sure what's the right solution here -- pessimistically indexing all parmeters of all functions under the sun doesn't feel right, but, at the same time, lazily loading stuff for completion is obviously non-great.</p>",
        "id": 256088640,
        "sender_full_name": "matklad",
        "timestamp": 1633365081
    },
    {
        "content": "<p><span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> </p>\n<p>OK, if we had free ram, I'd definitely say \"just index this\". We are rather tight on ram though...</p>",
        "id": 256088804,
        "sender_full_name": "matklad",
        "timestamp": 1633365124
    },
    {
        "content": "<p>we could try and see how much more RAM it uses</p>",
        "id": 256088906,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1633365152
    },
    {
        "content": "<p>Yeah, let's do something stupid and store <code>params: String</code> which is an <code>$$</code> separated list of all <code>pat.to_string()</code> for functions in an item tree. If that's like an extra megabyte, than, sure, let's just do this</p>",
        "id": 256089075,
        "sender_full_name": "matklad",
        "timestamp": 1633365209
    },
    {
        "content": "<p>Another interesting place to stuff this into is import_index, on the grounds of being \"for ides\"s</p>",
        "id": 256089297,
        "sender_full_name": "matklad",
        "timestamp": 1633365270
    },
    {
        "content": "<p>theoretically, we know the range of the function in the source code and could just precisely parse its header again, couldn't we? probably hard to do within salsa though <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span></p>",
        "id": 256089501,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1633365337
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"129457\">@Florian Diebold</span> unless I misunderstood you, this is exactly what is happening today, and that is exactly the problem -- we re-parse file</p>",
        "id": 256089733,
        "sender_full_name": "matklad",
        "timestamp": 1633365412
    },
    {
        "content": "<p>I mean that we don't need to re-parse the whole file</p>",
        "id": 256089780,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1633365433
    },
    {
        "content": "<p>we could just directly look at the <code>fn foo(...)</code></p>",
        "id": 256089826,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1633365450
    },
    {
        "content": "<p>Interesting observation -- bigger files have more functions, so auto-import is more likely to hit heavy files</p>",
        "id": 256089831,
        "sender_full_name": "matklad",
        "timestamp": 1633365452
    },
    {
        "content": "<p>unless I'm missing something</p>",
        "id": 256089861,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1633365467
    },
    {
        "content": "<p>Oh, right, that's interesting. Well, today, to find out the range, I think we do have to re-parse the whole file (to map from ID to text range). But yeah, we presumably can store just a range</p>",
        "id": 256089998,
        "sender_full_name": "matklad",
        "timestamp": 1633365506
    },
    {
        "content": "<p>Btw, this touches on something I've been thinking about recently: today we sort-of assume that file are small, and file for us is a unit of change. But files are not always small:</p>\n<ul>\n<li><a href=\"https://github.com/dotnet/runtime/blob/main/src/coreclr/gc/gc.cpp\">https://github.com/dotnet/runtime/blob/main/src/coreclr/gc/gc.cpp</a></li>\n<li><a href=\"https://github.com/microsoft/TypeScript/blob/main/src/compiler/checker.ts\">https://github.com/microsoft/TypeScript/blob/main/src/compiler/checker.ts</a></li>\n</ul>",
        "id": 256090549,
        "sender_full_name": "matklad",
        "timestamp": 1633365701
    },
    {
        "content": "<p>isn't a <code>FileAstId</code> in the end a <code>SyntaxNodePtr</code> (or rather an index leading to that) which contains the range?</p>",
        "id": 256090791,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1633365780
    },
    {
        "content": "<p>I wonder if we should lift that assumption? I'd lean towards no -- files give us error isolation (unclosed <code>{</code> can't span multiple files), and, in Rust, it's fair to say that files should be small. </p>\n<p>I wonder if the fix here is to split <code>AVX</code> intrinsics into several files maybe?</p>",
        "id": 256090805,
        "sender_full_name": "matklad",
        "timestamp": 1633365784
    },
    {
        "content": "<p>I don't know, people heavily use generated code in Rust, might not be possible to convince them all to split up their files</p>",
        "id": 256091037,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1633365863
    },
    {
        "content": "<p><span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> <span class=\"user-mention silent\" data-user-id=\"129457\">Florian Diebold</span> is right as usual -- we do have a text range in <code>AstIdMap</code>, and we could use that (although macro-based files make this non-trivial)</p>",
        "id": 256091265,
        "sender_full_name": "matklad",
        "timestamp": 1633365959
    },
    {
        "content": "<p>Ye okay I am actually hitting this slow path quite a lot right now <span aria-label=\"laughing\" class=\"emoji emoji-1f606\" role=\"img\" title=\"laughing\">:laughing:</span></p>",
        "id": 256093217,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1633366714
    },
    {
        "content": "<p>Triggered it 3 times in a second just now</p>",
        "id": 256093232,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1633366723
    },
    {
        "content": "<p><span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> that is stange -- in theory our LRU cache should handle that</p>",
        "id": 256093300,
        "sender_full_name": "matklad",
        "timestamp": 1633366751
    },
    {
        "content": "<p>it is always the same file fwiw</p>",
        "id": 256093349,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1633366769
    },
    {
        "content": "<p>Might make sense to check why LRU is thrashed then!</p>\n<p>One theory I have is that auto-import suggests functions from more than 128 files</p>",
        "id": 256094275,
        "sender_full_name": "matklad",
        "timestamp": 1633367057
    },
    {
        "content": "<p>Ye I imagine so, I just bumped my lru cap gonna see if i hit it again</p>",
        "id": 256094327,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1633367081
    },
    {
        "content": "<p>Bumped it to 512 and I still get it</p>",
        "id": 256094736,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1633367228
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"211727\">Jonas Schievink  [he/him]</span> <a href=\"#narrow/stream/185405-t-compiler.2Frust-analyzer/topic/Completion.20performance/near/256088906\">said</a>:</p>\n<blockquote>\n<p>we could try and see how much more RAM it uses</p>\n</blockquote>\n<p>So I just tried this out by naively storing an <code>Interned&lt;str&gt;</code> per Function ItemTree entry with all its patterns joined together via<code>$</code> and that raised the memory usage of Item Collection(analysis-statis on ra's codebase) from <code>Item Collection:     14.14s, 446mb</code> to <code>Item Collection:     14.15s, 448mb</code></p>",
        "id": 260684183,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1636390035
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133169\">matklad</span> <a href=\"#narrow/stream/185405-t-compiler.2Frust-analyzer/topic/Completion.20performance/near/256089075\">said</a>:</p>\n<blockquote>\n<p>Yeah, let's do something stupid and store <code>params: String</code> which is an <code>$$</code> separated list of all <code>pat.to_string()</code> for functions in an item tree. If that's like an extra megabyte, than, sure, let's just do this</p>\n</blockquote>\n<p>So I guess this is a viable option</p>",
        "id": 260684321,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1636390087
    },
    {
        "content": "<p>Hmm actually we have some custom snippet rendering logic here though which requires the pattern ast nodes so I guess we want to try out the AST ptr idea aftera ll...</p>",
        "id": 260687711,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1636391566
    },
    {
        "content": "<p>Also as a side note, the integrated completion benchmark is a bit difficult to read output from due all the parse queries it triggers taking up a big chunk of time(which you normally wouldn't run into when using r-a normally as everythings already cached, but kicking off a different completion at first doesn't seem to cause caching in the benchmark?)<br>\n<span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> nvm it does have the things cached for the <code>doc completion</code>, odd</p>",
        "id": 260697679,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1636395599
    },
    {
        "content": "<p>So a very slow part of completions is a <code>trait_solve</code> query being triggered a lot(usually 50-60ms in r-a for me when its hit), is there anything we can do here?</p>",
        "id": 261048000,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1636575192
    },
    {
        "content": "<p>A lot in that part, from my limited perspective.<br>\nNot sure, how close exactly we should get to <code>trait_solve</code> itself, but the approach to flyimport trait completions was \"case-fuzzy search for any trait that has a method/constant/whatnot that contains given letter(s), do trait solving for all that were found, pick the ones that got solved for the given input\"</p>\n<p>That's not anyhow effective, I see a few low hanging fruits:</p>\n<ul>\n<li>trait resolution for types could be cached, now they are not at all</li>\n<li>\n<p>we can determine basic <code>impl Trait</code> cases for a certain struct already, I think we can split traits into categories by this characteristics and do trait solving for various blanket trait impls and such only, omitting \"simple\" traits from the solving process entirely</p>\n</li>\n<li>\n<p>maybe few more details in <a href=\"https://github.com/rust-analyzer/rust-analyzer/issues/7542#issuecomment-772880309\">https://github.com/rust-analyzer/rust-analyzer/issues/7542#issuecomment-772880309</a> and around</p>\n</li>\n</ul>",
        "id": 261144691,
        "sender_full_name": "Kirill Bulatov",
        "timestamp": 1636643195
    },
    {
        "content": "<p>Right flyimport also triggers that, I wasn't specifically talking about flyimport in this case though as we already do a trait solve when creating the <code>CompletionContext</code> with trait_solve being very costly(the most expensive part usually).</p>\n<div class=\"codehilite\"><pre><span></span><code> 63ms - handle_completion\n       57ms - CompletionContext::new\n           57ms - descend_into_macros\n               57ms - Semantics::analyze_impl\n                   42ms - infer:wait @ index\n                       40ms - infer_query\n                           39ms - trait_solve::wait\n                            0   - crate_def_map:wait (41 calls)\n                            0   - deref (4 calls)\n                            0   - resolve_obligations_as_possible (68 calls)\n                            0   - trait_solve::wait (15 calls)\n                   14ms - SourceBinder::to_module_def (1 calls)\n                    0   - body_with_source_map_query (1 calls)\n                    0   - crate_def_map:wait (2 calls)\n                    0   - impl_data_query (1 calls)\n            0   - Semantics::analyze_impl (3 calls)\n            0   - SourceBinder::to_module_def (2 calls)\n            0   - crate_def_map:wait (1 calls)\n        1ms - complete_unqualified_path (1 calls)\n        0   - crate_def_map:wait (19 calls)\n        0   - deref (2 calls)\n        0   - find_path_prefixed (1 calls)\n        0   - import_on_the_fly (1 calls)\n        0   - infer:wait (1 calls)\n        0   - item::Builder::build (30 calls)\n        2ms - iterate_method_candidates (1 calls)\n</code></pre></div>",
        "id": 261145696,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1636643688
    },
    {
        "content": "<p>completions are basically only really slow now due to inference and def map creation which seems to almost always happen on every completion request</p>",
        "id": 261145943,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1636643800
    },
    {
        "content": "<p>one problem I think I've seen was actually just revalidation of the inference query. Some trait queries might have a lot of dependencies to revalidate. Not sure what can be done about that</p>",
        "id": 265578380,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1640014480
    },
    {
        "content": "<p>Wanted to look into this again but realized hprof is completely useless with chalk as almost all spans turn into <code>???</code>, does chalk spawn threads for its work internally? Also is there a way to see why chalk reruns a query?</p>",
        "id": 266608084,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1641120767
    },
    {
        "content": "<p>I've taken a stab here too, from the <code>import_on_the_fly</code> part of the issue, but experience something odd.</p>\n<p>Looked at <a href=\"https://github.com/rust-analyzer/rust-analyzer/issues/10187\">https://github.com/rust-analyzer/rust-analyzer/issues/10187</a> : I could reproduce it more or less stable by opening a certain file from the issue in <code>tokio</code> repo and typing <code>printl</code> in quite reqular tempo of mine.<br>\nI've also tweaked the completion bench to presumably do the same, but its traces were quite different for some reason, so all testing was done with custom local r-a binary and <code>\"RA_PROFILE\": \"handle_completion&gt;16\",</code></p>\n<p>Here are the traces I see:</p>\n<div class=\"codehilite\"><pre><span></span><code>105ms - import_on_the_fly @ p\n   105ms - import_assets::search_for_imports\n      105ms - import_assets::search_for\n         105ms - import_assets::path_applicable_imports\n               105ms - items_with_name @ Name: p, crate: Exclude, assoc items: Some(&quot;tokio&quot;), limit: Some(40)\n                  105ms - find_items\n                     100ms - crate_symbols @ Query { query: &quot;p&quot;, lowercased: &quot;p&quot;, only_types: false, libs: false, exact: true, case_sensitive: false, limit: 40 }\n                           99ms - crate_symbols|module_ids.par_iter\n                                 0   - Snap::new (1 calls)\n                              99ms - ???\n                           0   - crate_symbols|module_ids_for_crate (1 calls)\n                           1ms - crate_symbols|query.search (1 calls)\n                        4ms - query_external_importables (1 calls)\n\n--------\n\n45ms - import_on_the_fly @ pri\n   44ms - import_assets::search_for_imports\n      44ms - import_assets::search_for\n            44ms - import_assets::path_applicable_imports\n               8ms - find_path_prefixed (61 calls)\n               24ms - get_name_definition (40 calls)\n               11ms - items_with_name (1 calls)\n            0   - import_assets::scope_definitions (1 calls)\n\n--------\n\n70ms - import_on_the_fly @ prin\n   70ms - import_assets::search_for_imports\n       70ms - import_assets::search_for\n           69ms - import_assets::path_applicable_imports\n               15ms - find_path_prefixed (70 calls)\n               45ms - get_name_definition (40 calls)\n                9ms - items_with_name (1 calls)\n            0   - import_assets::scope_definitions (1 calls)\n    0   - DefMap::module_id (4 calls)\n    0   - crate_def_map:wait (4 calls)\n    0   - render_resolution (41 calls)\n</code></pre></div>\n<p>I see two odd things here:</p>\n<ul>\n<li>\n<p><code>get_name_definition</code> is only used when searching crate's own items in <code>symbol_index</code>. Peculiar, that lookup over crate's dependencies does not show in the traces at all, but this method does. Also weird to notice that the very same place gets slower after another letter is added to completion.<br>\nOn the other hand, the <code>get_name_definition</code> call seems unavoidable with the way we build <code>symbol_index</code> now?</p>\n</li>\n<li>\n<p>the <code>crate_symbols|module_ids.par_iter</code> call is caused by my changes, I've tried to chase the <code>???</code> thing and found nothing?</p>\n</li>\n</ul>\n<p>Here's the diff:</p>\n<div class=\"codehilite\" data-code-language=\"Diff\"><pre><span></span><code><span class=\"gh\">diff --git a/crates/ide_db/src/apply_change.rs b/crates/ide_db/src/apply_change.rs</span>\n<span class=\"gh\">index 6c085ffc9..f7c70e107 100644</span>\n<span class=\"gd\">--- a/crates/ide_db/src/apply_change.rs</span>\n<span class=\"gi\">+++ b/crates/ide_db/src/apply_change.rs</span>\n<span class=\"gu\">@@ -137,7 +137,7 @@ impl RootDatabase {</span>\n             hir::db::InternTypeParamIdQuery\n\n             // SymbolsDatabase\n<span class=\"gd\">-            crate::symbol_index::ModuleSymbolsQuery</span>\n<span class=\"gi\">+            crate::symbol_index::ModuleSymbolsQueryQuery</span>\n             crate::symbol_index::LibrarySymbolsQuery\n             crate::symbol_index::LocalRootsQuery\n             crate::symbol_index::LibraryRootsQuery\n<span class=\"gh\">diff --git a/crates/ide_db/src/symbol_index.rs b/crates/ide_db/src/symbol_index.rs</span>\n<span class=\"gh\">index 62f4a8191..a495a6527 100644</span>\n<span class=\"gd\">--- a/crates/ide_db/src/symbol_index.rs</span>\n<span class=\"gi\">+++ b/crates/ide_db/src/symbol_index.rs</span>\n<span class=\"gu\">@@ -96,8 +96,13 @@ impl Query {</span>\n pub trait SymbolsDatabase: HirDatabase + SourceDatabaseExt + Upcast&lt;dyn HirDatabase&gt; {\n     /// The symbol index for a given module. These modules should only be in source roots that\n     /// are inside local_roots.\n<span class=\"gi\">+    #[salsa::transparent]</span>\n<span class=\"gi\">+    #[salsa::invoke(module_symbols_wait)]</span>\n     fn module_symbols(&amp;self, module_id: ModuleId) -&gt; Arc&lt;SymbolIndex&gt;;\n\n<span class=\"gi\">+    #[salsa::invoke(module_symbols)]</span>\n<span class=\"gi\">+    fn module_symbols_query(&amp;self, module_id: ModuleId) -&gt; Arc&lt;SymbolIndex&gt;;</span>\n<span class=\"gi\">+</span>\n     /// The symbol index for a given source root within library_roots.\n     fn library_symbols(&amp;self, source_root_id: SourceRootId) -&gt; Arc&lt;SymbolIndex&gt;;\n\n<span class=\"gu\">@@ -130,6 +135,10 @@ fn library_symbols(db: &amp;dyn SymbolsDatabase, source_root_id: SourceRootId) -&gt; Ar</span>\n     Arc::new(SymbolIndex::new(symbols))\n }\n\n<span class=\"gi\">+fn module_symbols_wait(db: &amp;dyn SymbolsDatabase, module_id: ModuleId) -&gt; Arc&lt;SymbolIndex&gt; {</span>\n<span class=\"gi\">+    let _p = profile::span(\"module_symbols::wait\");</span>\n<span class=\"gi\">+    db.module_symbols_query(module_id)</span>\n<span class=\"gi\">+}</span>\n fn module_symbols(db: &amp;dyn SymbolsDatabase, module_id: ModuleId) -&gt; Arc&lt;SymbolIndex&gt; {\n     let _p = profile::span(\"module_symbols\");\n     let symbols = SymbolCollector::collect(db, module_id);\n<span class=\"gu\">@@ -140,6 +149,7 @@ fn module_symbols(db: &amp;dyn SymbolsDatabase, module_id: ModuleId) -&gt; Arc&lt;SymbolIn</span>\n struct Snap&lt;DB&gt;(DB);\n impl&lt;DB: ParallelDatabase&gt; Snap&lt;salsa::Snapshot&lt;DB&gt;&gt; {\n     fn new(db: &amp;DB) -&gt; Self {\n<span class=\"gi\">+        let _p = profile::span(\"Snap::new\");</span>\n         Self(db.snapshot())\n     }\n }\n<span class=\"gu\">@@ -213,15 +223,23 @@ pub fn crate_symbols(db: &amp;RootDatabase, krate: CrateId, query: Query) -&gt; Vec&lt;Fil</span>\n     let _p = profile::span(\"crate_symbols\").detail(|| format!(\"{:?}\", query));\n\n     let module_ids = module_ids_for_crate(db, krate);\n<span class=\"gd\">-    let indices: Vec&lt;_&gt; = module_ids</span>\n<span class=\"gd\">-        .par_iter()</span>\n<span class=\"gd\">-        .map_with(Snap::new(db), |snap, &amp;module_id| snap.module_symbols(module_id))</span>\n<span class=\"gd\">-        .collect();</span>\n<span class=\"gi\">+    let indices: Vec&lt;_&gt; = {</span>\n<span class=\"gi\">+        let _p = profile::span(\"crate_symbols|module_ids.par_iter\");</span>\n<span class=\"gi\">+        module_ids</span>\n<span class=\"gi\">+            .par_iter()</span>\n<span class=\"gi\">+            .map_with(Snap::new(db), |snap, &amp;module_id| {</span>\n<span class=\"gi\">+                let _p = profile::span(\"crate_symbols|module_ids.map_with\")</span>\n<span class=\"gi\">+                    .detail(|| format!(\"{:?}\", module_id));</span>\n<span class=\"gi\">+                snap.module_symbols(module_id)</span>\n<span class=\"gi\">+            })</span>\n<span class=\"gi\">+            .collect()</span>\n<span class=\"gi\">+    };</span>\n\n     query.search(&amp;indices)\n }\n\n fn module_ids_for_crate(db: &amp;dyn DefDatabase, krate: CrateId) -&gt; Vec&lt;ModuleId&gt; {\n<span class=\"gi\">+    let _p = profile::span(\"module_ids_for_crate\");</span>\n     let def_map = db.crate_def_map(krate);\n     def_map.modules().map(|(id, _)| def_map.module_id(id)).collect()\n }\n</code></pre></div>\n<p>I've wrapped around presumably all code that could be in <code>???</code> yet got nothing. What am I missing? It it really <code>collect()</code> that's slow?</p>",
        "id": 266634316,
        "sender_full_name": "Kirill Bulatov",
        "timestamp": 1641159636
    },
    {
        "content": "<p>You need to remove the <code>par_iter</code> for the spans to work I think, as spans are recorded in a thread local storage.</p>",
        "id": 266635988,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1641162120
    },
    {
        "content": "<p>The <code>crate_symbols</code> query should only happen on the first completion though so that taking 100ms there is fine</p>",
        "id": 266636267,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1641162492
    },
    {
        "content": "<blockquote>\n<p>Peculiar, that lookup over crate's dependencies does not show in the traces at all, but this method does.</p>\n</blockquote>\n<p>Might as well be due to something running on a different thread? Though I don't see anything like that there so that seems odd</p>",
        "id": 266636423,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1641162733
    },
    {
        "content": "<p>Reminder that I've found it very helpful to restrict RA to a single thread to profile completion, but that we didn't add an option for that</p>",
        "id": 266673164,
        "sender_full_name": "matklad",
        "timestamp": 1641207135
    },
    {
        "content": "<p>I already tried that but that didn't change anything for the spans inside <code>trait_solve</code> unfortunately</p>",
        "id": 266674145,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1641207774
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"300586\">Lukas Wirth</span> <a href=\"#narrow/stream/185405-t-compiler.2Frust-analyzer/topic/Completion.20performance/near/266608084\">said</a>:</p>\n<blockquote>\n<p>Wanted to look into this again but realized hprof is completely useless with chalk as almost all spans turn into <code>???</code>, does chalk spawn threads for its work internally? Also is there a way to see why chalk reruns a query?</p>\n</blockquote>\n<p>Chalk doesn't spawn threads, no. Chalk also doesn't rerun queries, I guess you meant Salsa. You might actually be talking about the same thing I mentioned, in which case there actually <em>isn't</em> a query being rerun, it's just the Salsa revalidation of the trait solve query which takes so long. It could be related to Chalk checking far too many impls though, maybe because of some (sub)query like <code>?: Deref</code>.</p>",
        "id": 266676344,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1641209535
    },
    {
        "content": "<p>it could be nice to somehow get statistics about dependencies of our queries</p>",
        "id": 266676405,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1641209593
    },
    {
        "content": "<p>if you see <code>trait_solve::wait</code> but not <code>trait_solve_query</code>, it's either the query running in another thread or dependency revalidation</p>",
        "id": 266676505,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1641209706
    },
    {
        "content": "<p>Oh, now I see, that would make sense. Will check later again but I do think you only see <code>trait_solve::wait</code>but not <code>trait_solve_query</code></p>",
        "id": 266676539,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1641209759
    },
    {
        "content": "<p>if we used <code>tracing</code> for our profiling, we could probably get spans for salsa in there as well <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span></p>",
        "id": 266682647,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1641214533
    },
    {
        "content": "<p>... that would also obviate the need for <code>:wait</code> queries</p>",
        "id": 266682714,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1641214571
    },
    {
        "content": "<p>Would using tracing over our profiling infra give us any downsides in the general case? it shouldn't right? <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span></p>",
        "id": 266683042,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1641214816
    },
    {
        "content": "<p>Turns out we also have an issue about this, albeit very small <a href=\"https://github.com/rust-analyzer/rust-analyzer/issues/3794\">https://github.com/rust-analyzer/rust-analyzer/issues/3794</a></p>",
        "id": 266683081,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1641214830
    },
    {
        "content": "<p>I think there was some more discussion about it somewhere, maybe here?</p>",
        "id": 266702023,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1641225479
    },
    {
        "content": "<p>The only thing I remember is switching from <code>log</code> to <code>tracing</code>, but maybe there was more</p>",
        "id": 266702120,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1641225523
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"300586\">Lukas Wirth</span> <a href=\"#narrow/stream/185405-t-compiler.2Frust-analyzer/topic/Completion.20performance/near/266683042\">said</a>:</p>\n<blockquote>\n<p>Would using tracing over our profiling infra give us any downsides in the general case? it shouldn't right? <span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span></p>\n</blockquote>\n<p>Just to note, current <code>tracing-subscriber</code> implementation always eager to call <code>Debug/Display</code> on every new span's variable, disregarding of whether the actual span gets any logging events or not later, so you at least loose a way to defer those details as we do now via <code>.detail(|| format!(\"{:?}\", file_id));</code> .<br>\nThat might cause some performance issues (especially notable on log-less spans), but hard to say in general whether it would be notable or not.</p>",
        "id": 266722315,
        "sender_full_name": "Kirill Bulatov",
        "timestamp": 1641235739
    },
    {
        "content": "<p>Looking at the span macros from tracing it seems to actually not be eager with formatting if the span is disabled</p>",
        "id": 266791429,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1641292020
    },
    {
        "content": "<p>On another note, we currently have a query limit employed for flyimport completions when searching dependencies, I assume we won't really be able to ever get rid of that but assuming we manage to improve the performance here we should be able to bump the limit up a bit right?<br>\nBecause currently we have flyimport completions that sometimes disappear(<code>std::iter::once</code> has this behaviour) when you type out more characters, which doesn't really make sense at first but which I assume is due to the use of a <code>FxHashSet</code> <a href=\"https://github.com/rust-analyzer/rust-analyzer/blob/7409880a07803c34590ad162d7854061145c6eae/crates/hir_def/src/import_map.rs#L415\">here</a>. Replacing that with an <code>FxIndexSet</code> should fix that, but currently has the problem that <code>std::iter::once</code> won't get completed at all anymore, due to all the std simd functions matching prior to it, filling the current limit. <a href=\"https://github.com/rust-analyzer/rust-analyzer/issues/10112\">r-a#10112</a></p>\n<p>Just wanted to throw that in here as it is somewhat relevant</p>",
        "id": 266817442,
        "sender_full_name": "Lukas Wirth",
        "timestamp": 1641308298
    },
    {
        "content": "<p>I don't think the limit goes away in the near/mid-future, but the situation is odd indeed.</p>\n<p>I think, this particular issue could be solved by caching the previous search input and reusing it.<br>\nI.e.: <code>pri</code> returned N results, on <code>prin</code> we could first filter out those old results and query more, if needed.</p>\n<p>Alas, no proper idea how to invalidate that kind of cache and where to store that.<br>\n(maybe just a plain LRU in Salsa?)</p>",
        "id": 266822342,
        "sender_full_name": "Kirill Bulatov",
        "timestamp": 1641310644
    }
]