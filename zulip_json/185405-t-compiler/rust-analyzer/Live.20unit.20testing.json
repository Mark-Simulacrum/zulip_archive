[
    {
        "content": "<p>Not sure whether this is the right place to askâ€”if not please do point me elsewhere!  Just wondering whether there are any efforts underway (or if not, whether it is on any roadmap) to implement something akin to \"live unit testing\" for Rust (where the IDE continuously updates visual indicators of unit test results AS ONE CODES: see for example <a href=\"https://wallabyjs.com/\">https://wallabyjs.com/</a> and <a href=\"https://docs.microsoft.com/en-us/visualstudio/test/live-unit-testing\">https://docs.microsoft.com/en-us/visualstudio/test/live-unit-testing</a> )?  Compilation time obviously a hinderance but perhaps moving toward a realistic possibility with <a href=\"https://github.com/bjorn3/rustc_codegen_cranelift/issues/1087\">https://github.com/bjorn3/rustc_codegen_cranelift/issues/1087</a> ... cc <span class=\"user-mention\" data-user-id=\"133247\">@bjorn3</span></p>",
        "id": 217883005,
        "sender_full_name": "eggyal",
        "timestamp": 1606310462
    },
    {
        "content": "<p>Seems like this would require running the compiler on not-yet-saved files, aka VFS support</p>",
        "id": 217883766,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1606310892
    },
    {
        "content": "<p><a href=\"https://github.com/rust-analyzer/rust-analyzer/issues/3601\">https://github.com/rust-analyzer/rust-analyzer/issues/3601</a></p>",
        "id": 217883904,
        "sender_full_name": "Jeremy Kolb",
        "timestamp": 1606310993
    },
    {
        "content": "<p>and that, yeah :)</p>",
        "id": 217883988,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1606311025
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211727\">@Jonas Schievink</span>  Perhaps.  Or else mirroring the source files in an on-disk cache to which modifications (not yet saved to the working tree) are stored and compiling that (I believe this is how Wallaby does it, via IDE plugins).</p>",
        "id": 217884064,
        "sender_full_name": "eggyal",
        "timestamp": 1606311076
    },
    {
        "content": "<p>yeah, but that's pretty error-prone</p>",
        "id": 217884110,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1606311110
    },
    {
        "content": "<p>This is a nice idea! When using nightly rustc, VFS support is easy to implement. All you have to do is implement <a href=\"https://doc.rust-lang.org/nightly/nightly-rustc/rustc_span/source_map/trait.FileLoader.html\"><code>FileLoader</code></a> and pass it to <code>rustc_driver</code> in a custom driver. This is pretty much what rls does as far as I know. As for the referenced cg_clif issue, I made some progress on lazy compilation. The same Cranelift changes necessary for this would enable hot code swapping from the Cranelift side. I don't know how easy it will be to abuse incremental compilation for this purpose though, but it is certainly high on my todo list.</p>",
        "id": 217884267,
        "sender_full_name": "bjorn3",
        "timestamp": 1606311187
    },
    {
        "content": "<p>we don't call rustc in-process, so it's not so easy <span aria-label=\"grimacing\" class=\"emoji emoji-1f62c\" role=\"img\" title=\"grimacing\">:grimacing:</span></p>",
        "id": 217884410,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1606311245
    },
    {
        "content": "<p>If only rust-analyzer were to require nightly...</p>",
        "id": 217884471,
        "sender_full_name": "bjorn3",
        "timestamp": 1606311292
    },
    {
        "content": "<p>Maybe someone could take <a href=\"https://github.com/rust-analyzer/rust-analyzer/pull/5765\">https://github.com/rust-analyzer/rust-analyzer/pull/5765</a> and push it over the edge</p>",
        "id": 217884624,
        "sender_full_name": "Jeremy Kolb",
        "timestamp": 1606311387
    },
    {
        "content": "<p>I don't see pinning r-a to nightly Rust versions as too big of a problem, as long as we only update the version when really necessary.</p>",
        "id": 217884856,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1606311530
    },
    {
        "content": "<p>(I feel like we update dependencies way too frequently, my target dir is over 30 GB already)</p>",
        "id": 217884893,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1606311554
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"203366\">@Jeremy Kolb</span> the test explorers are great but do they update live?  I think this requires instrumentation in order to determine which tests have been affected by any given modifications, or else one will need to rerun the entire suite after every edit. Perhaps <span class=\"user-mention\" data-user-id=\"296355\">@Rich Kadel</span>'s work on <a href=\"https://github.com/rust-lang/rust/issues/79121\">https://github.com/rust-lang/rust/issues/79121</a> could help here</p>",
        "id": 217884977,
        "sender_full_name": "eggyal",
        "timestamp": 1606311603
    },
    {
        "content": "<p>That would require pretty far-reaching code analysis</p>",
        "id": 217885099,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1606311658
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"211727\">@Jonas Schievink</span>  Or just run tests (with instrumentation) and record what code regions each has exercised/covered</p>",
        "id": 217885224,
        "sender_full_name": "eggyal",
        "timestamp": 1606311723
    },
    {
        "content": "<p>I'm not sure but my guess is that it's probably not live.</p>",
        "id": 217885381,
        "sender_full_name": "Jeremy Kolb",
        "timestamp": 1606311802
    },
    {
        "content": "<p>I'd say the pieces for this are coming together, but we're probably still a few years away from being able to do this</p>",
        "id": 217885548,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1606311878
    },
    {
        "content": "<p>Sounds like a github issue sketching out the design and dependencies could be helpful?</p>",
        "id": 217885842,
        "sender_full_name": "eggyal",
        "timestamp": 1606312024
    },
    {
        "content": "<p>heh, I suggested something like this a while back: <a href=\"#narrow/stream/242791-t-infra/topic/Speculative.20CI.3F/near/200533333\">https://rust-lang.zulipchat.com/#narrow/stream/242791-t-infra/topic/Speculative.20CI.3F/near/200533333</a></p>",
        "id": 217886001,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1606312104
    },
    {
        "content": "<p>ugh, the official discord hid the #infra channel for some reason so you can't look at it anymore</p>",
        "id": 217886271,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1606312219
    },
    {
        "content": "<p>I had found a project doing this in python</p>",
        "id": 217886294,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1606312236
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"232545\">@Joshua Nelson</span> I think in the context of CI this doesn't really help. For running unit-tests live while editing code, it's plausible because we can compile everything, run all tests and collect coverage, and then know which tests cover which code (though even that would be relying on the tests being deterministic). But I don't think you can reliably do the analysis which tests depend on which code statically, so this wouldn't help you reduce CI times</p>",
        "id": 217886374,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1606312287
    },
    {
        "content": "<p>right, this is dynamic - you need state between CI runs</p>",
        "id": 217886407,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1606312308
    },
    {
        "content": "<p>to know which tests depend on which code, and also which files have been modified</p>",
        "id": 217886487,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1606312332
    },
    {
        "content": "<p>hmm, I didn't think about non-determinism</p>",
        "id": 217886702,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1606312451
    },
    {
        "content": "<p>even then -- if your IDE live-testing doesn't run some test it should, it's a slight annoyance. If the CI doesn't run some test it should, that's a huge problem</p>",
        "id": 217886732,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1606312474
    },
    {
        "content": "<p>With lazy compilation instrumenting would be trivial. It wouldn't even be necessary to add instrumentation calls in the jitted code. Just record the function call when you lazily compile a function.</p>",
        "id": 217886784,
        "sender_full_name": "bjorn3",
        "timestamp": 1606312502
    },
    {
        "content": "<p><span aria-label=\"thinking\" class=\"emoji emoji-1f914\" role=\"img\" title=\"thinking\">:thinking:</span> how would that work if you're running multiple tests -- you wouldn't know that the second test also called the same function, would you?</p>",
        "id": 217886863,
        "sender_full_name": "Florian Diebold",
        "timestamp": 1606312559
    },
    {
        "content": "<p>You could reset the GOT used for swapping all calls from the lazy compilation stub to the jitted code back to the lazy compilation stubs after every test and then as optimization keep a pointer to the jitted code in a side-table.</p>",
        "id": 217887025,
        "sender_full_name": "bjorn3",
        "timestamp": 1606312626
    },
    {
        "content": "<p>Opened <a href=\"https://github.com/bjorn3/rustc_codegen_cranelift/issues/1113\">bjorn3/rustc_codegen_cranelift#1113</a> for the instrumentation.</p>",
        "id": 217888331,
        "sender_full_name": "bjorn3",
        "timestamp": 1606313178
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"133247\">@bjorn3</span> I guess you can do it at the function level, but instrumenting code paths within each function provides much richer feedback: eg test coverage and failure paths</p>",
        "id": 217893129,
        "sender_full_name": "eggyal",
        "timestamp": 1606315504
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249694\">@eggyal</span> True, but it also has much higher overhead. When trying to use cg_clif as frontend for yorick a while ago, I had to instrument the start of each basic block. When the instrumentation function immediately returned without doing anything, the overhead was 15% in the instrumentation function. Which doesn't account for any pessimizations of regalloc. When instrumentation was disabled at runtime using a global flag, the overhead was 30% after writing inline asm to prevent cranelift from spilling registers clobbered in the enabled case. Maybe the overhead could be improved by being  smarter about where to add the instrumentation calls. One instrumentation call at the top of each function may be more doable.</p>",
        "id": 217896807,
        "sender_full_name": "bjorn3",
        "timestamp": 1606317170
    },
    {
        "content": "<p>Or maybe only instrument user code and keep all code in dependencies uninstrumented?</p>",
        "id": 217896937,
        "sender_full_name": "bjorn3",
        "timestamp": 1606317241
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"133247\">@bjorn3</span>, that's definitely significant.  However I'd observe from using Wallaby that, after the initial run of the full test suite, one rarely sees more than a few unit tests invoked by any given edit... and, being unit tests, execution typically is of the order of millisecondsâ€”so even a 30% uplift may not be very material in practice?</p>",
        "id": 217904439,
        "sender_full_name": "eggyal",
        "timestamp": 1606320603
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249694\">@eggyal</span> The overhead may not be very important in this case. Also thinking about it some more, the overhead can be significantly reduced in this case by simply having a global for every instrumentation point and writing directly to that global without doing a call each time.</p>",
        "id": 217910201,
        "sender_full_name": "bjorn3",
        "timestamp": 1606323057
    },
    {
        "content": "<p>I actually don't think we need any fancy techniques here</p>",
        "id": 218428191,
        "sender_full_name": "matklad",
        "timestamp": 1606832785
    },
    {
        "content": "<p>We can just re-use our <code>checkOnSave</code> infra, but with using <code>cargo test</code> instead of <code>cargo check</code></p>",
        "id": 218428235,
        "sender_full_name": "matklad",
        "timestamp": 1606832807
    },
    {
        "content": "<p>I think the most work here is getting the UI bits (which are not part of standard LSP, and as such would require a bunch of custom code)</p>",
        "id": 218428317,
        "sender_full_name": "matklad",
        "timestamp": 1606832845
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"133169\">@matklad</span> that would rerun <em>all</em> the tests, right? We've been discussing how to only rerun changed tests.</p>",
        "id": 218428568,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1606832953
    },
    {
        "content": "<p>But I agree an opt-in way to rerun everything is good in the meantime, since incremental retesting is a bit of a research project</p>",
        "id": 218428624,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1606832981
    },
    {
        "content": "<p>The discussion converged to that, but we don't need that to implement the original feature request</p>",
        "id": 218428846,
        "sender_full_name": "matklad",
        "timestamp": 1606833077
    },
    {
        "content": "<p>Just revisiting this a bit... <span class=\"user-mention\" data-user-id=\"133169\">@matklad</span> you mentioned most the work would be on UI as reporting test results is not in standard LSP, but VS does have Live Unit Testing for other languages so I guess MS have an API for it even if itâ€™s not public/open?  Is there any way we could find out more, rather than (as you say) reinvent the wheel (which appears to be Wallabyâ€™s approach)?</p>",
        "id": 223307457,
        "sender_full_name": "eggyal",
        "timestamp": 1611096285
    },
    {
        "content": "<p>I think just thoroughly googing around and reading the sources of other extensions would do the trick</p>",
        "id": 223308575,
        "sender_full_name": "matklad",
        "timestamp": 1611096942
    },
    {
        "content": "<p>(lurking). If I understand this discussion right, VSCode has an issue for standardizing the test interface: <a href=\"https://github.com/microsoft/vscode/issues/107467\">https://github.com/microsoft/vscode/issues/107467</a></p>",
        "id": 223417125,
        "sender_full_name": "David Barsky",
        "timestamp": 1611168541
    },
    {
        "content": "<p>(it's part of the January 2021 iteration plan: <a href=\"https://github.com/microsoft/vscode/issues/112419\">https://github.com/microsoft/vscode/issues/112419</a>)</p>",
        "id": 223417161,
        "sender_full_name": "David Barsky",
        "timestamp": 1611168559
    },
    {
        "content": "<p>My mind was just wandering over this once again, and on re-reading the thread I think it may be worth adding to what <span class=\"user-mention silent\" data-user-id=\"133247\">bjorn3</span> <a href=\"#narrow/stream/185405-t-compiler.2Frust-analyzer/topic/Live.20unit.20testing/near/217910201\">said</a>:</p>\n<blockquote>\n<p>simply having a global for every instrumentation point and writing directly to that global without doing a call each time.</p>\n</blockquote>\n<p>I believe this is exactly how <code>-Zinstrument-coverage</code> works, albeit that the counters are incremented via LLVM intrinsics that obviously aren't available in cg-clif; furthermore that approach does not instrument every block as the counts for many can be calculated from those of others (eg in <code>if ... else</code> only one branch need be counted as the other is simply the difference between the parent and that counted one).  Might it be worth adding similar instrumentation intrinsics to cg-clif?  That feels like something I could take a crack at.</p>",
        "id": 233637982,
        "sender_full_name": "eggyal",
        "timestamp": 1617882018
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"249694\">@eggyal</span> For determining which functions are used, only per-function instrumentation is necessary, not per-block instrumentation. I do see value in full <code>-Zinstrument-coverage</code> support (maybe even compatible with LLVM), but for now I think per-function coverage should be easier. I am happy with a PR for either option.</p>",
        "id": 233642818,
        "sender_full_name": "bjorn3",
        "timestamp": 1617884528
    },
    {
        "content": "<p>Created <a href=\"https://github.com/rust-analyzer/rust-analyzer/issues/8420\">https://github.com/rust-analyzer/rust-analyzer/issues/8420</a> to track this</p>",
        "id": 233646643,
        "sender_full_name": "eggyal",
        "timestamp": 1617886374
    }
]