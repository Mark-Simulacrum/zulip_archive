[
    {
        "content": "<p>Is anyone already working on the new pass manager? <a href=\"https://github.com/rust-lang/rust/issues/64289\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/issues/64289\">https://github.com/rust-lang/rust/issues/64289</a><br>\nIf not, I would be interested to try this myself</p>",
        "id": 175360041,
        "sender_full_name": "cuviper",
        "timestamp": 1568136956
    },
    {
        "content": "<p>Nope, not aware of anyone working on newpm yet. Feel free :)</p>",
        "id": 175381342,
        "sender_full_name": "Nikita Popov",
        "timestamp": 1568152030
    },
    {
        "content": "<p>Did you have any luck with newpm?</p>",
        "id": 177193003,
        "sender_full_name": "Nikita Popov",
        "timestamp": 1570050762
    },
    {
        "content": "<p>I started poking at it a little, mostly to learn how the new bits work, nothing to run yet</p>",
        "id": 177263886,
        "sender_full_name": "cuviper",
        "timestamp": 1570121787
    },
    {
        "content": "<p>unfortunately I got sidetracked with other work</p>",
        "id": 177263917,
        "sender_full_name": "cuviper",
        "timestamp": 1570121806
    },
    {
        "content": "<p>Looking forward to seeing this in action. Apparently the new pass manager can improve optimization quality: <a href=\"https://groups.google.com/d/msg/llvm-dev/CZmUJC4gMjQ/004NTMEYBAAJ\" target=\"_blank\" title=\"https://groups.google.com/d/msg/llvm-dev/CZmUJC4gMjQ/004NTMEYBAAJ\">https://groups.google.com/d/msg/llvm-dev/CZmUJC4gMjQ/004NTMEYBAAJ</a></p>",
        "id": 177520122,
        "sender_full_name": "mw",
        "timestamp": 1570455822
    },
    {
        "content": "<p>FYI this is still on my mind, but personal life has been intense lately</p>",
        "id": 179256417,
        "sender_full_name": "cuviper",
        "timestamp": 1572284887
    },
    {
        "content": "<p>I's there any summary on how the new pass manager is different from the old one and why?<br>\nI know the new pass manager was a multi-year effort, but I used only the most basic functionality in the old pass manager myself, so I find it hard to imagine why it would be such a big deal.</p>",
        "id": 185099460,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1578481784
    },
    {
        "content": "<p>I'm not really familiar either, but I believe the main difference and advantage is in how it manages analysis passes.</p>",
        "id": 185107709,
        "sender_full_name": "Nikita Popov",
        "timestamp": 1578488853
    },
    {
        "content": "<p>I believe those get computed more lazily now and also get invalidated more lazily (e.g. if a transform pass doesn't make any changes, even if it does not explicitly preserve some specific analysis.)</p>",
        "id": 185107827,
        "sender_full_name": "Nikita Popov",
        "timestamp": 1578488924
    },
    {
        "content": "<p>And apparently some kinds of analysis couldn't be accessed in some types of transformation passes before ... or something.</p>",
        "id": 185107894,
        "sender_full_name": "Nikita Popov",
        "timestamp": 1578488971
    },
    {
        "content": "<p>I'm working on some MIR optimizations and I'm seeing a massive regression in compile times when my optimization is enabled due to LLVM (on one particular test case). I'm working on trying to debug this more but I've noticed that if I enabled the new pass manager via <code>-Znew-llvm-pass-manager</code>, that seems to resolve the issue. </p>\n<p>Is there a timeline for using the new pass manager by default or are we blocked on something? Is there anything I can do to help get that flipped on by default?</p>",
        "id": 188936644,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1582558579
    },
    {
        "content": "<p>one reason to not make the switch is that not even clang is using the new pass manager yet</p>",
        "id": 188972964,
        "sender_full_name": "andjo403",
        "timestamp": 1582583189
    },
    {
        "content": "<p>Ah, I see. I was just reading in LLVM weekly that passes are still being ported to it. Perhaps \"experimental pass manager\" is a better term <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span></p>",
        "id": 188973282,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1582583404
    },
    {
        "content": "<p>what optimizations those are</p>",
        "id": 188974358,
        "sender_full_name": "nagisa",
        "timestamp": 1582584280
    },
    {
        "content": "<p>MIR optimisations should first and foremost be for reducing compile times, optimising a generic IR will not allow super high quality code anyway â€“ LLVM will do it.</p>",
        "id": 188974396,
        "sender_full_name": "nagisa",
        "timestamp": 1582584321
    },
    {
        "content": "<p>The MIR inliner. It's a win for most of the rustc-perf benchmarks but <code>deeply-nested</code> shows an enormous slowdown when it's enabled.</p>",
        "id": 188979088,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1582588486
    },
    {
        "content": "<p>I think the core issue is that some of the iterator methods are currently just slightly too costly for LLVM to inline them. After turning on MIR inliner, they just squeeze by the cost threshold which triggers an exponential blowup in terms of locals.</p>",
        "id": 188979194,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1582588575
    },
    {
        "content": "<p>I have a number of local tweaks that I think fix that at the MIR level but I'm still seeing LLVM take massive amounts of compilation time.</p>",
        "id": 188979211,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1582588617
    },
    {
        "content": "<p>I've tried following the guide here <a href=\"https://rust-lang.github.io/rustc-guide/codegen/debugging.html\" target=\"_blank\" title=\"https://rust-lang.github.io/rustc-guide/codegen/debugging.html\">https://rust-lang.github.io/rustc-guide/codegen/debugging.html</a> but unfortunately if I set <code>-Ccodegen-units=1</code>, the slowdown goes away and if I use <code>opt</code> on the individual files generated by <code>--emit llvm-ir</code>, there's no slowdown.</p>",
        "id": 188979293,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1582588714
    },
    {
        "content": "<p>So I'm not really sure where to go next. I've been starting to poke at the codegen partition code; maybe there's something that can be tweaked there? That's just speculation on my part though.</p>",
        "id": 188979338,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1582588795
    },
    {
        "content": "<p>I happened to notice that the new pass manager also resolves the issue but it looks like that's currently a dead end.</p>",
        "id": 188979610,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1582589018
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/187780-t-compiler.2Fwg-llvm/topic/new.20pass.20manager/near/188979610\" title=\"#narrow/stream/187780-t-compiler.2Fwg-llvm/topic/new.20pass.20manager/near/188979610\">said</a>:</p>\n<blockquote>\n<p>I happened to notice that the new pass manager also resolves the issue but it looks like that's currently a dead end.</p>\n</blockquote>\n<p>Very likely to be because \"new pass manager\" is not full featured yet?</p>",
        "id": 188985516,
        "sender_full_name": "nagisa",
        "timestamp": 1582596319
    },
    {
        "content": "<p>Consider tweaking inlining thresholds in Rust?</p>",
        "id": 188985527,
        "sender_full_name": "nagisa",
        "timestamp": 1582596351
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> Have you tried extracting the LLVM IR for the codegen unit which slows down? Maybe you could report a performance problem upstream to LLVM?</p>",
        "id": 189423922,
        "sender_full_name": "Zoxc",
        "timestamp": 1583048595
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span> Sorry, just getting back to this. I do have the LLVM IR for the codegen unit which is slow. I'm not really sure how to get <code>opt</code> to do exactly what <code>rustc</code> is doing though so I don't have a clean repro. </p>\n<p>I suspect a lot of this is self-inflicted and possibly not a bug in LLVM since we've slapped <code>#[inline]</code> on pretty much everything in <code>std::iter</code></p>",
        "id": 190117470,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1583787809
    },
    {
        "content": "<p>If anyone has advice on invoking <code>opt</code> with the same set of optimization passes <code>rustc</code> uses, that would be very helpful! :)</p>",
        "id": 190117549,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1583787843
    },
    {
        "content": "<p>I'm assuming you're using opt -O3 currently? You can try -Zprint-llvm-passes and pass the output of that to opt.</p>",
        "id": 190150808,
        "sender_full_name": "Nikita Popov",
        "timestamp": 1583829166
    },
    {
        "content": "<p>Regarding the original question, we should give using the new pass manager another try after updating to LLVM 10. There are a couple of issues I'm still aware of, so not sure if we'll actually make the switch already.</p>",
        "id": 190151019,
        "sender_full_name": "Nikita Popov",
        "timestamp": 1583829385
    },
    {
        "content": "<p>You want the IR before any LLVM passes run, I'm not sure if we have an easy way to output that.</p>",
        "id": 190272181,
        "sender_full_name": "Zoxc",
        "timestamp": 1583926791
    },
    {
        "content": "<p>That's the <code>-Cno-prepopulate-passes</code> flag right? <a href=\"https://rustc-dev-guide.rust-lang.org/codegen/debugging.html#compiler-options-to-know-and-love\" target=\"_blank\" title=\"https://rustc-dev-guide.rust-lang.org/codegen/debugging.html#compiler-options-to-know-and-love\">https://rustc-dev-guide.rust-lang.org/codegen/debugging.html#compiler-options-to-know-and-love</a></p>",
        "id": 190279103,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1583932492
    },
    {
        "content": "<p>In theory, not sure it's accurate in practice =P</p>",
        "id": 190394532,
        "sender_full_name": "Zoxc",
        "timestamp": 1584022934
    },
    {
        "content": "<p>relatively accurate. AFAIR we still just output an error if we would run any passes</p>",
        "id": 190395972,
        "sender_full_name": "nagisa",
        "timestamp": 1584023581
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> Do we have a limit for how large functions can be before we stop inlining?</p>",
        "id": 190400545,
        "sender_full_name": "Zoxc",
        "timestamp": 1584025754
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116466\">@Zoxc</span> not currently no</p>",
        "id": 190401599,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1584026258
    },
    {
        "content": "<p>Let me brain dump what I've learned so far in case it helps spark an idea from anyone else:</p>\n<p>The problematic test case is <a href=\"https://github.com/rust-lang/rustc-perf/blob/master/collector/benchmarks/deeply-nested/src/lib.rs\" target=\"_blank\" title=\"https://github.com/rust-lang/rustc-perf/blob/master/collector/benchmarks/deeply-nested/src/lib.rs\"><code>deeply-nested</code></a>.</p>\n<p>With MIR inlining enabled, we hand LLVM a couple thousand lines of IR for <code>foo()</code> which it chews through very quickly (this isn't the compilation time issue). The problem is that because we box the value as <code>Box&lt;dyn Iterator&lt;Item = ()&gt;&gt;</code> , the collector also has to codegen <a href=\"https://github.com/rust-lang/rust/blob/master/src/librustc_mir/monomorphize/collector.rs#L504-L536\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/blob/master/src/librustc_mir/monomorphize/collector.rs#L504-L536\">all of the trait methods</a>. It's this code which LLVM is choking on because it spends a huge amount of processing the <code>Iterator::next()</code> body after inlining all of the <code>Chain</code> adapters. </p>\n<p>I suspect the reason that LLVM inlining is triggering so aggressively here is that currently something in <code>std::iter</code> is just over the threshold to inline and so it is not currently getting inlined but with MIR inlining enabled, it may now be just small enough to inline. I have not confirmed this though.</p>",
        "id": 190404672,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1584027715
    },
    {
        "content": "<p>You could try adding a max function size and stop inlining into such functions. It might help with the regression since you don't seem too sure about that cause.</p>\n<p>We could also just regress <code>deeply-nested</code> since it's just a synthetic benchmark. It would be interesting to see if adding or removing more <code>.chain(empty())</code>s from it changes the regression.</p>",
        "id": 190409256,
        "sender_full_name": "Zoxc",
        "timestamp": 1584029659
    }
]