[
    {
        "content": "<p>While experimenting with reporting <code>maxrss</code> acquired via <code>getrusage</code>, I have found something odd</p>",
        "id": 227333210,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614026205
    },
    {
        "content": "<p>I’m still trying to confirm this, but it seems like on my mac, I am consistently observing rustc_middle taking about 2.5 GB maxrss</p>",
        "id": 227333292,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614026261
    },
    {
        "content": "<p>is that lower or higher than you expect?</p>",
        "id": 227333547,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1614026365
    },
    {
        "content": "<p>lower</p>",
        "id": 227333693,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614026422
    },
    {
        "content": "<p>let me go check what i was seeing on linux</p>",
        "id": 227333714,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614026430
    },
    {
        "content": "<p>but I thought on Linux it was on the order of 6 GB</p>",
        "id": 227333722,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614026436
    },
    {
        "content": "<p>it could be a consequence of <a href=\"https://github.com/rust-lang/rust/issues/70951\">#70951</a> :-).</p>",
        "id": 227333996,
        "sender_full_name": "tm",
        "timestamp": 1614026577
    },
    {
        "content": "<p>oh, you’re right; I wasn’t checking if I was comparing the same builds</p>",
        "id": 227334376,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614026763
    },
    {
        "content": "<p>(but, no; I think both of the builds I’m evaluated are at the same point in the git history, and both predate PR <a href=\"https://github.com/rust-lang/rust/issues/70951\">#70951</a> landing. I think. Checking again now.)</p>",
        "id": 227335704,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614027315
    },
    {
        "content": "<p>The memory usage is going to depend on the number of CPUs on the system, so if they're different, that could account for it. Also, the allocators will behave differently.</p>\n<p>Btw, I found that changes over the last ~8 days have reduced max-RSS when compiling the entire rustc by around 750 MB on my 8 CPU system. I'm sure <a href=\"https://github.com/rust-lang/rust/issues/70951\">#70951</a> accounts for all or most of that.</p>",
        "id": 227342074,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1614030041
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"306073\">Tyson Nottingham</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/rustc_middle.20mac.20os.20x.20weirdness/near/227342074\">said</a>:</p>\n<blockquote>\n<p>The memory usage is going to depend on the number of CPUs on the system, so if they're different, that could account for it.</p>\n</blockquote>\n<p>is this true even if I pass <code>-j1</code> to <code>x.py</code>, or will passing that act as a control for that variable?</p>",
        "id": 227343322,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614030559
    },
    {
        "content": "<p>It's true even with -j1, at least until <a href=\"https://github.com/rust-lang/rust/issues/82127\">#82127</a> is in the bootstrapping compiler.</p>",
        "id": 227343663,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1614030711
    },
    {
        "content": "<p>I'm not sure about default allocators, but I recall that eddyb ran into a jemalloc behavior where there's a background thread that every 30 seconds cleans up memory or something like that, which meant that if your benchmark was ~30 seconds long (under or over depending on noise easily) you could see massively different instruction counts. I imagine it'd have similar effects on memory.</p>",
        "id": 227343750,
        "sender_full_name": "simulacrum",
        "timestamp": 1614030732
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"306073\">Tyson Nottingham</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/rustc_middle.20mac.20os.20x.20weirdness/near/227343663\">said</a>:</p>\n<blockquote>\n<p>It's true even with -j1, at least until <a href=\"https://github.com/rust-lang/rust/issues/82127\">#82127</a> is in the bootstrapping compiler.</p>\n</blockquote>\n<p>I find this surprising -- I would expect -j1 to isolate you to one CPU (aside from allocator shenanigans like the one I mention), so the <em>number</em> of CPUs shouldn't matter</p>",
        "id": 227343846,
        "sender_full_name": "simulacrum",
        "timestamp": 1614030784
    },
    {
        "content": "<p>comparing macOS's default allocator to glibc though seems like it's going to have different behavior though no matter what</p>",
        "id": 227343904,
        "sender_full_name": "simulacrum",
        "timestamp": 1614030806
    },
    {
        "content": "<p>(or to jemalloc)</p>",
        "id": 227343927,
        "sender_full_name": "simulacrum",
        "timestamp": 1614030818
    },
    {
        "content": "<p>different behavior, I totally expect. but going from 2.5 GB to 6 GB is more extreme than I would have expected.</p>",
        "id": 227344009,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614030845
    },
    {
        "content": "<p>(Caveat: I still need to verify this. I’m doing something else at moment but hoping to come back to this in a sec.)</p>",
        "id": 227344059,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614030872
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/rustc_middle.20mac.20os.20x.20weirdness/near/227343846\">said</a>:</p>\n<blockquote>\n<p>I find this surprising -- I would expect -j1 to isolate you to one CPU (aside from allocator shenanigans like the one I mention), so the <em>number</em> of CPUs shouldn't matter</p>\n</blockquote>\n<p>It does isolate you to one CPU, but the problem is that the codegen scheduler still thinks we need to codegen a bunch of CGUs to LLVM modules ahead of time in order to meet demand of number-of-CPUs workers, basically. So it has more LLVM modules in memory at once than it needs to with -j1. That's one of the things that <a href=\"https://github.com/rust-lang/rust/issues/82127\">#82127</a> resolves.</p>",
        "id": 227344601,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1614031101
    },
    {
        "content": "<p>Ah, right, and since we use time as a metric for how to schedule, that can definitely vary between cpus</p>",
        "id": 227344702,
        "sender_full_name": "simulacrum",
        "timestamp": 1614031155
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116083\">pnkfelix</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/rustc_middle.20mac.20os.20x.20weirdness/near/227344059\">said</a>:</p>\n<blockquote>\n<p>(Caveat: I still need to verify this. I’m doing something else at moment but hoping to come back to this in a sec.)</p>\n</blockquote>\n<p>hmm, apparently what I rememered as 6 GB on Linux is actually 3.4 GB … so, not as severe as what I had thought… <span aria-label=\"shrug\" class=\"emoji emoji-1f937\" role=\"img\" title=\"shrug\">:shrug:</span></p>",
        "id": 227346691,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614031613
    },
    {
        "content": "<p>(argh wait let me try again with a clean build… What’s wrong with me…)</p>",
        "id": 227347707,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614031907
    },
    {
        "content": "<p><del>hmm. So some of my clean Linux runs yielded maxrss 3.4 GB for rustc_middle, but one I just did now (starting from the same point) yielded 7.2 GB.</del> Argh! I forgot, this more recent run wasn’t passing <code>-j1</code>! Passing <code>-j1</code> brings it back down to 3.4 GB</p>",
        "id": 227452221,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614095541
    },
    {
        "content": "<p><del>so that’s not great, in terms of trying to rely on this data</del></p>",
        "id": 227452267,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614095561
    },
    {
        "content": "<p>I suppose a natural next step would be to use a different tool to try to determine what the truth is</p>",
        "id": 227452349,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614095592
    },
    {
        "content": "<p>but I’m also wondering: Do I attempt to land this code at this point? The main data I want to get from it is the maxrss reading, but I am now worried that the values are too noisy to be of real use. (Update: less worried after remembered the <code>-j1</code> issue. Looking into it more…)</p>",
        "id": 227452446,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614095630
    }
]