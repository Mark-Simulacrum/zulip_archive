[
    {
        "content": "<p>I forgot to set up a casual chat channel Wednesday, so here's an early one for Thursday</p>",
        "id": 228711690,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614829624
    },
    {
        "content": "<p>FYI: I've attempted to add similar stats to <code>rusage</code> on Windows: <a href=\"https://github.com/rust-lang/rust/pull/82754\">https://github.com/rust-lang/rust/pull/82754</a></p>",
        "id": 228746970,
        "sender_full_name": "rylev",
        "timestamp": 1614853051
    },
    {
        "content": "<p>was doing the <code>mir_opt_level</code> work, <a href=\"https://github.com/rust-lang/rust/issues/82736\">#82736</a> is up and already r+</p>",
        "id": 228780365,
        "sender_full_name": "Santiago Pastorino",
        "timestamp": 1614867864
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224872\">rylev</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/sprint.20day.204.20chat/near/228746970\">said</a>:</p>\n<blockquote>\n<p>FYI: I've attempted to add similar stats to <code>rusage</code> on Windows: <a href=\"https://github.com/rust-lang/rust/pull/82754\">https://github.com/rust-lang/rust/pull/82754</a></p>\n</blockquote>\n<p>Hey @rylev, do you have any inkling as to how <em>accurate</em> the values look that you get out? Do they seem plausible?</p>",
        "id": 228780783,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614868023
    },
    {
        "content": "<p>moved the rest of the messages to <a class=\"stream-topic\" data-stream-id=\"276895\" href=\"/#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/mir_opt_level.20changes\">#t-compiler/shrinkmem-sprint &gt; mir_opt_level changes</a></p>",
        "id": 228780787,
        "sender_full_name": "Santiago Pastorino",
        "timestamp": 1614868024
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span> sorry didn't see this message. Yes they seem accurate. Linux reports roughly double the memory usage, but that could plausibly be explained by the linker invocations not being in the Windows stats</p>",
        "id": 228812401,
        "sender_full_name": "rylev",
        "timestamp": 1614878009
    },
    {
        "content": "<p>Or it could be chalked up to differences in the underlying allocators. When you say “Linux reports …”, is that from perf? or local builds? (I’m mostly curious whether part of this could be chalked up to jemalloc …)</p>",
        "id": 228817907,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614879911
    },
    {
        "content": "<p>well, glibc or musl or whatever vs. windows system allocator is likely pretty different too</p>",
        "id": 228818092,
        "sender_full_name": "simulacrum",
        "timestamp": 1614879976
    },
    {
        "content": "<p>right.</p>",
        "id": 228818156,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614880006
    },
    {
        "content": "<p>arguably it would be <em>good</em> to do all these measurements with jemalloc linked in. But wait, do we even support jemalloc on Windows anyway?</p>",
        "id": 228818238,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614880036
    },
    {
        "content": "<p>no, not really, just linux</p>",
        "id": 228818289,
        "sender_full_name": "simulacrum",
        "timestamp": 1614880054
    },
    {
        "content": "<p>(that is, I’m suggesting it would be useful as a way to eliminate one source of variation)</p>",
        "id": 228818298,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614880057
    },
    {
        "content": "<p>Linux and Mac OS X, no?</p>",
        "id": 228818313,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614880063
    },
    {
        "content": "<p>(and really probably just x86_64-unknown-linux-gnu)</p>",
        "id": 228818329,
        "sender_full_name": "simulacrum",
        "timestamp": 1614880070
    },
    {
        "content": "<p>I think macOS turned out to not actually enable it? I forget, there's a recent thread</p>",
        "id": 228818370,
        "sender_full_name": "simulacrum",
        "timestamp": 1614880084
    },
    {
        "content": "<p>Hmm I had thought the builders linked in jemalloc on Mac OS X.</p>",
        "id": 228818409,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614880087
    },
    {
        "content": "<p>Oh that’s right, that recent thread, I forgot.</p>",
        "id": 228818436,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614880094
    },
    {
        "content": "<p>they <em>try</em> for sure</p>",
        "id": 228818442,
        "sender_full_name": "simulacrum",
        "timestamp": 1614880095
    },
    {
        "content": "<p>There's a PR to actually enable jemalloc on macs (<a href=\"https://github.com/rust-lang/rust/pull/82642\">https://github.com/rust-lang/rust/pull/82642</a>)</p>",
        "id": 228818792,
        "sender_full_name": "nagisa",
        "timestamp": 1614880248
    },
    {
        "content": "<p>I made a PR which shrinks max memory usage a bit: <a href=\"https://github.com/rust-lang/rust/pull/82727\">https://github.com/rust-lang/rust/pull/82727</a> any takers?</p>",
        "id": 228821739,
        "sender_full_name": "oli",
        "timestamp": 1614881313
    },
    {
        "content": "<p>how are you telling its coming from LLVM optimizing things?</p>",
        "id": 228822818,
        "sender_full_name": "nagisa",
        "timestamp": 1614881717
    },
    {
        "content": "<p>(it could be within LLVM if you're looking at bootsrap timings, but not otherwise)</p>",
        "id": 228822889,
        "sender_full_name": "nagisa",
        "timestamp": 1614881752
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"124288\">oli</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/sprint.20day.204.20chat/near/228821739\">said</a>:</p>\n<blockquote>\n<p>I made a PR which shrinks max memory usage a bit: <a href=\"https://github.com/rust-lang/rust/pull/82727\">https://github.com/rust-lang/rust/pull/82727</a> any takers?</p>\n</blockquote>\n<p>you may want to separate out the tidy changes. At least, github \"hide whitespace changes\" is missing a lot of cases I would have expected to be treated as pure-whitespace</p>",
        "id": 228825889,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614882774
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"124288\">oli</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/sprint.20day.204.20chat/near/228821739\">said</a>:</p>\n<blockquote>\n<p>I made a PR which shrinks max memory usage a bit: <a href=\"https://github.com/rust-lang/rust/pull/82727\">https://github.com/rust-lang/rust/pull/82727</a> any takers?</p>\n</blockquote>\n<p>looks great to me</p>",
        "id": 228834506,
        "sender_full_name": "Santiago Pastorino",
        "timestamp": 1614885950
    },
    {
        "content": "<p>agreed with Felix, there's a lot of rustfmt changes that may be better on a separate commit for easier reading</p>",
        "id": 228834601,
        "sender_full_name": "Santiago Pastorino",
        "timestamp": 1614885977
    },
    {
        "content": "<p>Oh... I didn't see those... I did the cranelift thing afterwards and forgot to check the PR diff again</p>",
        "id": 228921414,
        "sender_full_name": "oli",
        "timestamp": 1614935483
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"123586\">nagisa</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/sprint.20day.204.20chat/near/228822818\">said</a>:</p>\n<blockquote>\n<p>how are you telling its coming from LLVM optimizing things?</p>\n</blockquote>\n<p>I looked at the detailed log of <code>inflate-opt full</code>: <a href=\"https://perf.rust-lang.org/detailed-query.html?commit=fe1d496e550e5902514bf91cb314f7ffa8813ec6&amp;base_commit=7f32f62aa5ceba1b795f3702e502d8473238be6b&amp;benchmark=inflate-opt&amp;run_name=full\">https://perf.rust-lang.org/detailed-query.html?commit=fe1d496e550e5902514bf91cb314f7ffa8813ec6&amp;base_commit=7f32f62aa5ceba1b795f3702e502d8473238be6b&amp;benchmark=inflate-opt&amp;run_name=full</a> and it looks like typeck got faster, but LLVM balances LTO speed against LLVM passes speed</p>",
        "id": 228924531,
        "sender_full_name": "oli",
        "timestamp": 1614936987
    }
]