[
    {
        "content": "<p>Created <a href=\"https://hackmd.io/Br1k5qy0QWuPdbMZMdyeqQ\">hackmd</a> for people to collaboratively post ideas/notes on, as discussed in <a class=\"stream-topic\" data-stream-id=\"238009\" href=\"/#narrow/stream/238009-t-compiler.2Fmeetings/topic/.5Bplanning.20meeting.5D.202021-02-12\">#t-compiler/meetings &gt; [planning meeting] 2021-02-12</a></p>",
        "id": 226156390,
        "sender_full_name": "pnkfelix",
        "timestamp": 1613145835
    },
    {
        "content": "<p>I can start by adding things from the meeting :)</p>",
        "id": 226157488,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1613146296
    },
    {
        "content": "<p>I also want to mention \"send less IR to LLVM\" should also help with memory usage, and I've had a vague idea for a while how to do it: <a href=\"https://github.com/rust-lang/rust/issues/77960\">https://github.com/rust-lang/rust/issues/77960</a></p>",
        "id": 226158641,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1613146798
    },
    {
        "content": "<p>I added a few bullet points to the HackMD.<br>\n<span class=\"user-mention\" data-user-id=\"306073\">@Tyson Nottingham</span>: do you have ideas from your investigations of the DepGraph and query system?</p>",
        "id": 226186436,
        "sender_full_name": "cjgillot",
        "timestamp": 1613159253
    },
    {
        "content": "<p>wow great start everyone!</p>",
        "id": 226189813,
        "sender_full_name": "pnkfelix",
        "timestamp": 1613160720
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"248906\">cjgillot</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/brainstorming.20hackmd/near/226186436\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"306073\">Tyson Nottingham</span>: do you have ideas from your investigations of the DepGraph and query system?</p>\n</blockquote>\n<p>Sure. I'll add some notes to the HackMD when I get a chance. I've been looking into the memory usage for a couple months, so I've got a few ideas.</p>",
        "id": 226190281,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1613160926
    },
    {
        "content": "<p>Mostly outside the DepGraph though tbh</p>",
        "id": 226190434,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1613160985
    },
    {
        "content": "<p>I'm somewhat actively working on codegen scheduling. There's one low-hanging fruit there that I'm profiling a solution for now (I'll link the PR when it's ready). But there are more gains to be had there, for sure.</p>\n<p>I was planning to take on the general scheduling issue, but perhaps someone else should pick it up if there's demand to get it done more quickly. I'm having to scale back working on rustc, as it's become hard to justify it while I'm out of work. I'll create a GH issue / write-up for improving the scheduling more generally and link it here. That should be useful either way.</p>",
        "id": 226196509,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1613164181
    },
    {
        "content": "<blockquote>\n<p>Find a way to swap in a custom allocator? (#[global_allocator] won’t work)</p>\n</blockquote>\n<p>At the risk of asking the obvious, does <code>LD_PRELOAD=/path/to/custommalloc.so</code> not work?</p>",
        "id": 226306854,
        "sender_full_name": "The 8472",
        "timestamp": 1613312897
    },
    {
        "content": "<p>Here's the PR for the low-hanging codegen scheduling memory reduction I mentioned -- <a href=\"https://github.com/rust-lang/rust/issues/82127\">#82127</a>.</p>",
        "id": 226340234,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1613357493
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330154\">The 8472</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/brainstorming.20hackmd/near/226306854\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>Find a way to swap in a custom allocator? (#[global_allocator] won’t work)</p>\n</blockquote>\n<p>At the risk of asking the obvious, does <code>LD_PRELOAD=/path/to/custommalloc.so</code> not work?</p>\n</blockquote>\n<p>Its worth investigating. (The <code>#[global_allocator]</code> wont work comment was in reference to that not intercepting memory requests from LLVM, if I recall correctly. <code>LD_PRELOAD</code> might handle that context fine; I need to look into it.)</p>",
        "id": 226399974,
        "sender_full_name": "pnkfelix",
        "timestamp": 1613404457
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"306073\">Tyson Nottingham</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/brainstorming.20hackmd/near/226340234\">said</a>:</p>\n<blockquote>\n<p>Here's the PR for the low-hanging codegen scheduling memory reduction I mentioned -- <a href=\"https://github.com/rust-lang/rust/issues/82127\">#82127</a>.</p>\n</blockquote>\n<p>Silly Question: What tools did you use to make those graphs that you posted in the PR? I would like for us all to coalesce around a standard workflow, and its possible your workflow is a good candidate.</p>",
        "id": 226404092,
        "sender_full_name": "pnkfelix",
        "timestamp": 1613405987
    },
    {
        "content": "<p>(Oh, I see you wrote \"Stats were gathered by polling system memory usage once per second via the free command on Linux. The machine was otherwise left alone during benchmarking. I'm sure there's a better way, but this did a passable job.\" I'd agree: There's probably better, but this is passable, especially since I think everyone will have <code>free</code> installed. Did you just hack together a perl script or something to turn the <code>free</code> outputs into data to feed into gnuplot?)</p>",
        "id": 226404438,
        "sender_full_name": "pnkfelix",
        "timestamp": 1613406172
    },
    {
        "content": "<p>There also is <code>src/ci/cpu-usage-over-time.py</code>, but that doesn't seem to run on PR builds</p>",
        "id": 226414879,
        "sender_full_name": "The 8472",
        "timestamp": 1613412214
    },
    {
        "content": "<p>there are also fun rust system probes like <a href=\"https://github.com/kali/readings\">https://github.com/kali/readings</a> which does its graphs using the <code>plotters</code> crate IIRC</p>",
        "id": 226419451,
        "sender_full_name": "lqd",
        "timestamp": 1613415468
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116083\">pnkfelix</span> <a href=\"#narrow/stream/276895-t-compiler.2Fshrinkmem-sprint/topic/brainstorming.20hackmd/near/226404438\">said</a>:</p>\n<blockquote>\n<p>Did you just hack together a perl script or something to turn the <code>free</code> outputs into data to feed into gnuplot?)</p>\n</blockquote>\n<p>Yeah, just used bash and imported into LibreOffice Calc.</p>\n<div class=\"codehilite\" data-code-language=\"Bash\"><pre><span></span><code><span class=\"nv\">time</span><span class=\"o\">=</span><span class=\"m\">0</span><span class=\"p\">;</span> <span class=\"k\">while</span> <span class=\"o\">[</span> -f ../rust/timer.txt <span class=\"o\">]</span><span class=\"p\">;</span> <span class=\"k\">do</span> <span class=\"nv\">mem</span><span class=\"o\">=</span><span class=\"k\">$(</span>free -m <span class=\"p\">|</span> awk <span class=\"s1\">'/Mem/ {print $3}'</span><span class=\"k\">)</span><span class=\"p\">;</span> <span class=\"nb\">echo</span> <span class=\"s2\">\"</span><span class=\"nv\">$time</span><span class=\"s2\">,</span><span class=\"nv\">$mem</span><span class=\"s2\">\"</span> &gt;&gt; memory_usage.csv<span class=\"p\">;</span> sleep <span class=\"m\">1</span><span class=\"p\">;</span> <span class=\"nv\">time</span><span class=\"o\">=</span><span class=\"k\">$((</span><span class=\"nb\">time</span> <span class=\"o\">+</span> <span class=\"m\">1</span><span class=\"k\">))</span><span class=\"p\">;</span> <span class=\"k\">done</span>\n</code></pre></div>",
        "id": 226423370,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1613418047
    },
    {
        "content": "<p>Added a bunch of ideas related to CGU stuff.</p>",
        "id": 226460873,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1613437721
    },
    {
        "content": "<blockquote>\n<p>Might not play well with rustup but should work with rustc?</p>\n</blockquote>\n<p><code>rustup</code> is a red herring, it's jemalloc that breaks</p>",
        "id": 228297266,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1614629250
    },
    {
        "content": "<p>Anyone want to review <a href=\"https://hackmd.io/Br1k5qy0QWuPdbMZMdyeqQ\">the hackmd</a> with me now and try to identify the ideas that are worthy of publicizing in a dedicated zulip topic in this stream?</p>",
        "id": 228297724,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614629420
    },
    {
        "content": "<p>Yep.</p>",
        "id": 228297903,
        "sender_full_name": "cjgillot",
        "timestamp": 1614629493
    },
    {
        "content": "<p>lets see.</p>\n<h2><a href=\"https://hackmd.io/Br1k5qy0QWuPdbMZMdyeqQ?view#Tools-for-measuring-memory-usage\">tools for measuring memory usage</a></h2>",
        "id": 228298362,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614629661
    },
    {
        "content": "<p>the section on <code>-Z time-passes</code> leads me to wonder: Is there anyway to make the output reflect the nesting of passes?</p>",
        "id": 228298500,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614629725
    },
    {
        "content": "<p>not sure. Probably not quickly</p>",
        "id": 228298542,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614629744
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"232545\">@Joshua Nelson</span> do you have a recommended strategy for getting around the <code>heaptrack</code> breakage when linking jemalloc statically? E.g., do you turn off jemalloc support in rustc for such builds?</p>",
        "id": 228298756,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614629832
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116083\">@pnkfelix</span> I've never gotten it working. I mainly profile rustdoc so it hasn't bothered me too much</p>",
        "id": 228298796,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1614629851
    },
    {
        "content": "<p>I would expect turning off jemalloc to fix it though</p>",
        "id": 228298807,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1614629858
    },
    {
        "content": "<p>I’ll admit that I’m still confused about our default status with respect to <code>jemalloc</code>. The <code>config.toml.example</code> file leads me to think that we have it off by default, in which case I would not worry about this.</p>",
        "id": 228298967,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614629923
    },
    {
        "content": "<p>/me goes to see if the jemalloc symbols are in their <code>rustc</code> binary</p>",
        "id": 228299002,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614629944
    },
    {
        "content": "<p>It's off by default for local <code>x.py</code> builds, but I'm pretty sure it's enabled for rustc binaries distributed by rustup.</p>",
        "id": 228299771,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1614630246
    },
    {
        "content": "<p>looks like it's set on Mac and Linux at least:</p>\n<div class=\"codehilite\"><pre><span></span><code>$ rg jemalloc src/ci\nsrc/ci/github-actions/ci.yml\n435:              RUST_CONFIGURE_ARGS: --host=x86_64-apple-darwin --target=x86_64-apple-darwin,aarch64-apple-ios,x86_64-apple-ios --enable-full-tools --enable-sanitizers --enable-profiler --set rust.jemalloc --set llvm.ninja=false\n446:              RUST_CONFIGURE_ARGS: --enable-extended --enable-profiler --set rust.jemalloc --set llvm.ninja=false\n456:              RUST_CONFIGURE_ARGS: --build=x86_64-apple-darwin --enable-sanitizers --enable-profiler --set rust.jemalloc --set llvm.ninja=false\n\nsrc/ci/docker/host-x86_64/dist-i686-linux/Dockerfile\n97:      --set rust.jemalloc\n\nsrc/ci/docker/host-x86_64/dist-x86_64-linux/Dockerfile\n102:      --set rust.jemalloc\n</code></pre></div>",
        "id": 228301504,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1614630915
    },
    {
        "content": "<p>Right, okay; so this is one of those instances where the CI differs from the default developer experience ...</p>",
        "id": 228301759,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614631028
    },
    {
        "content": "<p>(one of these days I'll put a note about this in the <code>config.toml.example</code>)</p>",
        "id": 228312408,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614635443
    },
    {
        "content": "<p>I braindumped a bit about codegen scheduling in <a href=\"https://github.com/rust-lang/rust/issues/82685\">#82685</a>. I've moved on to some other areas of interest, so I'm kind of throwing that over the wall. :)</p>",
        "id": 228346222,
        "sender_full_name": "Tyson Nottingham",
        "timestamp": 1614654709
    },
    {
        "content": "<p>I pinged a friend who works on scheduling for his PhD thesis, I'll let you know if he's interested :)</p>",
        "id": 228346294,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1614654743
    },
    {
        "content": "<p>Is there any reason why we shouldn't put a default (but user-overridable) upper-bound on the CGU size?</p>",
        "id": 228693889,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614817523
    },
    {
        "content": "<p>Nothing immediately comes to mind.</p>",
        "id": 228694003,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1614817569
    },
    {
        "content": "<p>I was just musing to myself that the processing of combining them unconditionally until one hits the desired number w.r.t. processor cores is <em>obviously</em> problematic for memory usage</p>",
        "id": 228694008,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614817571
    },
    {
        "content": "<p>a point that <span class=\"user-mention\" data-user-id=\"306073\">@Tyson Nottingham</span> pointed out in their write-up on <a href=\"https://github.com/rust-lang/rust/issues/82685\">#82685</a>.</p>",
        "id": 228694040,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614817586
    },
    {
        "content": "<p>but i figured a bound like I outlined should be trivial to implement, and if its large enough, it need not have noticeable impact on most crates...</p>",
        "id": 228694081,
        "sender_full_name": "pnkfelix",
        "timestamp": 1614817618
    },
    {
        "content": "<p>I was investigating the cgu merging algorithm today and after testing out a few different things, I found no difference in the biggest cgus in <code>rustc_mir</code> because the largest cgus don't appear to be the result of merging smaller ones together. They just start out <em>huge</em>.</p>",
        "id": 228694131,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1614817652
    },
    {
        "content": "<p>So breaking up large cgus before we start the merging process seems worth while to me.</p>",
        "id": 228694717,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1614817962
    },
    {
        "content": "<p>I'd be interested in some data on why they're big - are we including a bunch of generic code? Are they still large with -Zshare-generics (not sure if that precisely does what I want)?</p>\n<p>Mostly I'm thinking that if the problem is, loosely, modules that are \"too big\" that's not great, and I'd like to tackle it in the compiler rather than via education, but it feels like a very different problem to us adding a bunch of code which potentially all gets inlined by LLVM, where splitting may result in worse performance.</p>\n<p>My recollection is that our algorithm today for creating modules isn't based on the \"usage\" graph of function calls etc, but rather is module-based, and then we add a bunch atop that for the used generic code. Maybe that's wrong though?</p>",
        "id": 228696738,
        "sender_full_name": "simulacrum",
        "timestamp": 1614819235
    },
    {
        "content": "<p>I think that is generally accurate. Modules are primary driving factor behind partitioning, so the generated CGUs tend to have say all HashMaps together, all Vecs together, all Zip iterators together. The call graph is significant for inline functions.</p>",
        "id": 228737846,
        "sender_full_name": "tm",
        "timestamp": 1614848608
    }
]