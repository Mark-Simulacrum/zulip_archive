[
    {
        "content": "<p>volatile load and store are stable, but the other volatile intrinsics are not. Namely: volatile_set_memory, volatile_copy_memory, unaligned_volatile_load, unaligned_volatile_store, volatile_copy_nonoverlapping_memory, </p>\n<p>There are these slightly older issues about some of these: <a href=\"https://github.com/rust-lang/rust/issues/76892\">https://github.com/rust-lang/rust/issues/76892</a>, <a href=\"https://github.com/rust-lang/rust/issues/58041\">https://github.com/rust-lang/rust/issues/58041</a>, but neither issue seems to have had a comment from a T-libs member.</p>\n<p>What would the T-libs concerns be for having any/all of these become stable? Do we just need some stabilization PRs or do people think that we'd need some sort of bigger effort?</p>",
        "id": 232520929,
        "sender_full_name": "Lokathor",
        "timestamp": 1617152569
    },
    {
        "content": "<p>My only potential concern would be having a robust enough idea of what specifically they guarantee - Ralf may have ideas there?</p>",
        "id": 232520997,
        "sender_full_name": "Steven Fackler",
        "timestamp": 1617152641
    },
    {
        "content": "<p>For volatile load/store we can get away with \"it does what C does\". But these other volatile ops don't really have an equivalent in C. I would prefer if we went with something better defined such as <a href=\"https://reviews.llvm.org/D27133\">https://reviews.llvm.org/D27133</a> which is what you usually want in these cases.</p>",
        "id": 232563413,
        "sender_full_name": "Amanieu",
        "timestamp": 1617184249
    },
    {
        "content": "<p>Well, volatile unaligned load and volatile unaligned store are perfectly clear, i think we can agree. I don't think they're common but I do think they're necessary to have available if that's thay you've gotta do.</p>",
        "id": 232606836,
        "sender_full_name": "Lokathor",
        "timestamp": 1617202927
    },
    {
        "content": "<p>As to the other three, memory set, memory copy, and memory copy-nonoverlapping are all three obvious in what they do. They work like the non-volatile version but the compiler can't omit/add/split/merge the operations with other operations.</p>",
        "id": 232607771,
        "sender_full_name": "Lokathor",
        "timestamp": 1617203284
    },
    {
        "content": "<p>I'm not sure what atomics would have to do with it <span class=\"user-mention\" data-user-id=\"143274\">@Amanieu</span></p>",
        "id": 232608498,
        "sender_full_name": "Lokathor",
        "timestamp": 1617203544
    },
    {
        "content": "<p>Particularly: I want to use this on a device that doesn't have atomics in the first place</p>",
        "id": 232608559,
        "sender_full_name": "Lokathor",
        "timestamp": 1617203574
    },
    {
        "content": "<p>Note that we already expose <code>Atomic*::load/store</code> on devices that don't support atomics.</p>",
        "id": 232631350,
        "sender_full_name": "Amanieu",
        "timestamp": 1617211481
    },
    {
        "content": "<p>The LLVM docs on volatile memcpy explicitly say:</p>\n<blockquote>\n<p>If the isvolatile parameter is true, the llvm.memcpy call is a volatile operation. The detailed access behavior is not very cleanly specified and it is unwise to depend on it.</p>\n</blockquote>",
        "id": 232632007,
        "sender_full_name": "Amanieu",
        "timestamp": 1617211707
    },
    {
        "content": "<p>Sure, atomics are available, but they can be elided.</p>",
        "id": 232639189,
        "sender_full_name": "Lokathor",
        "timestamp": 1617214448
    },
    {
        "content": "<p>What I want to have a bulk copy that can't be elided. I also don't care about the detailed access for these bulk operations. I just need, for example, \"copy all of this 96k from ROM into VRAM as quick as you can go\"</p>",
        "id": 232639289,
        "sender_full_name": "Lokathor",
        "timestamp": 1617214485
    },
    {
        "content": "<p>And it doesn't have to be atomic at all, and it's clearly not single-instruction-sized accesses, it just needs to happen</p>",
        "id": 232639396,
        "sender_full_name": "Lokathor",
        "timestamp": 1617214517
    },
    {
        "content": "<p>If you did need detailed access (eg, \"only use u8 access for this part of memory\"), then you could write an explicit loop using the correct data type</p>",
        "id": 232639713,
        "sender_full_name": "Lokathor",
        "timestamp": 1617214639
    },
    {
        "content": "<blockquote>\n<p>What I want to have a bulk copy that can't be elided. I also don't care about the detailed access for these bulk operations. I just need, for example, \"copy all of this 96k from ROM into VRAM as quick as you can go\"</p>\n</blockquote>\n<p>But the width of individual accesses could matter for some use-cases. Must a <code>memcpy_volatile(*const [u8], *mut [u8], usize)</code> compile to a bunch of 1-byte writes or is the compiler allowed to turn this into word-sized accesses?</p>",
        "id": 232677432,
        "sender_full_name": "The 8472",
        "timestamp": 1617230862
    },
    {
        "content": "<p>That's what we were just saying. LLVM documents say:</p>\n<blockquote>\n<p>The detailed access behavior is not very cleanly specified and it is unwise to depend on it.</p>\n</blockquote>\n<p>So, it does a copy, and precisely the access pattern of that copy basically isn't specified.</p>\n<p>As I said above, if you need a precise access pattern to happen you'd have to write the loop yourself. If you don't need a precise access pattern you can just call the bulk operation.</p>",
        "id": 232690274,
        "sender_full_name": "Lokathor",
        "timestamp": 1617240048
    },
    {
        "content": "<p>But stabilizing something that's not cleanly specified seems... unwise? At least we'd need a specification that says what is guaranteed to remain when llvm cleans up their mess.</p>",
        "id": 232691369,
        "sender_full_name": "The 8472",
        "timestamp": 1617241060
    },
    {
        "content": "<p>The point is that you deliberately <em>don't</em> want to specify the details. You would use the intrinsic when you <em>want</em> a bulk operation to simply happen without worrying about the details, and let LLVM do the best memcopy it can manage on the device.</p>",
        "id": 232691916,
        "sender_full_name": "Lokathor",
        "timestamp": 1617241595
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224471\">@Lokathor</span> What exactly is your use case for a volatile memcpy?</p>",
        "id": 232693420,
        "sender_full_name": "Amanieu",
        "timestamp": 1617242820
    },
    {
        "content": "<p>I already said: bulk copying ROM into VRAM</p>",
        "id": 232695755,
        "sender_full_name": "Lokathor",
        "timestamp": 1617245013
    },
    {
        "content": "<p>I would have expected a normal <code>memcpy</code> to be sufficient for this.</p>",
        "id": 232698794,
        "sender_full_name": "Amanieu",
        "timestamp": 1617248027
    },
    {
        "content": "<p>The VRAM that you are copying to is \"externally visible\" from the point of view of the compiler: since you conjured a pointer out of thin air it has to assume that some other code (e.g. the GPU) also has access to this memory so it cannot elide the <code>memcpy</code>.</p>",
        "id": 232698917,
        "sender_full_name": "Amanieu",
        "timestamp": 1617248110
    },
    {
        "content": "<p>ROM and VRAM both behave like normal memory. Volatile mainly useful for things that <em>don't</em> act like memory. For example a hardware register that must be accessed with 32-bit loads/stores: you don't want the compiler to combine 2 operations into a 64-bit load/store or to split the operation into individual bytes.</p>",
        "id": 232699073,
        "sender_full_name": "Amanieu",
        "timestamp": 1617248279
    },
    {
        "content": "<p>Yes I'm aware of the MMIO usage of volatile to control a device.</p>",
        "id": 232701524,
        "sender_full_name": "Lokathor",
        "timestamp": 1617250535
    },
    {
        "content": "<p>However, I'm also aware of access elision, which is what I don't want to ever have happen.</p>",
        "id": 232701594,
        "sender_full_name": "Lokathor",
        "timestamp": 1617250583
    },
    {
        "content": "<p>Now because this is an intrinsic I am literally unable to just write this myself, or I would do that and not ask the standard library to do it for me.</p>",
        "id": 232701662,
        "sender_full_name": "Lokathor",
        "timestamp": 1617250677
    },
    {
        "content": "<p>You can just use <code>copy_nonoverlapping</code> for this: the compiler can't elide the copy because the destination is external to Rust.</p>",
        "id": 232701846,
        "sender_full_name": "Amanieu",
        "timestamp": 1617250839
    },
    {
        "content": "<p>Could you say more about this \"eternally visible\" thing? Because I'm unfamiliar with that.</p>",
        "id": 232701850,
        "sender_full_name": "Lokathor",
        "timestamp": 1617250841
    },
    {
        "content": "<p><a href=\"https://github.com/rust-lang/unsafe-code-guidelines/issues/215\">https://github.com/rust-lang/unsafe-code-guidelines/issues/215</a></p>",
        "id": 232701975,
        "sender_full_name": "Amanieu",
        "timestamp": 1617250932
    },
    {
        "content": "<p>particularly, <em>all</em> MMIO locations are externally visible memory, it would seem, so <em>most</em> MMIO can just use non-volatile access, by that logic (if you're just setting a video mode for example).</p>",
        "id": 232701977,
        "sender_full_name": "Lokathor",
        "timestamp": 1617250934
    },
    {
        "content": "<p>Sure, for MMIO the only part of volatile semantics that you actually need is the guarantee that the access is atomic and not merged/split.</p>",
        "id": 232702027,
        "sender_full_name": "Amanieu",
        "timestamp": 1617251015
    },
    {
        "content": "<p>What I mean by externally visible is that in the abstract machine the GPU itself acts as a separate thread of execution that reads/writes memory. So the compiler cannot elide the memcpy because the destination is then read by another \"thread\".</p>",
        "id": 232702114,
        "sender_full_name": "Amanieu",
        "timestamp": 1617251083
    },
    {
        "content": "<p>how does the compiler know that it cannot elide that any more or less than it might think it can elide <code>(0x0400_0000 as *mut u16).write(1234)</code></p>",
        "id": 232702159,
        "sender_full_name": "Lokathor",
        "timestamp": 1617251143
    },
    {
        "content": "<p>particularly, if there are repeated memcopy operations to the same region of memory, can we say <em>for sure</em> that the compiler won't collapse those down into just the final memcopy?</p>",
        "id": 232702297,
        "sender_full_name": "Lokathor",
        "timestamp": 1617251235
    },
    {
        "content": "<p>Side note: for much mmio even the merge-split thing isn't requried</p>",
        "id": 232702324,
        "sender_full_name": "Lokathor",
        "timestamp": 1617251278
    },
    {
        "content": "<p>The compiler is only allowed to elide when it <em>knows</em> that the memory is private. This can be because it is a local variable or because the visibility rules prevent external code from accessing it (think <code>static</code> in C). If the compiler cannot determine this, it <em>must</em> conservatively assume that the memory may be accessed externally.</p>",
        "id": 232702428,
        "sender_full_name": "Amanieu",
        "timestamp": 1617251374
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/219381-t-libs/topic/Stabilizing.20the.20other.20volatile.20ops.3F/near/232702297\">said</a>:</p>\n<blockquote>\n<p>particularly, if there are repeated memcopy operations to the same region of memory, can we say <em>for sure</em> that the compiler won't collapse those down into just the final memcopy?</p>\n</blockquote>\n<p>Use a fence. This is basically shared memory concurrency where you treat the GPU as a separate thread. You may need to use hardware-specific fences instead of the standard ones in <code>core::sync::atomic</code>, but the same basic principle applies.</p>",
        "id": 232702508,
        "sender_full_name": "Amanieu",
        "timestamp": 1617251433
    },
    {
        "content": "<p>does a standard <code>compier_fence</code> suffice?</p>",
        "id": 232703167,
        "sender_full_name": "Lokathor",
        "timestamp": 1617252059
    },
    {
        "content": "<p>That's sufficient for the compiler not to elide it. But you generally also need a hardware fence too. Consider a hypothetical case where the CPU has a massive store buffer: a sufficiently smart CPU could elide earlier stores that are overwritten by later stores, which means the GPU only sees the final data, not any intermediate stores.</p>",
        "id": 232705550,
        "sender_full_name": "Amanieu",
        "timestamp": 1617254117
    },
    {
        "content": "<p>Luckily I'm using a CPU designed in 1994 that has no such nonsense.</p>",
        "id": 232705710,
        "sender_full_name": "Lokathor",
        "timestamp": 1617254282
    },
    {
        "content": "<p>As a general rule you need a fence that synchronizes through all layers between you and the target hardware. ARM has an operand to the DMB/DSB instructions which specifies the domain that it applies to: non-shareable, inner-shareable, outer-shareable, system.</p>",
        "id": 232705800,
        "sender_full_name": "Amanieu",
        "timestamp": 1617254351
    },
    {
        "content": "<p>I was just going to suggest to use assembly if there are special instructions to perform uncached writes to device memory, but I guess that doesn't apply there</p>",
        "id": 232705805,
        "sender_full_name": "The 8472",
        "timestamp": 1617254364
    },
    {
        "content": "<p>I'm unfamiliar with DMB and DSB. I take it they were added after ARMv4T?</p>",
        "id": 232705898,
        "sender_full_name": "Lokathor",
        "timestamp": 1617254428
    },
    {
        "content": "<p>Before ARMv7 DMB &amp; DSB are implemented as instruction on CP15. On ARMv7 they became dedicated instructions.</p>",
        "id": 232706051,
        "sender_full_name": "Amanieu",
        "timestamp": 1617254569
    },
    {
        "content": "<p>Actually I just looked it up and it seems that DMB/DSB were introduced in ARMv6.</p>",
        "id": 232706338,
        "sender_full_name": "Amanieu",
        "timestamp": 1617254912
    },
    {
        "content": "<p>So in your case you only need a compiler fence for ARMv4.</p>",
        "id": 232706350,
        "sender_full_name": "Amanieu",
        "timestamp": 1617254927
    }
]