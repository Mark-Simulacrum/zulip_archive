[
    {
        "content": "<p>Coming from <a href=\"https://github.com/rust-lang/rust/issues/86269\">#86269</a>, to discuss the signature for <code>lerp</code>. I'll summarize what's been said in the issue so far shortly.</p>",
        "id": 244050240,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624770430
    },
    {
        "content": "<p>Summary as I see it so far</p>\n<p><a href=\"https://github.com/rust-lang/rust/issues/86269#issuecomment-864347515\">https://github.com/rust-lang/rust/issues/86269#issuecomment-864347515</a>, data collection by <span class=\"user-mention\" data-user-id=\"132829\">@Christopher Durham</span> </p>\n<p><code>nalgebra</code>, <code>euclid</code>, <code>glam</code>, <code>cgmath</code>, <code>kurbo</code>, and <code>ultraviolet</code> all provide <code>v0.lerp(v1, t)</code>. <code>emath</code> provides <code>lerp(v0..=v1, t)</code>, and <code>vek</code> provides <code>lerp(v0, v1, t)</code>.</p>\n<p><a href=\"https://github.com/rust-lang/rust/pull/86462#issuecomment-865391638\">https://github.com/rust-lang/rust/pull/86462#issuecomment-865391638</a>, data collection by <span class=\"user-mention\" data-user-id=\"132829\">@Christopher Durham</span> </p>\n<p>HLSL, GLSL, C++20, Unity, Unreal, Godot, GameMaker, and p5.js provide <code>lerp(v0, v1, t)</code>.  Godot, Blender, and pygame provide <code>v0.lerp(v1, t)</code>. numpy provides <code>lerp(t, v0, v1)</code>.</p>\n<p><a href=\"https://github.com/rust-lang/rust/pull/86462#issuecomment-867162705\">https://github.com/rust-lang/rust/pull/86462#issuecomment-867162705</a> notes that vectorized <code>lerp</code> (e.g. <code>lerp(f32x4, f32x4, f32x4)</code>) will prefer to _not_ use <code>RangeInclusive</code>.</p>\n<p><a href=\"https://github.com/rust-lang/rust/pull/86462#issuecomment-867200253\">https://github.com/rust-lang/rust/pull/86462#issuecomment-867200253</a> concurs that the use of <code>RangeInclusive</code> implies that only an increasing range would be allowed, but <code>lerp</code> wants to support lerping in either direction.</p>\n<p><a href=\"https://github.com/rust-lang/rust/pull/86462#issuecomment-867170825\">https://github.com/rust-lang/rust/pull/86462#issuecomment-867170825</a> notes that <code>t.lerp(v0, v1)</code> extends nicely to <code>t.qarp(v0, v1, v2)</code> and <code>t.curp(v0, v1, v2, v3)</code>.</p>\n<p><a href=\"https://github.com/rust-lang/rust/issues/86269#issuecomment-869098042\">https://github.com/rust-lang/rust/issues/86269#issuecomment-869098042</a> notes that (without std traits) 3rd party libraries would not be able to provide <code>t.lerp(v0, v1)</code> for their own types, a problem which does not apply to <code>v0.lerp(v1, t)</code>, due to how method lookup and overloading works.</p>\n<p><a href=\"https://github.com/rust-lang/rust/issues/86269#issuecomment-869098630\">https://github.com/rust-lang/rust/issues/86269#issuecomment-869098630</a> calls more attention to the scope of change required for the ecosystem to migrate from <code>v0.lerp(v1, t)</code> to <code>t.lerp(v0, v1)</code>, if std goes with that order and allows 3rd party crates to hook into it.</p>\n<p><a href=\"https://github.com/rust-lang/rust/issues/86269#issuecomment-869099716\">https://github.com/rust-lang/rust/issues/86269#issuecomment-869099716</a> notes that this is effectively a double-dispatch problem, with a primary dispatch of the interpolated type, and a secondary dispatch on the bitwidth of <code>t</code> (don't forget this should work for both <code>f32</code> and <code>f64</code>, if not even also other types able to express values in <code>0.0..=1.0</code>).</p>",
        "id": 244052210,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624774830
    },
    {
        "content": "<blockquote>\n<p>vectorized lerp (e.g. lerp(f32x4, f32x4, f32x4)) will prefer to _not_ use RangeInclusive.</p>\n</blockquote>\n<p>I'm very convinced by this statement. Particularly with MS moving to windows 11, which basically requires CPUs that will have avx2 as a minimum cpu feature set, it will be an even bigger performance gap to not be using simd when possible.</p>",
        "id": 244054691,
        "sender_full_name": "Lokathor",
        "timestamp": 1624779352
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244054691\">said</a>:</p>\n<blockquote>\n<blockquote>\n<p>vectorized lerp (e.g. lerp(f32x4, f32x4, f32x4)) will prefer to _not_ use RangeInclusive.</p>\n</blockquote>\n<p>I'm very convinced by this statement. Particularly with MS moving to windows 11, which basically requires CPUs that will have avx2 as a minimum cpu feature set, it will be an even bigger performance gap to not be using simd when possible.</p>\n</blockquote>\n<p>I see no reason to think that vectorized <code>lerp</code>with or without using <code>RangeInclusive</code> will have any performance differences... these should produce identical assembly assuming <code>lerp</code> is inlined:<br>\n<span class=\"user-mention\" data-user-id=\"281757\">@Jubilee</span> note that  it's a range where the endpoints are vectors, <em>not</em> a vector of ranges.</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">fn</span> <span class=\"nf\">f</span><span class=\"p\">(</span><span class=\"n\">a</span>: <span class=\"nc\">f32x4</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">b</span>: <span class=\"nc\">f32x4</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">t</span>: <span class=\"nc\">f32x4</span><span class=\"p\">)</span><span class=\"w\"> </span>-&gt; <span class=\"nc\">f32x4</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">t</span><span class=\"p\">.</span><span class=\"n\">lerp</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"o\">..=</span><span class=\"n\">b</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">fn</span> <span class=\"nf\">f</span><span class=\"p\">(</span><span class=\"n\">a</span>: <span class=\"nc\">f32x4</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">b</span>: <span class=\"nc\">f32x4</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">t</span>: <span class=\"nc\">f32x4</span><span class=\"p\">)</span><span class=\"w\"> </span>-&gt; <span class=\"nc\">f32x4</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">t</span><span class=\"p\">.</span><span class=\"n\">lerp</span><span class=\"p\">(</span><span class=\"n\">a</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">b</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 244058045,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624785339
    },
    {
        "content": "<p>...hm.</p>",
        "id": 244058105,
        "sender_full_name": "Jubilee",
        "timestamp": 1624785448
    },
    {
        "content": "<p>I think that goes bad places in practice considering RangeInclusive's invariants but I could see it as an alternative, I suppose.</p>",
        "id": 244058149,
        "sender_full_name": "Jubilee",
        "timestamp": 1624785510
    },
    {
        "content": "<p>yup, I'm not saying that RangeInclusive is better or worse, I'm just saying vector performance should not be a factor.</p>",
        "id": 244058302,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624785828
    },
    {
        "content": "<p>Why not change the name to make it clear? <code>val.interpolate_between(start: f32, end: f32)</code>? You still could put doc alias to lerp on it. Although there's some debate around the correct use of doc aliases...</p>",
        "id": 244060773,
        "sender_full_name": "The 8472",
        "timestamp": 1624790188
    },
    {
        "content": "<p>The parameter names already are start and end and those generally show up in IDE context assists, that already might be good enough.</p>",
        "id": 244060782,
        "sender_full_name": "The 8472",
        "timestamp": 1624790223
    },
    {
        "content": "<p>another option for naming: <code>lerp</code> is a linear Bézier curve, if we might add quadratic and cubic Bézier curves later then we could name the linear Bézier curve <code>t.bezier([start, end])</code>, the quadratic Bézier curve <code>t.bezier([start, c, end])</code>, and the cubic Bézier curve <code>t.bezier([start, c1, c2, end])</code></p>",
        "id": 244061183,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624790970
    },
    {
        "content": "<p>I guess that's the other side of this question -- do we want things like Bezier in core?  If not, do we even want lerp?  It doesn't need an intrinsic or anything to implement it, right?</p>",
        "id": 244072927,
        "sender_full_name": "scottmcm",
        "timestamp": 1624809675
    },
    {
        "content": "<p>yeah anyone can just make their own lerp function</p>",
        "id": 244076713,
        "sender_full_name": "Lokathor",
        "timestamp": 1624815368
    },
    {
        "content": "<p>looks like it's pretty tricky to get a correct one. see all the edge cases handled in that PR that added it</p>",
        "id": 244076935,
        "sender_full_name": "Mara",
        "timestamp": 1624815727
    },
    {
        "content": "<p>well part of the \"lerp controversy\" is that people sometimes legitimately want different formulas because they care about different things. Which isn't to say that we can't provide a \"sane default\".</p>",
        "id": 244077076,
        "sender_full_name": "Lokathor",
        "timestamp": 1624815964
    },
    {
        "content": "<p>the PR that added it doesn't seem to be handling any edge cases. Also, this tends to be very performance sensitive, so a version like e.g. C++'s (which tries to handle a billion edge cases) is unlikely to ever get used.</p>\n<p>i'd actually guess that the version that landed is the same way, since AFIACT it uses the fma call that (unless you compile with a recent <code>-Ctarget-cpu</code> or <code>-Ctarget-feature</code> on a arch that has fused-multiply-accumulate instructions) will compile to a libc invocation.</p>",
        "id": 244077095,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624815985
    },
    {
        "content": "<p>I also tend to agree with lokathor, I don't know that this is a good thing to provide, since there are a lot of different choices you can make here.</p>\n<p>EDIT: (actually, rereading, I misread lokathor's comment... well, nevertheless...)</p>",
        "id": 244077104,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624816010
    },
    {
        "content": "<p>I'd <em>also</em> be fine if the whole function went away and there was just no standard library lerp. Enough people seem to want it though.</p>",
        "id": 244077175,
        "sender_full_name": "Lokathor",
        "timestamp": 1624816114
    },
    {
        "content": "<p>it would be nice to get feedback from prospective users (game developers?) as to what implementation they're currently using and whether this interface/implementation is sufficient</p>",
        "id": 244077753,
        "sender_full_name": "bstrie",
        "timestamp": 1624816936
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"209168\">Thom Chiovoloni</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244077095\">said</a>:</p>\n<blockquote>\n<p>the PR that added it doesn't seem to be handling any edge cases.</p>\n</blockquote>\n<p>are we talking about thes same PR? <a href=\"https://github.com/rust-lang/rust/pull/85925/files\">#85925</a> specifically handles exactness, monoticity and consistency</p>",
        "id": 244077961,
        "sender_full_name": "Mara",
        "timestamp": 1624817239
    },
    {
        "content": "<p>those are very easy to get wrong or implement in a non-performant way</p>",
        "id": 244077967,
        "sender_full_name": "Mara",
        "timestamp": 1624817255
    },
    {
        "content": "<p>Unfortunately, the implementation actually currently isn't monotonic</p>",
        "id": 244078024,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624817298
    },
    {
        "content": "<p>we weren't talking about the same PR</p>",
        "id": 244078025,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624817301
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>Not monotonic: lerp(0.24997729, 0.27129978, 0.9048672) = 0.42967725\n             &gt; lerp(0.2499773 , 0.27129978, 0.9048672) = 0.42967722\n</code></pre></div>",
        "id": 244078056,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624817394
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"256342\">bstrie</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244077753\">said</a>:</p>\n<blockquote>\n<p>it would be nice to get feedback from prospective users (game developers?) as to what implementation they're currently using and whether this interface/implementation is sufficient</p>\n</blockquote>\n<p>i'm a game developer (currently independent, although i've worked at studios in the past and have games on steam and the like).</p>\n<p>i joked last night with another friend of mine (who is also a game developer) that there's almost no way that this ends up with something usable, which is i guess to be expected (it would be the track record for c++'s efforts here too). i think this kind of thing is probably better left to math libs, who can evaluate the tradeoffs here better.</p>\n<p>in my code i don't bother with the f64 version, and have both done lerp as a trait (which I don't do anymore), and as inherent <code>pub fn lerp(self, b: Self, t: f32) -&gt; Self</code> on relevant types. I just do it as <code>a * (1.0 - t) + b * t</code>, and the lack of monotonicity or exactness for <code>a == b</code> has never caused bugs for me (in comparison: poor performance in this sort of code <em>has</em>, so...)</p>",
        "id": 244078121,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624817477
    },
    {
        "content": "<p>also again, an implementation that calls to libm::fmaf twice unless you pass special compiler flags is... imo borderline unacceptable</p>",
        "id": 244078178,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624817547
    },
    {
        "content": "<p>I definitely agree that we'd want to use loose math that can optimize to FMA rather than requiring FMA</p>",
        "id": 244078195,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624817598
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"132829\">Christopher Durham</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244078056\">said</a>:</p>\n<blockquote>\n<p><div class=\"codehilite\"><pre><span></span><code>Not monotonic: lerp(0.24997729, 0.27129978, 0.9048672) = 0.42967725\n             &gt; lerp(0.2499773 , 0.27129978, 0.9048672) = 0.42967722\n</code></pre></div><br>\n</p>\n</blockquote>\n<p>i get the opposite results:</p>\n<div class=\"codehilite\"><pre><span></span><code>[src/main.rs:11] f32::lerp(0.24997729, 0.27129978, 0.9048672) = 0.42967722\n[src/main.rs:12] f32::lerp(0.2499773 , 0.27129978, 0.9048672) = 0.42967725\n</code></pre></div>",
        "id": 244078273,
        "sender_full_name": "Mara",
        "timestamp": 1624817668
    },
    {
        "content": "<p>I'll test again, maybe I messed something up</p>",
        "id": 244078282,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624817688
    },
    {
        "content": "<p>does this call for a whole family of lerp functions that each provide different guarantees?</p>",
        "id": 244078356,
        "sender_full_name": "bstrie",
        "timestamp": 1624817772
    },
    {
        "content": "<p>Also gamedev (grad student); I've put a lot of time into documenting existing practice in the tracking issue. As far as API, I don't have any preference beyond making sure that the same API works for vector types</p>",
        "id": 244078363,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624817790
    },
    {
        "content": "<p>As far as implementation: all of the guarantees aren't all that important if you can bound them to e.g. ±2 ULP, because such drift is negligible in gamedev/graphics</p>",
        "id": 244078442,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624817899
    },
    {
        "content": "<p>WRT \"aren't that important\", are they so unimportant that std could get away with adding or removing any of those guarantees in any arbitrary release? in other words, would these guarantees (or the lack thereof) be part of the stable API?</p>",
        "id": 244078831,
        "sender_full_name": "bstrie",
        "timestamp": 1624818390
    },
    {
        "content": "<p>With something like <code>lerp</code>, the exact behavior quickly becomes relied upon, even if not explicitly stable.<br>\nAlso, the performance characteristics are implicitly part of the guarantees, and very important for such a building block.</p>",
        "id": 244078896,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624818515
    },
    {
        "content": "<p>I find it hard to think of an \"open to change\" specification+implementation that would both be open to improvement in the future plus be usable by gamedevs who want <code>lerp</code> to be <em>free</em>.</p>",
        "id": 244078911,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624818564
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310399\">Mara</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244078273\">said</a>:</p>\n<blockquote>\n<p>i get the opposite results:</p>\n<p><div class=\"codehilite\"><pre><span></span><code>[src/main.rs:11] f32::lerp(0.24997729, 0.27129978, 0.9048672) = 0.42967722\n[src/main.rs:12] f32::lerp(0.2499773 , 0.27129978, 0.9048672) = 0.42967725\n</code></pre></div><br>\n</p>\n</blockquote>\n<p>I'm still getting <a href=\"https://play.rust-lang.org/?version=nightly&amp;mode=release&amp;edition=2018&amp;gist=235d933360a1af9d658ac1bc59a1e432\">plenty of montonicity violations</a>:</p>\n<div class=\"codehilite\"><pre><span></span><code>Not monotonic:\n  lerp(0.000015328364, 0.10231668, 0.85570544) = 0.102328226\n  lerp(0.000015328365, 0.10231668, 0.85570544) = 0.10232822\nNot monotonic:\n  lerp(0.000015401183, 0.10231668, 0.85570544) = 0.102328286\n  lerp(0.000015401185, 0.10231668, 0.85570544) = 0.10232828\nNot monotonic:\n  lerp(0.000015474003, 0.10231668, 0.85570544) = 0.10232834\n  lerp(0.000015474005, 0.10231668, 0.85570544) = 0.10232833\nNot monotonic:\n  lerp(0.00001554682, 0.10231668, 0.85570544) = 0.1023284\n  lerp(0.000015546822, 0.10231668, 0.85570544) = 0.10232839\nNot monotonic:\n  lerp(0.00001561964, 0.10231668, 0.85570544) = 0.10232845\n  lerp(0.000015619642, 0.10231668, 0.85570544) = 0.10232844\nNot monotonic:\n  lerp(0.000015692458, 0.10231668, 0.85570544) = 0.1023285\n  lerp(0.00001569246, 0.10231668, 0.85570544) = 0.102328494\nNot monotonic:\n  lerp(0.000015765278, 0.10231668, 0.85570544) = 0.10232856\n  lerp(0.00001576528, 0.10231668, 0.85570544) = 0.102328554\n</code></pre></div>",
        "id": 244079032,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624818727
    },
    {
        "content": "<p>IMO it seems like the tradeoffs are a bit too subtle to add this to std. If \"correct\" implementations are slow, and slow implementations are useless, and assuming that std only wants to contain useful things, then the question is whether std wants to deliberately contain an \"incorrect\" thing. I have to ask, who proposed this for C++, and were they happy with a \"useless\" implementation being the result? Was their use case different?</p>",
        "id": 244079077,
        "sender_full_name": "bstrie",
        "timestamp": 1624818843
    },
    {
        "content": "<p>c++ is notorious for doing this, honestly. there's lots of useless stuff in the stdlib std::complex and std::valarray are the same way, and that's just considering numerically-relevant stuff</p>",
        "id": 244079174,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624818998
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"132829\">@Christopher Durham</span> you have a <code>t</code> where you need a <code>nextt</code>. but yeah, still many not-monotonic results.</p>",
        "id": 244079205,
        "sender_full_name": "Mara",
        "timestamp": 1624819076
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310399\">Mara</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244079205\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"132829\">Christopher Durham</span> you have a <code>t</code> where you need a <code>nextt</code>. but yeah, still many not-monotonic results.</p>\n</blockquote>\n<p>whoops <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>",
        "id": 244079249,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624819093
    },
    {
        "content": "<p>Right, I understand C++ is famous for overspecifying, but in the pursuit of being charitable it would be useful to know who specifically proposed this, whether they had a personal stake in the outcome, and what their use case was.</p>",
        "id": 244079260,
        "sender_full_name": "bstrie",
        "timestamp": 1624819134
    },
    {
        "content": "<p>I continue to wish that C++ papers included any of the motivation, but here's the paper that added <code>std::midpoint</code> and <code>std::lerp</code>: <a href=\"https://wg21.link/p0811\">https://wg21.link/p0811</a></p>",
        "id": 244079262,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624819138
    },
    {
        "content": "<p>it's also worth noting that c++ has a notorious problem where game developers aren't part of the standards committees, and instead just complain that the stdlib is unusable for gamedev</p>",
        "id": 244079455,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624819503
    },
    {
        "content": "<p>i must admit i'm guilty of doing that when I used c++ and not rust (not that i'd have been qualified to participate in a meaningful way, probably). rust doesn't have that problem, since more of the discussion is in the open</p>",
        "id": 244079527,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624819578
    },
    {
        "content": "<p>also it's a lot harder to avoid using the stdlib in rust</p>",
        "id": 244079532,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624819589
    },
    {
        "content": "<p>are there consumers of this aside from gamedevs?</p>",
        "id": 244079618,
        "sender_full_name": "Jubilee",
        "timestamp": 1624819745
    },
    {
        "content": "<p>(although in this case it would be very easy to avoid using the stdlib, of course, so i have no <em>real</em> opposition to this function, although it will be annoying to change my old code that uses a trait for this if it's named <code>lerp</code>, since the inherent impl will override the trait-based implementation...)</p>",
        "id": 244079694,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624819838
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"132829\">Christopher Durham</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244078195\">said</a>:</p>\n<blockquote>\n<p>I definitely agree that we'd want to use loose math that can optimize to FMA rather than requiring FMA</p>\n</blockquote>\n<p>By \"loose math\" do you mean something like GCC's -ffast-math? That's a bit of a can of worms, but in the past people have resisted the idea of adding such a flag to Rust and instead favored having different functions entirely for inexact math. For example, I could imagine a <code>lerp</code> function with all the correctness guarantees, and a <code>lerp_inexact</code> function for the screaming fast version.</p>",
        "id": 244079711,
        "sender_full_name": "bstrie",
        "timestamp": 1624819868
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"281757\">Jubilee</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244079618\">said</a>:</p>\n<blockquote>\n<p>are there consumers of this aside from gamedevs?</p>\n</blockquote>\n<p>i'd use it in control engineering. sensor fusion. flight controllers.</p>",
        "id": 244079717,
        "sender_full_name": "Mara",
        "timestamp": 1624819885
    },
    {
        "content": "<blockquote>\n<p>By \"loose math\" do you mean something like GCC's -ffast-math? That's a bit of a can of worms</p>\n</blockquote>\n<p>i have a WIP RFC for fast math (rather, more principled float model support), but i need to get back to it. it's certainly nontrivial</p>",
        "id": 244079782,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624819957
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"256342\">bstrie</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244079711\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"132829\">Christopher Durham</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244078195\">said</a>:</p>\n<blockquote>\n<p>I definitely agree that we'd want to use loose math that can optimize to FMA rather than requiring FMA</p>\n</blockquote>\n<p>By \"loose math\" do you mean something like GCC's -ffast-math? That's a bit of a can of worms, but in the past people have resisted the idea of adding such a flag to Rust and instead favored having different functions entirely for inexact math. For example, I could imagine a <code>lerp</code> function with all the correctness guarantees, and a <code>lerp_inexact</code> function for the screaming fast version.</p>\n</blockquote>\n<p>There's some discussion elsewhere on <em>targetted</em> use of inexact math, but a global <code>-ffast-math</code> isn't what I'm talking about. I'm just suggesting that <code>lerp</code> could be implemented with the float operations tagged with <code>contract</code> (or whatever the flag is) to <em>only</em> allow the increased-precision optimizations (i.e. FMA).</p>",
        "id": 244079799,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624819976
    },
    {
        "content": "<p>i think llvm already has an intrinsic for \"fma if hardware supported, separate mul+add otherwise\"</p>",
        "id": 244079823,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624820023
    },
    {
        "content": "<p>yeah, we'd just want to use <a href=\"https://llvm.org/docs/LangRef.html#llvm-fmuladd-intrinsic\">https://llvm.org/docs/LangRef.html#llvm-fmuladd-intrinsic</a>, no need to worry about the contract optimization</p>",
        "id": 244079878,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624820065
    },
    {
        "content": "<p>it would have to be implemented for cranelift/gcc, but ofc its fine to implement that as unfused</p>",
        "id": 244079891,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624820083
    },
    {
        "content": "<p>But then again... gamedev is a field that does want to be able to get float determinism (for e.g. networking and replays), so perhaps baking in nondeterminism into a core primitive is just another way to make it not get used (in such use cases)...</p>",
        "id": 244079915,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624820130
    },
    {
        "content": "<p>yeah, i think it would be fine to never fuse these operations, and then if we do get the ability to enable non-conforming float opttimizations, enabling contraction would improve the performance there</p>",
        "id": 244079966,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624820187
    },
    {
        "content": "<p>The sad(ish) thing is that more precise FMA makes guaranteeing properties about <code>lerp</code> easier, so not using it means either less guarantees or more code</p>",
        "id": 244079996,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624820279
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310399\">Mara</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244079717\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"281757\">Jubilee</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244079618\">said</a>:</p>\n<blockquote>\n<p>are there consumers of this aside from gamedevs?</p>\n</blockquote>\n<p>i'd use it in control engineering. sensor fusion. flight controllers.</p>\n</blockquote>\n<p>alright, it sounds like performance would still be a concern but correctness would tend to rate higher.</p>",
        "id": 244080044,
        "sender_full_name": "Jubilee",
        "timestamp": 1624820314
    },
    {
        "content": "<p>All implementations seem to struggle most when numbers are (close to) denormal</p>",
        "id": 244080272,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624820691
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"281757\">Jubilee</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244080044\">said</a>:</p>\n<blockquote>\n<p>alright, it sounds like performance would still be a concern but correctness would tend to rate higher.</p>\n</blockquote>\n<p>it'd probably be fine if things like this aren't perfect and a lsb or two off. but i rather pay a few extra clockcycles than potentially having to debug some issue with it. especially because instead of resulting in a flickering pixel, it might cause a heavy drone to fall out of the sky ^^</p>",
        "id": 244080277,
        "sender_full_name": "Mara",
        "timestamp": 1624820706
    },
    {
        "content": "<p>Doing tests, <code>lerp(t, 0.06256735, 0.3860399)</code> gave me several steps of 2 ULP with <code>((1.0 - t) * v0) + (t * v1)</code></p>",
        "id": 244080283,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624820731
    },
    {
        "content": "<p>I'm not qualified to do an analysis on the maximum ULP deviation from the perfect result though</p>",
        "id": 244080290,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624820753
    },
    {
        "content": "<p>right, I think we can compromise on correctness here with a Good Enough at some point.</p>",
        "id": 244080295,
        "sender_full_name": "Jubilee",
        "timestamp": 1624820761
    },
    {
        "content": "<p>I've not seen anything in my test range (of only doing numbers 0-1) that ever steps more than 2 ULP for a 1 ULP movement in t, though</p>",
        "id": 244080343,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624820789
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"132829\">Christopher Durham</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244079262\">said</a>:</p>\n<blockquote>\n<p>I continue to wish that C++ papers included any of the motivation, but here's the paper that added <code>std::midpoint</code> and <code>std::lerp</code>: <a href=\"https://wg21.link/p0811\">https://wg21.link/p0811</a></p>\n</blockquote>\n<p>i don't see any discussion about motivation or performance in the meeting notes either. :(</p>",
        "id": 244080438,
        "sender_full_name": "Mara",
        "timestamp": 1624820972
    },
    {
        "content": "<p>feels like a bit of a \"because it's there\" at this point yeah.</p>",
        "id": 244080485,
        "sender_full_name": "Jubilee",
        "timestamp": 1624821015
    },
    {
        "content": "<p>I made a math.SE question about showing a bound on the non-monoticity of <code>((1.0 - t) * v0) + (t * v1)</code>, but I don't really expect it to get any attention.<br>\n<a href=\"https://math.stackexchange.com/q/4184626/573727\">https://math.stackexchange.com/q/4184626/573727</a></p>",
        "id": 244081222,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624822280
    },
    {
        "content": "<p>A previous math.SE, cited by P0811, which discusses providing guarantees as well: <a href=\"https://math.stackexchange.com/q/907327/573727\">https://math.stackexchange.com/q/907327/573727</a></p>",
        "id": 244081275,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624822336
    },
    {
        "content": "<p>wait, does <code>mul_add</code> in LLVM genuinely not just emit fma instructions on x86 and ARM? that was part of the main reason why I chose that implementation -- it's only two float instructions but gives you all the extra nice stuff for free</p>",
        "id": 244082968,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624825145
    },
    {
        "content": "<p>I'd argue that <code>lerp</code> should be implemented as exactly <code>a * (1.0 - t) + b * t</code> since that version gives the endpoints for <code>t == 0.0 || t == 1.0</code>, it is 100% reproducible across all IEEE 754 compliant archs, I've also done some game-dev and am currently working on project-portable-simd as well as writing a Vulkan driver (Kazan) for Libre-SOC's CPU/GPU-hybrid that I'm also working on -- that formula avoids the biggest pitfall (not returning endpoints for <code>t == 1.0</code>) and is fast enough, it's also the same way linear bezier curves are implemented (we can argue about whether to spell <code>lerp</code> as <code>t.bezier([a, b])</code> and have <code>fn bezier&lt;const N: usize&gt;(self, control_points: [T; N]) -&gt; Self::Output</code> for all <code>N &gt; 0</code>, if we do, I think we should use a trait in order to allow (excuse my syntax) <code>f32::bezier([f32x4; 2]) -&gt; f32x4</code> and <code>f32x4::bezier([f32; 2]) -&gt; f32x4</code>).</p>",
        "id": 244083207,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624825540
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330161\">Clar Fon</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244082968\">said</a>:</p>\n<blockquote>\n<p>wait, does <code>mul_add</code> in LLVM genuinely not just emit fma instructions on x86 and ARM? that was part of the main reason why I chose that implementation -- it's only two float instructions but gives you all the extra nice stuff for free</p>\n</blockquote>\n<p>it does, but only when the <code>fma</code> target features are enabled -- otherwise it calls the <code>fma</code> math lib function.</p>",
        "id": 244083256,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624825620
    },
    {
        "content": "<p>assuming you're referring to <code>f32::mul_add</code></p>",
        "id": 244083317,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624825685
    },
    {
        "content": "<p>if your referring to <code>llvm.mul_add.*</code>, yes it is defined to generate,  depending on target support, either a separate mul and add or a fma -- no other options (without fast-math).</p>",
        "id": 244083379,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624825810
    },
    {
        "content": "<p>I guess I should probably clarify where the FMA implementation came from -- I wrote up some code (which I unfortunately don't have right now, since my hard drive died) that would run some tests for the various different properties, with the goal of seeing what would be the most reasonable implementation with the least number of branches. I found that the FMA implementation had the least number of branches and the most guarantees, which is why I went with it. The <code>a * (1.0 - t) + b * t</code> was the runner-up but it took more operations, which is why I didn't go with it.</p>\n<p>I was under the impression that nowdays basically every x86_64 and aarch64 processor supports FMA, and that LLVM would emit these instructions, which is why I assumed it would be fine. If that's not the case, then it's definitely worth reconsidering, since it can be more expensive than the alternatives.</p>",
        "id": 244083672,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624826330
    },
    {
        "content": "<p>I also did some investigation into other lerp implementations (admittedly, not very much) and found that basically which version of the equation was used was almost entirely random, and I had assumed that most people hadn't given it much thought, which is why I went ahead with the FMA version. It was pretty consistent that most implementations chose to reduce the amount of branches, though (with the exception of those that explicitly wanted to clamp t to [0.0, 1.0]) and that C++ went overboard with around 5 branches per call.</p>",
        "id": 244083768,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624826449
    },
    {
        "content": "<p>You can configure your Rust program to strictly require <code>fma</code>, but by default they do not have <code>fma</code> enabled as a required CPU ability, and so LLBM will not emit <code>fma</code> operaions</p>",
        "id": 244083776,
        "sender_full_name": "Lokathor",
        "timestamp": 1624826458
    },
    {
        "content": "<p>I'm not knowledgeable enough about what hardware is out there, but it seems reasonable to assume that it'd take a lot of effort to find a CPU without FMA support nowadays, right? I would assume that most game, etc. software now tries to use it wherever they can, but I could be wrong about that.</p>",
        "id": 244083882,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624826570
    },
    {
        "content": "<p>Currently, Rust only enables the minimum possible CPU features: <code>sse</code> and <code>sse2</code> on most x86_64, but also I <em>think</em> <code>ssse3</code> on one of the mac targets.</p>",
        "id": 244083965,
        "sender_full_name": "Lokathor",
        "timestamp": 1624826665
    },
    {
        "content": "<p>okay, so, even with target-feature=fma, it seems that Rust still emits the libc instruction? o.o <a href=\"https://rust.godbolt.org/z/hWjsbxG9Y\">https://rust.godbolt.org/z/hWjsbxG9Y</a></p>",
        "id": 244084686,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624827710
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330161\">Clar Fon</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244083882\">said</a>:</p>\n<blockquote>\n<p>I'm not knowledgeable enough about what hardware is out there, but it seems reasonable to assume that it'd take a lot of effort to find a CPU without FMA support nowadays, right? I would assume that most game, etc. software now tries to use it wherever they can, but I could be wrong about that.</p>\n</blockquote>\n<p>My laptop doesn't have FMA, it's a Intel Ivy Bridge microarchitecture (released 2013 according to Wikipedia).</p>",
        "id": 244084802,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624827839
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330161\">Clar Fon</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244084686\">said</a>:</p>\n<blockquote>\n<p>okay, so, even with target-feature=fma, it seems that Rust still emits the libc instruction? o.o <a href=\"https://rust.godbolt.org/z/hWjsbxG9Y\">https://rust.godbolt.org/z/hWjsbxG9Y</a></p>\n</blockquote>\n<p>you'd have to build-std, which you can't do in godbolt currently</p>",
        "id": 244084848,
        "sender_full_name": "Lokathor",
        "timestamp": 1624827878
    },
    {
        "content": "<p>admittedly I don't use my laptop much -- why I haven't upgraded.</p>",
        "id": 244084855,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624827900
    },
    {
        "content": "<p>Does the Win11 minspec include FMA? I don't know what features are guaranteed by what.</p>",
        "id": 244084917,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624827964
    },
    {
        "content": "<p>\"basically yeah\" since you need TPM 2.0 (i think technically 1.2 works also), which is new enough that you'll have FMA</p>",
        "id": 244084962,
        "sender_full_name": "Lokathor",
        "timestamp": 1624828014
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244084848\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"330161\">Clar Fon</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244084686\">said</a>:</p>\n<blockquote>\n<p>okay, so, even with target-feature=fma, it seems that Rust still emits the libc instruction? o.o <a href=\"https://rust.godbolt.org/z/hWjsbxG9Y\">https://rust.godbolt.org/z/hWjsbxG9Y</a></p>\n</blockquote>\n<p>you'd have to build-std, which you can't do in godbolt currently</p>\n</blockquote>\n<p>isn't the function marked as inline, though? I didn't realise that you had to call the intrinsic directly for it to be optimised</p>",
        "id": 244084971,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624828047
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"260325\">Chris Denton</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244084959\">said</a>:</p>\n<blockquote>\n<p>Try <code>-O -C target-cpu=native</code>?</p>\n</blockquote>\n<p>oh, right, you didn't set <code>-Copt-level=3</code></p>",
        "id": 244084973,
        "sender_full_name": "Lokathor",
        "timestamp": 1624828050
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330161\">Clar Fon</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244084686\">said</a>:</p>\n<blockquote>\n<p>okay, so, even with target-feature=fma, it seems that Rust still emits the libc instruction? o.o <a href=\"https://rust.godbolt.org/z/hWjsbxG9Y\">https://rust.godbolt.org/z/hWjsbxG9Y</a></p>\n</blockquote>\n<p>You have to use <code>-C target-feature=+fma</code>, not <code>-C target-feature=fma</code></p>",
        "id": 244084979,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828062
    },
    {
        "content": "<p>ah, I see now. this works, then: <a href=\"https://rust.godbolt.org/z/EdeEd6n74\">https://rust.godbolt.org/z/EdeEd6n74</a></p>",
        "id": 244085039,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624828110
    },
    {
        "content": "<p><code>-O -C target-feature=fma -C target-cpu=skylake</code> gives you a <code>jmp</code>, <code>-O -C target-feature=+fma -C target-cpu=skylake</code> gives you a <code>vfmadd213sd</code></p>",
        "id": 244085042,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828122
    },
    {
        "content": "<p>rustc definitely should probably at least warn on <code>-C target-feature=feat</code> instead of <code>-C target-feature=+feat</code> or <code>-C target-feature=-feat</code></p>",
        "id": 244085052,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828148
    },
    {
        "content": "<p><code>-feat</code> <em>should</em> work (though perhaps it doesn't)</p>",
        "id": 244085062,
        "sender_full_name": "Lokathor",
        "timestamp": 1624828173
    },
    {
        "content": "<p>Still, I think that the takeaway is that unfortunately, even in the year 2021, we can't rely on FMA being emitted or supported by CPUs, meaning that FMA doesn't have the benefit of only emitting one instruction</p>",
        "id": 244085069,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624828197
    },
    {
        "content": "<p>Current behavior on godbolt seems to be <code>=feat</code> disables, <code>=-feat</code> disables, <code>=+feat</code> enables</p>",
        "id": 244085112,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828208
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"310399\">Mara</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244080277\">said</a>:</p>\n<blockquote>\n<p>especially because instead of resulting in a flickering pixel, it might cause a heavy drone to fall out of the sky ^^</p>\n</blockquote>\n<p>well, it is worth noting that floating point inaccuracy in some computational geometry function (for example, in collision detection) can be the difference between a function that converges and one that infinite loops¹, so it's not <em>all</em> just about graphical errors — it can also cause serious bugs for us too if stuff is dubious.</p>\n<p>that said, for code that sensitive you often prefer to avoid library functions that you don't control, unless they are precisely specified (for that reason).</p>\n<p>¹ okay, in practice you usually put a bound of ~100 or so on this, with a debug_assert that it never reaches that</p>\n<p><span class=\"user-mention silent\" data-user-id=\"229517\">Jacob Lifshay</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244083207\">said</a>:</p>\n<blockquote>\n<p>I'd argue that <code>lerp</code> should be implemented as exactly <code>a * (1.0 - t) + b * t</code> since that version gives the endpoints for <code>t == 0.0 || t == 1.0</code>, it is 100% reproducible across all IEEE 754 compliant archs...</p>\n</blockquote>\n<p>fwiw this is simple enough to be completely usable in games, and i agree that it avoids most of the pitfalls, including determinism/platform independence, returning correct results on the endpoints, etc. i can't really say how important the guarantees are for other disciplines tho</p>",
        "id": 244085142,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624828307
    },
    {
        "content": "<p>in slightly more positive news, aarch64 does guarantee fma instructions by itself, unlike x86: <a href=\"https://rust.godbolt.org/z/cE1K8oaGc\">https://rust.godbolt.org/z/cE1K8oaGc</a></p>",
        "id": 244085200,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624828387
    },
    {
        "content": "<p>The one thing keeping me from saying just go with <code>(1.0 - t) * v0 + t * v1</code> is the fact (fear?) that it can return values outside of <code>v0..=v1</code> even when <code>t</code> is in <code>0..=1</code></p>",
        "id": 244085257,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828477
    },
    {
        "content": "<p>If we could confidently determine that that isn't the case, and/or put a confidence on the ULP variance, then I'd 100% say just use that impl</p>",
        "id": 244085282,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828532
    },
    {
        "content": "<p>But at the same time, this thread was initially supposed to be for the API, not the implementation <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>",
        "id": 244085297,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828558
    },
    {
        "content": "<p>apologies for commandeering the thread <span aria-label=\"frown\" class=\"emoji emoji-1f641\" role=\"img\" title=\"frown\">:frown:</span></p>\n<p>I do think that both aspects are important, though</p>",
        "id": 244085356,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624828622
    },
    {
        "content": "<p>well the \"good\" implementation is clearly <code>lerp&lt;F: CanLerp&gt;(start: F, end: F, percent: F) -&gt; F</code> ;P</p>",
        "id": 244085362,
        "sender_full_name": "Lokathor",
        "timestamp": 1624828629
    },
    {
        "content": "<p>ignoring the joke, I do think that the standard library's current status quo forbids making <code>lerp</code> part of a trait, and would delegate that to crates like <code>num-traits</code></p>",
        "id": 244085422,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624828695
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244085362\">said</a>:</p>\n<blockquote>\n<p>well the \"good\" implementation is clearly <code>lerp&lt;F: CanLerp&gt;(start: F, end: F, percent: F) -&gt; F</code> ;P</p>\n</blockquote>\n<p>Not quite, see e.g. <a href=\"https://docs.rs/ultraviolet/0.8.1/ultraviolet/interp/trait.Lerp.html\">ultraviolet's definition of <code>Lerp</code></a></p>",
        "id": 244085441,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828736
    },
    {
        "content": "<p>If you have that trait you can make the free function, so, sure</p>",
        "id": 244085455,
        "sender_full_name": "Lokathor",
        "timestamp": 1624828766
    },
    {
        "content": "<p>I'm talking about the fact that you can lerp with a different type for the t than the interpolated value</p>",
        "id": 244085480,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828803
    },
    {
        "content": "<p>Anyway, I would like to avoid providing a std lerp signature which 3rd party crates cannot use, separately from the \"what are they already using\" question</p>",
        "id": 244085517,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828811
    },
    {
        "content": "<p>It would be bad imo if std uses <code>t.lerp(v0, v1)</code> but 3rd party crates <em>have</em> to continue to use <code>v0.lerp(v1, t)</code> because they cannot use <code>t.lerp(v0, v1)</code> and match std</p>",
        "id": 244085538,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828853
    },
    {
        "content": "<p>strongly agree. the end result has to be one of the two changing, and for the moment it's swinging heavily in the favor of changing the libstd lerp, despite what I would prefer</p>",
        "id": 244085554,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624828889
    },
    {
        "content": "<p>that would be worse than Ranges not being Copy</p>",
        "id": 244085557,
        "sender_full_name": "Lokathor",
        "timestamp": 1624828894
    },
    {
        "content": "<p>The thing is that 3rd party libs can't even define <code>f32::lerp(self, v0: Vec3, v1: Vec3)</code> if we provide an inherent <code>lerp</code> that's not generic</p>",
        "id": 244085608,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624828943
    },
    {
        "content": "<p>Well, if we spell it <code>t.bezier([a, b])</code> we don't have to worry about conflicting with the many differing <code>lerp</code> signatures.</p>",
        "id": 244085621,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624828983
    },
    {
        "content": "<p>i dont think there's a good way to make it part of a trait really. even the suggestion in the thread for the <code>Lerp</code> trait has the issue that it locks us into having f64 as the highest precision floats (and regardless of your feelings here — i personally suspect there are more reasons not to support any form of extended precision than there are to support them — we probably don't want to do that for something like this)</p>",
        "id": 244085642,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624829011
    },
    {
        "content": "<p>not if it's Lerp&lt;T&gt;</p>",
        "id": 244085697,
        "sender_full_name": "Lokathor",
        "timestamp": 1624829047
    },
    {
        "content": "<p>yeah, I strongly disagree with locking any particular float type. and am against <code>bezier</code> as a name, as it's explicitly linear interpolation</p>",
        "id": 244085700,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624829051
    },
    {
        "content": "<p>The alternative to my hardcoded dispatch to <code>f32</code> and <code>f64</code> is to make it MORE GENERIC with <code>Lerp&lt;T&gt;</code></p>",
        "id": 244085702,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624829055
    },
    {
        "content": "<p>Again, see ultraviolet as an example <a href=\"https://docs.rs/ultraviolet/0.8.1/ultraviolet/interp/trait.Lerp.html\">https://docs.rs/ultraviolet/0.8.1/ultraviolet/interp/trait.Lerp.html</a></p>",
        "id": 244085709,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624829073
    },
    {
        "content": "<p>Though that's <code>v0.lerp(v1, t)</code>, it could potentially be jiggled into <code>t.lerp(v0, v1)</code> order...</p>",
        "id": 244085725,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624829107
    },
    {
        "content": "<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">trait</span><span class=\"w\"> </span><span class=\"n\">Bezier</span><span class=\"o\">&lt;</span><span class=\"n\">T</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"k\">const</span><span class=\"w\"> </span><span class=\"n\">N</span>: <span class=\"kt\">usize</span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">type</span> <span class=\"nc\">Output</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">fn</span> <span class=\"nf\">bezier</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">control_points</span>: <span class=\"p\">[</span><span class=\"n\">T</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"n\">N</span><span class=\"p\">])</span><span class=\"w\"> </span>-&gt; <span class=\"nc\">Self</span>::<span class=\"n\">Output</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 244085795,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624829175
    },
    {
        "content": "<p>a full bézier implementation is much more nuanced than linear interpolation, though. it's way less used than lerp.</p>",
        "id": 244085806,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624829222
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330161\">Clar Fon</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244085806\">said</a>:</p>\n<blockquote>\n<p>a full bézier implementation is much more nuanced than linear interpolation, though. it's way less used than lerp.</p>\n</blockquote>\n<p>While it's less used, it's not really more nuanced. It's just a lerp of lerps.</p>",
        "id": 244085820,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624829259
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330161\">Clar Fon</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244085554\">said</a>:</p>\n<blockquote>\n<p>strongly agree. the end result has to be one of the two changing, and for the moment it's swinging heavily in the favor of changing the libstd lerp, despite what I would prefer</p>\n</blockquote>\n<p>I think this is a bit extreme. If there's truly a worry with clashing with library crates, then I'd pick a name other than <code>lerp</code> rather than contort the function signature.</p>",
        "id": 244085822,
        "sender_full_name": "bstrie",
        "timestamp": 1624829264
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330161\">Clar Fon</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244085700\">said</a>:</p>\n<blockquote>\n<p>yeah, I strongly disagree with locking any particular float type. and am against <code>bezier</code> as a name, as it's explicitly linear interpolation</p>\n</blockquote>\n<p>but a second-order Bezier Curve is explicitly linear interpolation...</p>",
        "id": 244085823,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624829264
    },
    {
        "content": "<p>how do you define a 0th-order or 1st-order bézier, though? and what level of accuracy do you guarantee?</p>",
        "id": 244085884,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624829347
    },
    {
        "content": "<p>in particular I think it would be very unprecedented for the stdlib to condone splitting the endpoints of a range across the receiver and the arguments</p>",
        "id": 244085885,
        "sender_full_name": "bstrie",
        "timestamp": 1624829362
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330161\">Clar Fon</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244085884\">said</a>:</p>\n<blockquote>\n<p>how do you define a 0th-order or 1st-order bézier, though? and what level of accuracy do you guarantee?</p>\n</blockquote>\n<p>It'd have to be in the <strong><em>future</em></strong> of const generics where you could exclude <code>0</code>. A 1st order is just returning the argument.</p>",
        "id": 244085956,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624829421
    },
    {
        "content": "<p>we <em>can</em> get away with just implementing 2nd, 3rd, and 4th order Bezier curves for now, and leave the fully general implementation for later. the <code>Bezier</code> trait can still be generic over <code>N</code>, we just have std impls for <code>N == 2, 3, 4</code></p>",
        "id": 244085971,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624829456
    },
    {
        "content": "<p>speaking as a pure outsider here, \"lerp\" feels like forbidding jargon that means nothing to anyone who doesn't already know what it means. \"bezier\" is only mildly better.</p>",
        "id": 244085993,
        "sender_full_name": "bstrie",
        "timestamp": 1624829490
    },
    {
        "content": "<p>which is not to imply that I really care strongly about bikeshedding the name of this API, but if a problem can be solved by renaming, I'm just saying that the current name is not exactly ideal</p>",
        "id": 244086075,
        "sender_full_name": "bstrie",
        "timestamp": 1624829558
    },
    {
        "content": "<p>how about having doc aliases for <code>lerp</code> and <code>interpolate</code> on <code>bezier</code>?</p>",
        "id": 244086076,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624829562
    },
    {
        "content": "<p>doc aliases could solve the issue, although again, I'm not sure that it's a good precedent to have a full bézier implementation in libstd</p>",
        "id": 244086091,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624829592
    },
    {
        "content": "<p>why not \"interpolate\"?</p>",
        "id": 244086092,
        "sender_full_name": "bstrie",
        "timestamp": 1624829608
    },
    {
        "content": "<p>i think that even if bezier is a thing, lerp will also be a thing, because that's more what people expect</p>",
        "id": 244086097,
        "sender_full_name": "Lokathor",
        "timestamp": 1624829619
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"256342\">bstrie</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244085993\">said</a>:</p>\n<blockquote>\n<p>speaking as a pure outsider here, \"lerp\" feels like forbidding jargon that means nothing to anyone who doesn't already know what it means. \"bezier\" is only mildly better.</p>\n</blockquote>\n<p>My response to that, unfortunately, is \"well what is <code>cmp</code>, <code>str</code>, <code>fn</code>, <code>rc</code>, <code>mutex</code>?\" <code>lerp</code> is the industry standard name for the function.</p>",
        "id": 244086102,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624829627
    },
    {
        "content": "<p>but, I could write a full bezier implementation for <code>f32</code> in &lt;20loc...</p>",
        "id": 244086107,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624829640
    },
    {
        "content": "<p>sure, but a lot of those names are also awful, and <em>somebody</em> has to be grumpy about it :P don't get me started on \"string\"...</p>",
        "id": 244086146,
        "sender_full_name": "bstrie",
        "timestamp": 1624829653
    },
    {
        "content": "<p>pub struct ListOfUnicodeCodePoints { ... }</p>",
        "id": 244086157,
        "sender_full_name": "Lokathor",
        "timestamp": 1624829684
    },
    {
        "content": "<p>try <code>Text</code> :P</p>",
        "id": 244086171,
        "sender_full_name": "bstrie",
        "timestamp": 1624829698
    },
    {
        "content": "<p>sure, you could easily write a bézier implementation, and you could easily write a gamma and zeta implementation, and--</p>",
        "id": 244086178,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624829708
    },
    {
        "content": "<p>but I digress</p>",
        "id": 244086179,
        "sender_full_name": "bstrie",
        "timestamp": 1624829711
    },
    {
        "content": "<p>better would be <code>struct TextBuf</code> and <code>text</code></p>",
        "id": 244086187,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624829722
    },
    {
        "content": "<p>I feel like regardless of what happens, the discussion should be on how lerp should work, not whether we should have a full bézier implementation instead</p>",
        "id": 244086199,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624829756
    },
    {
        "content": "<p>it would take waay more code to get a good <code>gamma</code> or <code>zeta</code> implementation, bezier is relatively simple by comparison.</p>",
        "id": 244086243,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624829796
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"330161\">@Clar Fon</span> I think that \"core and std can't have nice things\" is a poor stance that the rust project often accidentally leans towards. If we can provide good things, particularly low maintenance ones, we should.</p>",
        "id": 244086246,
        "sender_full_name": "Lokathor",
        "timestamp": 1624829806
    },
    {
        "content": "<p>that's very fair, Lokathor</p>",
        "id": 244086259,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624829831
    },
    {
        "content": "<p>and I shouldn't be using the slippery slope argument</p>",
        "id": 244086266,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624829849
    },
    {
        "content": "<p>my main concern is that making a good API for bézier is trickier than lerp</p>",
        "id": 244086268,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624829863
    },
    {
        "content": "<p>now that's valid. If the API is hard to design that's a true concern</p>",
        "id": 244086273,
        "sender_full_name": "Lokathor",
        "timestamp": 1624829878
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330161\">Clar Fon</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244086268\">said</a>:</p>\n<blockquote>\n<p>my main concern is that making a good API for bézier is trickier than lerp</p>\n</blockquote>\n<p>There's less question on whether <code>v0.bezier(v1, v2, t)</code> is valid, though <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span> because it's clearly not</p>",
        "id": 244086315,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624829904
    },
    {
        "content": "<p>agreed</p>",
        "id": 244086320,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624829925
    },
    {
        "content": "<p>personally i'm not sure i'd be entirely comfortable with <code>bezier</code> being in my math code even if it gives identical results just because i'm a dummy that doesn't know math and so i'm not familiar with it. I'd genuinely like it to say the normal name \"lerp\" so that I know it's the normal thing.</p>",
        "id": 244086372,
        "sender_full_name": "Lokathor",
        "timestamp": 1624830009
    },
    {
        "content": "<p>there is definitely comfort to be found in simple cases of larger things. it's why a lot of people have trouble with Haskell even though technically you can say that a lot of things are monoids</p>",
        "id": 244086388,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624830088
    },
    {
        "content": "<p>As proof of simplicity, <code>Bezier</code> and <code>Lerp</code>-from-<code>Bezier</code>: <a href=\"https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=06be1bed6c1e6a0a68bd5fcf2f34bdc7\">https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=06be1bed6c1e6a0a68bd5fcf2f34bdc7</a></p>",
        "id": 244086434,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624830152
    },
    {
        "content": "<p>But also I can see how this is potentially too \"clever\" for std (whereas it'd be right at home in e.g. nalgebra)</p>",
        "id": 244086442,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624830205
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"256342\">bstrie</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244086171\">said</a>:</p>\n<blockquote>\n<p>try <code>Text</code> :P</p>\n</blockquote>\n<p>Text is what a human reads and writes. Strings are not required to have such meaning. <span aria-label=\"innocent\" class=\"emoji emoji-1f607\" role=\"img\" title=\"innocent\">:innocent:</span></p>",
        "id": 244086445,
        "sender_full_name": "Jubilee",
        "timestamp": 1624830212
    },
    {
        "content": "<p>And with more careful consideration of base impls (plus better const generics and specialization oh my) you could extend it so you can get everything when providing just <code>impl Bezier&lt;Scalar, 2&gt; for MyType</code>.</p>",
        "id": 244086492,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624830261
    },
    {
        "content": "<p>I'd be happy to see the <code>Bezier</code>/<code>Lerp</code> in that playground in std, though I worry if this steps too much towards <code>num</code>, which was separated from <code>std</code> for a reason</p>",
        "id": 244086552,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624830364
    },
    {
        "content": "<p>nor actually be rendered ( merely renderable )<br>\nregardless, the virtues quickly err in favor of terseness for experienced users, and the real mistake is not in such but in going so overboard the code is unreadable.</p>",
        "id": 244086569,
        "sender_full_name": "Jubilee",
        "timestamp": 1624830389
    },
    {
        "content": "<p>( e.g. \"jnz\" instead of \"jump_nonzero\", really? )</p>",
        "id": 244086637,
        "sender_full_name": "Jubilee",
        "timestamp": 1624830491
    },
    {
        "content": "<p>can't believe you're not spelling it the obviously correct way: jn0</p>",
        "id": 244086659,
        "sender_full_name": "Lokathor",
        "timestamp": 1624830546
    },
    {
        "content": "<p>As you <em>could</em> generically provide a single default <code>Bezier</code> impl for any <code>T, S</code> where <code>S: One + Sub&lt;Output=S&gt;, T: Add&lt;Output=Self&gt; + Mul&lt;S, Output=Self&gt;</code> (I think I got those bounds correct)</p>",
        "id": 244086666,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624830561
    },
    {
        "content": "<p>I rest my case <span aria-label=\"grinning face with smiling eyes\" class=\"emoji emoji-1f601\" role=\"img\" title=\"grinning face with smiling eyes\">:grinning_face_with_smiling_eyes:</span></p>",
        "id": 244086683,
        "sender_full_name": "Jubilee",
        "timestamp": 1624830596
    },
    {
        "content": "<p>So the problem with all the generics is that the docs become incomprehensible</p>",
        "id": 244086736,
        "sender_full_name": "Lokathor",
        "timestamp": 1624830618
    },
    {
        "content": "<p>also num was split from std ages ago when we knew a lot less about rust, i think these days we know a lot more, and eventually we should bring num stuff back into core</p>",
        "id": 244086754,
        "sender_full_name": "Lokathor",
        "timestamp": 1624830652
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224471\">Lokathor</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244086736\">said</a>:</p>\n<blockquote>\n<p>So the problem with all the generics is that the docs become incomprehensible</p>\n</blockquote>\n<p>Agree, as another key point of gamedev libs that mainline libs tend to ignore is simplicity and low-optimization perf</p>",
        "id": 244086763,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624830674
    },
    {
        "content": "<p>I'm sorry</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">impl</span><span class=\"o\">&lt;</span><span class=\"n\">S</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">T</span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"n\">Bezier</span><span class=\"o\">&lt;</span><span class=\"n\">T</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"k\">for</span><span class=\"w\"> </span><span class=\"n\">S</span><span class=\"w\"></span>\n<span class=\"k\">where</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">S</span>: <span class=\"nc\">One</span><span class=\"p\">,</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">for</span><span class=\"o\">&lt;'</span><span class=\"na\">a</span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"o\">&amp;'</span><span class=\"na\">a</span><span class=\"w\"> </span><span class=\"n\">S</span>: <span class=\"nc\">Sub</span><span class=\"o\">&lt;</span><span class=\"n\">Output</span><span class=\"o\">=</span><span class=\"n\">S</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">T</span>: <span class=\"nc\">Add</span><span class=\"o\">&lt;</span><span class=\"n\">Output</span><span class=\"o\">=</span><span class=\"n\">T</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">for</span><span class=\"o\">&lt;'</span><span class=\"na\">a</span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"o\">&amp;'</span><span class=\"na\">a</span><span class=\"w\"> </span><span class=\"n\">T</span>: <span class=\"nc\">Mul</span><span class=\"o\">&lt;&amp;'</span><span class=\"na\">a</span><span class=\"w\"> </span><span class=\"n\">S</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">Output</span><span class=\"o\">=</span><span class=\"n\">T</span><span class=\"o\">&gt;</span><span class=\"p\">,</span><span class=\"w\"></span>\n<span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">fn</span> <span class=\"nf\">bezier</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"p\">[</span><span class=\"n\">v0</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">v1</span><span class=\"p\">]</span>: <span class=\"kp\">&amp;</span><span class=\"p\">[</span><span class=\"n\">T</span><span class=\"p\">;</span><span class=\"w\"> </span><span class=\"mi\">2</span><span class=\"p\">])</span><span class=\"w\"> </span>-&gt; <span class=\"nc\">T</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"n\">v0</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"o\">&amp;</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">S</span>::<span class=\"n\">one</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"o\">-</span><span class=\"w\"> </span><span class=\"bp\">self</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">+</span><span class=\"w\"> </span><span class=\"n\">v1</span><span class=\"w\"> </span><span class=\"o\">*</span><span class=\"w\"> </span><span class=\"bp\">self</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 244087026,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624830997
    },
    {
        "content": "<p>And to be clear I'm aware that it's probably better to be <code>splat(one())</code> rather than just <code>one()</code> but even I have a limit somewhere</p>",
        "id": 244087118,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624831097
    },
    {
        "content": "<p>And it's that I don't see anyone provide a generic <code>splat</code> <span aria-label=\"laughing\" class=\"emoji emoji-1f606\" role=\"img\" title=\"laughing\">:laughing:</span></p>",
        "id": 244087143,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624831147
    },
    {
        "content": "<p>splat!</p>",
        "id": 244087197,
        "sender_full_name": "Jubilee",
        "timestamp": 1624831203
    },
    {
        "content": "<p>the subtlety of this API is getting to the point where I feel like an actual RFC might be in order</p>",
        "id": 244087251,
        "sender_full_name": "bstrie",
        "timestamp": 1624831253
    },
    {
        "content": "<p>I'm just tangenting onto <code>Bezier</code> because nerd catnip tbf</p>",
        "id": 244087267,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624831280
    },
    {
        "content": "<p><span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>",
        "id": 244087270,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624831282
    },
    {
        "content": "<p>one last thing though: the definition of <code>Lerp</code> from an order-2 <code>Bezier</code> feels inverted to me</p>",
        "id": 244087281,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624831304
    },
    {
        "content": "<p>Sure, pure linear interpolation <em>is</em> a special case of bezier interpolation, but... at least every time someone's explained bezier interpolation it's been by using lerps</p>",
        "id": 244087413,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624831491
    },
    {
        "content": "<p>Full naive bezier implementation for any degree for <code>f32</code>: <a href=\"https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=5ed4f67104e633cc51708c8334769622\">https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=5ed4f67104e633cc51708c8334769622</a></p>",
        "id": 244088121,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624832597
    },
    {
        "content": "<p>if you look at the llvm ir for <code>lerp_test</code> which is implemented in terms of bezier, it's there just so it generates llvm ir, you can see it's identical to <code>(1.0 - t) * a +  t * b</code></p>",
        "id": 244088198,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624832742
    },
    {
        "content": "<p>Well, I understand defining bezier as lerp-of-lerps, and don't really understand how you've implemented it here, so, uh, point against for simplicity. I have very little idea how I'd go about making e.g. a <code>Vec3</code> type work with this trait.</p>",
        "id": 244088539,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624833292
    },
    {
        "content": "<p>I think the one thing we're relatively sure of is that whatever <code>lerp</code> stdlib gets (if it gets one) should be a signature also providable by 3rd party math libs for their own types</p>",
        "id": 244088550,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624833342
    },
    {
        "content": "<p>portable simd will, for example, want to lerp as well</p>",
        "id": 244088600,
        "sender_full_name": "Lokathor",
        "timestamp": 1624833373
    },
    {
        "content": "<p>(Loathe to say it, but, what about non-<code>Copy</code> numeric types...)</p>",
        "id": 244088605,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624833390
    },
    {
        "content": "<p>That's not even unreasonable. A sufficiently large matrix might be Vec&lt;f32&gt; backed</p>",
        "id": 244088616,
        "sender_full_name": "Lokathor",
        "timestamp": 1624833427
    },
    {
        "content": "<p>So I guess we'd want to do something like <code>Add</code> &amp; the other math traits where it's implemented both for <code>&amp;T</code> and <code>T</code> when <code>T: Copy</code>?</p>",
        "id": 244088675,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624833504
    },
    {
        "content": "<p>Yeah, I think I'm agreeing now that there's enough nuance here that this should go through a proper RFC to get more eyes and discussion</p>",
        "id": 244088686,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624833548
    },
    {
        "content": "<p>i think the type being lerped is always taken by self, and then you can clone it if you want to, otherwise you just update in place and return using the same heap allocation</p>",
        "id": 244088699,
        "sender_full_name": "Lokathor",
        "timestamp": 1624833597
    },
    {
        "content": "<p>that is, the caller can decide if they want to do that clone, the impl will akways take by self and always modify in place</p>",
        "id": 244088742,
        "sender_full_name": "Lokathor",
        "timestamp": 1624833627
    },
    {
        "content": "<p>Feels more like <code>lerp(&amp;mut self, v1, t)</code> now...</p>",
        "id": 244088743,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624833643
    },
    {
        "content": "<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">pub</span><span class=\"w\"> </span><span class=\"k\">trait</span><span class=\"w\"> </span><span class=\"n\">Add</span><span class=\"o\">&lt;</span><span class=\"n\">Rhs</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"bp\">Self</span><span class=\"o\">&gt;</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">type</span> <span class=\"nc\">Output</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"cp\">#[must_use]</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">pub</span><span class=\"w\"> </span><span class=\"k\">fn</span> <span class=\"nf\">add</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">rhs</span>: <span class=\"nc\">Rhs</span><span class=\"p\">)</span><span class=\"w\"> </span>-&gt; <span class=\"nc\">Self</span>::<span class=\"n\">Output</span><span class=\"p\">;</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 244088752,
        "sender_full_name": "Lokathor",
        "timestamp": 1624833667
    },
    {
        "content": "<p>And <code>AddAssign</code> for inplace</p>",
        "id": 244088757,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624833685
    },
    {
        "content": "<p>well, yeah, but you would unlikely have lerpassign</p>",
        "id": 244088761,
        "sender_full_name": "Lokathor",
        "timestamp": 1624833714
    },
    {
        "content": "<p>So would this be <code>Lerp(self, v1: &amp;Self, t: &amp;Scale) -&gt; Self</code> then?</p>",
        "id": 244088809,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624833760
    },
    {
        "content": "<p>v1 probably is also moved</p>",
        "id": 244088818,
        "sender_full_name": "Lokathor",
        "timestamp": 1624833802
    },
    {
        "content": "<p>Lerp(self, v1: Self, t: Scale) -&gt; Self</p>",
        "id": 244088821,
        "sender_full_name": "Lokathor",
        "timestamp": 1624833831
    },
    {
        "content": "<p>I will note that this has got us back to <code>v0.lerp(v1, t)</code></p>",
        "id": 244088862,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624833853
    },
    {
        "content": "<p>no avoiding that</p>",
        "id": 244088866,
        "sender_full_name": "Lokathor",
        "timestamp": 1624833861
    },
    {
        "content": "<p>well, if the trait takes both <code>t</code> and <code>control_points</code> by value, you <em>can</em> just implement it for <code>&amp;YourHeavyweightType</code></p>",
        "id": 244088894,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624833952
    },
    {
        "content": "<p>I'm at the point where I've no more to add so I'm going to go do the work that I'm supposed to be doing right now /wave</p>",
        "id": 244088950,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624834036
    },
    {
        "content": "<p>kinda like how <code>num_bigint::BigInt</code> impls <code>Add</code> for both references and by-value <code>BigInt</code></p>",
        "id": 244088960,
        "sender_full_name": "Jacob Lifshay",
        "timestamp": 1624834064
    },
    {
        "content": "<p>I ran <a href=\"https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=20d7ed562c014947fa1d21631f69de9f\">some code</a> that suggests that <code>((1.0 - t) * v0) + (t * v1)</code> is in fact <strong><em>bounded</em></strong> to return a value between <code>v0</code> and <code>v1</code>. I still feel like I've seen a counterexample at some point, but perhaps I'm mistaken.</p>",
        "id": 244090349,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624836422
    },
    {
        "content": "<p>... and nvm adjusted it and found a counterexample quickly: <code>lerp(0.000000029802326, 139443040, 197225040) = 139443020</code></p>",
        "id": 244090414,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624836583
    },
    {
        "content": "<p>(That's 1 ULP out of range)</p>",
        "id": 244090965,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624837559
    },
    {
        "content": "<p>Adjusted code: <a href=\"https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=8c98a6c4ebd605b374a9566db74dc328\">https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=8c98a6c4ebd605b374a9566db74dc328</a></p>",
        "id": 244091031,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624837668
    },
    {
        "content": "<p>So what's the biggest start/end range where 0.0 ..= 1.0 for scale will always give correctly start ..= end</p>",
        "id": 244091929,
        "sender_full_name": "Lokathor",
        "timestamp": 1624839227
    },
    {
        "content": "<p>like, if it's \"something big\" then can we note that in the docs and say \"you only need to worry if inputs exceed +/- FOONUM\"</p>",
        "id": 244091974,
        "sender_full_name": "Lokathor",
        "timestamp": 1624839263
    },
    {
        "content": "<p>It's worth noting that it's monotonic if the signs of <code>v0</code> and <code>v1</code> differ</p>",
        "id": 244093091,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624841311
    },
    {
        "content": "<p>So technically, an arbitrarily large range could be monotonic</p>",
        "id": 244093097,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624841327
    },
    {
        "content": "<p>I don't know an efficient way to search for the smallest input where it lacks <strong><em>boundedness</em></strong> though</p>",
        "id": 244093108,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624841370
    },
    {
        "content": "<p>Well i'm thinking that many cases would be just lerping 0.0 to 1.0, 255.0, 1000.0, or similar \"small\" values.</p>",
        "id": 244093324,
        "sender_full_name": "Lokathor",
        "timestamp": 1624841709
    },
    {
        "content": "<p>Searching (will edit this message a few more times):</p>\n<div class=\"codehilite\"><pre><span></span><code>    lerp(0.000000029818942, 724085.75, 994951.9) = 724085.7\n    lerp(0.000000029809552, 52037.652, 61402.95) = 52037.65\n    lerp(0.00000002982163, 2636.042, 3392.6443) = 2636.0417\n    lerp(0.000000029833707, 696.9417, 952.48224) = 696.94165\n    lerp(0.000000029841495, 64.93388, 94.82493) = 64.933876\n    lerp(0.000000029802916, 8.089652, 9.701944) = 8.089651\n</code></pre></div>",
        "id": 244094646,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624843952
    },
    {
        "content": "<p>So, yeah, even with reasonable values, a really small <code>t</code> can escape the bound</p>",
        "id": 244094731,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624844095
    },
    {
        "content": "<p>To be clear, this is testing <code>((1.0 - t) * v0) + (t * v1)</code></p>",
        "id": 244094793,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624844191
    },
    {
        "content": "<p>I'm now <a href=\"https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=2b4f68d05e2b3be5fb9e650072e8748b\">burning my CPU</a> trying to show a bound of approximately 2 ULP, comparing against <a href=\"https://math.stackexchange.com/a/2969873/573727\">what should be an exact calculation</a>, summed at twice the precision.</p>",
        "id": 244094996,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624844544
    },
    {
        "content": "<p>Not a proof, but experimental results.</p>",
        "id": 244095008,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624844565
    },
    {
        "content": "<p>Final count: I checked over 15000 different increasing min/max pairs for all values of t, and found a maximum deviation of 2 ULP from the error-corrected lerp. 94% of checked argument triples had no deviation from the error-corrected value; 6% deviated by 1 ULP; and 0.0003% varied by 2 ULP.</p>",
        "id": 244098980,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624851430
    },
    {
        "content": "<p>blasted floating point</p>",
        "id": 244102310,
        "sender_full_name": "Lokathor",
        "timestamp": 1624856353
    },
    {
        "content": "<p>mind sharing the code you've been using to find counterexamples? I made similar code at some point but it kind of sucked and used a jank (MIN..=MAX) =&gt; (0.0..=1.0) mapping to get it working with proptest</p>",
        "id": 244133985,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624881840
    },
    {
        "content": "<p>from what I gathered, the C++ specification for lerp was proposed given a very specific implementation that could not possibly match all criteria they added, so no matter what, some of those criteria aren't going to make the cut</p>",
        "id": 244134098,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624881913
    },
    {
        "content": "<p>my main thought was that we'd look for a reasonable subset that has a reasonable implementation with minimal branching</p>",
        "id": 244134162,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624881947
    },
    {
        "content": "<p>(for example, I believe that the glibc implementation isn't monotonic)</p>",
        "id": 244134236,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624881971
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"330161\">Clar Fon</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244133985\">said</a>:</p>\n<blockquote>\n<p>mind sharing the code you've been using to find counterexamples?</p>\n</blockquote>\n<p>Most recent: <a href=\"https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=2b4f68d05e2b3be5fb9e650072e8748b\">https://play.rust-lang.org/?version=stable&amp;mode=release&amp;edition=2018&amp;gist=2b4f68d05e2b3be5fb9e650072e8748b</a><br>\nIt's not pretty, but it works. Just adding extra checks in the loop to check other properties.</p>",
        "id": 244153987,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624890939
    },
    {
        "content": "<p>ugly code in this situation is better than no code <span aria-label=\"stuck out tongue\" class=\"emoji emoji-1f61b\" role=\"img\" title=\"stuck out tongue\">:stuck_out_tongue:</span></p>",
        "id": 244161744,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624894060
    },
    {
        "content": "<p>I'm increasingly skeptical that something like this that isn't close to being standardized in industry usage is a fit for the standard library. getting all the rust-based libs to agree to use a single implementation would give confidence that this should be added to std</p>",
        "id": 244171695,
        "sender_full_name": "bstrie",
        "timestamp": 1624898231
    },
    {
        "content": "<p>Its existence is standardised in industry, but its details are not</p>",
        "id": 244171956,
        "sender_full_name": "Clar Fon",
        "timestamp": 1624898360
    },
    {
        "content": "<p>yes, which means I think it's still a promising avenue to pursue, but it needs consensus from existing library users. the stdlib doesn't want to dictate standards, it just wants to legitimize existing widespread patterns</p>",
        "id": 244172170,
        "sender_full_name": "bstrie",
        "timestamp": 1624898476
    },
    {
        "content": "<p>at best, as it stands it seems like you would not be able to get away with a one-size-fits-all solution, and would need to have several varieties of this function</p>",
        "id": 244172255,
        "sender_full_name": "bstrie",
        "timestamp": 1624898524
    },
    {
        "content": "<p>this is not to delegitimize the amount of work you have done so far, which is impressive, thoughtful, and thorough. I just think the problem space might not be ready for a solution to be set in stone at this point in time</p>",
        "id": 244172877,
        "sender_full_name": "bstrie",
        "timestamp": 1624898844
    },
    {
        "content": "<p>If you think that the writers of all the math libraries will agree with each other on their own and then that one answer should be imported to the standard library, i think you're missing a key factor in the psychology of people who go off and make their own entire math library.</p>",
        "id": 244174381,
        "sender_full_name": "Lokathor",
        "timestamp": 1624899555
    },
    {
        "content": "<p>you appear to be arguing that people can't be convinced to use a single implementation, which strikes me as an implicit argument against adding this to std</p>",
        "id": 244174538,
        "sender_full_name": "bstrie",
        "timestamp": 1624899609
    },
    {
        "content": "<p>Well, no</p>",
        "id": 244174659,
        "sender_full_name": "Lokathor",
        "timestamp": 1624899665
    },
    {
        "content": "<p>There's zero value at all for math lib writers to have interop with each other. None whatsoever. However, there's value to users to have a standard way to to things. The standard library exists to set a standard that people are expected to conform to or have a good reason for not conforming to.</p>",
        "id": 244174762,
        "sender_full_name": "Lokathor",
        "timestamp": 1624899712
    },
    {
        "content": "<p>your talk of psychology makes it sound as though you think people are irrationally averse to the proposition of converging on a single implementation, which suggests that they won't be bothered be not having a good reason for not conforming to it</p>",
        "id": 244174964,
        "sender_full_name": "bstrie",
        "timestamp": 1624899784
    },
    {
        "content": "<p>I don't think they're <em>irrationally</em> averse, I just think there's nothing by default that's actually giving people any reason to do it the same way anyone else is doing it.</p>",
        "id": 244175213,
        "sender_full_name": "Lokathor",
        "timestamp": 1624899898
    },
    {
        "content": "<p>then that suggests to me that they can be reasoned with and convinced to use a single implementation, and I further suggest that the next step of action is to do so external to std</p>",
        "id": 244175558,
        "sender_full_name": "bstrie",
        "timestamp": 1624900052
    },
    {
        "content": "<p>Send a PR to various libraries changing out their implementation of lerp for the proposed std implementation (the actual shape of their API is irrelevant to this phase and shouldn’t change in these PRs). Point them to this thread/issue and tell them that it’s part of a broader effort to include a lerp in std, and invite them to comment. If they have no objections to the PR, then that adds weight to the value of this proposal. If they do have objections, then collect them, determine if they’re reasonable/actionable, and take them into account in the proposal.</p>",
        "id": 244176670,
        "sender_full_name": "bstrie",
        "timestamp": 1624900557
    },
    {
        "content": "<p>nalgebra, euclid, emath, and ultraviolet all currently use <code>(1-t)v0</code>. glam, cgmath, and kurbo use <code>t(v1-v0)</code>. vek provides both.</p>",
        "id": 244177375,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624900837
    },
    {
        "content": "<p>What does vek call the two different versions?</p>",
        "id": 244191559,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1624907427
    },
    {
        "content": "<p>seems to be <code>lerp</code> and <code>lerp_precise</code>, <a href=\"https://docs.rs/vek/0.15.1/vek/ops/trait.Lerp.html\">https://docs.rs/vek/0.15.1/vek/ops/trait.Lerp.html</a></p>",
        "id": 244196370,
        "sender_full_name": "Lokathor",
        "timestamp": 1624910147
    },
    {
        "content": "<p>Tested the same amount of lerps with the <code>t(v1-v0)</code> method, though with new random min/max pairs. That gave me 99.5% 0 ULP deviation from error-corrected, 0.5% 1 ULP deviation, and 0.00004% 2 ULP deviation.</p>",
        "id": 244202159,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624913057
    },
    {
        "content": "<p>Based on this (scuffed) probabilistic test, it suggests that <code>v0 + t * (v1 - v0)</code> is actually more accurate than <code>(1 - t) * v0 + t * v1</code>.</p>",
        "id": 244202373,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624913170
    },
    {
        "content": "<p>And to be clear, this was with no explicit FMA operations.</p>",
        "id": 244202401,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624913182
    },
    {
        "content": "<p>I... honestly don't know which I prefer anymore</p>",
        "id": 244202484,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624913238
    },
    {
        "content": "<p>Though I should clarify that my \"precise\" calculation is still limited by the precision of the computer, it just attempts to capture the error in each step and add them back in at the end.</p>",
        "id": 244202670,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624913354
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"132829\">Christopher Durham</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244202373\">said</a>:</p>\n<blockquote>\n<p>Based on this (scuffed) probabilistic test, it suggests that <code>v0 + t * (v1 - v0)</code> is actually more accurate than <code>(1 - t) * v0 + t * v1</code>.</p>\n</blockquote>\n<p>yes, that should be accurate. it has fewer operations that will cause rounding — the issue is that it isn't precise at t == 1, which can be a footgun</p>",
        "id": 244203412,
        "sender_full_name": "Thom Chiovoloni",
        "timestamp": 1624913762
    },
    {
        "content": "<p>Yeah, though given that the <strong><em>exact</em></strong> formula still isn't <strong><em>bounded</em></strong> nor <strong><em>consistent</em></strong>, I'm not exactly certain how valuable a property that is</p>",
        "id": 244203803,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624913984
    },
    {
        "content": "<p>Did anybody consider adding a couple bits to the floats to hold the intermediate results?!</p>",
        "id": 244203948,
        "sender_full_name": "nagisa",
        "timestamp": 1624914038
    },
    {
        "content": "<p>While useful for testing deviation, adding bits is not all that practical in practice, since while for scalar <code>f32</code> it'd be \"free\" (assuming <code>f32</code> and <code>f64</code> are \"the same speed,\" which isn't a given), once you're packing multiple simd lanes adding bits becomes things you can't really do</p>",
        "id": 244204218,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624914175
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"132829\">Christopher Durham</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244203803\">said</a>:</p>\n<blockquote>\n<p>Yeah, though given that the <strong><em>exact</em></strong> formula still isn't <strong><em>bounded</em></strong> nor <strong><em>consistent</em></strong>, I'm not exactly certain how valuable a property that is</p>\n</blockquote>\n<p>Like, for example, <code>(uint8_t) Lerp( Clamp( t, 0, 1 ), 0, 255 )</code>&lt;sub&gt;C&lt;/sub&gt; isn't guaranteed sound for all <code>t</code>, because the <code>Lerp</code> isn't bounded with either formula, you have to <code>(uint8_t) Clamp( Lerp( t, 0, 255 ), 0, 255 )</code> instead</p>",
        "id": 244204253,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624914196
    },
    {
        "content": "<p>I was taking shots at f80 and the horror that x86's fpu was in the past ^^</p>",
        "id": 244204401,
        "sender_full_name": "nagisa",
        "timestamp": 1624914279
    },
    {
        "content": "<p>If all you care about is a single precise result it's not a horrible idea in isolation</p>",
        "id": 244204480,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624914320
    },
    {
        "content": "<p>(Now I have to, of course, bring up the <a href=\"https://twitter.com/mycoliza/status/1031048252152369152?s=20\"><code>long double</code></a>)</p>\n<div class=\"inline-preview-twitter\"><div class=\"twitter-tweet\"><a href=\"https://twitter.com/mycoliza/status/1031048252152369152?s=20\"><img class=\"twitter-avatar\" src=\"https://uploads.zulipusercontent.net/850b7fef7fa746078748dc4a8a544f29fc9882f8/68747470733a2f2f7062732e7477696d672e636f6d2f70726f66696c655f696d616765732f313035373238343830343138303233383333372f4468777935756d705f6e6f726d616c2e6a7067\"></a><p><a href=\"https://twitter.com/ManishEarth\">@ManishEarth</a> <a href=\"https://twitter.com/myrrlyn\">@myrrlyn</a> <a href=\"https://twitter.com/iximeow\">@iximeow</a> @adam_n_p <a href=\"https://twitter.com/hdevalence\">@hdevalence</a> <a href=\"https://twitter.com/isislovecruft\">@isislovecruft</a> <a href=\"https://twitter.com/mgattozzi\">@mgattozzi</a> <a href=\"https://twitter.com/havvy\">@havvy</a> <a href=\"https://twitter.com/Sunjay03\">@Sunjay03</a> @6b766e <a href=\"https://twitter.com/steveklabnik\">@steveklabnik</a> implemented, naturally, as the sum of two IEEE 754 double-precision numbers</p><span>- 𓃭𓇋𓊃𓄿𓁐 (@mycoliza)</span></div></div>",
        "id": 244204651,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624914393
    },
    {
        "content": "<p>BTW, got an answer on <a href=\"https://math.stackexchange.com/a/4185537/573727\">https://math.stackexchange.com/a/4185537/573727</a>; TL;DR theoretical max ULP deviance for <code>(1-t)</code> version is around 2 + (cry if very big <code>v0</code> and very small <code>v1</code>).</p>",
        "id": 244205348,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624914798
    },
    {
        "content": "<p>I'm going to be highly amused if <span class=\"user-mention\" data-user-id=\"271719\">@Mario Carneiro</span> answered that question without even realizing it was Rust-related :P</p>",
        "id": 244205625,
        "sender_full_name": "bstrie",
        "timestamp": 1624914919
    },
    {
        "content": "<p>full disclosure: the question was brought to my attention earlier in this thread, although I have answered questions like that in the past on MSE</p>",
        "id": 244206064,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1624915090
    },
    {
        "content": "<p>As far as I can tell, it's a good answer</p>",
        "id": 244206130,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624915136
    },
    {
        "content": "<p>it would be good to see whether there are any actual inputs that demonstrate that the bound is approximately tight</p>",
        "id": 244206166,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1624915160
    },
    {
        "content": "<p>in particular, whether the relative accuracy really does take a nose dive when the output is supposed to be small</p>",
        "id": 244206201,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1624915192
    },
    {
        "content": "<p><del>Well, uh, <code>thread 'main' panicked at 'lerp(1, 340282350000000000000000000000000000000, 0.00000011920929) had a deviation of 872415232 ULP', src\\main.rs:126:13</code></del></p>",
        "id": 244206328,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624915247
    },
    {
        "content": "<p>Wait that was the <code>(v1-v0)</code> impl</p>",
        "id": 244206353,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624915269
    },
    {
        "content": "<p>Manually testing, I didn't find anything beyond a 2 ULP variance for the <code>(1-t)</code> impl</p>",
        "id": 244206667,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624915450
    },
    {
        "content": "<p>I might let my computer do a random search with very small <code>v1</code> and very large <code>v0</code> again tomorrow but I need to use my cores for the rest of today</p>",
        "id": 244206697,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624915475
    },
    {
        "content": "<p>This does give me more confidence that <code>(1-t)</code> behaves \"better\" for extreme inputs, though</p>",
        "id": 244206762,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624915535
    },
    {
        "content": "<p>This one has a good chance of just being error in my error-corrected calculation, but for the literal edgest of cases <code>'lerp(0.000000000000000000000000000000000000000000001, 340282350000000000000000000000000000000, -340282350000000000000000000000000000000) had a deviation of 4194305 ULP', src\\main.rs:126:13</code> (<code>(1-t)</code> lerp)</p>",
        "id": 244207040,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624915688
    },
    {
        "content": "<p>Note that the analysis I gave is wrong for denormal numbers because relative error is larger in that case</p>",
        "id": 244207076,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1624915720
    },
    {
        "content": "<p>I have no good way to skip denormals in my sweep <span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span></p>",
        "id": 244207096,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624915740
    },
    {
        "content": "<p>Though I can just start at the other end... <code>thread 'main' panicked at 'lerp(0.99999994, 340282350000000000000000000000000000000, -340282350000000000000000000000000000000) had a deviation of 2143289341 ULP', src\\main.rs:130:13</code></p>",
        "id": 244207154,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624915786
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"132829\">Christopher Durham</span> <a href=\"#narrow/stream/219381-t-libs/topic/lerp.20API.20design/near/244206762\">said</a>:</p>\n<blockquote>\n<p>This does give me more confidence that <code>(1-t)</code> behaves \"better\" for extreme inputs, though</p>\n</blockquote>\n<p>There might be a reason for that: The problematic assumption is that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi><mo>⊕</mo><mi>b</mi><mo>=</mo><mo stretchy=\"false\">(</mo><mi>a</mi><mo>+</mo><mi>b</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">(</mo><mn>1</mn><mo>±</mo><mi>ϵ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">a\\oplus b=(a+b)(1\\pm\\epsilon)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.66666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⊕</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">a</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mclose\">)</span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">±</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">ϵ</span><span class=\"mclose\">)</span></span></span></span>, which is a very bad estimate if <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi></mrow><annotation encoding=\"application/x-tex\">a</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">a</span></span></span></span> is much bigger than <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span> so that <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>a</mi><mi>ϵ</mi></mrow><annotation encoding=\"application/x-tex\">a\\epsilon</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">ϵ</span></span></span></span> is lots of ulps. I think the real estimate has this error bounded by <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi></mrow><annotation encoding=\"application/x-tex\">b</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathnormal\">b</span></span></span></span> at least</p>",
        "id": 244207161,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1624915792
    },
    {
        "content": "<p>This is also a sign change</p>",
        "id": 244207168,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624915797
    },
    {
        "content": "<p>There's also a decent chance that my \"ULP variation\" code is wrong around denormals and/or sign changes tbh</p>",
        "id": 244207579,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624916057
    },
    {
        "content": "<p>I didn't see it covered here, I believe precise refers to getting v = v1 when t = 1. See <a href=\"https://en.wikipedia.org/wiki/Linear_interpolation#Programming_language_support\">https://en.wikipedia.org/wiki/Linear_interpolation#Programming_language_support</a>. Also covers monotonic properties of both.</p>",
        "id": 244262863,
        "sender_full_name": "Cameron Hart",
        "timestamp": 1624964152
    },
    {
        "content": "<p>I've been using <strong><em>bold italic</em></strong> when referring specifically to the properties as I defined on the tracking issue: <a href=\"https://github.com/rust-lang/rust/issues/86269#issuecomment-869108301\">https://github.com/rust-lang/rust/issues/86269#issuecomment-869108301</a></p>\n<p>These are the properties as described by the C++ paper as well.</p>",
        "id": 244317758,
        "sender_full_name": "Christopher Durham",
        "timestamp": 1624987836
    }
]