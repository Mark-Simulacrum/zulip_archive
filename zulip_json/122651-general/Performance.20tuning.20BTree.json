[
    {
        "content": "<p>Is there someone in this stream, or elsewhere on Zulip, whom I could ask a few questions on how to test a small performance tweak for BTree?</p>",
        "id": 222862360,
        "sender_full_name": "Bram van den Heuvel",
        "timestamp": 1610720260
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"257813\">@Stein Somers</span> works on btree quite a lot, they might have suggestions</p>",
        "id": 222864057,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1610721016
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"257813\">@Stein Somers</span>,</p>\n<p>Do you know if someone ever tried to tune the node capacity? The benches for capacity 5 seem faster.</p>\n<p>I was trying to use binary search in the nodes (as was suggested at the PR that merges the \"branchless\" version). That seemed faster. I suspected that with binary search, it would be worth increasing the capacity (was not the case). Then I noticed that with a smaller capacity, binary search was faster. So I tested linear search against that same capacity, and it was faster too (5 instead of 6). </p>\n<p>Faster here is counting the number of tests that are faster.</p>\n<p>Binary search seems to have a much lower variance, most of the time, which might be interested. A few test cases however have variance increased again by quite a bit (i.e. increased variance of variance, decreased mean of variance). So far, it looks like binary search could lead to a 5% improvement on average.</p>\n<p>Finally, I thought that something might be wrong with my bench setup. E.g. by running one test after the other -&gt; different heat -&gt; different clock frequency -&gt; different ns.</p>",
        "id": 222865438,
        "sender_full_name": "Bram van den Heuvel",
        "timestamp": 1610721647
    },
    {
        "content": "<p>It would also be interesting to try a different order of elements, instead of  binary search over sorted node.<br>\nI would start by looking to see what benchmarking was used in other PR's to the Btree file.</p>",
        "id": 222869888,
        "sender_full_name": "Eh2406",
        "timestamp": 1610723331
    },
    {
        "content": "<p>You can disable turbo-boost to decrease variance if you're benchmarking wall clock time. Helps especially on thermally constrained laptops.<br>\nAlternatively you can bench instructions, but I think the built-in bench still doesn't support that, you'll need some 3rd-party benchmark crate for that.</p>",
        "id": 222882674,
        "sender_full_name": "The 8472",
        "timestamp": 1610727929
    },
    {
        "content": "<p>You probably should run existing benchmarks too. Even if a particular search gets faster something else might get slowed down.</p>",
        "id": 222882822,
        "sender_full_name": "The 8472",
        "timestamp": 1610727978
    },
    {
        "content": "<p>I would assume the size of the elements in the btree will make a big difference to cache behaviour, and often binary search depends heavily on the branch predictor.  So general benchmarking is probably really hard here :/</p>",
        "id": 222893739,
        "sender_full_name": "scottmcm",
        "timestamp": 1610731871
    },
    {
        "content": "<p>I haven't seen any discussion on capacity, except the one from years ago when B was a parameter changed into a constant.</p>\n<p>Do you mean the benches under library/alloc/benches? They are somewhat arbitrary, and like all microbenchmarks, highly focused on read-only features. Changing capacity could have a relatively big impact on allocation, for better or worse (less capacity means more allocations but typically less wasted space, for instance a typical node has a usage of 6/11 = 54%, which would be 3/5 = 60%). In my experience, they behave consistently within a few %, provided you <a href=\"https://github.com/ssomers/cargo-benchcmp\">pick the best from a few runs</a>.</p>\n<p>A 5% change is nothing, you get 25% by <a href=\"https://github.com/rust-lang/rust/pull/74693\">turning off some optimizations</a> (no, I did not mistype here). I bet you'd get more than 5% by simply inverting the current linear search, because usually in benchmarks, keys increase and you tend to come up with something that belongs at the end of the array.</p>",
        "id": 222893980,
        "sender_full_name": "Stein Somers",
        "timestamp": 1610731956
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"257813\">@Stein Somers</span> thanks for the response. <a href=\"/user_uploads/4715/crir0IeMKBaV54lwjI6e47AK/timings.ods\">Here</a> are some of the runs I did today, in case it interests you.</p>",
        "id": 222894753,
        "sender_full_name": "Bram van den Heuvel",
        "timestamp": 1610732275
    },
    {
        "content": "<p>Does the CI provide a possibility to run benches, e.g. as part of a PR, in a more \"constant\" environment than my laptop?</p>",
        "id": 222894866,
        "sender_full_name": "Bram van den Heuvel",
        "timestamp": 1610732306
    },
    {
        "content": "<blockquote>\n<p>they behave consistently</p>\n</blockquote>\n<p>Wait, I mean: they behave consistently when running the same code. Any change in code can sometimes tip the balance and change the performance of multiple test cases tens of percents.</p>",
        "id": 222894880,
        "sender_full_name": "Stein Somers",
        "timestamp": 1610732310
    },
    {
        "content": "<p>I thought that with 59 benches, there would be a sufficient coverage of the different applications. Interesting.</p>",
        "id": 222895094,
        "sender_full_name": "Bram van den Heuvel",
        "timestamp": 1610732398
    },
    {
        "content": "<p><span aria-label=\"upside down\" class=\"emoji emoji-1f643\" role=\"img\" title=\"upside down\">:upside_down:</span> if only the CI provided the possibility to <a href=\"https://internals.rust-lang.org/t/x-py-how-to-benchmark-liballoc/11635/8\">even check the syntax of benches</a>â€¦</p>",
        "id": 222895427,
        "sender_full_name": "Stein Somers",
        "timestamp": 1610732543
    },
    {
        "content": "<p>Not sure if the ability to specify B (<code>with_b</code>) ever worked, but it was <a href=\"https://github.com/rust-lang/rust/issues/27795\">deprecated</a>, <a href=\"https://github.com/rust-lang/rust/pull/30182\">removed</a>, and its traces wiped out while <a href=\"https://github.com/rust-lang/rust/issues/27865\">introducing parent pointers</a>. I do remember some discussion about it, but (as usual) can't find anything substantial in writing.</p>",
        "id": 222898714,
        "sender_full_name": "Stein Somers",
        "timestamp": 1610733875
    },
    {
        "content": "<p>I saw this note in one of those, which makes sense to me:</p>\n<blockquote>\n<p>I think this shouldn't go stable, this is definitely something that would be much better at the type level.</p>\n</blockquote>\n<p>So it sounds to me like the runtime config was removed, which totally makes sense.  With <code>min_const_generics</code> landing soon, you could try experimenting with making it configurable that way...</p>\n<p>(Can a type parameter be marked unstable?)</p>",
        "id": 222907507,
        "sender_full_name": "scottmcm",
        "timestamp": 1610737249
    },
    {
        "content": "<p>can const parameters have a default?</p>",
        "id": 222908295,
        "sender_full_name": "cuviper",
        "timestamp": 1610737514
    },
    {
        "content": "<p>Good question.  I have no idea.</p>",
        "id": 222909058,
        "sender_full_name": "scottmcm",
        "timestamp": 1610737828
    },
    {
        "content": "<div class=\"codehilite\"><pre><span></span><code>error[E0658]: default values for const generic parameters are experimental\n --&gt; src/lib.rs:3:29\n  |\n3 | pub type Foo&lt;const N: usize = 42&gt; = [u8; N];\n  |                             ^^^^\n  |\n  = note: see issue #44580 &lt;https://github.com/rust-lang/rust/issues/44580&gt; for more information\n  = help: add `#![feature(const_generics_defaults)]` to the crate attributes to enable\n</code></pre></div>",
        "id": 222911030,
        "sender_full_name": "cuviper",
        "timestamp": 1610738574
    },
    {
        "content": "<p>that feature doesn't help though, and taken alone it errors unknown feature</p>",
        "id": 222911076,
        "sender_full_name": "cuviper",
        "timestamp": 1610738598
    },
    {
        "content": "<p>maybe it's a typo</p>",
        "id": 222911083,
        "sender_full_name": "cuviper",
        "timestamp": 1610738601
    },
    {
        "content": "<p>nevermind, it was my typo</p>",
        "id": 222911240,
        "sender_full_name": "cuviper",
        "timestamp": 1610738652
    },
    {
        "content": "<p>also need to allow <code>incomplete_features</code>, and give <code>42</code> an explicit type</p>",
        "id": 222911398,
        "sender_full_name": "cuviper",
        "timestamp": 1610738719
    },
    {
        "content": "<p>and then it ICEs</p>",
        "id": 222911404,
        "sender_full_name": "cuviper",
        "timestamp": 1610738723
    },
    {
        "content": "<p>I guess as a prototype it could just use a strategy type instead.  Might be nice anyway, to allow math defining the size</p>",
        "id": 222916544,
        "sender_full_name": "scottmcm",
        "timestamp": 1610740825
    },
    {
        "content": "<p>(So there are more elements per node in a <code>BTreeSet&lt;u8&gt;</code> than a <code>BTreeSet&lt;[String; 7]&gt;</code>)</p>",
        "id": 222916627,
        "sender_full_name": "scottmcm",
        "timestamp": 1610740859
    },
    {
        "content": "<p>this can also be explored in a crate, along the lines of <code>binary-heap-plus</code></p>",
        "id": 222916782,
        "sender_full_name": "cuviper",
        "timestamp": 1610740922
    },
    {
        "content": "<p>then a non-default const parameter is fine</p>",
        "id": 222916903,
        "sender_full_name": "cuviper",
        "timestamp": 1610740964
    },
    {
        "content": "<p>but computing based on <code>size_of</code> would also be neat</p>",
        "id": 222916962,
        "sender_full_name": "cuviper",
        "timestamp": 1610740986
    },
    {
        "content": "<p>Certainly C++ ended up moving away from using value template parameters for anything non-deduced, so one could argue that the strategy is always better even with full const generics support.</p>\n<p>Crate-ification of the whole btree stuff might be interesting, like kindof happened with HashMap (if indirectly).</p>",
        "id": 222918372,
        "sender_full_name": "scottmcm",
        "timestamp": 1610741496
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"323979\">Bram van den Heuvel</span> <a href=\"#narrow/stream/122651-general/topic/Performance.20tuning.20BTree/near/222894753\">said</a>:</p>\n<blockquote>\n<p><a href=\"/user_uploads/4715/crir0IeMKBaV54lwjI6e47AK/timings.ods\">Here</a> are some of the runs I did today, in case it interests you.</p>\n</blockquote>\n<p>Wait, \"capacity 6\" and \"capacity 8\"? Those are odd because they're not odd. Capacity = 2B - 1 = always odd?</p>",
        "id": 222920592,
        "sender_full_name": "Stein Somers",
        "timestamp": 1610742470
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"257813\">@Stein Somers</span> there is  a constant defined in the node module, I tweaked that.</p>",
        "id": 222927877,
        "sender_full_name": "Bram van den Heuvel",
        "timestamp": 1610746082
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"257813\">@Stein Somers</span> I find it a bit suspect that all configurations seem to be better than the current state, which is why I fear that the tests weren't quite done right. The ugly copy-paste of bench output at the bottom is another run of the current state, it however gave the same results.</p>",
        "id": 222928275,
        "sender_full_name": "Bram van den Heuvel",
        "timestamp": 1610746310
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"323979\">Bram van den Heuvel</span> <a href=\"#narrow/stream/122651-general/topic/Performance.20tuning.20BTree/near/222927877\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"257813\">Stein Somers</span> there is  a constant defined in the node module, I tweaked that.</p>\n</blockquote>\n<p>But which constant? If you tweak CAPACITY and it no longer equals 2B-1, some methods won't do what they're supposed to do. Unit tests show it but benchmarks usually don't test the results they obtain. I would expect some to crash, thanks to all unsafe code, but when I try B=6, CAPACITY=8, the benchmarks actually complete as if all is well, whatever they actually test.</p>\n<p>When I try different values of B (4, 5, 6, 7, 8, 9, 10, 12, 16). on Windows x64, smaller than the default 6 is slower, bigger is faster, much bigger is slower again. The ideal would be 8 or 9.</p>\n<p>The discussion I remembered is the first review discussion on <a href=\"https://github.com/rust-lang/rust/pull/17334/files#diff-0fbf0f551021f7c23fb61b403f5688ffaf8a767ceec795f73ea363a2f431ffb6\">map.rs in the complete btree rewrite\n#17334</a>. As far as I can tell, the number 6 was introduced at that point (over 6 years ago). Was it thoroughly assessed? There are clues that it wasn't: the comment next to it \"//FIXME(Gankro): Tune this as a function of size_of&lt;K/V&gt;?\", the fact that <a href=\"https://en.wikipedia.org/wiki/B-tree\">the Wikipedia article</a> doesn't mention <code>B</code> as a parameter at all but speaks of order. Since then, data has been removed (like <code>b</code>) and some added (back pointers).</p>",
        "id": 222950479,
        "sender_full_name": "Stein Somers",
        "timestamp": 1610761675
    },
    {
        "content": "<p>@SteinSomers You're right, I meant to say I tuned different values of B, of course. Capacity being a function of B. I was careless in the communication, my apologies.</p>\n<p>Interesting to see that values of 8 or 9 are best on your setup. What if you do binary search instead? Can you go even higher? <a href=\"https://github.com/vandenheuvel/rust/commit/abb2097f2a9103c212a9a3b516fc48f00ca760e8\">Example</a></p>",
        "id": 222977589,
        "sender_full_name": "Bram van den Heuvel",
        "timestamp": 1610798394
    },
    {
        "content": "<p>I'll try later. Part of your binary search code looks like the previous slice access code. I've been trying to reconstruct exactly why we turned away from using a slice (because of <a href=\"https://github.com/rust-lang/rust/issues/73915\">#73915</a>. It seems pretty unlikely that there is actual undefined behaviour in your binary search code, but it might violate the (proposed) stacked borrows rules. I hate it that I still don't seem to understand any of that stuff.</p>",
        "id": 222991631,
        "sender_full_name": "Stein Somers",
        "timestamp": 1610815565
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"323979\">Bram van den Heuvel</span> <a href=\"#narrow/stream/122651-general/topic/Performance.20tuning.20BTree/near/222928275\">said</a>:</p>\n<blockquote>\n<p>I find it a bit suspect that all configurations seem to be better than the current state, which is why I fear that the tests weren't quite done right.</p>\n</blockquote>\n<p>I agree it's suspect, unless perhaps if you're on 32 bit. This is (apart from colors that I can't seem to capture here) my difference between B=4 and B=6:</p>\n<div class=\"codehilite\"><pre><span></span><code>&gt;cargo-benchcmp.exe benchcmp b4 b6 --threshold 3\n name                                           b4 ns/iter  b6 ns/iter  diff ns/iter   diff %  speedup\n btree::map::clone_fat_100                      47,377      45,872            -1,505   -3.18%   x 1.03\n btree::map::clone_fat_100_and_drain_all        134,522     157,490           22,968   17.07%   x 0.85\n btree::map::clone_fat_100_and_drain_half       103,900     112,280            8,380    8.07%   x 0.93\n btree::map::clone_fat_100_and_pop_all          154,120     175,940           21,820   14.16%   x 0.88\n btree::map::clone_fat_100_and_remove_all       182,725     216,320           33,595   18.39%   x 0.84\n btree::map::clone_fat_100_and_remove_half      120,497     133,360           12,863   10.67%   x 0.90\n btree::map::clone_fat_val_100                  31,679      24,446            -7,233  -22.83%   x 1.30\n btree::map::clone_fat_val_100_and_clear        32,186      24,418            -7,768  -24.13%   x 1.32\n btree::map::clone_fat_val_100_and_drain_all    64,004      59,242            -4,762   -7.44%   x 1.08\n btree::map::clone_fat_val_100_and_drain_half   57,006      51,112            -5,894  -10.34%   x 1.12\n btree::map::clone_fat_val_100_and_into_iter    43,395      35,326            -8,069  -18.59%   x 1.23\n btree::map::clone_fat_val_100_and_pop_all      73,259      68,299            -4,960   -6.77%   x 1.07\n btree::map::clone_fat_val_100_and_remove_half  60,470      53,691            -6,779  -11.21%   x 1.13\n btree::map::clone_slim_100                     5,294       2,119             -3,175  -59.97%   x 2.50\n btree::map::clone_slim_100_and_clear           5,271       2,222             -3,049  -57.84%   x 2.37\n btree::map::clone_slim_100_and_drain_all       6,627       3,632             -2,995  -45.19%   x 1.82\n btree::map::clone_slim_100_and_drain_half      6,262       3,020             -3,242  -51.77%   x 2.07\n btree::map::clone_slim_100_and_into_iter       5,458       2,265             -3,193  -58.50%   x 2.41\n btree::map::clone_slim_100_and_pop_all         7,151       3,823             -3,328  -46.54%   x 1.87\n btree::map::clone_slim_100_and_remove_all      8,324       5,042             -3,282  -39.43%   x 1.65\n btree::map::clone_slim_100_and_remove_half     6,550       3,401             -3,149  -48.08%   x 1.93\n btree::map::clone_slim_10k                     290,405     262,550          -27,855   -9.59%   x 1.11\n btree::map::clone_slim_10k_and_clear           287,933     258,333          -29,600  -10.28%   x 1.11\n btree::map::clone_slim_10k_and_drain_all       416,035     391,235          -24,800   -5.96%   x 1.06\n btree::map::clone_slim_10k_and_drain_half      395,475     359,150          -36,325   -9.19%   x 1.10\n btree::map::clone_slim_10k_and_into_iter       286,853     258,896          -27,957   -9.75%   x 1.11\n btree::map::clone_slim_10k_and_pop_all         454,875     424,620          -30,255   -6.65%   x 1.07\n btree::map::clone_slim_10k_and_remove_all      619,797     592,790          -27,007   -4.36%   x 1.05\n btree::map::clone_slim_10k_and_remove_half     577,440     553,130          -24,310   -4.21%   x 1.04\n btree::map::find_rand_100                      12          13                     1    8.33%   x 0.92\n btree::map::find_rand_10_000                   59          56                    -3   -5.08%   x 1.05\n btree::map::find_seq_100                       11          12                     1    9.09%   x 0.92\n btree::map::find_seq_10_000                    35          37                     2    5.71%   x 0.95\n btree::map::first_and_last_0                   12          10                    -2  -16.67%   x 1.20\n btree::map::first_and_last_100                 42          49                     7   16.67%   x 0.86\n btree::map::first_and_last_10k                 85          61                   -24  -28.24%   x 1.39\n btree::map::insert_rand_100                    40          45                     5   12.50%   x 0.89\n btree::map::insert_rand_10_000                 40          43                     3    7.50%   x 0.93\n btree::map::insert_seq_100                     45          49                     4    8.89%   x 0.92\n btree::map::iter_1m                            14,865      13,879              -986   -6.63%   x 1.07\n btree::map::iteration_1000                     3,418       3,535                117    3.42%   x 0.97\n btree::map::iteration_100000                   618,140     510,870         -107,270  -17.35%   x 1.21\n btree::map::iteration_mut_1000                 3,800       3,982                182    4.79%   x 0.95\n btree::map::iteration_mut_100000               625,930     548,390          -77,540  -12.39%   x 1.14\n btree::map::iteration_mut_20                   70          67                    -3   -4.29%   x 1.04\n btree::map::range_included_excluded            529,918     443,190          -86,728  -16.37%   x 1.20\n btree::map::range_included_included            441,616     522,970           81,354   18.42%   x 0.84\n btree::map::range_included_unbounded           143,018     179,338           36,320   25.40%   x 0.80\n btree::set::clone_100                          5,283       1,918             -3,365  -63.69%   x 2.75\n btree::set::clone_100_and_clear                5,296       1,948             -3,348  -63.22%   x 2.72\n btree::set::clone_100_and_drain_all            6,328       2,921             -3,407  -53.84%   x 2.17\n btree::set::clone_100_and_drain_half           6,103       2,523             -3,580  -58.66%   x 2.42\n btree::set::clone_100_and_into_iter            5,224       1,884             -3,340  -63.94%   x 2.77\n btree::set::clone_100_and_pop_all              5,924       2,546             -3,378  -57.02%   x 2.33\n btree::set::clone_100_and_remove_all           7,086       3,608             -3,478  -49.08%   x 1.96\n btree::set::clone_100_and_remove_half          5,943       2,604             -3,339  -56.18%   x 2.28\n btree::set::clone_10k                          274,580     227,957          -46,623  -16.98%   x 1.20\n btree::set::clone_10k_and_clear                277,315     226,945          -50,370  -18.16%   x 1.22\n btree::set::clone_10k_and_drain_all            380,330     329,383          -50,947  -13.40%   x 1.15\n btree::set::clone_10k_and_drain_half           362,025     309,520          -52,505  -14.50%   x 1.17\n btree::set::clone_10k_and_into_iter            277,903     226,372          -51,531  -18.54%   x 1.23\n btree::set::clone_10k_and_pop_all              356,085     293,573          -62,512  -17.56%   x 1.21\n btree::set::clone_10k_and_remove_all           516,590     438,045          -78,545  -15.20%   x 1.18\n btree::set::clone_10k_and_remove_half          529,180     479,260          -49,920   -9.43%   x 1.10\n btree::set::difference_random_100_vs_10k       3,162       3,298                136    4.30%   x 0.96\n btree::set::difference_random_10k_vs_100       64,625      59,959            -4,666   -7.22%   x 1.08\n btree::set::difference_random_10k_vs_10k       215,760     196,224          -19,536   -9.05%   x 1.10\n btree::set::difference_staggered_100_vs_10k    2,331       2,231               -100   -4.29%   x 1.04\n btree::set::intersection_100_pos_vs_10k_neg    19          18                    -1   -5.26%   x 1.06\n btree::set::intersection_10k_neg_vs_10k_pos    20          19                    -1   -5.00%   x 1.05\n btree::set::intersection_10k_pos_vs_10k_neg    20          19                    -1   -5.00%   x 1.05\n btree::set::intersection_random_10k_vs_10k     192,072     167,036          -25,036  -13.03%   x 1.15\n btree::set::intersection_staggered_100_vs_100  697         653                  -44   -6.31%   x 1.07\n btree::set::intersection_staggered_100_vs_10k  2,152       2,026               -126   -5.86%   x 1.06\n btree::set::intersection_staggered_10k_vs_10k  67,997      62,555            -5,442   -8.00%   x 1.09\n btree::set::is_subset_100_vs_100               544         509                  -35   -6.43%   x 1.07\n btree::set::is_subset_100_vs_10k               1,425       1,775                350   24.56%   x 0.80\n btree::set::is_subset_10k_vs_10k               63,833      59,613            -4,220   -6.61%   x 1.07\n</code></pre></div>\n<p>The mutable benchmarks (those starting with <code>clone_</code> are massively better, as expected, because there are more nodes to clone. <code>clone_fat_</code> seems to fare well, but these are among those benchmarks that tend to change their mind whenever something changes. A few immutable benchmark fare well too, but the mood is overwhelmingly for B=6.</p>",
        "id": 222996455,
        "sender_full_name": "Stein Somers",
        "timestamp": 1610820491
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"257813\">Stein Somers</span> <a href=\"#narrow/stream/122651-general/topic/Performance.20tuning.20BTree/near/222991631\">said</a>:</p>\n<blockquote>\n<p>I'll try later. Part of your binary search code looks like the previous slice access code. I've been trying to reconstruct exactly why we turned away from using a slice (because of <a href=\"https://github.com/rust-lang/rust/issues/73915\">#73915</a>. It seems pretty unlikely that there is actual undefined behaviour in your binary search code, but it might violate the (proposed) stacked borrows rules. I hate it that I still don't seem to understand any of that stuff.</p>\n</blockquote>\n<p>I'm afraid I don't understand it either!</p>",
        "id": 223200429,
        "sender_full_name": "Bram van den Heuvel",
        "timestamp": 1611046676
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"257813\">Stein Somers</span> <a href=\"#narrow/stream/122651-general/topic/Performance.20tuning.20BTree/near/222996455\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"323979\">Bram van den Heuvel</span> <a href=\"#narrow/stream/122651-general/topic/Performance.20tuning.20BTree/near/222928275\">said</a>:</p>\n<blockquote>\n<p>I find it a bit suspect that all configurations seem to be better than the current state, which is why I fear that the tests weren't quite done right.</p>\n</blockquote>\n<p>I agree it's suspect, unless perhaps if you're on 32 bit. This is (apart from colors that I can't seem to capture here) my difference between B=4 and B=6:</p>\n<div class=\"codehilite\"><pre><span></span><code>&gt;cargo-benchcmp.exe benchcmp b4 b6 --threshold 3\n name                                           b4 ns/iter  b6 ns/iter  diff ns/iter   diff %  speedup\n btree::map::clone_fat_100                      47,377      45,872            -1,505   -3.18%   x 1.03\n btree::map::clone_fat_100_and_drain_all        134,522     157,490           22,968   17.07%   x 0.85\n btree::map::clone_fat_100_and_drain_half       103,900     112,280            8,380    8.07%   x 0.93\n btree::map::clone_fat_100_and_pop_all          154,120     175,940           21,820   14.16%   x 0.88\n btree::map::clone_fat_100_and_remove_all       182,725     216,320           33,595   18.39%   x 0.84\n btree::map::clone_fat_100_and_remove_half      120,497     133,360           12,863   10.67%   x 0.90\n btree::map::clone_fat_val_100                  31,679      24,446            -7,233  -22.83%   x 1.30\n btree::map::clone_fat_val_100_and_clear        32,186      24,418            -7,768  -24.13%   x 1.32\n btree::map::clone_fat_val_100_and_drain_all    64,004      59,242            -4,762   -7.44%   x 1.08\n btree::map::clone_fat_val_100_and_drain_half   57,006      51,112            -5,894  -10.34%   x 1.12\n btree::map::clone_fat_val_100_and_into_iter    43,395      35,326            -8,069  -18.59%   x 1.23\n btree::map::clone_fat_val_100_and_pop_all      73,259      68,299            -4,960   -6.77%   x 1.07\n btree::map::clone_fat_val_100_and_remove_half  60,470      53,691            -6,779  -11.21%   x 1.13\n btree::map::clone_slim_100                     5,294       2,119             -3,175  -59.97%   x 2.50\n btree::map::clone_slim_100_and_clear           5,271       2,222             -3,049  -57.84%   x 2.37\n btree::map::clone_slim_100_and_drain_all       6,627       3,632             -2,995  -45.19%   x 1.82\n btree::map::clone_slim_100_and_drain_half      6,262       3,020             -3,242  -51.77%   x 2.07\n btree::map::clone_slim_100_and_into_iter       5,458       2,265             -3,193  -58.50%   x 2.41\n btree::map::clone_slim_100_and_pop_all         7,151       3,823             -3,328  -46.54%   x 1.87\n btree::map::clone_slim_100_and_remove_all      8,324       5,042             -3,282  -39.43%   x 1.65\n btree::map::clone_slim_100_and_remove_half     6,550       3,401             -3,149  -48.08%   x 1.93\n btree::map::clone_slim_10k                     290,405     262,550          -27,855   -9.59%   x 1.11\n btree::map::clone_slim_10k_and_clear           287,933     258,333          -29,600  -10.28%   x 1.11\n btree::map::clone_slim_10k_and_drain_all       416,035     391,235          -24,800   -5.96%   x 1.06\n btree::map::clone_slim_10k_and_drain_half      395,475     359,150          -36,325   -9.19%   x 1.10\n btree::map::clone_slim_10k_and_into_iter       286,853     258,896          -27,957   -9.75%   x 1.11\n btree::map::clone_slim_10k_and_pop_all         454,875     424,620          -30,255   -6.65%   x 1.07\n btree::map::clone_slim_10k_and_remove_all      619,797     592,790          -27,007   -4.36%   x 1.05\n btree::map::clone_slim_10k_and_remove_half     577,440     553,130          -24,310   -4.21%   x 1.04\n btree::map::find_rand_100                      12          13                     1    8.33%   x 0.92\n btree::map::find_rand_10_000                   59          56                    -3   -5.08%   x 1.05\n btree::map::find_seq_100                       11          12                     1    9.09%   x 0.92\n btree::map::find_seq_10_000                    35          37                     2    5.71%   x 0.95\n btree::map::first_and_last_0                   12          10                    -2  -16.67%   x 1.20\n btree::map::first_and_last_100                 42          49                     7   16.67%   x 0.86\n btree::map::first_and_last_10k                 85          61                   -24  -28.24%   x 1.39\n btree::map::insert_rand_100                    40          45                     5   12.50%   x 0.89\n btree::map::insert_rand_10_000                 40          43                     3    7.50%   x 0.93\n btree::map::insert_seq_100                     45          49                     4    8.89%   x 0.92\n btree::map::iter_1m                            14,865      13,879              -986   -6.63%   x 1.07\n btree::map::iteration_1000                     3,418       3,535                117    3.42%   x 0.97\n btree::map::iteration_100000                   618,140     510,870         -107,270  -17.35%   x 1.21\n btree::map::iteration_mut_1000                 3,800       3,982                182    4.79%   x 0.95\n btree::map::iteration_mut_100000               625,930     548,390          -77,540  -12.39%   x 1.14\n btree::map::iteration_mut_20                   70          67                    -3   -4.29%   x 1.04\n btree::map::range_included_excluded            529,918     443,190          -86,728  -16.37%   x 1.20\n btree::map::range_included_included            441,616     522,970           81,354   18.42%   x 0.84\n btree::map::range_included_unbounded           143,018     179,338           36,320   25.40%   x 0.80\n btree::set::clone_100                          5,283       1,918             -3,365  -63.69%   x 2.75\n btree::set::clone_100_and_clear                5,296       1,948             -3,348  -63.22%   x 2.72\n btree::set::clone_100_and_drain_all            6,328       2,921             -3,407  -53.84%   x 2.17\n btree::set::clone_100_and_drain_half           6,103       2,523             -3,580  -58.66%   x 2.42\n btree::set::clone_100_and_into_iter            5,224       1,884             -3,340  -63.94%   x 2.77\n btree::set::clone_100_and_pop_all              5,924       2,546             -3,378  -57.02%   x 2.33\n btree::set::clone_100_and_remove_all           7,086       3,608             -3,478  -49.08%   x 1.96\n btree::set::clone_100_and_remove_half          5,943       2,604             -3,339  -56.18%   x 2.28\n btree::set::clone_10k                          274,580     227,957          -46,623  -16.98%   x 1.20\n btree::set::clone_10k_and_clear                277,315     226,945          -50,370  -18.16%   x 1.22\n btree::set::clone_10k_and_drain_all            380,330     329,383          -50,947  -13.40%   x 1.15\n btree::set::clone_10k_and_drain_half           362,025     309,520          -52,505  -14.50%   x 1.17\n btree::set::clone_10k_and_into_iter            277,903     226,372          -51,531  -18.54%   x 1.23\n btree::set::clone_10k_and_pop_all              356,085     293,573          -62,512  -17.56%   x 1.21\n btree::set::clone_10k_and_remove_all           516,590     438,045          -78,545  -15.20%   x 1.18\n btree::set::clone_10k_and_remove_half          529,180     479,260          -49,920   -9.43%   x 1.10\n btree::set::difference_random_100_vs_10k       3,162       3,298                136    4.30%   x 0.96\n btree::set::difference_random_10k_vs_100       64,625      59,959            -4,666   -7.22%   x 1.08\n btree::set::difference_random_10k_vs_10k       215,760     196,224          -19,536   -9.05%   x 1.10\n btree::set::difference_staggered_100_vs_10k    2,331       2,231               -100   -4.29%   x 1.04\n btree::set::intersection_100_pos_vs_10k_neg    19          18                    -1   -5.26%   x 1.06\n btree::set::intersection_10k_neg_vs_10k_pos    20          19                    -1   -5.00%   x 1.05\n btree::set::intersection_10k_pos_vs_10k_neg    20          19                    -1   -5.00%   x 1.05\n btree::set::intersection_random_10k_vs_10k     192,072     167,036          -25,036  -13.03%   x 1.15\n btree::set::intersection_staggered_100_vs_100  697         653                  -44   -6.31%   x 1.07\n btree::set::intersection_staggered_100_vs_10k  2,152       2,026               -126   -5.86%   x 1.06\n btree::set::intersection_staggered_10k_vs_10k  67,997      62,555            -5,442   -8.00%   x 1.09\n btree::set::is_subset_100_vs_100               544         509                  -35   -6.43%   x 1.07\n btree::set::is_subset_100_vs_10k               1,425       1,775                350   24.56%   x 0.80\n btree::set::is_subset_10k_vs_10k               63,833      59,613            -4,220   -6.61%   x 1.07\n</code></pre></div>\n<p>The mutable benchmarks (those starting with <code>clone_</code> are massively better, as expected, because there are more nodes to clone. <code>clone_fat_</code> seems to fare well, but these are among those benchmarks that tend to change their mind whenever something changes. A few immutable benchmark fare well too, but the mood is overwhelmingly for B=6.</p>\n</blockquote>\n<p>I'm not on 32 bit. I repeated the benches for the current state once and got similar results though.</p>",
        "id": 223200509,
        "sender_full_name": "Bram van den Heuvel",
        "timestamp": 1611046714
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"323979\">Bram van den Heuvel</span> [said]<a href=\"https://github.com/vandenheuvel/rust/commit/abb2097f2a9103c212a9a3b516fc48f00ca760e8\">Example</a></p>\n<p>Never mind stacked borrow rules, that code is broken. The keys to search in are not<code>self.keys</code> but <code>self.keys[..len]</code>. So your binary search is predominantly reading random, probably zero-initialized memory.</p>",
        "id": 223385334,
        "sender_full_name": "Stein Somers",
        "timestamp": 1611155224
    },
    {
        "content": "<p>I'm somewhat sure what was wrong with the previous slice access code and fixed it, and supplanted the good part of your binary search on top of it at <a href=\"https://github.com/ssomers/rust/tree/btree_binary_search\">my btree_binary_search branch</a>. Time to start measuring.</p>",
        "id": 223418113,
        "sender_full_name": "Stein Somers",
        "timestamp": 1611169000
    },
    {
        "content": "<p>With the right code, from my measurements, binary search doesn't help and instead somewhat harms performance. Also, inverting the linear search also has a slight penalty. My earlier diagnosis that for linear search, B=8 or 9 is better is a bit dubious: mutable tests are a lot better, obviously because there are fewer allocations, but immutable tests are on the decline above 7. Also, for 32-bit, that's above 6. So, on my Intel Core i5-9400F CPU, it seems the current code and B=6 is the best for 32 bit builds, B=7 would be better for 64 bit builds only.</p>",
        "id": 223541031,
        "sender_full_name": "Stein Somers",
        "timestamp": 1611249430
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"257813\">@Stein Somers</span> did you also try binary search for larger values of <code>B</code>? Maybe it starts to shine there.<br>\nThanks regardless for the more elaborate analysis and clearing this up.</p>",
        "id": 223880324,
        "sender_full_name": "Bram van den Heuvel",
        "timestamp": 1611571791
    },
    {
        "content": "<p>I tried up to B=12. The results clearly say binary search is worse, much more than they say that B=12 does worse than B=6 with linear search. B=12 pretty much means only 12 elements per array in these benchmarks. I'll try something bigger because clearly there should be some point at which binary search pays off.</p>",
        "id": 223882117,
        "sender_full_name": "Stein Somers",
        "timestamp": 1611572928
    },
    {
        "content": "<p>Another surprise came up: on Windows, the size limit per key-value pair is &lt; 24KB, and this reduces linearly with increasing B. So some of the benchmarks bail out with stack overflow.</p>\n<p>Anyway, for B=24, the linear and binary seem on par. For B=36, it's like linear takes the edge again. But at B=48, linear is clearly unable to catch up. At B=60, linear is eating binary's dust.</p>",
        "id": 223927330,
        "sender_full_name": "Stein Somers",
        "timestamp": 1611594024
    }
]