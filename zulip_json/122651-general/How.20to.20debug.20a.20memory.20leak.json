[
    {
        "content": "<p>I have a language server implemented in Rust, and I have noticed that it consumes far more memory than it is expected to, especially over time and use. I don't know if the problem is a memory leak in the strict sense of leaked allocated memory (which is possible as the program contains a lisp interpreter using Arc's behind the scene and perhaps Arc cycles are getting away) or whether one of my data structures is simply holding on to references it doesn't need to. I have no idea where in the program the issue is, I have only a 1000-km view of the situation. What techniques can I use to narrow down the problem to something more actionable?</p>\n<p>I have tried using <a href=\"https://github.com/japaric/rust-san\">rust-san</a> but because it is a language server the provided interface (using environment variables to start it and communicating on standard out) conflicts with testing in situ (where it is run by the editor using a fixed command string and IO is used for communication with the editor).</p>",
        "id": 199954287,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591414996
    },
    {
        "content": "<p>One thing which would be great is a way to take a \"census\" of the owned allocated memory, similar to the view a garbage collector would have, perhaps using some macros? Is there a crate out there for this kind of thing?</p>",
        "id": 199954390,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591415229
    },
    {
        "content": "<p>There's <a href=\"https://valgrind.org/docs/manual/dh-manual.html\">DHAT</a>, but it might be a bit low-level for you. You don't get a report aggregated by type like in a managed language, but by allocation stack trace.</p>",
        "id": 199957424,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591421642
    },
    {
        "content": "<blockquote>\n<p>because it is a language server the provided interface (using environment variables to start it and communicating on standard out) conflicts with testing in situ (where it is run by the editor using a fixed command string and IO is used for communication with the editor)</p>\n</blockquote>\n<p>Actually, being a language server might be a great thing. You could record the LSP trace (use it for a couple of hours) and play it back to a fresh instance of the server in a matter of seconds. You could even add it to CI to make sure you don't regress performance or memory usage.</p>",
        "id": 199957469,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591421730
    },
    {
        "content": "<p>Is there a way to run valgrind/DHAT/rust-san in a way so that it outputs to a file that I specify in the server code itself (rather than using command line inputs)?</p>",
        "id": 199958094,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591422908
    },
    {
        "content": "<p>These set ups all seem to assume that stdout is free for printing tracing info but this immediately crashes the editor connection because it's expecting JSON</p>",
        "id": 199958140,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591422971
    },
    {
        "content": "<p>I don't think so. You could also write a wrapper script that launches <code>valgrind</code> with the parameters you expect and use it as the LSP server</p>",
        "id": 199958151,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591422993
    },
    {
        "content": "<p>I think they log to <code>stderr</code>, not <code>stdout</code>?</p>",
        "id": 199958156,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591423015
    },
    {
        "content": "<p>that's a good point, I <em>think</em> that vscode should forward stderr output to its own output console rather than crash and burn</p>",
        "id": 199958202,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423068
    },
    {
        "content": "<p>It does, see <a href=\"https://github.com/rust-analyzer/rust-analyzer/tree/master/docs/dev#logging\">https://github.com/rust-analyzer/rust-analyzer/tree/master/docs/dev#logging</a></p>",
        "id": 199958246,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591423104
    },
    {
        "content": "<p>and with your unit test idea it doesn't matter since the simulated client isn't paying attention to what the server says</p>",
        "id": 199958247,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423107
    },
    {
        "content": "<p>Yeah. You could record and compare it to a known good output, but..</p>",
        "id": 199958264,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591423161
    },
    {
        "content": "<p>but I tried enabling leak check and noticed no difference, no output or anything and I haven't yet figured out whether I didn't turn it on right or whether I actually have no leaks</p>",
        "id": 199958268,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423168
    },
    {
        "content": "<p>If you don't call <code>mem::forget</code> or have leaks in some native libraries, you probably don't have leaks <em>per se</em> (though you can still e.g. make reference cycles).</p>",
        "id": 199958313,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591423203
    },
    {
        "content": "<p>well like I said, arc cycles are a possibility, although it should only matter if the language source I'm reading does some funny business</p>",
        "id": 199958335,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423259
    },
    {
        "content": "<p>originally I estimated that this is not a major concern and I have not yet had the facility to test that estimation</p>",
        "id": 199958355,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423311
    },
    {
        "content": "<p>Do you support those reader macros things -- how are they called? The <code>#1=(1 2 . #1#)</code> syntax.</p>",
        "id": 199958401,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591423334
    },
    {
        "content": "<p>It has mutable cells and function closures, so you can tie up loops if you want to but it would be weird code</p>",
        "id": 199958413,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423382
    },
    {
        "content": "<p>not directly but you can simulate them with refs</p>",
        "id": 199958424,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423421
    },
    {
        "content": "<p>But only at run-time, right? And so your LSP server won't evaluate them?</p>",
        "id": 199958475,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591423486
    },
    {
        "content": "<p>The code is evaluated on the spot</p>",
        "id": 199958482,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423507
    },
    {
        "content": "<p>The language isn't actually lisp, lisp is the macro language for my language</p>",
        "id": 199958485,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423528
    },
    {
        "content": "<p>Ah</p>",
        "id": 199958493,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591423539
    },
    {
        "content": "<p>I suspect the problem is that the server is holding on to environment data for all old versions of a file, but it seems like most attempts to profile it would require large code changes</p>",
        "id": 199958550,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423616
    },
    {
        "content": "<p>Or small changes repeated a lot of times. Like removing and adding back code or something like that. You could probably edit the LSP trace to get e.g. a million of those.</p>",
        "id": 199958603,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591423704
    },
    {
        "content": "<p>in theory it should maintain constant memory over a workload like that</p>",
        "id": 199958611,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423746
    },
    {
        "content": "<p>Is there an easy way to obtain an LSP trace? I guess the server can pass what it sees to a file</p>",
        "id": 199958658,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591423826
    },
    {
        "content": "<p>VS Code can also produce a trace, there's a special <code>\"extension-name.trace.server\": \"verbose\"</code> setting, but it adds some timestamps or such to every request. I guess logging from the server would be the easiest? Another trick I used once was to write a small program that spawns the server and logs its stdin/stdout to files.</p>",
        "id": 199958660,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591423855
    },
    {
        "content": "<p>ah, something like <code>server.sh</code> containing <code>tee lsp.log | server</code></p>",
        "id": 199958725,
        "sender_full_name": "Mario Carneiro",
        "timestamp": 1591424017
    },
    {
        "content": "<p>Sigh. I wrote some Rust code for it. <code>tee stdin.log | server | tee stdout.log</code> might have done the trick.</p>",
        "id": 199958772,
        "sender_full_name": "Laurențiu",
        "timestamp": 1591424097
    }
]