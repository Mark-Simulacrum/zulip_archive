[
    {
        "content": "<p>XXHash (and thus <a href=\"https://github.com/shepmaster/twox-hash\" target=\"_blank\" title=\"https://github.com/shepmaster/twox-hash\">twox-hash</a>) derives a large part of its speed from treating <code>&amp;[u8]</code> as <code>&amp;[u64]</code> (or <code>&amp;[u32]</code>). I recently rewrote it to take advantage of <code>slice::align_to</code>, which made the code much nicer (hooray!). However, it also tanked the performance for unaligned input data (e.g. 10.5 Gb/sec -&gt; 4.5 Gb/sec).</p>\n<p>Would it be (a) correct and (b) memory safe to ignore this alignment <em>on X86 / X86_64 only</em>, falling back to the <code>align_to</code> version on other platforms?</p>",
        "id": 171897617,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564335794
    },
    {
        "content": "<p>Doing an unaligned load is UB in Rust no matter the target architecture</p>",
        "id": 171898324,
        "sender_full_name": "RalfJ",
        "timestamp": 1564337144
    },
    {
        "content": "<p>we set the appropriate attributes so LLVM will optimize assuming pointers are aligned</p>",
        "id": 171898365,
        "sender_full_name": "RalfJ",
        "timestamp": 1564337185
    },
    {
        "content": "<p>I don't know exactly what this entails, <span class=\"user-mention\" data-user-id=\"124289\">@rkruppe</span> would likely know more -- but for now, the answer to your question is \"no\" on both accounts</p>",
        "id": 171898369,
        "sender_full_name": "RalfJ",
        "timestamp": 1564337213
    },
    {
        "content": "<p>are you saying that XXHash/twox-hash currently performs such unaligned loads? Or why did things get slowed with <code>align_to</code>?</p>",
        "id": 171898377,
        "sender_full_name": "RalfJ",
        "timestamp": 1564337254
    },
    {
        "content": "<p>Using <code>ptr::read_unaligned</code> instead of references/normal accesses is necessary to the avoid UB Ralf mentioned. That will kill some generic peephole optimizations which probably aren't important for this kind of code, and for x86 it shouldn't influence the final machine code (except the trivial movaps -&gt; movups if any SIMD is introduced).</p>",
        "id": 171898677,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1564337875
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124289\">@rkruppe</span> I guess one question here is how costly it would be to make the \"unaligned deref is UB\" be a target-dependent property and <em>not</em> require this for x86</p>",
        "id": 171898722,
        "sender_full_name": "RalfJ",
        "timestamp": 1564337937
    },
    {
        "content": "<p>Making it target-dependent would be pretty gross</p>",
        "id": 171898728,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1564337955
    },
    {
        "content": "<p>fair. I am asking mostly because I saw code in the wild in rust-lang crates (<code>rand</code>) that assumed it actually was target-dependent... so this is likely a common misconception.</p>",
        "id": 171898889,
        "sender_full_name": "RalfJ",
        "timestamp": 1564338298
    },
    {
        "content": "<p>I've been thinking about this for a couple minutes and none of my concerns are about LLVM optimizations (well, except one which is presumably temporary and avoidable)</p>",
        "id": 171898904,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1564338339
    },
    {
        "content": "<p>one issue with allowing it on x86 is that if people only run Miri on x86, they wouldn't get the error, thus missing this UB-- of course this applies to all target-dependent UB but this seems like a more subtle one. the issue in <code>rand</code> was only found because I ran it in Miri.</p>",
        "id": 171899077,
        "sender_full_name": "RalfJ",
        "timestamp": 1564338636
    },
    {
        "content": "<p>Some things that worry me are: the effect this will have on the ecosystem (code that's non-portable in undetectable ways -- currently, even if unaligned accesses are not \"miscompiled\" on x86, miri and lints and docs can steer away from it unconditionally); how people would probably request structs to be packed automatically on such targets; what that would do to type-pun-ability between atomics and normal data (since atomics do require alignment even on x86); the fact that in today's software unaligned accesses are rather limited so there might still be some non-obvious performance cliffs in some hardware</p>",
        "id": 171899090,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1564338679
    },
    {
        "content": "<p>Oh also, I can feel in my bones that as soon as we open this pandora's box, people are going to request it as option for other targets too, including those where only some chips support unaligned loads/stores (efficiently). e.g. doing this for the baseline risc-v targets is probably not a good idea because implementations that trap &amp; emulate on unaligned accesses are encouraged, but if someone's targeting only chips that support it efficiently and natively, they'll want the non-UB as much as x86 people</p>",
        "id": 171899170,
        "sender_full_name": "Hanna Kruppe",
        "timestamp": 1564338830
    },
    {
        "content": "<blockquote>\n<p>are you saying that XXHash/twox-hash currently performs such unaligned loads</p>\n</blockquote>\n<p>Version 1.3 <a href=\"https://github.com/shepmaster/twox-hash/blob/v1.3.0/src/number_streams.rs#L37-L44\" target=\"_blank\" title=\"https://github.com/shepmaster/twox-hash/blob/v1.3.0/src/number_streams.rs#L37-L44\">took a <code>&amp;[u8]</code> and got a <code>*const u64</code></a>, then did <a href=\"https://github.com/shepmaster/twox-hash/blob/v1.3.0/src/number_streams.rs#L56\" target=\"_blank\" title=\"https://github.com/shepmaster/twox-hash/blob/v1.3.0/src/number_streams.rs#L56\"><code>ptr::read</code></a>. I guess that's incorrect and should have been <code>read_unaligned</code>, but it was presumably <strong>close</strong> to being right.</p>\n<p>Version 1.4 <a href=\"https://github.com/shepmaster/twox-hash/blob/v1.4.2/src/lib.rs#L72-L88\" target=\"_blank\" title=\"https://github.com/shepmaster/twox-hash/blob/v1.4.2/src/lib.rs#L72-L88\">switched to <code>slice::align_to</code></a>, which should be easier to verify as correct. The problem is that the unaligned data \"percolates\" through the entire computation because it gets buffered internally. It can only speed up again if we finish that internal buffer and the remainder is aligned (not super likely).</p>",
        "id": 171899461,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564339408
    },
    {
        "content": "<p>However, <a href=\"https://github.com/Cyan4973/xxHash/blob/dev/xxhash.c\" target=\"_blank\" title=\"https://github.com/Cyan4973/xxHash/blob/dev/xxhash.c\">XXHash is C code</a>. It's relatively readable, but I'm not 100% I'll state what it does correctly. I think it basically says \"am I x86? if so, just cast the buffer\"</p>",
        "id": 171899514,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564339482
    },
    {
        "content": "<p>It sounds like I need to change my abstraction to a platform-specific type that, given a <code>&amp;[u8]</code>, can return an iterator of leading <code>u8</code>, an iterator of <code>u64</code>, and an iterator of trailing <code>u8</code>. I can implement that with <code>align_to</code> on non-x86, and raw pointers and <code>read_unaligned</code> on x86.</p>",
        "id": 171899746,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564339901
    },
    {
        "content": "<p>I’m surprised align_to would cause a 50% perf hit, unless your test buffers are super small.</p>",
        "id": 171899862,
        "sender_full_name": "nagisa",
        "timestamp": 1564340058
    },
    {
        "content": "<p>Aligning u8 -&gt; u64 is at most 10 cycles of instructions.</p>",
        "id": 171899873,
        "sender_full_name": "nagisa",
        "timestamp": 1564340088
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124289\">@rkruppe</span> I generally agree. Those are some good arguments. Also see <a href=\"https://github.com/rust-lang/rust/issues/53871\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/issues/53871\">https://github.com/rust-lang/rust/issues/53871</a> and <a href=\"https://github.com/rust-lang/rust/issues/54915\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/issues/54915\">https://github.com/rust-lang/rust/issues/54915</a> which would be undermined by this.<br>\nThough we could do what we do for overflow, which is to say that on some platforms an unaligned access will either panic or succeed -- but not cause UB.</p>",
        "id": 171899887,
        "sender_full_name": "RalfJ",
        "timestamp": 1564340106
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116155\">@Jake Goulding</span> </p>\n<blockquote>\n<p>Version 1.3 took a &amp;[u8] and got a *const u64, then did ptr::read. I guess that's incorrect and should have been read_unaligned, but it was presumably close to being right.</p>\n</blockquote>\n<p>not sure what your measure of distance is here, but this is indeed an unaligned access and hence UB. but using <code>read_unaligned</code> instead is probably an easy fix (and maybe \"how hard is it to fix\" was your measure of distance here?)</p>",
        "id": 171899940,
        "sender_full_name": "RalfJ",
        "timestamp": 1564340201
    },
    {
        "content": "<p>FWIW x86 does not universally support unaligned loads/stores transparently once you get to SSE/AVX. If the compiler thinks that it should be using aligned sse load to load from an address and that address ends up being insufficiently aligned, code will not run.</p>",
        "id": 171899996,
        "sender_full_name": "nagisa",
        "timestamp": 1564340326
    },
    {
        "content": "<p>there's also <a href=\"https://doc.rust-lang.org/std/primitive.pointer.html#method.align_offset-1\" target=\"_blank\" title=\"https://doc.rust-lang.org/std/primitive.pointer.html#method.align_offset-1\">ptr::align_offset</a> which gives you the basics of <code>align_to</code> if <code>align_to</code> is overkill for your situation</p>",
        "id": 171900064,
        "sender_full_name": "oli",
        "timestamp": 1564340408
    },
    {
        "content": "<p>In general I haven’t found a situation where <code>align_to</code> would be inferior to  <code>align_offset</code>. Compiler will aggressively eliminate portions of <code>align_to</code> that end up computing unnecessary stuff</p>",
        "id": 171900082,
        "sender_full_name": "nagisa",
        "timestamp": 1564340491
    },
    {
        "content": "<p>(such as would be the case if you did not use the last slice of unaligned elements)</p>",
        "id": 171900126,
        "sender_full_name": "nagisa",
        "timestamp": 1564340528
    },
    {
        "content": "<p>My suspicion why the perf hit occurred is that the implementation ends up calling <code>align_to</code> in a fairly hot loop..</p>",
        "id": 171900214,
        "sender_full_name": "nagisa",
        "timestamp": 1564340760
    },
    {
        "content": "<p><a href=\"https://github.com/shepmaster/twox-hash/commit/da2c45433688eb1117bf84f4f3532397b089198f#diff-0fddf2104b2e6fa6ab0ec32025ee9f1bR166\" target=\"_blank\" title=\"https://github.com/shepmaster/twox-hash/commit/da2c45433688eb1117bf84f4f3532397b089198f#diff-0fddf2104b2e6fa6ab0ec32025ee9f1bR166\">https://github.com/shepmaster/twox-hash/commit/da2c45433688eb1117bf84f4f3532397b089198f#diff-0fddf2104b2e6fa6ab0ec32025ee9f1bR166</a> for example appears to be using <code>align_to</code> mostly to \"just\" extract the aligned portion of the data that’s expected to be 1x4xu64.</p>",
        "id": 171900270,
        "sender_full_name": "nagisa",
        "timestamp": 1564340843
    },
    {
        "content": "<blockquote>\n<p>I’m surprised align_to would cause a 50% perf hit, unless your test buffers are super small.</p>\n</blockquote>\n<p>Basically, the algo wants to deal with <code>[u64; 4]</code> chunks. If we read from a <code>&amp;[u8]</code>that is one byte misaligned from that, then we slurp in X bytes to fill the buffer, then process it. The remaining data is <em>still</em> misaligned by one byte, so the process repeats.</p>\n<p>In the old <code>ptr::read</code> situation, if we had data in the buffer, we could fill and finish the buffer and then treat the remainder of bytes as big chunks.</p>",
        "id": 171900316,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564340890
    },
    {
        "content": "<blockquote>\n<p><code>read_unaligned</code> instead is probably an easy fix (and maybe \"how hard is it to fix\" was your measure of distance here?</p>\n</blockquote>\n<p>Indeed.</p>",
        "id": 171900393,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564341013
    },
    {
        "content": "<p>Ah, I see. Yeah, to use <code>align_to</code> well, you must have means to process the bytes in head and tail independently.</p>",
        "id": 171900400,
        "sender_full_name": "nagisa",
        "timestamp": 1564341028
    },
    {
        "content": "<p>Right. AFAIK XXHash simply doesn't have that, instead opting to always buffer the data up. </p>\n<p>Now, 5GB is nothing to sneeze at, but knowing that I'm leaving <em>another</em> 5GB/sec behind is aggravating <span aria-label=\"wink\" class=\"emoji emoji-1f609\" role=\"img\" title=\"wink\">:wink:</span></p>",
        "id": 171900425,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564341113
    },
    {
        "content": "<p>I think in your case <span class=\"user-mention\" data-user-id=\"116155\">@Jake Goulding</span> doing a reverse is what you want to do. memcpy your bytes into <code>[u64; 4]</code> basically.</p>",
        "id": 171900484,
        "sender_full_name": "nagisa",
        "timestamp": 1564341160
    },
    {
        "content": "<blockquote>\n<p>FWIW x86 does not universally support unaligned loads/stores transparently [...] code will not run.</p>\n</blockquote>\n<p>Could you expand a bit on what you mean by \"not run\"? There are various ways I could assume that presents.</p>",
        "id": 171900496,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564341202
    },
    {
        "content": "<p>Do you mean to <em>always</em> copy into the buffer? I believe that's effectively what the code does now.</p>",
        "id": 171900550,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564341248
    },
    {
        "content": "<p>well, there're separate instructions for aligned and unaligned load/store in SSE and the CPU will trap if an aligned instruction is used with an mis-aligned address.</p>",
        "id": 171900552,
        "sender_full_name": "nagisa",
        "timestamp": 1564341250
    },
    {
        "content": "<p>That’s probably the most plausible way assumed-to-be-aligned-but-really-misaligned-reads-UB can manifest itself on x86.</p>",
        "id": 171900572,
        "sender_full_name": "nagisa",
        "timestamp": 1564341331
    },
    {
        "content": "<p>Just to clarify for myself, on x86, I can do <code>&amp;[u8] </code> -&gt; <code>*const u8</code> -&gt;  <code>*const [u64; 4]</code> and then <code>ptr::read_unaligned</code> and this shouldn't trigger UB (so long as I stay in bounds of the <code>&amp;[u8]</code>)?</p>",
        "id": 171901099,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564342299
    },
    {
        "content": "<p><code>read_unaligned</code> doesn't make mention of platform-specific things; what happens if I use it on a platform that is more strict about alignment?</p>",
        "id": 171901152,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564342390
    },
    {
        "content": "<blockquote>\n<p>Just to clarify for myself, on x86, I can do <code>&amp;[u8] </code> -&gt; <code>*const u8</code> -&gt;  <code>*const [u64; 4]</code> and then <code>ptr::read_unaligned</code> and this shouldn't trigger UB (so long as I stay in bounds of the <code>&amp;[u8]</code>)?</p>\n</blockquote>\n<p>Yes, that should work.</p>",
        "id": 171901157,
        "sender_full_name": "nagisa",
        "timestamp": 1564342435
    },
    {
        "content": "<blockquote>\n<p><code>read_unaligned</code> doesn't make mention of platform-specific things; what happens if I use it on a platform that is more strict about alignment?</p>\n</blockquote>\n<p>The compiler will have to split reads into aligned parts and stitch the result back into what you want. This could be done as a memcpy under the covers.</p>",
        "id": 171901217,
        "sender_full_name": "nagisa",
        "timestamp": 1564342523
    },
    {
        "content": "<p>hmm. So if I can't do something better than what the compiler does, it might be better for me to use <code>read_unaligned</code> on all the platforms anyway...?</p>",
        "id": 171901268,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564342602
    },
    {
        "content": "<p>Since I'm basically buffering unaligned data in a way that is reminiscent of memcpy</p>",
        "id": 171901392,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564342807
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116155\">@Jake Goulding</span> probably. If you had no bounds on space, you could allocate a properly aligned buffer and copy everything in one go</p>",
        "id": 171905244,
        "sender_full_name": "nagisa",
        "timestamp": 1564349712
    },
    {
        "content": "<p>which would be significantly faster in certain scenarios</p>",
        "id": 171905249,
        "sender_full_name": "nagisa",
        "timestamp": 1564349722
    },
    {
        "content": "<p>seems like a bad API for this case if you have to re-align every 32-byte buffer, instead of being able to process some prefix and then a sequence of properly aligned 32-byte buffers</p>",
        "id": 171905515,
        "sender_full_name": "RalfJ",
        "timestamp": 1564350209
    },
    {
        "content": "<p>I mean the algorithm already has to support smaller chunks, right? what if I hash a <code>u16</code>?</p>",
        "id": 171905560,
        "sender_full_name": "RalfJ",
        "timestamp": 1564350256
    },
    {
        "content": "<blockquote>\n<p>if you have to re-align every 32-byte buffer</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"120791\">@RalfJ</span> certainly, but as I understand it, the algorithm itself was designed assuming x86 semantics. Thus the API itself has some of these assumptions baked-in. The algorithm effectively requires that it be cheap to \"realign\"  </p>\n<blockquote>\n<p>what if I hash a <code>u16</code>?</p>\n</blockquote>\n<p>That's fine, but there's special code both for \"finalizing\" the hash and for the specific case where you only hashed data of length less-than the internal buffer. AFAIK, we can't just \"finish\" the buffer and then keep adding on afterwards.</p>",
        "id": 171907391,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564353702
    },
    {
        "content": "<blockquote>\n<p>allocate a properly aligned buffer and copy everything in one go</p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"123586\">@nagisa</span> I should probably add that to the documentation for those on other architectures.</p>",
        "id": 171907435,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564353762
    },
    {
        "content": "<p>Thank you, RalfJ, rkruppe, and nagisa!</p>",
        "id": 171910481,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1564359983
    }
]