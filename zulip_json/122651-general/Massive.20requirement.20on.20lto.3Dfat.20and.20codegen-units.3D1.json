[
    {
        "content": "<p>Hi, I am working on a project and during optimization I found out that the project very heavily relies on</p>\n<div class=\"codehilite\"><pre><span></span><code>[profile.release]\nlto = &quot;fat&quot;\ncodegen-units = 1\n</code></pre></div>\n<p>in order to have a decent performance.</p>\n<p>The next best configuration I found (which is <code>lto=\"thin\", codegen-units=1</code>) still has 40% worse performance!<br>\nWith the default profile settings I see slowdowns of factor x4-x5.</p>\n<p>What could be the reason for this massive reliance on this particular profile?<br>\nI'd really like the project to be well optimized under default profile settings since users usually forget to set them and they add tons of compile time overhead. I am asking here since usually I see performance improvements in the range of 10-15% with the aforementioned profile but not in the range of 400-500%.</p>\n<p>The following Gist link shows all the data I collected under various profile settings and has a summary:<br>\n<a href=\"https://gist.github.com/Robbepop/0644e9eb000bb1dad6a003a72534263a\">https://gist.github.com/Robbepop/0644e9eb000bb1dad6a003a72534263a</a></p>",
        "id": 268391610,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642513244
    },
    {
        "content": "<p>maybe there are some critical inlining decisions that llvm can only figure out while having the entire program in scope</p>",
        "id": 268392413,
        "sender_full_name": "matthiaskrgr",
        "timestamp": 1642513608
    },
    {
        "content": "<p>I also thought about this but I even tried adding <code>#[inline]</code> pervasively to all functions in the codebase and the speedup under all profiles was very similar than without those annotations.</p>",
        "id": 268392592,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642513684
    },
    {
        "content": "<p>I used flamegraph and found some odd behavior under the settings that are causing the massive slowdowns.</p>\n<p>What confuses me is that <code>execute_until_done</code> is shown there twice in the hierarchy, however, as far as I understand my own code there is absolutely no recursion going on that could cause <code>execute_until_done</code> to call itself again. Also in the fast run this \"recursion\" is shown to be optimized away.</p>\n<p>Can anyone here tell me what this scenario is telling me? <a href=\"/user_uploads/4715/CiaQnQrXYcivkezeCMk8SDva/2022-01-18-180440_1259x666_scrot.png\">2022-01-18-180440_1259x666_scrot.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/4715/CiaQnQrXYcivkezeCMk8SDva/2022-01-18-180440_1259x666_scrot.png\" title=\"2022-01-18-180440_1259x666_scrot.png\"><img src=\"/user_uploads/4715/CiaQnQrXYcivkezeCMk8SDva/2022-01-18-180440_1259x666_scrot.png\"></a></div>",
        "id": 268427549,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642527043
    },
    {
        "content": "<p>Maybe it gets confused by inlining? Although in <code>perf report</code> inlined functions are usually shown properly as long as debug info is available.</p>",
        "id": 268428449,
        "sender_full_name": "The 8472",
        "timestamp": 1642527421
    },
    {
        "content": "<p>Have you tried PGO? Maybe LLVM can make better decision that way without having to resort to fat LTO</p>",
        "id": 268428610,
        "sender_full_name": "The 8472",
        "timestamp": 1642527488
    },
    {
        "content": "<p>I have never touched PGO, need to see how it works in Rust first.<br>\nThe things that confuses me most is that this slowdown happens to the rewrite of some Wasm execution engine that did not happen to the old version. On the good configurations the new engine is a lot faster &gt;30% and on default settings is is almost 400% slower due to this problem.</p>",
        "id": 268428950,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642527650
    },
    {
        "content": "<p>I would not accept this for production usage until the default configs at least sanely optimize the new engine.</p>",
        "id": 268429080,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642527714
    },
    {
        "content": "<p>You could try using <code>perf diff</code> or cachegrind diff and see which hot methods regress. Then do some code golfing to make the code more pleasing to the optimizer. Often it's bound checks or branches that don't get eliminated and then pessimizations cascade from there.</p>",
        "id": 268429792,
        "sender_full_name": "The 8472",
        "timestamp": 1642528019
    },
    {
        "content": "<p>You also should check if it's not a problem with your benchmark. With whole-program-optimization it just might be the case that something gets optimized away because the compiler sees that some result isn't used or the inputs are constant.</p>",
        "id": 268430030,
        "sender_full_name": "The 8472",
        "timestamp": 1642528122
    },
    {
        "content": "<p>In the flamegraph above I can see a very clear distinction that I cannot explain to myself.<br>\nThis is the seemingly recursive call of <code>execute_until_done</code> that does not exist in the better optimized (and super fast) run.<br>\nI can upload a screenshot of the fast run.</p>",
        "id": 268430226,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642528211
    },
    {
        "content": "<p>if the flamegraph isn't detailed enough run <code>perf report</code> and look at the assembly where it's spending cycles</p>",
        "id": 268430686,
        "sender_full_name": "The 8472",
        "timestamp": 1642528435
    },
    {
        "content": "<p><a href=\"/user_uploads/4715/SAy9bLnIFitzZyq0qTs1sv7D/2022-01-18-185551_2533x658_scrot.png\">2022-01-18-185551_2533x658_scrot.png</a></p>\n<div class=\"message_inline_image\"><a href=\"/user_uploads/4715/SAy9bLnIFitzZyq0qTs1sv7D/2022-01-18-185551_2533x658_scrot.png\" title=\"2022-01-18-185551_2533x658_scrot.png\"><img src=\"/user_uploads/4715/SAy9bLnIFitzZyq0qTs1sv7D/2022-01-18-185551_2533x658_scrot.png\"></a></div>",
        "id": 268431031,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642528574
    },
    {
        "content": "<p>The <code>perf report</code> shows black only after loading. I guess I have to learn how to use it first.<br>\nThe 2nd screenshot shows the fast run and as you can see there is no \"recursive\" call to <code>execute_until_done</code> anymore and it looks more like what I expected the other to look like, too.</p>",
        "id": 268431728,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642528837
    },
    {
        "content": "<p>It seems you are just profiling the wasmtime runtime. You need to profile the JITed functions as described here: <a href=\"https://docs.wasmtime.dev/examples-profiling-perf.html\">https://docs.wasmtime.dev/examples-profiling-perf.html</a></p>",
        "id": 268431853,
        "sender_full_name": "Hans Kratz",
        "timestamp": 1642528890
    },
    {
        "content": "<p>I am not trying to profile Wasmtime but the <code>wasmi</code> interpreter.</p>",
        "id": 268431962,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642528923
    },
    {
        "content": "<p>In that case <code>perf</code> will not help you as it gives you no feedback which part of your WASM code the time is spent in.</p>",
        "id": 268432330,
        "sender_full_name": "Hans Kratz",
        "timestamp": 1642529076
    },
    {
        "content": "<p>Well, flamegraphs are relative (unless there's more info on hover?) so it shows a larger fraction of time spent in <code>visit</code>, so to some extent it might be shuffling around code and the issue could be elsewhere. </p>\n<p>You can use <a href=\"https://github.com/KDAB/hotspot\">kdab hotspot</a> to navigate perf recordings a bit better. But it doesn't have the assembly view, so you have to juggle hotspot and <code>perf report</code>.</p>",
        "id": 268432385,
        "sender_full_name": "The 8472",
        "timestamp": 1642529106
    },
    {
        "content": "<p>I assume the goal is profiling the interpreter itself.</p>",
        "id": 268432482,
        "sender_full_name": "The 8472",
        "timestamp": 1642529156
    },
    {
        "content": "<p>I'd assume that there is some time spent in <code>visit_instruction</code> because the majority of the time spent in an interpreter is the dynamic dispatch of instructions which is displayed by <code>visit_instruction</code> taking a long time.</p>",
        "id": 268432561,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642529186
    },
    {
        "content": "<p>Note though that the 2nd flamegraph I uploaded here shows the good run that yields very decent timings and does not need to be optimized further. However, the first graph shows the problematic duplication of the <code>execute_until_done</code> which I seriously cannot explain.</p>",
        "id": 268432646,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642529242
    },
    {
        "content": "<p>We are talking about slowdowns between both graphs of 400-500%.</p>",
        "id": 268432719,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642529277
    },
    {
        "content": "<p>Yeah, but when inlining changes then comparing the graphs can be very misleading. Some changes just redistribute instructions while the blowup lies elsewhere, usually closer to the leaf methods.</p>",
        "id": 268433977,
        "sender_full_name": "The 8472",
        "timestamp": 1642529879
    },
    {
        "content": "<p>In this GitHub issue we collect all information about this strange missed optimization potential:<br>\n<a href=\"https://github.com/paritytech/wasmi/issues/339\">https://github.com/paritytech/wasmi/issues/339</a><br>\nThanks so far for the answers!<br>\nI am trying to do some more research on this and will come back once I found some more details.</p>",
        "id": 268536922,
        "sender_full_name": "Hero Bird",
        "timestamp": 1642598220
    }
]