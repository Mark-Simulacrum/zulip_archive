[
    {
        "content": "<p>I just read on reddit (<a href=\"https://www.reddit.com/r/rust/comments/mykk7x/gpu_compute_shader_for_sha256_using_rust/\">https://www.reddit.com/r/rust/comments/mykk7x/gpu_compute_shader_for_sha256_using_rust/</a>) that rust-gpu allows compute shaders. This is an example: <a href=\"https://github.com/RustyBamboo/hash-shader/blob/main/vulkan/kernel/src/lib.rs#L322-L342\">https://github.com/RustyBamboo/hash-shader/blob/main/vulkan/kernel/src/lib.rs#L322-L342</a></p>\n<p>I'm not sure I fully understand how slices work in Rust yet, but I don't really understand why that example is correct.</p>",
        "id": 238649324,
        "sender_full_name": "hannahE2",
        "timestamp": 1620925262
    },
    {
        "content": "<p>Doesn't every \"thread\" in the compute shader get a copy of the <code>hash: &amp;mut [u32]</code> slice ?</p>\n<p>I'd have thought that having copies of an exclusive reference on multiple threads was exactly what these were designed to prevent.</p>\n<p>Could someone explain how and why this works for someone that's just getting started with Rust?</p>\n<p>Is it ok to have multiple mutable references to the same slice in certain situations?</p>",
        "id": 238649755,
        "sender_full_name": "hannahE2",
        "timestamp": 1620925441
    },
    {
        "content": "<p>cc <span class=\"user-mention\" data-user-id=\"119009\">@eddyb</span> do you work on this maybe?</p>",
        "id": 238649841,
        "sender_full_name": "hannahE2",
        "timestamp": 1620925472
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"409057\">@hannahE2</span> the answer is that isn't at the moment, but other features are needed to make it sound aren't available yet, so it's a known issue, and won't look like that forever.</p>",
        "id": 238672213,
        "sender_full_name": "XAMPPRocky",
        "timestamp": 1620935969
    },
    {
        "content": "<p>alright, I see nobody has rep- oh wow that's a race condition and a half</p>",
        "id": 238672227,
        "sender_full_name": "eddyb",
        "timestamp": 1620935978
    },
    {
        "content": "<p>basically it's WIP, <code>&amp;mut</code> in the interface is almost always going to be wrong</p>",
        "id": 238672259,
        "sender_full_name": "eddyb",
        "timestamp": 1620935999
    },
    {
        "content": "<p>outputs should be <code>&amp;mut MaybeUninit&lt;T&gt;</code> (but ideally returned, maybe in a <code>struct</code>), not <code>&amp;mut T</code>, and any kind of buffer should be shared references with interior mutability</p>",
        "id": 238672471,
        "sender_full_name": "eddyb",
        "timestamp": 1620936067
    },
    {
        "content": "<p>think <code>&amp;[AtomicU32]</code> for your example</p>",
        "id": 238672489,
        "sender_full_name": "eddyb",
        "timestamp": 1620936074
    },
    {
        "content": "<p>(or some kind of wrapper that allows more interesting access patterns)</p>",
        "id": 238672517,
        "sender_full_name": "eddyb",
        "timestamp": 1620936086
    },
    {
        "content": "<blockquote>\n<p>Is it ok to have multiple mutable references to the same slice in certain situations?</p>\n</blockquote>\n<p>never, as far as I'm concerned</p>",
        "id": 238672584,
        "sender_full_name": "eddyb",
        "timestamp": 1620936117
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"409057\">@hannahE2</span> btw if you're not already in the Rust-GPU Discord, you might want to join, since that's the main place of discussion - it's not officially supported (yet :P) so mentions of it on Zulip could get lost</p>",
        "id": 238672742,
        "sender_full_name": "eddyb",
        "timestamp": 1620936172
    },
    {
        "content": "<p>discord requires a valid email address, I don't really like sharing mine to third-parties without a good reason</p>",
        "id": 238744957,
        "sender_full_name": "hannahE2",
        "timestamp": 1620987303
    },
    {
        "content": "<p>So if the input must be <code>&amp;[AtomicU32]</code>, isn't that like super slow?</p>",
        "id": 238744998,
        "sender_full_name": "hannahE2",
        "timestamp": 1620987336
    },
    {
        "content": "<p>i'm just thinking of using atomic loads and stores for all memory accesses that can be written to<br>\nIIRC, on GPUs, atomic accesses require device-wide fences that invalidate all caches.</p>",
        "id": 238745083,
        "sender_full_name": "hannahE2",
        "timestamp": 1620987374
    },
    {
        "content": "<p>So most people use unordered loads/stores, and then synchronize in some other way (group sync's, etc.)</p>",
        "id": 238745126,
        "sender_full_name": "hannahE2",
        "timestamp": 1620987411
    },
    {
        "content": "<p>For someone that wants to learn Rust gpu, is there a good example somewhere of how to implement basic compute kernels correctly and efficiently? I'm think, e.g., a 1D heat conduction kernel with halos and \"thread group\" local memory, and then also how to implement a prefix-sum so that it matches memcpy in speed.</p>",
        "id": 238745273,
        "sender_full_name": "hannahE2",
        "timestamp": 1620987513
    },
    {
        "content": "<p>Ralph had a blogpost about prefix-sum that I really liked showing a decoupled lookback implementation with Vulkan, which is something that can be easily compared with CUDA cub's prefix sum.</p>",
        "id": 238745352,
        "sender_full_name": "hannahE2",
        "timestamp": 1620987578
    },
    {
        "content": "<p>I'd guess one also has to use atomics for slices in \"group private memory\" that will be accessed by different threads, right?</p>",
        "id": 238745984,
        "sender_full_name": "hannahE2",
        "timestamp": 1620987969
    },
    {
        "content": "<p>Are those atomics \"different\" than normal <code>core::atomic</code> types ? Using device-wide atomics and fences for group local atomic accesses would be overkill as well.</p>",
        "id": 238746067,
        "sender_full_name": "hannahE2",
        "timestamp": 1620988019
    },
    {
        "content": "<p>discord requires <em>a</em> email, it doesn't have to be your real main email.</p>",
        "id": 238827415,
        "sender_full_name": "Lokathor",
        "timestamp": 1621025235
    },
    {
        "content": "<p>yeah, doesn't Zulip also require something like that?</p>",
        "id": 238909058,
        "sender_full_name": "eddyb",
        "timestamp": 1621095977
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"409057\">hannahE2</span> <a href=\"#narrow/stream/122651-general/topic/Why.20is.20rust-gpu.20sound.20.3F/near/238745126\">said</a>:</p>\n<blockquote>\n<p>So most people use unordered loads/stores, and then synchronize in some other way (group sync's, etc.)</p>\n</blockquote>\n<p>the non-atomic synchronization would require specialized wrapper types that control the kinds of indices you can use to read/write, IIRC. we don't have that yet</p>",
        "id": 238909191,
        "sender_full_name": "eddyb",
        "timestamp": 1621096129
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"409057\">hannahE2</span> <a href=\"#narrow/stream/122651-general/topic/Why.20is.20rust-gpu.20sound.20.3F/near/238745273\">said</a>:</p>\n<blockquote>\n<p>For someone that wants to learn Rust gpu, is there a good example somewhere of how to implement basic compute kernels correctly and efficiently? I'm think, e.g., a 1D heat conduction kernel with halos and \"thread group\" local memory, and then also how to implement a prefix-sum so that it matches memcpy in speed.</p>\n</blockquote>\n<p>compute shaders aren't a huge focus right now, so some functionality may be missing, but also the people more knowledgeable than me are on the Rust-GPU Discord</p>",
        "id": 238909333,
        "sender_full_name": "eddyb",
        "timestamp": 1621096266
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"409057\">hannahE2</span> <a href=\"#narrow/stream/122651-general/topic/Why.20is.20rust-gpu.20sound.20.3F/near/238746067\">said</a>:</p>\n<blockquote>\n<p>Are those atomics \"different\" than normal <code>core::atomic</code> types ? Using device-wide atomics and fences for group local atomic accesses would be overkill as well.</p>\n</blockquote>\n<p>you can't use atomics yet even, to be clear (unless we fixed the relevant bugs), I was just describing the \"default\" case, where you don't have anything more specialized that applies, for the future. right now you have to use <code>&amp;mut [u32]</code> or w/e anyway</p>",
        "id": 238909403,
        "sender_full_name": "eddyb",
        "timestamp": 1621096329
    },
    {
        "content": "<p>You can set barriers right now with <code>spirv_std::arch::{memory_barrier, control_barrier}</code>, for atomic ops you can use <code>asm!</code>.</p>\n<p>The atomic operations would probably be at least separate functions for gpu atomic ops, but doesn’t have to separate types, as spirv doesn’t have atomic ints (except AtomicCounter, which is its own type) just atomic operations.</p>",
        "id": 238947057,
        "sender_full_name": "XAMPPRocky",
        "timestamp": 1621137637
    }
]