[
    {
        "content": "<p>I don't think I have any updates</p>",
        "id": 182959661,
        "sender_full_name": "simulacrum",
        "timestamp": 1575901537
    },
    {
        "content": "<p>I have not spent time on looking into making Cargo act as the jobserver for rustc (vs. the pipe, etc)</p>",
        "id": 182959748,
        "sender_full_name": "simulacrum",
        "timestamp": 1575901564
    },
    {
        "content": "<p><span class=\"user-group-mention\" data-user-group-id=\"1117\">@WG-parallel-rustc</span> do we think it's worth meeting today, given this?</p>",
        "id": 182959794,
        "sender_full_name": "simulacrum",
        "timestamp": 1575901597
    },
    {
        "content": "<p>(not sure if others have things to talk about)</p>",
        "id": 182959801,
        "sender_full_name": "simulacrum",
        "timestamp": 1575901606
    },
    {
        "content": "<p>not from my side, last week I were doing some MIR stuff</p>",
        "id": 182960624,
        "sender_full_name": "Santiago Pastorino",
        "timestamp": 1575902138
    },
    {
        "content": "<p>okay, let's tentatively cancel, but if someone feels that we should meet, then please say so in the next hour</p>",
        "id": 182974775,
        "sender_full_name": "simulacrum",
        "timestamp": 1575909967
    },
    {
        "content": "<p>Cancelling sounds ok with me</p>",
        "id": 182975749,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1575910565
    },
    {
        "content": "<p>Hey all sorry i'm slow</p>",
        "id": 182994456,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922193
    },
    {
        "content": "<p>but i'm also ok :)</p>",
        "id": 182994501,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922204
    },
    {
        "content": "<p>that said, I see there's been a lot of activity, <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> is it possible to summarize what's up?</p>",
        "id": 182994702,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922327
    },
    {
        "content": "<p>I saw some discussion of possible bugs in the new rustc scheduler, or at least the jobserver integration with it?</p>",
        "id": 182994727,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922340
    },
    {
        "content": "<p>Yeah, I can provide some summary</p>",
        "id": 182994742,
        "sender_full_name": "simulacrum",
        "timestamp": 1575922354
    },
    {
        "content": "<p>We've loosely concluded that the current jobserver, at least on linux, is showing fairly high contention inside the kernel (for read/write calls on the pipe), which we believe is due to ~all rustc threads waiting for a jobserver token getting woken up on every new token (vs. just one). Using a POSIX IPC semaphore here seems to resolve things, but is not viable due to being incompatible with make (and cmake, etc.).</p>\n<p>We also discovered that at least the new rayon branch is incorrectly releasing the implicit (and only) token held by a rustc process when it goes to sleep due to lack of work; we have a tentative fix planned that'll be within rustc itself essentially avoiding the bug by just not ever releasing the implicit token.</p>",
        "id": 182994969,
        "sender_full_name": "simulacrum",
        "timestamp": 1575922514
    },
    {
        "content": "<p>For the contention, the current plan is that rustc will no longer directly connect to the jobserver, but rather call into Cargo (via some sort of pipe, possibly, or some other mechanism -- this is a bit unclear right now), and Cargo will issue the blocking reads/writes on the jobserver pipe. This should give us flexibility in terms of which rustc's get tokens and is more generally nice for getting control over scheduling tokens across the <code>rustc</code>s we spawn. That work is planned for myself to do, but I've been semi-avoiding it so far since it sounds like a relatively large task (and I need to spend some design time writing up a spec before digging in, I think).</p>",
        "id": 182995205,
        "sender_full_name": "simulacrum",
        "timestamp": 1575922668
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116266\">@Santiago Pastorino</span> is planning on doing the rayon bug mitigation, I think.</p>",
        "id": 182995227,
        "sender_full_name": "simulacrum",
        "timestamp": 1575922683
    },
    {
        "content": "<p>Hmm</p>",
        "id": 182995293,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922702
    },
    {
        "content": "<p>OK</p>",
        "id": 182995295,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922703
    },
    {
        "content": "<p>It seems like this might also impact folks attempting to run rustc outside of cargo</p>",
        "id": 182995310,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922715
    },
    {
        "content": "<p>Though I guess we've never really \"approved\" of them using the jobserver, right?</p>",
        "id": 182995324,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922726
    },
    {
        "content": "<p>Ah, so, in general the thought is that we can always fallback on the old mode</p>",
        "id": 182995348,
        "sender_full_name": "simulacrum",
        "timestamp": 1575922739
    },
    {
        "content": "<p>that's not too hard</p>",
        "id": 182995353,
        "sender_full_name": "simulacrum",
        "timestamp": 1575922741
    },
    {
        "content": "<p>(I remember at some point us -- or maybe just me -- thinking that it'd be nice if they could integrate into \"standard\" workflows)</p>",
        "id": 182995368,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922751
    },
    {
        "content": "<p>it's just that the old mode might basically limit you to, say, 2-4 threads at most per rustc</p>",
        "id": 182995377,
        "sender_full_name": "simulacrum",
        "timestamp": 1575922758
    },
    {
        "content": "<p>the main motivation for interjecting cargo</p>",
        "id": 182995400,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922783
    },
    {
        "content": "<p>is..well, what is it? :)</p>",
        "id": 182995409,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922790
    },
    {
        "content": "<p>being able to have a richer vocab than just \"give me and I'll block\"?</p>",
        "id": 182995472,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922803
    },
    {
        "content": "<p>having just one thread/process doing the writing into the jobserver pipe to mitigate the contention</p>",
        "id": 182995482,
        "sender_full_name": "simulacrum",
        "timestamp": 1575922807
    },
    {
        "content": "<p>OK.</p>",
        "id": 182995533,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922848
    },
    {
        "content": "<blockquote>\n<p>We've loosely concluded that the current jobserver, at least on linux, is showing fairly high contention inside the kernel (for read/write calls on the pipe), which we believe is due to ~all rustc threads waiting for a jobserver token getting woken up on every new token (vs. just one).</p>\n</blockquote>\n<p>do we believe this is because of rayon's \"wake-up-the-world\" scheduler behavior?</p>",
        "id": 182995596,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575922885
    },
    {
        "content": "<p>I think, well, maybe, but mostly no -- this is more so because linux itself will wake up all T*N (in the large core count case, up to ~800 threads) threads when a single byte is written into the jobserver pipe, where  all are doing <code>read(&amp;mut [_; 1])</code> basically</p>",
        "id": 182995807,
        "sender_full_name": "simulacrum",
        "timestamp": 1575923009
    },
    {
        "content": "<p>Ok. Yeah I was thinking that I didn't quite see how it could be linked to rayon since rayon threads are basically all just blocked</p>",
        "id": 182995846,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575923040
    },
    {
        "content": "<p>i.e., the rayon events will be going out to the threads, and if they were sleeping they'd wake up, but they're not sleeping, they're blocking waiting for jobserver events</p>",
        "id": 182995920,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575923070
    },
    {
        "content": "<p>it's only linked to rayon insofar as rayon currently is not quite well supporting the \"don't spawn T threads until you need them\" / slow-start or so, but that's just exacerbating the problem rather than causing it most likely</p>",
        "id": 182995950,
        "sender_full_name": "simulacrum",
        "timestamp": 1575923093
    },
    {
        "content": "<p>yes. the new scheduler in principle would help with <em>that specific part</em> of the problem perhaps</p>",
        "id": 182995986,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575923121
    },
    {
        "content": "<p>to be clear, ~all benchmarks were done with your fork of rayon</p>",
        "id": 182996020,
        "sender_full_name": "simulacrum",
        "timestamp": 1575923150
    },
    {
        "content": "<p>yes, ok</p>",
        "id": 182996159,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575923235
    },
    {
        "content": "<p>it won't help beyond the <em>benchmarks</em></p>",
        "id": 182996172,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575923240
    },
    {
        "content": "<p>since they're already using it :)</p>",
        "id": 182996198,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575923255
    },
    {
        "content": "<p>I think that's all -- I don't think we've made other progress etc</p>",
        "id": 182996418,
        "sender_full_name": "simulacrum",
        "timestamp": 1575923390
    },
    {
        "content": "<p>thanks <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> <span aria-label=\"heart\" class=\"emoji emoji-2764\" role=\"img\" title=\"heart\">:heart:</span></p>",
        "id": 182996922,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1575923705
    }
]