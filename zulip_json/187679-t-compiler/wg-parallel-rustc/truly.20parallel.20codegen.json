[
    {
        "content": "<p>I think we touched on this briefly durning the planning meeting last time, but parallel rustc should enable us to actually enable truly parallel codegen for all cgus I think</p>",
        "id": 177177208,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040113
    },
    {
        "content": "<p>where right now we codegen every CGU sequentially and then fork it off into the background to actually get llvm codegen'd</p>",
        "id": 177177232,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040127
    },
    {
        "content": "<p>or well I should say truly parallel translation to LLVM IR, not codegen</p>",
        "id": 177177237,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040134
    },
    {
        "content": "<p>My impression based on the comments in the codegen crates was that LLVM itself doesn't let us do that? Was that incorrect?</p>",
        "id": 177177275,
        "sender_full_name": "simulacrum",
        "timestamp": 1570040158
    },
    {
        "content": "<p>nah we can invoke LLVM in parallel as much as we like</p>",
        "id": 177177334,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040176
    },
    {
        "content": "<p>Do we just not do it today because the compiler itself can't codegen in parallel since queries etc are single threaded?</p>",
        "id": 177177335,
        "sender_full_name": "simulacrum",
        "timestamp": 1570040177
    },
    {
        "content": "<p>we do that today for actual codegen/optimization</p>",
        "id": 177177341,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040181
    },
    {
        "content": "<p>the only reason we don't translate to LLVM in parallel is that rustc's data structures don't support it</p>",
        "id": 177177352,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040190
    },
    {
        "content": "<p>but this could be a pretty huge win for a parallel compiler</p>",
        "id": 177177363,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040202
    },
    {
        "content": "<p>yeah, I somehow thought that LLVM did not support parallel 'IR creation'</p>",
        "id": 177177367,
        "sender_full_name": "simulacrum",
        "timestamp": 1570040204
    },
    {
        "content": "<p>because translation to IR is such a hgue time chunk in both debug and release builds</p>",
        "id": 177177379,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040217
    },
    {
        "content": "<p>but yeah that sounds like a big win compared to today, maybe even the \"ticket\" so to speak</p>",
        "id": 177177380,
        "sender_full_name": "simulacrum",
        "timestamp": 1570040218
    },
    {
        "content": "<p>it would also, I think, radically simplify the backend</p>",
        "id": 177177399,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040228
    },
    {
        "content": "<p>right now there's all this crazy jobserver stuff and threads flying around, but truly being parallel here would make things quite a bit easier</p>",
        "id": 177177417,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040243
    },
    {
        "content": "<p>it is also a major departure from what we do today</p>",
        "id": 177177433,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040257
    },
    {
        "content": "<p>so we wouldn't be able to capitalize on it until parallel compilation lands</p>",
        "id": 177177450,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040265
    },
    {
        "content": "<p>but I think this is something we'll want to keep in mind, is that 100% parallel translation to LLVM IR is a win we have not actually unlocked yet</p>",
        "id": 177177514,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040286
    },
    {
        "content": "<p>even if parallel rustc is built</p>",
        "id": 177177523,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040294
    },
    {
        "content": "<p>indeed, yes -- so you think it's not viable to sort of have both at the same time? i.e., how we do with queries elsewhere?</p>",
        "id": 177177563,
        "sender_full_name": "simulacrum",
        "timestamp": 1570040334
    },
    {
        "content": "<p>well it's not really both at the same time</p>",
        "id": 177177734,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040436
    },
    {
        "content": "<p>it's more of that rustc will at some point determine \"here's N codegen units\"</p>",
        "id": 177177747,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040445
    },
    {
        "content": "<p>today we have this complicated way of one thread translates all N units to LLVM IR and then forks off work to background crates for codegen/optimization</p>",
        "id": 177177775,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040466
    },
    {
        "content": "<p>whereas with a truly parallel rustc we can simply, like with rayon, have a \"parallel for loop\"</p>",
        "id": 177177799,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040478
    },
    {
        "content": "<p>where we just translate to llvm ir, immediately optimize/codegen, and then go further</p>",
        "id": 177177825,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040488
    },
    {
        "content": "<p>writing the synchronization point for LTO and/or ThinLTO would also be almost trivial</p>",
        "id": 177177839,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040502
    },
    {
        "content": "<p>since you'd just wait for all codegen to be done, link everything, and then spin up another parallel for loop</p>",
        "id": 177177858,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040519
    },
    {
        "content": "<p>there's a lot of complication today due to the inherent architecture</p>",
        "id": 177177914,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040538
    },
    {
        "content": "<p>where you can't share rustc data structures across threads</p>",
        "id": 177177921,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040544
    },
    {
        "content": "<p>but if we lift that restriction then all of a sudden we can write most of the translation backend in a much more natural way</p>",
        "id": 177177944,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570040557
    },
    {
        "content": "<p>Do we not already have that loop today though that could be \"optionally parallel\"?</p>",
        "id": 177177988,
        "sender_full_name": "simulacrum",
        "timestamp": 1570040593
    },
    {
        "content": "<p>Similar to how the rest of the compiler is written</p>",
        "id": 177178009,
        "sender_full_name": "simulacrum",
        "timestamp": 1570040617
    },
    {
        "content": "<p>hey sorry went away into a meeting</p>",
        "id": 177185248,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570045636
    },
    {
        "content": "<p>we don't have a straightforward loop for codegen, no</p>",
        "id": 177185267,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570045650
    },
    {
        "content": "<p>we have this -- <a href=\"https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src/librustc_codegen_ssa/back/write.rs#L1059-L1193\" target=\"_blank\" title=\"https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src/librustc_codegen_ssa/back/write.rs#L1059-L1193\">https://github.com/rust-lang/rust/blob/f2023ac599c38a59f86552089e6791c5a73412d3/src/librustc_codegen_ssa/back/write.rs#L1059-L1193</a></p>",
        "id": 177185331,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570045685
    },
    {
        "content": "<p>it tries to balance work between the main thread and other threads</p>",
        "id": 177185343,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570045698
    },
    {
        "content": "<p>it gets significantly more complicated when most work is parallel but some work has to stick to one thread</p>",
        "id": 177185353,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570045709
    },
    {
        "content": "<p>yeah, that makes sense -- bit unfortunate that we don't have executors out there that already enable this, via two separate buckets of both Send tasks and non-Send tasks</p>",
        "id": 177189046,
        "sender_full_name": "simulacrum",
        "timestamp": 1570047992
    },
    {
        "content": "<p>though we probably know enough extra information that it wouldn't be ideal to just use an off the shelf solution even if it existed</p>",
        "id": 177189072,
        "sender_full_name": "simulacrum",
        "timestamp": 1570048022
    },
    {
        "content": "<blockquote>\n<p>but I think this is something we'll want to keep in mind, is that 100% parallel translation to LLVM IR is a win we have not actually unlocked yet</p>\n</blockquote>\n<p>interesting!</p>",
        "id": 177191914,
        "sender_full_name": "Santiago Pastorino",
        "timestamp": 1570049930
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116015\">@Alex Crichton</span> I think this is definitely a goal -- the one major thing we have to be careful about I think is that we don't want to have too many LLVM modules created all at once, just to keep memory usage down.</p>",
        "id": 177543616,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1570470965
    },
    {
        "content": "<p>but I think that the existing parallel compilation stuff totally supports this already</p>",
        "id": 177543629,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1570470976
    },
    {
        "content": "<p>or am I missing something?</p>",
        "id": 177543632,
        "sender_full_name": "nikomatsakis",
        "timestamp": 1570470979
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116009\">@nikomatsakis</span> right yeah, but I think the jobserver plus rearchitecting things would basically fix that</p>",
        "id": 177565868,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570486367
    },
    {
        "content": "<p>today we have one thread, which if it runs as fast as possible, generates all llvm modules</p>",
        "id": 177565885,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570486380
    },
    {
        "content": "<p>and then those llvm modules sit idle in memory while we wait for parallelism to come optimize/codegen them</p>",
        "id": 177565895,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570486390
    },
    {
        "content": "<p>if we instead used one token at a time to take an entire llvm module through to completion</p>",
        "id": 177565905,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570486401
    },
    {
        "content": "<p>for example you translate to llvm ir, then immediately optimized, then immediately codegen</p>",
        "id": 177565916,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570486412
    },
    {
        "content": "<p>that would be the same solution we have now of trading off who does what</p>",
        "id": 177565922,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570486420
    },
    {
        "content": "<p>this, I think, is definitely an area of complexity that would simply \"go away\" if we switch to truly parallel codegen governed by a jobserver</p>",
        "id": 177565985,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570486446
    },
    {
        "content": "<p>currently we have to rate limit the main thread to stop codegen'ing and switch to optimizing to avoid producing too many llvm modules sitting in memory</p>",
        "id": 177566058,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570486534
    },
    {
        "content": "<p>but with truly parallel codegen no rate limiting is needed since we take an llvm module through to completion each time</p>",
        "id": 177566065,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1570486546
    }
]