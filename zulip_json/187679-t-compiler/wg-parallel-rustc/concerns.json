[
    {
        "content": "<p>One thing that worries me about the parallel compiler is that it will make profiling and benchmarking harder.</p>",
        "id": 165137292,
        "sender_full_name": "njn",
        "timestamp": 1557295224
    },
    {
        "content": "<p>Instruction count is the metric with the least variance, by a long way. Currently it correlates well with wall time, which is the true metric of concern (i.e. what users observe). In a parallel compiler, that correlation will be greatly weakened.</p>",
        "id": 165137322,
        "sender_full_name": "njn",
        "timestamp": 1557295286
    },
    {
        "content": "<p>As a result, our ability to detect small regressions (and improvements) to compiler performance will be harmed.</p>",
        "id": 165137374,
        "sender_full_name": "njn",
        "timestamp": 1557295331
    },
    {
        "content": "<p>More generally, the use of coarse-grained parallelism in compilers is well-established and is known to work well. But I'm worried about fine-grained parallelism. The perf numbers I've seen so far have had some good improvements on some workloads, but also some drastic regressions on others.</p>",
        "id": 165137409,
        "sender_full_name": "njn",
        "timestamp": 1557295404
    },
    {
        "content": "<p>I agree that fine-grained parallelism in a compiler is a mostly uncharted field. I wonder what it would look like if we went for a more traditional approach (which usually scales better to distributed compilation).</p>",
        "id": 165172762,
        "sender_full_name": "mw",
        "timestamp": 1557329124
    },
    {
        "content": "<p>On the other hand, we should soon be in a position to do a real world evaluation of a compiled with fine-grained parallelism built in, which is pretty interesting.</p>",
        "id": 165172863,
        "sender_full_name": "mw",
        "timestamp": 1557329180
    },
    {
        "content": "<p>regarding profiling: the compiler will still allow being locked to only one thread, which should make the correlation between instruction count and wall-time greater again. Maybe we should keep collecting numbers for single-thread runs in order to make detection of regressions easier?</p>",
        "id": 165173049,
        "sender_full_name": "mw",
        "timestamp": 1557329316
    },
    {
        "content": "<p>Agree with <span class=\"user-mention\" data-user-id=\"124287\">@mw</span> about regression detection. We can always constraint with one thread to make the performance comparison meaningful.</p>\n<p>About profiling, I'm not quite sure whether it refers to profile the compilation using rustc? Is such profiling useful?</p>",
        "id": 165193678,
        "sender_full_name": "lwshang",
        "timestamp": 1557344077
    },
    {
        "content": "<p>We should measure what we ship. I'm worried that measuring single-thread runs would be misleading if we are shipping a multi-threaded compiler.</p>",
        "id": 165195899,
        "sender_full_name": "njn",
        "timestamp": 1557345767
    },
    {
        "content": "<p>Isn't multi-threaded codegen already enabled in rustc by default?<br>\nDo perf runs disable it (thus decreasing variance) or not (thus not measuring what we ship)?</p>",
        "id": 165202868,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1557350939
    },
    {
        "content": "<p>I believe that we do not disable parallel codegen</p>",
        "id": 165202931,
        "sender_full_name": "simulacrum",
        "timestamp": 1557350999
    },
    {
        "content": "<p>We definitely should measure what we ship. But single-threaded runs could be done in addition in order to have improved regression detection.</p>",
        "id": 165236411,
        "sender_full_name": "mw",
        "timestamp": 1557393457
    }
]