[
    {
        "content": "<p>Where can I ask about the infrastructure where perf runs are run?</p>\n<p>I'm interested in what is being worked on there. Specifically, I'd like to know if there are plans to have more than one particular hardware setup in the future, so that the runs have more representative results. </p>\n<p>Among other things ^^</p>",
        "id": 202277194,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593413875
    },
    {
        "content": "<p>no we probably won't have multiple hardware platforms just for the sake of \"representative\" runs -- that's not really what our perf infra focuses on today I think</p>",
        "id": 202306348,
        "sender_full_name": "simulacrum",
        "timestamp": 1593436223
    },
    {
        "content": "<p>but you can ask here and I can try to answer</p>",
        "id": 202306370,
        "sender_full_name": "simulacrum",
        "timestamp": 1593436237
    },
    {
        "content": "<p>What does it focus on? <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span></p>",
        "id": 202344219,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593452382
    },
    {
        "content": "<p>Uh well I don't really know that there's a good descriptor</p>",
        "id": 202344313,
        "sender_full_name": "simulacrum",
        "timestamp": 1593452421
    },
    {
        "content": "<p>So here is my reasoning:</p>\n<p>I ask because measuring software performance with any degree of certainty is hard, and moreso when you want your samples to be representative of other computers.</p>\n<p>If we're thus making decisions based on the perf benchmarks that we run, we should strive to make them representative of the realities of the Rust community.</p>\n<p>The community has a very diverse setup of machines with which they work. If our benchmarks are run on just one machine, we need to know if it is actually representative of the whole. </p>\n<p>Does the amount of RAM change performance? Does the amount of cores change it? Does the size of the cpu cache change it?</p>\n<p>If any of the answers to those questions is Yes, then we should really think about why we have only one machine, shouldn't we? :)</p>",
        "id": 202345118,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593452879
    },
    {
        "content": "<p>That's basically where I came from to ask that question</p>",
        "id": 202345233,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593452931
    },
    {
        "content": "<p>I thought that what was limiting us from having more machines was money, but I don't really know. Is it the cost? How much does running the perf benchmarks cost per month, more or less?<br>\nOr is it something different? Is it the burden of maintaining it that's keeping us out of that?</p>",
        "id": 202345456,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593453037
    },
    {
        "content": "<p>I'm hearing \"I'd like to take over maintenance and development of perf.rlo\" <span aria-label=\"smirk\" class=\"emoji emoji-1f60f\" role=\"img\" title=\"smirk\">:smirk:</span></p>",
        "id": 202345635,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1593453135
    },
    {
        "content": "<blockquote>\n<p>Does the amount of RAM change performance?</p>\n</blockquote>\n<p>I think only when having little ram would cause swapping.</p>\n<blockquote>\n<p>Does the amount of cores change it?</p>\n</blockquote>\n<p>check builds: no, those are single threaded within a single rustc process.<br>\ndebug/opt builds: yes, optimization after codegen happens in parallel</p>\n<blockquote>\n<p>Does the size of the cpu cache change it?</p>\n</blockquote>\n<p>Probably</p>",
        "id": 202345712,
        "sender_full_name": "bjorn3",
        "timestamp": 1593453189
    },
    {
        "content": "<blockquote>\n<p>I'm hearing \"I'd like to take over maintenance and development of perf.rlo\" <span aria-label=\"smirk\" class=\"emoji emoji-1f60f\" role=\"img\" title=\"smirk\">:smirk:</span></p>\n</blockquote>\n<p><span class=\"user-mention\" data-user-id=\"116155\">@Jake Goulding</span> I really kind of do, dammit XD you figured me out.<br>\nI might or might not be able to in the short term. I have promised away 4 months of me to the mir-opt group through my undergrad thesis, which will hopefully get started in July.<br>\nConsidering where the world is and where I am right now, I don't think I have the bandwidth. But heck, after I clear the thesis? I would be SO HAPPY TO DO IT. There aren't many things that call to me as much as testing and measuring do. <span aria-label=\"blush\" class=\"emoji emoji-1f60a\" role=\"img\" title=\"blush\">:blush:</span></p>",
        "id": 202346668,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593453639
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"133247\">@bjorn3</span> thank you for the answers :)<br>\nI'm guessing that cache size matters a lot up to a point, after which caching doesn't help much. It would be nice to test that. I wonder if there are still chips where model A and model B only differ in their cache size?</p>",
        "id": 202347039,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593453809
    },
    {
        "content": "<blockquote>\n<p>I thought that what was limiting us from having more machines was money, but I don't really know. Is it the cost? How much does running the perf benchmarks cost per month, more or less?<br>\nOr is it something different? Is it the burden of maintaining it that's keeping us out of that?</p>\n</blockquote>\n<p>So, at the moment we're running benchmarks on Hetzner's AX41-NVMe: <a href=\"https://www.hetzner.com/dedicated-rootserver/ax41\">https://www.hetzner.com/dedicated-rootserver/ax41</a></p>",
        "id": 202347508,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1593454050
    },
    {
        "content": "<p>the \"problem\" is that we can't use VMs for benchmarks, so we can't rely on our existing sponsorships (spinning up a new VM on AWS would be way easier) and we need to seek the money somewhere, and we're limited on where we can get the servers at (because we're limited on bare metals)</p>",
        "id": 202347658,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1593454135
    },
    {
        "content": "<p>Right, right, that makes a lot of sense</p>",
        "id": 202347839,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593454232
    },
    {
        "content": "<p>So it is a bit of both columns then</p>",
        "id": 202347880,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593454255
    },
    {
        "content": "<p>Money + \"wait we need to run this on bare metal, heck\"</p>",
        "id": 202347910,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593454272
    },
    {
        "content": "<p>yeah</p>",
        "id": 202347921,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1593454277
    },
    {
        "content": "<p>and well, some impl work will need to be done :P</p>",
        "id": 202347945,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1593454287
    },
    {
        "content": "<p>Yas</p>",
        "id": 202347949,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593454293
    },
    {
        "content": "<p>:P</p>",
        "id": 202347955,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593454295
    },
    {
        "content": "<p>Of course</p>",
        "id": 202347964,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593454299
    },
    {
        "content": "<p>there's also the element that personally I think we're not really at the point where representative sampling makes a lot of sense</p>",
        "id": 202355781,
        "sender_full_name": "simulacrum",
        "timestamp": 1593458155
    },
    {
        "content": "<p>even just the one machine we have now gives us a ton of data per run</p>",
        "id": 202355877,
        "sender_full_name": "simulacrum",
        "timestamp": 1593458179
    },
    {
        "content": "<p>and to my knowledge, focusing on instruction counts is going to be pretty deterministic across machines independent of cache size/memory size/disk size, or at least mostly so</p>",
        "id": 202355955,
        "sender_full_name": "simulacrum",
        "timestamp": 1593458223
    },
    {
        "content": "<p>(obviously there's differences, but ... not significant, I'd imagine)</p>",
        "id": 202355976,
        "sender_full_name": "simulacrum",
        "timestamp": 1593458236
    },
    {
        "content": "<p>I would also say that -- at least for now -- we don't seem to be at the point where we're \"fast enough\" on the <em>one</em> machine we do have</p>",
        "id": 202356120,
        "sender_full_name": "simulacrum",
        "timestamp": 1593458298
    },
    {
        "content": "<p>so we're not really at the point where we're making decisions like \"well this would be better here but worse on this other machine/architecture\"</p>",
        "id": 202356151,
        "sender_full_name": "simulacrum",
        "timestamp": 1593458322
    },
    {
        "content": "<p>of course, maybe that's partially for a lack of data... but I think at least for the most part rustc is going to be pretty equivalent independent of machine (possibly modulo things like windows antivirus, but that's not really about the hardware)</p>",
        "id": 202356219,
        "sender_full_name": "simulacrum",
        "timestamp": 1593458359
    },
    {
        "content": "<p>and I think if I was to suggest where to spend time, it would be in increasing the usability of the metrics we do gather and expanding that set -- we mostly just look at instructions today, because everything else is quite variable. But there's a lot of other interesting metrics to collect</p>",
        "id": 202356356,
        "sender_full_name": "simulacrum",
        "timestamp": 1593458421
    },
    {
        "content": "<p>one project that IMO would be worthwhile is figuring out a way for the self-profile data to come with instruction counts</p>",
        "id": 202356374,
        "sender_full_name": "simulacrum",
        "timestamp": 1593458436
    },
    {
        "content": "<blockquote>\n<p>deterministic across machines</p>\n</blockquote>\n<p>I do wonder about different architectures. E.g. with the impending ARMpocalypse, I could see codegen changes being good on x86 and bad on ARM (or vice versa). That should be a smaller side project to figure that out, however.</p>",
        "id": 202357224,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1593458951
    },
    {
        "content": "<p>You expose many fair points, <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span>.</p>\n<p>The other thing I would like to see is less latency, by having more than one machine available (this time, not in the sense of \"different machines\", but actually in the sense of \"more copies of the same reference machine\"). I think we could really use a second one at the moment, because there are some days where you have to wait around 24 hours for a perf run to be done.</p>",
        "id": 202362682,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593461935
    },
    {
        "content": "<p>Yeah, different archs are interesting to look at (more so than anything else). Not really feasible for our CI budget though.</p>",
        "id": 202362735,
        "sender_full_name": "simulacrum",
        "timestamp": 1593461971
    },
    {
        "content": "<p>hm, so it's true that less latency is perhaps somewhat desirable, but the intent is that people can run it locally, and that gives you <em>very</em> low latency</p>",
        "id": 202362787,
        "sender_full_name": "simulacrum",
        "timestamp": 1593462000
    },
    {
        "content": "<p>we can't do much better than try builds + ~2 hours anyway, and that gets to around 4 hours. tbh, I usually can't iterate more than twice per day at that rate... so once or twice doesn't matter much</p>",
        "id": 202362889,
        "sender_full_name": "simulacrum",
        "timestamp": 1593462043
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/242791-t-infra/topic/Meta.3F.20About.20perf.20runs.20infra/near/202356356\">said</a>:</p>\n<blockquote>\n<p>and I think if I was to suggest where to spend time, it would be in increasing the usability of the metrics we do gather and expanding that set -- we mostly just look at instructions today, because everything else is quite variable. But there's a lot of other interesting metrics to collect</p>\n</blockquote>\n<p>I completely agree :)<br>\nBoth w.r.t. usability (How do you answer \"where should we spend most of our resources if we want to increase compilation performance?\" and \"what kind of metrics are we currently lacking?\")<br>\nAnd also w.r.t. interesting metrics that we could be collecting :3</p>\n<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/242791-t-infra/topic/Meta.3F.20About.20perf.20runs.20infra/near/202355976\">said</a>:</p>\n<blockquote>\n<p>(obviously there's differences, but ... not significant, I'd imagine)</p>\n</blockquote>\n<p>I would like to test that, just to be sure we're standing on more or less solid assumptions.</p>\n<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/242791-t-infra/topic/Meta.3F.20About.20perf.20runs.20infra/near/202356374\">said</a>:</p>\n<blockquote>\n<p>one project that IMO would be worthwhile is figuring out a way for the self-profile data to come with instruction counts</p>\n</blockquote>\n<p>Ohhh, yeah, that would be really nice. If this was solid enough, it could open the door for \"benchmarking rustc yourself\". If given enough control over what tests to run and so on (because not all tests will be relevant to all possible modifications to the compiler), it could really be a quick way of testing your own changes for performance without having to rely on the bandwidth of perf.rlo</p>",
        "id": 202363543,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1593462392
    }
]