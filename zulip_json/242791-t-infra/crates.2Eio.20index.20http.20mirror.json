[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"120054\">@Jon Gjengset</span> has raised in <a class=\"stream-topic\" data-stream-id=\"246057\" href=\"/#narrow/stream/246057-t-cargo/topic/http.20registry.20RFC\">#t-cargo &gt; http registry RFC</a> that it'd be good for a soon-to-be-merged RFC to have a real endpoint for folks to test against, before we migrate <a href=\"http://crates.io\">crates.io</a> itself to that new API</p>",
        "id": 218775795,
        "sender_full_name": "simulacrum",
        "timestamp": 1607043193
    },
    {
        "content": "<blockquote>\n<p>I do think it would be valuable to have a real endpoint that people can try out after my PR lands so that people can test, but that's relatively low priority. To make it low effort, that should probably just be a CloudFront in front of <a href=\"http://raw.githubusercontent.com\">raw.githubusercontent.com</a> with a relatively short cache expiry time, so that we don't have to implement any purging or S3 bucket updating.</p>\n</blockquote>",
        "id": 218775817,
        "sender_full_name": "simulacrum",
        "timestamp": 1607043234
    },
    {
        "content": "<p>I am a bit concerned about making requests direct to github</p>",
        "id": 218775863,
        "sender_full_name": "simulacrum",
        "timestamp": 1607043255
    },
    {
        "content": "<p>I think what I'd do is setup a tiny ec2 instance with nginx serving a checkout of the index and a cronjob refreshing it every 5 minutes or so</p>",
        "id": 218775904,
        "sender_full_name": "simulacrum",
        "timestamp": 1607043313
    },
    {
        "content": "<p>Hehe, that would work too I suppose. My guess would be that proxying to GitHub would be fine _if_ we did explicit cache eviction as opposed to a timeout, but with a TTL I agree it's probably better to proxy to something under <a href=\"http://crates.io\">crates.io</a> control.</p>",
        "id": 218776182,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607043576
    },
    {
        "content": "<p>I don't know that we have fine-grained access to caching like that for cloudfront</p>",
        "id": 218776272,
        "sender_full_name": "simulacrum",
        "timestamp": 1607043650
    },
    {
        "content": "<p>I do think that medium-term you'd want <a href=\"http://crates.io\">crates.io</a> to, on publish, go poke both the checkout server to do a pull and the CloudFront cache to evict the index file of the published crate. But that's probably not needed for initial experimentation. It just means people will sometimes get very slightly stale views of the index, which is fine.</p>",
        "id": 218776278,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607043658
    },
    {
        "content": "<p>I think Pietro mentioned that there is indeed a cache shootdown API for cloudfront</p>",
        "id": 218776300,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607043687
    },
    {
        "content": "<p>Cache invalidations exist on cloudfront, but they're somewhat expensive IIRC</p>",
        "id": 218776378,
        "sender_full_name": "simulacrum",
        "timestamp": 1607043769
    },
    {
        "content": "<p>$0.005/invalidation path (which can be <code>*</code>)</p>",
        "id": 218776419,
        "sender_full_name": "simulacrum",
        "timestamp": 1607043796
    },
    {
        "content": "<p>Huh, interesting. That's a bummer. Well, even more reason to stick to simple cache expiry for the initial test then. I'll go poke at some things \"behind the scenes\" at AWS too and see what I can find out there.</p>",
        "id": 218776546,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607043909
    },
    {
        "content": "<p>Are you able to set short TTLs for the CloudFront caching at the moment? Or is it something silly like \"minimum of 1hr TTL\"?</p>",
        "id": 218777164,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607044568
    },
    {
        "content": "<p>From <a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html#ExpirationDownloadDist\">https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html#ExpirationDownloadDist</a> it _seems_ like we can set TTL basically as low as we want, so at least that's good.</p>",
        "id": 218777334,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607044766
    },
    {
        "content": "<p><a href=\"https://aws.amazon.com/about-aws/whats-new/2010/08/31/cloudfront-adds-invalidation-feature/\">$0.005 charge for invalidating each file</a> * <a href=\"https://github.com/rust-lang/crates.io-index/graphs/commit-activity\">2644 commits to the index per week</a> = 13.22 US$ per week.</p>",
        "id": 218778449,
        "sender_full_name": "Eh2406",
        "timestamp": 1607046010
    },
    {
        "content": "<p>Yeah, it's not too bad -- only a couple extra hundred per year -- but I'd rather not add it just because :)</p>",
        "id": 218778920,
        "sender_full_name": "simulacrum",
        "timestamp": 1607046510
    },
    {
        "content": "<p>I think short TTLs would work -- I've long wanted to do some investigation/reading on how much CloudFront caching in front of S3 buys you</p>",
        "id": 218778937,
        "sender_full_name": "simulacrum",
        "timestamp": 1607046536
    },
    {
        "content": "<p>I think it's probably hard to measure in the US since our S3 buckets all live in us-west-2 I think</p>",
        "id": 218778962,
        "sender_full_name": "simulacrum",
        "timestamp": 1607046567
    },
    {
        "content": "<p>The main thing it would buy you is lower tail latency for users (they won't miss in cache unless the index file has _just_ been updated), and the ability for users to use a new crate version just _slightly_ faster (on average half the TTL). Is that worth it? Unclear...</p>",
        "id": 218784427,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607049190
    },
    {
        "content": "<p>I think for <a href=\"http://crates.io\">crates.io</a> the best way would be to actually just have the <a href=\"http://crates.io\">crates.io</a> backend update s3</p>",
        "id": 218817020,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1607078793
    },
    {
        "content": "<p>the requirement for that is to implement crate deletions on the application, instead of the current approach of \"pietro manually pushes a commit to the index\"</p>",
        "id": 218817106,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1607078862
    },
    {
        "content": "<p>in general <span class=\"user-mention\" data-user-id=\"120054\">@Jon Gjengset</span> I think the question of <a href=\"http://crates.io\">crates.io</a> implementing it needs to be done to the <a href=\"http://crates.io\">crates.io</a> team</p>",
        "id": 218817865,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1607079340
    },
    {
        "content": "<p>I know jtgeibel has opinions on this too</p>",
        "id": 218817875,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1607079348
    },
    {
        "content": "<p>yeah so to be clear I think that's absolutely the right way</p>",
        "id": 218834446,
        "sender_full_name": "simulacrum",
        "timestamp": 1607089754
    },
    {
        "content": "<p>but I was thinking that a temporary solution might be worthwhile if <a href=\"http://crates.io\">crates.io</a> doesn't have time</p>",
        "id": 218834481,
        "sender_full_name": "simulacrum",
        "timestamp": 1607089777
    },
    {
        "content": "<p>I don't think we should expect <a href=\"http://crates.io\">crates.io</a> to instantly implement that RFC</p>",
        "id": 218837677,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1607091508
    },
    {
        "content": "<p>both because we need to make sure <a href=\"http://crates.io\">crates.io</a> can scale</p>",
        "id": 218837787,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1607091574
    },
    {
        "content": "<p>and also because <a href=\"http://crates.io\">crates.io</a> currently has <em>very little</em> human bandwidth at the moment to design, implement and review</p>",
        "id": 218837814,
        "sender_full_name": "Pietro Albini",
        "timestamp": 1607091589
    },
    {
        "content": "<p>Right, hence trying to think how we can get some more testing while requiring as little from <a href=\"http://crates.io\">crates.io</a> as possible.</p>",
        "id": 218838266,
        "sender_full_name": "Eh2406",
        "timestamp": 1607091816
    },
    {
        "content": "<p>We have a bit of a chicken/egg thing developing:</p>\n<ul>\n<li>it is hard to get widespread testing without a production-ish server somewhere.</li>\n<li>it is (legitimately) not worth <a href=\"http://crates.io\">crates.io</a> teams time to set up a server for an unproven protocol.</li>\n</ul>\n<p>So we need to find some way to bootstrap, a server that is good enough to test on but is not much work for <a href=\"http://crates.io\">crates.io</a>.</p>",
        "id": 218844998,
        "sender_full_name": "Eh2406",
        "timestamp": 1607094889
    },
    {
        "content": "<p>yeah, and I think my solution is both low effort and well, is a static file server so scales well</p>",
        "id": 218847472,
        "sender_full_name": "simulacrum",
        "timestamp": 1607095884
    },
    {
        "content": "<p>My sense from talking to the CloudFront team is that 3k invalidations per week is such a low number that it's unlikely to get any kind of \"special treatment\" :p</p>",
        "id": 218873040,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607106574
    },
    {
        "content": "<p>not unexpected</p>",
        "id": 218873809,
        "sender_full_name": "simulacrum",
        "timestamp": 1607106915
    },
    {
        "content": "<p>I'm not sold we need it</p>",
        "id": 218873814,
        "sender_full_name": "simulacrum",
        "timestamp": 1607106919
    },
    {
        "content": "<p>I do think figuring out what an invalidation <em>means</em> might be nice</p>",
        "id": 218873835,
        "sender_full_name": "simulacrum",
        "timestamp": 1607106931
    },
    {
        "content": "<p>if that just kills our cache, then maybe we can set a TTL of 0 or something and get roughly the same effects</p>",
        "id": 218873874,
        "sender_full_name": "simulacrum",
        "timestamp": 1607106954
    },
    {
        "content": "<p>(presuming we invalidate everything)</p>",
        "id": 218873886,
        "sender_full_name": "simulacrum",
        "timestamp": 1607106960
    },
    {
        "content": "<p>The other way to look at this is that if specific invalidations means most things can have much longer TTLs, that might already make up for itself in terms of cost. Missing in cache is more expensive than hitting in cache after all.</p>",
        "id": 218874459,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607107201
    },
    {
        "content": "<p>It would be interesting to try to compare the two</p>",
        "id": 218874633,
        "sender_full_name": "simulacrum",
        "timestamp": 1607107289
    },
    {
        "content": "<p>I imagine it's going to end up being that missing is actually not that expensive cost wise (unclear on time though)</p>",
        "id": 218874758,
        "sender_full_name": "simulacrum",
        "timestamp": 1607107332
    },
    {
        "content": "<p>Another point the CloudFront team brought up to me was that the number of invalidations scales with the number of _active_ crates, not the number of crates total, which means that it'll likely have a lower rate than overall <a href=\"http://crates.io\">crates.io</a> size.</p>",
        "id": 218874763,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607107338
    },
    {
        "content": "<p>Yeah, could be, it's hard to say. But I imagine that the difference between a TTL=5m and no invalidations and TTL=3h + explicit invalidations makes quite the difference in terms of number of requests to the origin server. Not sure if CF also charges more for origin requests?</p>",
        "id": 218874893,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607107398
    },
    {
        "content": "<p>As far as I know we only pay the S3 GET cost</p>",
        "id": 218874956,
        "sender_full_name": "simulacrum",
        "timestamp": 1607107433
    },
    {
        "content": "<blockquote>\n<p>not the number of crates total, which means that it'll likely have a lower rate than overall <a href=\"http://crates.io\">crates.io</a> size</p>\n</blockquote>\n<p>The data is available of commits per day. It is no longer in github ui, but I can pull it together if you want it.</p>",
        "id": 218875060,
        "sender_full_name": "Eh2406",
        "timestamp": 1607107474
    },
    {
        "content": "<p>One thing that would also be super useful is to spin up a server in say australia or something far away and measure latency on invalidated requests</p>",
        "id": 218875128,
        "sender_full_name": "simulacrum",
        "timestamp": 1607107516
    },
    {
        "content": "<p>i.e. run your benchmarks against cold cloudfront or ttl cloudfront</p>",
        "id": 218875159,
        "sender_full_name": "simulacrum",
        "timestamp": 1607107536
    },
    {
        "content": "<p>Yeah, that would be interesting too.</p>",
        "id": 218875204,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607107559
    },
    {
        "content": "<p>Overall I feel like the experience of hitting cache often will be nicer for users, but I don't have direct data to that effect.</p>",
        "id": 218875288,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607107581
    },
    {
        "content": "<p>Yep, that would be my theory but would be nice to know how much that benefit is - if it's, say, 2x then I'm willing to invest in it</p>",
        "id": 218875360,
        "sender_full_name": "simulacrum",
        "timestamp": 1607107617
    },
    {
        "content": "<p>But if we win very little then invalidating might be just simpler model (since it gives us strong consistency presumably)</p>",
        "id": 218875440,
        "sender_full_name": "simulacrum",
        "timestamp": 1607107659
    },
    {
        "content": "<p>Not sure I follow: \"win\" in what regard? cost? I think the upsides of low TTL are reduced complexity and (maybe) slightly lower cost. And the upsides of invalidations are stronger consistency (no need to wait for TTL + retry), and likely lower tail latency.</p>",
        "id": 218875654,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607107790
    },
    {
        "content": "<p>No, time (ms)</p>",
        "id": 218875881,
        "sender_full_name": "simulacrum",
        "timestamp": 1607107913
    },
    {
        "content": "<p>Hm, I am surprised by the lower tail latency</p>",
        "id": 218875977,
        "sender_full_name": "simulacrum",
        "timestamp": 1607107944
    },
    {
        "content": "<p>I guess it depends on if we invalidate in a targeted manner</p>",
        "id": 218876043,
        "sender_full_name": "simulacrum",
        "timestamp": 1607107980
    },
    {
        "content": "<p>I know for static.r-l.o we basically just invalidate the whole bucket</p>",
        "id": 218876066,
        "sender_full_name": "simulacrum",
        "timestamp": 1607107994
    },
    {
        "content": "<p>/dist/* iirc</p>",
        "id": 218876078,
        "sender_full_name": "simulacrum",
        "timestamp": 1607108001
    },
    {
        "content": "<p>Which - who knows - might actually be biting us a bunch</p>",
        "id": 218876124,
        "sender_full_name": "simulacrum",
        "timestamp": 1607108028
    },
    {
        "content": "<p>Ah, no, I think for invalidations we'd specifically want targeted invalidations. Blanket invalidations would mean you probably do _worse_ than TTL depending on update frequency, at higher cost.</p>",
        "id": 218876543,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607108227
    },
    {
        "content": "<p>Lower tail latency because you'd hit CloudFront not the origin server more often, and the whole point of CloudFront is to cache to speed up access :p</p>",
        "id": 218876632,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607108265
    },
    {
        "content": "<p>I guess it also depends on the relative cost of S3 access vs CloudFront access</p>",
        "id": 218876691,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607108284
    },
    {
        "content": "<p>(assuming the index would also be served through an S3 bucket)</p>",
        "id": 218876744,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607108302
    },
    {
        "content": "<p>Another interesting data point in favor of TTL: CloudFront supports conditional requests (<code>If-Modified-Since</code>) to the origin server, so even with a low TTL it won't actually pull much _data_ from the backend server for things that expire but do not change. Would still inflict an incremental latency cost though.</p>",
        "id": 218878073,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607108947
    },
    {
        "content": "<p>Unless CloudFront checks with the origin server \"in the background\" rather than on a request, which I'm not sure about.</p>",
        "id": 218878153,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607109001
    },
    {
        "content": "<p>Overall, I think low TTL caching is probably the way to go for now unless we explicitly find that it's not good enough. Eventually, if we add a signed snapshot of the index with content-addressed index files like Pietro has been thinking about, that would in turn enable us to give all the index files a super long TTL (since they'd be immutable), and we'd _only_ need to think about the snapshot file.</p>",
        "id": 218879684,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607109780
    },
    {
        "content": "<blockquote>\n<p>not the number of crates total, which means that it'll likely have a lower rate than overall <a href=\"http://crates.io\">crates.io</a> size</p>\n</blockquote>\n<p>I ran some numbers. The commits per day is doubling every 1.75 years (R^2 = 0.94). That is slower than the number of crates witch is doubling every 1.5 years.</p>",
        "id": 218882769,
        "sender_full_name": "Eh2406",
        "timestamp": 1607111409
    },
    {
        "content": "<p>my thinking on this FWIW is that if we don't do invalidations, the 5m cache time is good. Otherwise with invalidations which should have \"near infinite\" cache times because it will be valid until we invalidate it. And yeah the number of changes to the index is O(publishes), not O(size of registry)</p>",
        "id": 218902578,
        "sender_full_name": "Alex Crichton",
        "timestamp": 1607123113
    },
    {
        "content": "<p>Hello from the CloudFront team!<br>\nI discussed this a bit with Jon yesterday. Both the low-ttl variant and invalidations should be feasible strategies.</p>\n<p>One thing that they all can't address is however having a mixed view of the index. <br>\nE.g. let's say a user builds something that uses hyper. The index for that is fetched - but it's not in cache - so we get a fresh version from the origin which tells that now a version requiring tokio 0.3 is available. Then the resolver tries to fetch tokio - but the index file for this is in cache and only lists version 0.2 ==&gt; Build fails, unless there are any retries (e.g. using if-modified-since headers).<br>\nIt's unlikely to happen - but just like all flaky and racy things it will happen, and make peoples builds fail. We all know those things are annoying, and it would be good to avoid it.</p>\n<p>We discussed that the easiest way to get around this is probably to have an \"index of index\". E.g. the a first HTTP request gives you the current index snapshot number (let's say <code>4123</code>). Then all follow-up requests go towards ( <code>/4123/path_to_crate</code>) instead of directly <code>path_to_crate</code>.<br>\n That makes sure that the client always has a consistent view of the index, and neither a TTL nor invalidations would be required for the index snapshots.</p>\n<p>There are obviously some downsides to it:</p>\n<ul>\n<li>1 more RTT --&gt; I'm not convinced it matters. The index of index files should be highly cached since everyone needs it. So in most cases we are only talking about 1 round trip to an edge-location which is very close to the user. And I guess there are multiple layers of follow-up lookups, so that a +1 doesn't add that much (but Jon likely has numbers on that)</li>\n<li>Who cleans up the old indexes? If the origin is S3, one could likely just use lifecycle rules for this which automatically delete files older than X (where X should here be bigger than the time <a href=\"http://crates.io\">crates.io</a> usually publishes new snapshots).</li>\n<li>Creating a snapshot requires copying O(N) packages, and N is growing exponentially. That is unfortunately true. But depending on the index size it might not matter at the moment. An optimization can be: On the authorative origin, don't copy files into the snapshot folders, but maintain the as symlink collections. E.g. <code>/4123/to/ki/tokio</code> points to <code>/tokio/up_to_0.3</code>. That way building a new snapshot mainly requires adding symlinks to the same revision. However one would require a custom origin for this. Whether it's worthwhile to go that route is likely a tradeoff between engineering complexity and cost. The preferred solution might change over time. Given the current solution is \"make a copy of the full index on each checkout\", and this would change it to \"make a copy of the full index on each build\" - it seems like the copy will be tolerable for some time.</li>\n</ul>\n<p>In case a custom origin is chosen instead of S3, and there are concerns about high load on this origin, one could look into using the \"CloudFront Origin Shield feature\", which adds a central cache layer between the edge locations and the authorative origin - which means the actual origin won't be queried by N edge locations anymore. But my feeling is that it might not be required for this use-case, since serving small static files should be rather efficient.</p>",
        "id": 218963929,
        "sender_full_name": "Matthias247",
        "timestamp": 1607220058
    },
    {
        "content": "<p>After finding the comment thread at <a href=\"https://github.com/rust-lang/rfcs/pull/2789/files#r536821549\">https://github.com/rust-lang/rfcs/pull/2789/files#r536821549</a> about this topic: Yes, retrying with a non-cacheable request can definitely also work! However in this case more of the complexity lives on the client side.</p>",
        "id": 218964853,
        "sender_full_name": "Matthias247",
        "timestamp": 1607221905
    },
    {
        "content": "<p>We can use the snapshot number for <a href=\"https://github.com/rust-lang/cargo/pull/8890#issuecomment-738181228\">RegistryData::current_version</a>, so that is an advantage.  Do you have a link for me to read up on what makes things non-cacheable? One thought is to add <code>?snapshot-number=4123</code> to the end of all file requests. That will force the cache to fetch each file once per publish, without the host needing to know how to serve old versions of the files. But I don't know the rules well enough to know if that makes sense.</p>",
        "id": 218966973,
        "sender_full_name": "Eh2406",
        "timestamp": 1607226128
    },
    {
        "content": "<p>Whether query strings are part of the cache-key (lead to separately cached versions of files) or not is now configurable via cache-policies:<br>\n<a href=\"https://aws.amazon.com/de/blogs/networking-and-content-delivery/amazon-cloudfront-announces-cache-and-origin-request-policies/\">https://aws.amazon.com/de/blogs/networking-and-content-delivery/amazon-cloudfront-announces-cache-and-origin-request-policies/</a><br>\n<a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/QueryStringParameters.html\">https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/QueryStringParameters.html</a><br>\n<a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html\">https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html</a></p>\n<p>So you can indeed add this kind of snapshot number and make sure you get a unique file. But that would require the origin to support the same. <br>\nOr if it doesn't, it would fall back to supporting only one revision and lose the immutable property (which might be good enough for alternate registries if they can support immutability through other means).</p>",
        "id": 218967645,
        "sender_full_name": "Matthias247",
        "timestamp": 1607227479
    },
    {
        "content": "<p>So, one concern with a query parameter is that some malicious user queries for a bunch of snapshot versions that that not yet happened yet to make the server cache a 404 (or worse yet, a stale view for that version). It can probably be worked around, but something worth keeping in mind.</p>",
        "id": 219123567,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607368012
    },
    {
        "content": "<p>Isn't that an issue with any hash addressed system?</p>",
        "id": 219124599,
        "sender_full_name": "Eh2406",
        "timestamp": 1607368440
    },
    {
        "content": "<p>No, it shouldn't be. If the storage is truly content-addressed, then trying to fetch a given file before it exists should result in a 404, and that 404 should be invalidated when the file does exist.</p>",
        "id": 219124935,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607368578
    },
    {
        "content": "<p>What prevents the cash from serving the old 404 after the new content is on the origin?</p>",
        "id": 219125177,
        "sender_full_name": "Eh2406",
        "timestamp": 1607368708
    },
    {
        "content": "<p>It's true that the 404 caching case is the same -- in both cases an invalidation has to happen for the hash when it occurs. The challenge is around serving someone a _stale_ version of a supposedly content-addressed file. If I request <code>/x/y?s=42</code> and the server just gives me whatever the current version of <code>/x/y</code> is (which may be <code>&lt;42</code> or even <code>&gt;42</code>), then things get awkward, because what I get back doesn't  match what I asked for</p>",
        "id": 219125506,
        "sender_full_name": "Jon Gjengset",
        "timestamp": 1607368876
    },
    {
        "content": "<p>True, It does not solve the security reason to have <code>hash addressing</code>, but it does solve the cash busting reason.</p>",
        "id": 219126399,
        "sender_full_name": "Eh2406",
        "timestamp": 1607369295
    },
    {
        "content": "<p>You can control the lifetime of cached error responses separately from good responses. There shouldn't be a big issue if TTL for 4xx/5xx is e.g. &lt; 1min</p>",
        "id": 219137116,
        "sender_full_name": "Matthias247",
        "timestamp": 1607374583
    },
    {
        "content": "<p>Default is 10s: <a href=\"https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/custom-error-pages-expiration.html\">https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/custom-error-pages-expiration.html</a></p>",
        "id": 219137199,
        "sender_full_name": "Matthias247",
        "timestamp": 1607374647
    }
]