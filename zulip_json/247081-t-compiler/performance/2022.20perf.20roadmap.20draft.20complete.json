[
    {
        "content": "<p>I have finished the draft of the <a href=\"https://hackmd.io/YJQSj_nLSZWl2sbI84R1qA?view\">Compiler performance roadmap for 2022</a>. Please take a look, comment on it, ask questions, etc.</p>",
        "id": 273033876,
        "sender_full_name": "nnethercote",
        "timestamp": 1645664073
    },
    {
        "content": "<p>In particular:</p>\n<ul>\n<li>Is anything important missing?</li>\n</ul>",
        "id": 273033897,
        "sender_full_name": "nnethercote",
        "timestamp": 1645664087
    },
    {
        "content": "<ul>\n<li>Is anything there you think shouldn't be?</li>\n</ul>",
        "id": 273033902,
        "sender_full_name": "nnethercote",
        "timestamp": 1645664093
    },
    {
        "content": "<ul>\n<li>Is anything unclear?</li>\n</ul>",
        "id": 273033908,
        "sender_full_name": "nnethercote",
        "timestamp": 1645664096
    },
    {
        "content": "<ul>\n<li>Are there items you want to assign to yourself?</li>\n</ul>",
        "id": 273034095,
        "sender_full_name": "nnethercote",
        "timestamp": 1645664229
    },
    {
        "content": "<p>I don't know if we should have any kind of official ratification procedure... hopefully consensus here is good enough, it's not a legal document <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 273034126,
        "sender_full_name": "nnethercote",
        "timestamp": 1645664271
    },
    {
        "content": "<p>Thanks!</p>",
        "id": 273034129,
        "sender_full_name": "nnethercote",
        "timestamp": 1645664278
    },
    {
        "content": "<p>I think my own goals on compiler bootstrap performance probably aren't well covered yet, might be good to add a section there. I plan to continue investing in that.</p>",
        "id": 273036965,
        "sender_full_name": "simulacrum",
        "timestamp": 1645666744
    },
    {
        "content": "<p>Good to hear, though I wonder if that's too specific for this document? Improvements would help rustc devs but not your typical Rust programmer.</p>",
        "id": 273041109,
        "sender_full_name": "nnethercote",
        "timestamp": 1645671477
    },
    {
        "content": "<p>Yeah, not sure</p>",
        "id": 273041496,
        "sender_full_name": "simulacrum",
        "timestamp": 1645671765
    },
    {
        "content": "<p>I think it influences the compiler performance wg's work (insofar as e.g. UX improvements to the triage comments, etc. will in part be informed by this work, I expect)</p>",
        "id": 273041519,
        "sender_full_name": "simulacrum",
        "timestamp": 1645671798
    },
    {
        "content": "<p>but most end users indeed probably don't care, though distros and other less Rust-y people could.</p>",
        "id": 273041524,
        "sender_full_name": "simulacrum",
        "timestamp": 1645671815
    },
    {
        "content": "<p>Let's leave it out for now, I think. We can always revise the roadmap and/or expand upon it in the future, afterall it's not like it must be exhaustive either :)</p>",
        "id": 273041605,
        "sender_full_name": "simulacrum",
        "timestamp": 1645671858
    },
    {
        "content": "<p>It would be nice to have these goals and tasks written somewhere, especially if other contributors can collaborate and help achieve them</p>",
        "id": 273051775,
        "sender_full_name": "lqd",
        "timestamp": 1645683391
    },
    {
        "content": "<p>As for preliminary task assignments:</p>\n<ul>\n<li>I can take the fxhash one: it would be great if mark could help make the repo and publishable for more people like us t-compiler contributors, I don’t know if bors is needed per se (I’m not even sure t-compiler has all necessary credentials) so that we can merge the PR syncing the repo with the actual <a href=\"http://crates.io\">crates.io</a> code at the very least. I hoped looking into it a bit more, esp if zoxc’s change is an instruction loss but cycles/wall-time because of vectorization, to see if the slice hashing could be vectorized a bit more even on our x64-v1 target (though if that part is of interest to others it’s very self contained and does not require any experience with rustc. It’s a good independent task, though fxhash is harsh and tends to waste a lot of people’s time). I’ll start with the WIP PR first anyways and see later.</li>\n<li>I can also take the cargo scheduling: I am looking into that now, and will ask the cargo team how/if to turn my prototype into a PR. I’m not sure the approach I took is acceptable, and I also need to test it more deeply to ensure the schedule is not just faster but also, you know, valid.</li>\n<li>I've looked a bit into the build scripts but it was only preliminary and seems a good independent task. I've noted the use cases I found in the analysis doc. wesley also mentioned the metabuild RFC, which is implemented in cargo, and could help with some of these use-cases (but not say, how seemingly slow they are to compile, and which needs to be compared to a regular hello world, and to check if it's a measurement issue or can be reproduced elsewhere)</li>\n<li>I'm currently trying to see if I can fix the pipelining issue in hyper (that is in hyper itself): it's not compiler work per se, but it does affect compile times for that whole eco-system significantly. There are in-progress and recently landed cargo PRs that could help as well.</li>\n<li>I do have access to a windows machine, and could try looking into PGO there</li>\n</ul>",
        "id": 273056194,
        "sender_full_name": "lqd",
        "timestamp": 1645688418
    },
    {
        "content": "<p>I was wondering, what do you all think about an item to take a look at allocators again: it's a very independent task. </p>\n<ul>\n<li>the mimalloc benchmarks were still a max-rss regressions but cpu time improvements were interesting. the beta supposed to fix the memory usage regressions seemed to nullify these perf improvements though, but maybe that has changed since the last perf run (unlikely, there's not that much activity in mimalloc but who knows). </li>\n<li>But I had tried locally snmalloc and it looked promising (especially if we want to do more multithreaded deallocs, say) and could maybe also help windows users though I've just looked at it on linux. It seemed at least worthy of taking a look. </li>\n<li>jemalloc 5.3 is about to release</li>\n<li>and of course there are others, like tcmalloc, though we likely wouldn't making much use of its multithreaded capabilities</li>\n</ul>\n<p>it doesn't have to be on the roadmap, much like mark's bootstrapping goals, for anyone to look at it</p>",
        "id": 273056621,
        "sender_full_name": "lqd",
        "timestamp": 1645688907
    },
    {
        "content": "<ul>\n<li><a href=\"https://github.com/rust-lang/rust/issues/93257\">#93257</a> suggest there might be opportunity for large improvement in building MIR cleanup blocks. Currently the code size is quadratic in input size in the provided test case.</li>\n</ul>",
        "id": 273058510,
        "sender_full_name": "tm",
        "timestamp": 1645690595
    },
    {
        "content": "<p>I believe we've seen this show up in real world profiles as well (and I had this issue bookmarked already apparently), e.g. in <code>tinyvec</code> IIRC</p>",
        "id": 273058816,
        "sender_full_name": "lqd",
        "timestamp": 1645690827
    },
    {
        "content": "<p>Good to have it fixed, but I don't think it needs to be mentioned on the roadmap</p>",
        "id": 273059147,
        "sender_full_name": "nnethercote",
        "timestamp": 1645691082
    },
    {
        "content": "<p>we can keep it at a high-level if you prefer, and link to other lists of more fine-grained tasks, for example if some people would want to know where they can contribute</p>",
        "id": 273060387,
        "sender_full_name": "lqd",
        "timestamp": 1645691940
    },
    {
        "content": "<p>(for the \"proc-macro2 and quote\" item in the list: there were <a href=\"https://github.com/dtolnay/quote/pull/162\">https://github.com/dtolnay/quote/pull/162</a> and <a href=\"https://github.com/dtolnay/proc-macro2/pull/239\">https://github.com/dtolnay/proc-macro2/pull/239</a> as examples of the general area of buffering to amortize the proc-macro bridge back and forth; I remember there are also WIP PRs for the bridge itself and can find them if we'd like to link things we could help test and land)</p>",
        "id": 273063810,
        "sender_full_name": "lqd",
        "timestamp": 1645694222
    },
    {
        "content": "<p>The roadmap looks good to me. One area that is potentially missing is getting Windows benchmarks running. While I think it's easy to argue that having benchmarks running on Windows would be helpful, it might not be worth the overall cost. <span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> was working on this before, but I believe the work has largely stalled at the point where the suite can at least be run locally. </p>\n<p>I won't have a ton of time to participate, but I'm hoping to have time to work a bit on perf.rlo UI/UX and PR process (e.g., gating bors when a PR is labeled as perf-regression with no perf-regression-triaged).</p>",
        "id": 273207645,
        "sender_full_name": "rylev",
        "timestamp": 1645782270
    }
]