[
    {
        "content": "<p>Good afternoon, a couple of days ago i found out about rustc's self profiling capabilities and measureme. I loved the concept from the start, being able to easily profile parts of code or your entire application very easily is something i wanted in my project and thought it would be very useful in general. However, looking deeper into it i realized measureme is just way too specific to rustc to be able to be easily adapted without making a wrapper on top of it. My main concerns boiled down to:</p>\n<h1>Profiling sub parts of an application</h1>\n<p>This is kind of just ugly, lets say i want to profile a small bit of code, well that means i must either lump the event with the rest of my program, or i need to make a new profiler, which well, its going to make 3 more files, here comes the clutter.</p>\n<h1>Automatic persistance to file is very very annoying</h1>\n<p>My biggest concern, no easy in-memory event data, this is pretty much the deal breaker for me, i would love to have control on what i do with my event data, do i want to just run a table generator to easily view the slowest traces? do i want to then output a flamegraph? all of this should be extremely easy for me to do on an EventData struct. i could simply have:</p>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">profile_data</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">my_app</span><span class=\"p\">.</span><span class=\"n\">profiler</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">();</span><span class=\"w\"></span>\n\n<span class=\"c1\">// display 20 slowest traces</span>\n<span class=\"c1\">// We can also offer both ASCII and (prettier) unicode tables</span>\n<span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">summarize_opts</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">SummarizeOptions</span>::<span class=\"n\">default</span><span class=\"p\">().</span><span class=\"n\">max_count</span><span class=\"p\">(</span><span class=\"mi\">20</span><span class=\"p\">).</span><span class=\"n\">chars</span><span class=\"p\">(</span><span class=\"n\">Chars</span>::<span class=\"n\">Unicode</span><span class=\"p\">);</span><span class=\"w\"></span>\n\n<span class=\"c1\">// Having a print function would allow us to use termcolor to style this nicely and still have it be portable</span>\n<span class=\"c1\">// Otherwise we can simply impl Display for this and have it render using uncolored text</span>\n<span class=\"n\">profile_data</span><span class=\"p\">.</span><span class=\"n\">summarize</span><span class=\"p\">(</span><span class=\"n\">summarize_opts</span><span class=\"p\">).</span><span class=\"n\">print</span><span class=\"p\">()</span><span class=\"o\">?</span><span class=\"p\">;</span><span class=\"w\"></span>\n\n<span class=\"c1\">// Make a flamegraph from the data and persist it to file, this should take a `Write` to allow for buffers but thats a separate thing</span>\n<span class=\"n\">profile_data</span><span class=\"p\">.</span><span class=\"n\">flamegraph</span><span class=\"p\">(</span><span class=\"s\">&quot;my_flamegraph.svg&quot;</span><span class=\"p\">)</span><span class=\"o\">?</span><span class=\"p\">;</span><span class=\"w\"></span>\n\n<span class=\"c1\">// Persist the data to disk in the form of 3 files, same as measureme does right now automatically.</span>\n<span class=\"n\">profile_data</span><span class=\"p\">.</span><span class=\"n\">persist</span><span class=\"p\">(</span><span class=\"s\">&quot;./my_trace/&quot;</span><span class=\"p\">)</span><span class=\"o\">?</span><span class=\"p\">;</span><span class=\"w\"></span>\n</code></pre></div>\n\n\n<p>lets say i want to get something specific from my profiler which has some nice data because it has already run on something. That would be very trivial.</p>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">profile_data</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">my_app</span><span class=\"p\">.</span><span class=\"n\">profiler</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">();</span><span class=\"w\"></span>\n\n<span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">duration</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">profile_data</span><span class=\"p\">.</span><span class=\"n\">get_trace_data</span><span class=\"p\">(</span><span class=\"s\">&quot;parsing&quot;</span><span class=\"p\">).</span><span class=\"n\">expect</span><span class=\"p\">(</span><span class=\"s\">&quot;Parsing has not been traced yet!&quot;</span><span class=\"p\">);</span><span class=\"w\"></span>\n\n<span class=\"n\">println</span><span class=\"o\">!</span><span class=\"p\">(</span><span class=\"s\">&quot;Parsing took {}ms&quot;</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">duration</span><span class=\"p\">.</span><span class=\"n\">as_millis</span><span class=\"p\">());</span><span class=\"w\"></span>\n</code></pre></div>\n\n\n<p>This would expand the scope of what you can do with the data massively, want to read existing data? very trivial:</p>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">profile_data</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">ProfileData</span>::<span class=\"n\">from_files</span><span class=\"p\">(</span><span class=\"s\">&quot;./my_trace/&quot;</span><span class=\"p\">).</span><span class=\"n\">expect</span><span class=\"p\">(</span><span class=\"s\">&quot;Invalid or missing data&quot;</span><span class=\"p\">);</span><span class=\"w\"></span>\n\n<span class=\"c1\">// We can also build dot graphs out of the data to allow for easier visualization of the flow of the program</span>\n<span class=\"c1\">// We can also include the time it took in each node and color them heatmap-like based on the % of the time they took</span>\n<span class=\"c1\">// basically an alternative to flamegraphs</span>\n<span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">dot_config</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">DotConfig</span>::<span class=\"n\">default</span><span class=\"p\">().</span><span class=\"n\">heatmap</span><span class=\"p\">();</span><span class=\"w\"></span>\n\n<span class=\"n\">profile_data</span><span class=\"p\">.</span><span class=\"n\">dot</span><span class=\"p\">(</span><span class=\"n\">dot_config</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"s\">&quot;dot_data.dot&quot;</span><span class=\"p\">)</span><span class=\"o\">?</span><span class=\"p\">;</span><span class=\"w\"></span>\n</code></pre></div>\n\n\n<p>Want to look at the difference between two runs? very trivial too:</p>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">first_data</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">ProfileData</span>::<span class=\"n\">from_files</span><span class=\"p\">(</span><span class=\"s\">&quot;./my_trace/&quot;</span><span class=\"p\">).</span><span class=\"n\">expect</span><span class=\"p\">(</span><span class=\"s\">&quot;Invalid or missing data&quot;</span><span class=\"p\">);</span><span class=\"w\"></span>\n<span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">second_data</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">my_app</span><span class=\"p\">.</span><span class=\"n\">profiler</span><span class=\"p\">.</span><span class=\"n\">data</span><span class=\"p\">();</span><span class=\"w\"></span>\n\n<span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">diff</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">DiffData</span>::<span class=\"n\">new</span><span class=\"p\">(</span><span class=\"n\">first_data</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">second_data</span><span class=\"p\">);</span><span class=\"w\"></span>\n\n<span class=\"n\">diff</span><span class=\"p\">.</span><span class=\"n\">flamegraph</span><span class=\"p\">(</span><span class=\"s\">&quot;my_diff_flamegraph.svg&quot;</span><span class=\"p\">)</span><span class=\"o\">?</span><span class=\"p\">;</span><span class=\"w\"></span>\n</code></pre></div>\n\n\n<p>This also works on Dot, and Summarize built in backends.</p>\n<h1>Analysis on existing data is painful if you do not want to run multiple analyses</h1>\n<p>Analysis tools being separate crates creates an ugly interface, what if i just want to get a flamegraph for this specific session? well, i need to first profile, then run a separate tool to convert it to the thing i actually want, then i need to clean up the profiling data.</p>\n<p>I understand why that is the case, sometimes you want to run multiple analyses, but automatically persisting to file leaves no room for easy output of individual analyzers. Analysis tools should be built in to the crate to allow for cleaner and more streamlined ways of analyzing that data.</p>\n<h1>Macros save the day</h1>\n<p>Macros would make using the library so much easier, being able to easily trace a function with a proc macro would make things very easy to use. The macros would work on a global profiler (a OnceCelled Profiler). This profiler can be enabled or disabled to pause tracing at any time. Proc macros may be used to profile with a different profiler but i have not thought about the best way of doing this yet, maybe an argument to the macro?</p>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"c1\">// No argument, the event recorded is the name of the function</span>\n<span class=\"cp\">#[trace]</span><span class=\"w\"></span>\n<span class=\"k\">pub</span><span class=\"w\"> </span><span class=\"k\">fn</span> <span class=\"nf\">parse_expr</span><span class=\"p\">(</span><span class=\"n\">p</span>: <span class=\"kp\">&amp;</span><span class=\"nc\">mut</span><span class=\"w\"> </span><span class=\"n\">Parser</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{}</span><span class=\"w\"></span>\n\n<span class=\"c1\">// The event recorded has the name fed in, the label and event ids are the same</span>\n<span class=\"cp\">#[trace(</span><span class=\"s\">&quot;Woohoo parse all the things🦀&quot;</span><span class=\"cp\">)]</span><span class=\"w\"></span>\n<span class=\"k\">pub</span><span class=\"w\"> </span><span class=\"k\">fn</span> <span class=\"nf\">something_else</span><span class=\"p\">(</span><span class=\"n\">p</span>: <span class=\"kp\">&amp;</span><span class=\"nc\">mut</span><span class=\"w\"> </span><span class=\"n\">Parser</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{}</span><span class=\"w\"></span>\n\n<span class=\"c1\">// The event recorded has the category of parsing and the name of the second argument</span>\n<span class=\"cp\">#[trace(</span><span class=\"s\">&quot;Parsing&quot;</span><span class=\"cp\">, </span><span class=\"s\">&quot;🦀consume tokens 🦀&quot;</span><span class=\"cp\">)]</span><span class=\"w\"></span>\n<span class=\"k\">pub</span><span class=\"w\"> </span><span class=\"k\">fn</span> <span class=\"nf\">consume</span><span class=\"p\">(</span><span class=\"n\">p</span>: <span class=\"kp\">&amp;</span><span class=\"nc\">mut</span><span class=\"w\"> </span><span class=\"n\">Parser</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{}</span><span class=\"w\"></span>\n\n<span class=\"k\">pub</span><span class=\"w\"> </span><span class=\"k\">fn</span> <span class=\"nf\">a</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"n\">trace_block</span><span class=\"o\">!</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"> </span><span class=\"s\">&quot;one chunky statement&quot;</span><span class=\"p\">,</span><span class=\"w\"></span>\n<span class=\"w\">       </span><span class=\"n\">do_something</span><span class=\"p\">();</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>\n\n\n<p>My proposal is to either:</p>\n<ul>\n<li>Refactor measureme into a more general, non-rustc specific library, it has a lot of potential and i genuinely think it is a great concept.</li>\n<li>Make a new library based on these concepts and eventually, if wanted, phase out measureme and use that library instead.</li>\n</ul>\n<p>Just some thoughts i had on this kind of thing, lemme know what you guys think and any criticisms of this design <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 207464721,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597873225
    },
    {
        "content": "<p>I believe that the backends used to write data are already well-factored out inside measureme, and if you wanted to add an in-memory backend we would not oppose that.</p>\n<p>Trace macros like you suggest are done (well, I suspect, though have not used) by tracing and that family of crates. I am personally not sure that they would help much in rustc's case, but I could be wrong. Integration of measureme and tracing via the subscriber functionality has been experimented with, in <a href=\"https://github.com/rust-lang/measureme/pull/120\">https://github.com/rust-lang/measureme/pull/120</a>, but at least at rustc's scale doesn't quite make sense as being in the same framework. I don't think rustc annotates enough functions to make it worthwhile to do as you suggest and add macros, because macros do have a readability/understanding cost. Of course, a proc macro should be able to call measureme's APIs if desired without measureme knowing anything about it.</p>",
        "id": 207465411,
        "sender_full_name": "simulacrum",
        "timestamp": 1597873687
    },
    {
        "content": "<p>I do realize at rustc's level it is just queries and those are profiled automatically (as far as i know), however rustc does not have to use the macros. They would mostly be something out of the scope of rustc, considering rustc already has a SelfProfiler, so it really makes no sense to use a global profiler and try to refactor it to use that.</p>",
        "id": 207465679,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597873908
    },
    {
        "content": "<p>Tracing does something kind of different, measureme is more about just knowing how long each thing took and how it compares to other runs. While tracing is about well, tracing the execution of a program, where you have data that can be tacked on to each event and it displays it nicely.</p>",
        "id": 207465815,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597873992
    },
    {
        "content": "<p>Hey <span class=\"user-mention\" data-user-id=\"276242\">@Riccardo D'Ambrosio</span>, thanks for the feedback! I'll try to respond to most of your points but apologies if I miss something. </p>\n<blockquote>\n<p>Profiling sub parts of an application</p>\n</blockquote>\n<p>I'm not quite following what the issue is. Could you expand on this a bit? </p>\n<blockquote>\n<p>Automatic persistance to file is very very annoying</p>\n</blockquote>\n<p>You can capture only in memory right now with the appropriate sink (for a basic example: <a href=\"https://docs.rs/measureme/0.7.1/measureme/struct.ByteVecSink.html\">https://docs.rs/measureme/0.7.1/measureme/struct.ByteVecSink.html</a>). This could probably be improved pretty easily to make this more ergonomic/performant. I would be happy to see improvements there.</p>\n<blockquote>\n<p>Analysis tools being separate crates creates an ugly interface, what if i just want to get a flamegraph for this specific session? </p>\n</blockquote>\n<p>With the in memory sink above, your app can call into those crates without going through the disk. Or least, we could certainly make that work however, it's unlikely we would move all of that code into the <code>measureme</code> crate directly since that's what rustc depends on and it wouldn't make use of that.</p>\n<blockquote>\n<p>Macros save the day</p>\n</blockquote>\n<p>I would not be opposed to having better ergonomics for profiling functions or sections of code but how your program integrates with <code>measureme</code> can vary so it would likely complicate the macros like you mention. </p>\n<blockquote>\n<p>Refactor measureme into a more general, non-rustc specific library, it has a lot of potential and i genuinely think it is a great concept.<br>\n   Make a new library based on these concepts and eventually, if wanted, phase out measureme and use that library instead.</p>\n</blockquote>\n<p>I think there's merit to both of these approaches however, rustc really really really cares about low overhead recording for millions to billions of events. I would be happy to land changes that make <code>measureme</code> easier to consume from other applications (FYI, the boa JS engine recently integrated <code>measureme</code> into their project and found a number of performance improvements) but we can't hurt rustc's use case in the process.</p>",
        "id": 207466250,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597874297
    },
    {
        "content": "<p>Thank you for the feedback!</p>\n<blockquote>\n<p>I'm not quite following what the issue is. Could you expand on this a bit?</p>\n</blockquote>\n<p>Right now measureme does not quite work ergonomically with multiple profilers, because well, each profiler dumps a good amount of data. 3 files being dumped with every profiler means you will run into clutter if you want to just have individual, isolated profilers for specific things.</p>\n<blockquote>\n<p>You can capture only in memory right now with the appropriate sink</p>\n</blockquote>\n<p>I looked at that, but the other big big part of my concerns was that the data is just so so so ugly to work with, you are essentially working over bytes of data, my proposal instead is:</p>\n<ul>\n<li>One single data struct</li>\n<li>the data struct has a persist method, this chooses whether to use the mmap or file backend (to my understanding, mmap sink is faster on non windows, correct?) automatically, the user doesnt need to know about this abstraction</li>\n<li>The data struct is kind of the heart of measureme, all the good stuff is here, it would have methods to get traces out of it, to maybe modify a trace, delete a trace, etc.</li>\n</ul>\n<blockquote>\n<p>... that's what rustc depends on and it wouldn't make use of that.</p>\n</blockquote>\n<p>methods such as <code>.flamegraph()</code> and <code>.dot()</code> would be feature locked (\"analysis\" maybe?), since i understand many uses may not need the analysis tools, they just want to use the data. a serialization feature would also be added to allow people to serialize the data into json for whatever they need.</p>\n<blockquote>\n<p>... but how your program integrates with measureme can vary so it would likely complicate the macros like you mention.</p>\n</blockquote>\n<p>I understand that, which is why the macros would be utilities for a \"const\" profiler (a profiler in a OnceCell), most people do not need many profilers, for them starting a single profiler at the start of the program is enough. Which is why that approach would help most people.</p>\n<blockquote>\n<p>... we can't hurt rustc's use case in the process.</p>\n</blockquote>\n<p>I understand that, making a data struct would not add a lot, if any, overhead to the existing implementation. Especially since a lot of this would be feature locked. I am not sure if a OnceCell dependency would be acceptable, if not, then that can be behind a feature too, its not too big of an issue id say.</p>",
        "id": 207467259,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597874961
    },
    {
        "content": "<blockquote>\n<p>Right now measureme does not quite work ergonomically with multiple profilers</p>\n</blockquote>\n<p>Ah, ok yes I totally agree. In general, we haven't thought through/don't have a good story around multiple profilers or capturing multiple crates into a single profile. (For example, you use a dependency which can export <code>measureme</code> events, how do you get that to talk to your profiler?)</p>\n<blockquote>\n<p>I looked at that, but the other big big part of my concerns was that the data is just so so so ugly to work with, you are essentially working over bytes of data</p>\n</blockquote>\n<p>In what sense? Consumers should either be using <code>Profiler::record_instant_event</code> or <code>Profiler::start_recording_interval_event</code> to generate data and then <code>analyzeme::ProfilingData</code> to read the data back. There shouldn't need to be any messing with raw bytes. </p>\n<blockquote>\n<p>One single data struct<br>\net al</p>\n</blockquote>\n<p>This generally seems fine to me in that we have this struct already <code>Profiler</code>. We could certainly add a convenience function to use the \"best\" serialization sink we ship with for your platform. The other functions seem probably fine as long as we can do them without storing all the events in memory if you're using a file sink. </p>\n<blockquote>\n<p>methods such as .flamegraph() and .dot() would be feature locked (\"analysis\" maybe?)</p>\n</blockquote>\n<p>Are you thinking these would return strings (for example) or a richer data type? This seems fine in principle since they're feature flagged off. </p>\n<blockquote>\n<p>a serialization feature would also be added to allow people to serialize the data into json for whatever they need.</p>\n</blockquote>\n<p>I don't see a huge need for that since that's essentially what the current file sinks give you but in a much more efficient format. I'm not strongly opposed though provided it's understood the json schema is not stable. </p>\n<blockquote>\n<p>I am not sure if a OnceCell dependency would be acceptable, if not, then that can be behind a feature too, its not too big of an issue id say.</p>\n</blockquote>\n<p>It's probably acceptable to take a dependency on OnceCell but, as you say, we can also feature flag that off.</p>",
        "id": 207468695,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597875996
    },
    {
        "content": "<p><code>OnceCell</code> is now in std too, if you're allowed unstable features</p>",
        "id": 207468846,
        "sender_full_name": "cuviper",
        "timestamp": 1597876107
    },
    {
        "content": "<p>isn't most of the point of the library being as cheap as possible?</p>",
        "id": 207468874,
        "sender_full_name": "eddyb",
        "timestamp": 1597876135
    },
    {
        "content": "<p>Oh, perfect! Yeah we can use unstable features if there's a good motivation.</p>",
        "id": 207468888,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597876144
    },
    {
        "content": "<p>otherwise you probably can just use tracing's timestamps?</p>",
        "id": 207468898,
        "sender_full_name": "eddyb",
        "timestamp": 1597876155
    },
    {
        "content": "<p>to sound less flippant: most of the complexity in <code>measureme</code> seems to be in trying to be <em>extremely</em> efficient, including have a whole string (rope?) management scheme that you would just not need if you were outputting JSON</p>",
        "id": 207469010,
        "sender_full_name": "eddyb",
        "timestamp": 1597876227
    },
    {
        "content": "<p>maybe the analaysis side could be shared? like I could see taking a stream of events and figuring out the nesting?</p>",
        "id": 207469026,
        "sender_full_name": "eddyb",
        "timestamp": 1597876260
    },
    {
        "content": "<p>but you can probably just do whatever you want for collecting them if you don't need the low-overhead</p>",
        "id": 207469110,
        "sender_full_name": "eddyb",
        "timestamp": 1597876327
    },
    {
        "content": "<blockquote>\n<p>Are you thinking these would return strings (for example) or a richer data type? This seems fine in principle since they're feature flagged off.</p>\n</blockquote>\n<p>Dot and Flamegraph would take a generic <code>Write</code> to allow people more control over where they want the final data to go. Summarize would output a string which can be easily printed.</p>",
        "id": 207469180,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597876383
    },
    {
        "content": "<p>Colored output with termcolor would be nice, since it would be feature locked i guess that would be acceptable?</p>",
        "id": 207469292,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597876456
    },
    {
        "content": "<p>summarize could output a printable data type that can also be serialized to JSON (like <code>summarize summarize --json</code>, which I've used extensibly)</p>",
        "id": 207469344,
        "sender_full_name": "eddyb",
        "timestamp": 1597876502
    },
    {
        "content": "<p>Yes, the main goal is to be very low-overhead. That's why events are persisted to disk and all of the analysis is done offline. I'd love to make things easier to use provided we don't hurt the performance.</p>",
        "id": 207469353,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597876509
    },
    {
        "content": "<p>there isn't much of an ergonomic problem in Rust to have a type that implements <code>fmt::Display</code> and you can just call <code>.to_string()</code> on it</p>",
        "id": 207469379,
        "sender_full_name": "eddyb",
        "timestamp": 1597876536
    },
    {
        "content": "<p>I kind of like that, but summarize only outputs X longest traces, maybe we could have an option to output all?</p>",
        "id": 207469406,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597876555
    },
    {
        "content": "<p>that's not what it does though?</p>",
        "id": 207469456,
        "sender_full_name": "eddyb",
        "timestamp": 1597876574
    },
    {
        "content": "<p>it outputs sums, not top N</p>",
        "id": 207469462,
        "sender_full_name": "eddyb",
        "timestamp": 1597876584
    },
    {
        "content": "<p>Is that not right? thats what i saw when i looked at it</p>",
        "id": 207469465,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597876586
    },
    {
        "content": "<p>and people usually truncate it but the output itself is 200+ rows long or however many queries rustc has</p>",
        "id": 207469480,
        "sender_full_name": "eddyb",
        "timestamp": 1597876609
    },
    {
        "content": "<p>yes i meant the top X summed traces with the same id</p>",
        "id": 207469489,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597876619
    },
    {
        "content": "<p>It sounds like a lot of this could be built in a separate library on top of <code>measureme</code> and then uplifted into measureme if there isn't adverse affects on performance.</p>",
        "id": 207469503,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597876629
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> most annoying thing to me for a long while was the split into 3 files, which I think is unnecessary for performance but I should prove it :P (especially now that we have better ways to quantify the overhead)</p>",
        "id": 207469529,
        "sender_full_name": "eddyb",
        "timestamp": 1597876657
    },
    {
        "content": "<p>Maybe separate crate and feature locked methods on the data struct?</p>",
        "id": 207469559,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597876681
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276242\">@Riccardo D'Ambrosio</span> I'm still not sure what you mean</p>",
        "id": 207469597,
        "sender_full_name": "eddyb",
        "timestamp": 1597876684
    },
    {
        "content": "<p>if you add together all the \"self time\"s you should get the exact total</p>",
        "id": 207469618,
        "sender_full_name": "eddyb",
        "timestamp": 1597876702
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"119009\">@eddyb</span>  I've got an idea bouncing around my head to get it down to 1 file I believe.</p>",
        "id": 207469619,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597876703
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"119009\">@eddyb</span> I think i misunderstood what summarize did, i think i get it now <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 207469626,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597876710
    },
    {
        "content": "<p>alright, glad that's resolved, I'll leave before this headache makes it even harder to talk lol</p>",
        "id": 207469655,
        "sender_full_name": "eddyb",
        "timestamp": 1597876736
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> I mean I would just put string building into events and have the reader side take the hit of having to build the string table, but maybe that's naive</p>",
        "id": 207469672,
        "sender_full_name": "eddyb",
        "timestamp": 1597876757
    },
    {
        "content": "<p>(note that I would only do this if it would not slow down recording regular events <em>at all</em>)</p>",
        "id": 207469761,
        "sender_full_name": "eddyb",
        "timestamp": 1597876808
    },
    {
        "content": "<p>Maybe It could be done like:</p>\n<ul>\n<li>Flamegraph, crox, stack collapse, and summarize are combined into one with analyzeme</li>\n<li>Refactor measureme data into a struct, that struct then has feature locked methods which just call analyzeme, methods like <code>.flamegraph()</code>, etc</li>\n<li>Analyzeme has further methods for getting diffs of existing files, etc</li>\n</ul>",
        "id": 207469863,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597876913
    },
    {
        "content": "<p>actually, something that's a bit odd but: why doesn't <code>measureme</code> use \"multiple binaries per Cargo package\"?</p>",
        "id": 207470001,
        "sender_full_name": "eddyb",
        "timestamp": 1597877015
    },
    {
        "content": "<p>or <code>analyzeme</code> I guess</p>",
        "id": 207470009,
        "sender_full_name": "eddyb",
        "timestamp": 1597877021
    },
    {
        "content": "<p>the binaries could be CLI wrappers around a library</p>",
        "id": 207470016,
        "sender_full_name": "eddyb",
        "timestamp": 1597877028
    },
    {
        "content": "<p>That way you have the best of both worlds, no more overhead (maybe persisting to file once instead of after each recording would be some overhead?) but you still have the ability to make nice graphs very easily</p>",
        "id": 207470025,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877038
    },
    {
        "content": "<p>Mostly that I didn't know what I was doing when I set up the workspace <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 207470079,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597877061
    },
    {
        "content": "<p>ah heh</p>",
        "id": 207470087,
        "sender_full_name": "eddyb",
        "timestamp": 1597877070
    },
    {
        "content": "<p>I think the problem is workspaces are new and some people learned about them and didn't know Cargo wasn't completely unusable before :P</p>",
        "id": 207470114,
        "sender_full_name": "eddyb",
        "timestamp": 1597877095
    },
    {
        "content": "<p>Im not sure if the macros and static profiler are acceptable without a feature, but that would be in measureme too</p>",
        "id": 207470168,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877144
    },
    {
        "content": "<p>like I keep seeing people surprised by \"multiple crates into one package\" and while it technically makes sense, maybe it could've been designed/communicated better</p>",
        "id": 207470173,
        "sender_full_name": "eddyb",
        "timestamp": 1597877147
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276242\">@Riccardo D'Ambrosio</span> what I'd say is you should use <code>measureme</code> only if you need the low overhead and otherwise directly record data in the <code>analyzeme</code> format</p>",
        "id": 207470252,
        "sender_full_name": "eddyb",
        "timestamp": 1597877191
    },
    {
        "content": "<p>(in memory or JSON or w/e)</p>",
        "id": 207470258,
        "sender_full_name": "eddyb",
        "timestamp": 1597877197
    },
    {
        "content": "<p>I think part of the reason it didn't occur to me was that we wanted analyzeme to be a separate crate in the workspace so once I'd figured that part out, the \"everything looks like a nail when all you have is a hammer\" syndrome kicked in.</p>",
        "id": 207470284,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597877220
    },
    {
        "content": "<p>Maybe the other way where analyzeme relies on measureme for getting the actual data? im not sure</p>",
        "id": 207470298,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877237
    },
    {
        "content": "<p>like if you need the <code>analyzeme</code> functionality without the profile recording, you could just skip all of that complexity entirely</p>",
        "id": 207470337,
        "sender_full_name": "eddyb",
        "timestamp": 1597877265
    },
    {
        "content": "<p>there's no need for everything built around the binary format and the string tables etc.</p>",
        "id": 207470408,
        "sender_full_name": "eddyb",
        "timestamp": 1597877302
    },
    {
        "content": "<p>So analyzeme would have its own profiler which gives different data?</p>",
        "id": 207470438,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877343
    },
    {
        "content": "<p>like the <code>Profiler</code> in <code>measureme</code> isn't really a \"profiler\" as much as it is a binary serializer of profile events</p>",
        "id": 207470462,
        "sender_full_name": "eddyb",
        "timestamp": 1597877369
    },
    {
        "content": "<p>the high-level data structures don't exist on the recording side right now, only on the analysis side</p>",
        "id": 207470486,
        "sender_full_name": "eddyb",
        "timestamp": 1597877391
    },
    {
        "content": "<p>yeah thats true, analyzeme having its own more high level profiler would be nice</p>",
        "id": 207470491,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877397
    },
    {
        "content": "<p>Well, I think eddyb's point is that if you're willing to accept the overhead of storing this stuff in memory and doing the analysis online, then a lot of the complexity that exists in measureme today is unnecessary.</p>",
        "id": 207470532,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597877404
    },
    {
        "content": "<p>thats true</p>",
        "id": 207470545,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877414
    },
    {
        "content": "<p><code>rustc_data_structures</code> has a type that is far more like what one might consider a profiler</p>",
        "id": 207470550,
        "sender_full_name": "eddyb",
        "timestamp": 1597877420
    },
    {
        "content": "<p>which wraps the <code>Profiler</code> from <code>measureme</code> and emits events into it</p>",
        "id": 207470560,
        "sender_full_name": "eddyb",
        "timestamp": 1597877431
    },
    {
        "content": "<p>so we could shift the perspective a bit around and have the <code>measureme</code> have a <code>LowOverheadRecorder</code></p>",
        "id": 207470591,
        "sender_full_name": "eddyb",
        "timestamp": 1597877456
    },
    {
        "content": "<p>yeah so measureme would be the low level high performance (yet limited) profiler</p>",
        "id": 207470616,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877481
    },
    {
        "content": "<p>and you could have a type that can wrap a \"recorder\"</p>",
        "id": 207470623,
        "sender_full_name": "eddyb",
        "timestamp": 1597877496
    },
    {
        "content": "<p>similar to how the <code>measureme</code> type today wraps a \"(byte) sink\"</p>",
        "id": 207470640,
        "sender_full_name": "eddyb",
        "timestamp": 1597877510
    },
    {
        "content": "<p>and doesn't care how the bytes are written</p>",
        "id": 207470687,
        "sender_full_name": "eddyb",
        "timestamp": 1597877523
    },
    {
        "content": "<p>just levels of abstraction</p>",
        "id": 207470698,
        "sender_full_name": "eddyb",
        "timestamp": 1597877532
    },
    {
        "content": "<p>that's only if you need a common API at all</p>",
        "id": 207470702,
        "sender_full_name": "eddyb",
        "timestamp": 1597877536
    },
    {
        "content": "<p>but also I was imagining you could build you own profiling thing pretty easily by just pushing <code>(Instant::now(), Event::Foo)</code> into a <code>Vec</code></p>",
        "id": 207470761,
        "sender_full_name": "eddyb",
        "timestamp": 1597877589
    },
    {
        "content": "<p>or hook it up to <code>tracing</code> events</p>",
        "id": 207470772,
        "sender_full_name": "eddyb",
        "timestamp": 1597877603
    },
    {
        "content": "<p>and I'd start by making a small demo like that, using the data types from <code>analyzeme</code> and then see if there is any point in abstracting it</p>",
        "id": 207470799,
        "sender_full_name": "eddyb",
        "timestamp": 1597877636
    },
    {
        "content": "<p>having spent the past few weeks of my life deep inside <code>measureme</code>, most of the code to me looks like a Rube Goldberg machine to encode timestamps into bytes :P</p>",
        "id": 207470902,
        "sender_full_name": "eddyb",
        "timestamp": 1597877720
    },
    {
        "content": "<p><span aria-label=\"grimacing\" class=\"emoji emoji-1f62c\" role=\"img\" title=\"grimacing\">:grimacing:</span></p>",
        "id": 207470914,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597877730
    },
    {
        "content": "<p>Haha thats true</p>",
        "id": 207470916,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877733
    },
    {
        "content": "<p>dont forget about the string table <span aria-label=\"wink\" class=\"emoji emoji-1f609\" role=\"img\" title=\"wink\">:wink:</span></p>",
        "id": 207470976,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877763
    },
    {
        "content": "<p>(not in a bad way, I just have mentally abstracted away anything that's outside \"time since start of profiling\" which is what I have been modifying)</p>",
        "id": 207470994,
        "sender_full_name": "eddyb",
        "timestamp": 1597877766
    },
    {
        "content": "<p>yeah, sorry, pairs of timestamps and (optimized) strings</p>",
        "id": 207471008,
        "sender_full_name": "eddyb",
        "timestamp": 1597877784
    },
    {
        "content": "<p>If not for the string table, traces from rustc would be multi-gigabyte probably. <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 207471046,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597877816
    },
    {
        "content": "<p>the virtual stuff is a really clever solution too</p>",
        "id": 207471064,
        "sender_full_name": "eddyb",
        "timestamp": 1597877828
    },
    {
        "content": "<p>I would've done something less elegant lol</p>",
        "id": 207471073,
        "sender_full_name": "eddyb",
        "timestamp": 1597877837
    },
    {
        "content": "<p>Interning saves the day</p>",
        "id": 207471078,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877841
    },
    {
        "content": "<p>interning and ropes and lazy binding :P</p>",
        "id": 207471091,
        "sender_full_name": "eddyb",
        "timestamp": 1597877860
    },
    {
        "content": "<p>The string table still confuses the heck out of me, im not sure whats going on there</p>",
        "id": 207471157,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877896
    },
    {
        "content": "<p>anyway like I said, I'll go before I get even less coherent, maybe if I forget all the Intel codenames the headache will go away</p>",
        "id": 207471161,
        "sender_full_name": "eddyb",
        "timestamp": 1597877900
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"276242\">@Riccardo D'Ambrosio</span> instead of storing strings, store instructions to build strings on the decoder side</p>",
        "id": 207471186,
        "sender_full_name": "eddyb",
        "timestamp": 1597877932
    },
    {
        "content": "<p>defer cost at any cost</p>",
        "id": 207471209,
        "sender_full_name": "eddyb",
        "timestamp": 1597877948
    },
    {
        "content": "<p>That should probably be the project moto lol</p>",
        "id": 207471233,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597877970
    },
    {
        "content": "<p>Hmmm, i think ive heard of ropes in terms of lexers, but im still not sure what they refer to haha</p>",
        "id": 207471245,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597877978
    },
    {
        "content": "<p>your string representation being <code>Vec&lt;String&gt;</code> or similar (probably linked lists). defer concatenation until needed (if ever)</p>",
        "id": 207471351,
        "sender_full_name": "eddyb",
        "timestamp": 1597878013
    },
    {
        "content": "<p>JS engines love to do this</p>",
        "id": 207471359,
        "sender_full_name": "eddyb",
        "timestamp": 1597878020
    },
    {
        "content": "<p>(and yes the name is just a pun lol)</p>",
        "id": 207471372,
        "sender_full_name": "eddyb",
        "timestamp": 1597878035
    },
    {
        "content": "<p>I think i will experiment and make my own lib first for my project (js linter, speed matters), then maybe ill see how i could rework analyzeme in the future to work like that <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 207471644,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597878237
    },
    {
        "content": "<p>You might also want to look in to the tracing crate. From what I've heard (I have not used it), it sounds like they're building similar tools so you might find they already have what you need.</p>",
        "id": 207471864,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597878378
    },
    {
        "content": "<p>I looked at it, I could probably use it, but i dont need tracing, i just need profiling data like measureme, so i think its overkill for me</p>",
        "id": 207471924,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597878435
    },
    {
        "content": "<p>Ah gotcha</p>",
        "id": 207471932,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597878448
    },
    {
        "content": "<p>Well, it is great to get some feedback on measureme so thank you a lot for that! It's clear there are some probably easy wins to make the crate easier to use without affecting performance at all.</p>",
        "id": 207472024,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1597878499
    },
    {
        "content": "<p>Thank you for the feedback too</p>",
        "id": 207472040,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597878521
    },
    {
        "content": "<p>the way measureme profiles is very _very_ similar to what tracing gives you more generically</p>",
        "id": 207473131,
        "sender_full_name": "nagisa",
        "timestamp": 1597879414
    },
    {
        "content": "<p>I would rather not include the whole of tracing when all i need is just basic profiling and graphing, i think the easiest way of doing this is actually to just make a new crate in my project lol</p>",
        "id": 207473501,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597879756
    },
    {
        "content": "<p>and as far as i know tracing doesnt have an easy way of say, making a flamegraph</p>",
        "id": 207473514,
        "sender_full_name": "Riccardo D'Ambrosio",
        "timestamp": 1597879774
    },
    {
        "content": "<p><a href=\"http://docs.rs/tracing-flame\">docs.rs/tracing-flame</a></p>",
        "id": 207473784,
        "sender_full_name": "nagisa",
        "timestamp": 1597879994
    }
]