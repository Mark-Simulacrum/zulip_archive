[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> so I got into a discussion with <span class=\"user-mention\" data-user-id=\"216025\">@Siân Griffin</span> about measuring things and cache misses came up again. would be nice to have that kind of data as well (and I suspect it might be possible to collect it with my <code>rdpmc</code> infra as well)</p>",
        "id": 205852671,
        "sender_full_name": "eddyb",
        "timestamp": 1596492347
    },
    {
        "content": "<p>I think they'd indeed be helpful</p>",
        "id": 205852831,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492403
    },
    {
        "content": "<p>it should be fairly easy to add nowadays, someone just needs to do  it</p>",
        "id": 205852858,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492412
    },
    {
        "content": "<p>mostly within self-profile, I imagine, though maybe outside it as well</p>",
        "id": 205852913,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492431
    },
    {
        "content": "<p>the one source of non-determinism that I can think of is cache lines getting invalidated by context-switching (including from syscalls). which is basically the side-channel that we have several named vulnerabilities for now :P</p>",
        "id": 205852931,
        "sender_full_name": "eddyb",
        "timestamp": 1596492444
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> tbh it would've been nice to already have the (whole-process) data for the past few months, given what I'm planning on doing, welp. maybe we can just start measuring it on perf.r-l.o through <code>perf stat</code>? I guess a filter is used and that's why we don't already have that data?</p>",
        "id": 205853073,
        "sender_full_name": "eddyb",
        "timestamp": 1596492543
    },
    {
        "content": "<p>yeah <a href=\"https://github.com/rust-lang/rustc-perf/blob/master/collector/src/rustc-fake.rs#L49\">https://github.com/rust-lang/rustc-perf/blob/master/collector/src/rustc-fake.rs#L49</a></p>",
        "id": 205853098,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492569
    },
    {
        "content": "<p>basically someone should just update that in a PR I think</p>",
        "id": 205853107,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492575
    },
    {
        "content": "<p>and I guess this table <a href=\"https://github.com/rust-lang/rustc-perf/blob/master/site/static/index.html#L48\">https://github.com/rust-lang/rustc-perf/blob/master/site/static/index.html#L48</a></p>",
        "id": 205853127,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492599
    },
    {
        "content": "<p>there aren't other places in the code which hardcode stuff like that?</p>",
        "id": 205853267,
        "sender_full_name": "eddyb",
        "timestamp": 1596492672
    },
    {
        "content": "<p>I think no, we removed all of them (or tried to)</p>",
        "id": 205853282,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492692
    },
    {
        "content": "<p><a href=\"https://gist.github.com/Mark-Simulacrum/151b4948d6bd1ab86b5c1d9b36ba64de\">https://gist.github.com/Mark-Simulacrum/151b4948d6bd1ab86b5c1d9b36ba64de</a></p>",
        "id": 205853283,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492694
    },
    {
        "content": "<p>that's the list of things we can collect without reading cpu manuals</p>",
        "id": 205853290,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492703
    },
    {
        "content": "<p>heh</p>",
        "id": 205853302,
        "sender_full_name": "eddyb",
        "timestamp": 1596492711
    },
    {
        "content": "<p>well I guess technically <a href=\"https://gist.github.com/Mark-Simulacrum/2146f7cf547b6a4cdf98c43340bb5706\">https://gist.github.com/Mark-Simulacrum/2146f7cf547b6a4cdf98c43340bb5706</a>? that's with sudo</p>",
        "id": 205853391,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492758
    },
    {
        "content": "<p>I don't think that has extra Hardware events</p>",
        "id": 205853468,
        "sender_full_name": "eddyb",
        "timestamp": 1596492828
    },
    {
        "content": "<p>but also, ugh, only L1. so not a great predictor for DRAM bandwidth</p>",
        "id": 205853545,
        "sender_full_name": "eddyb",
        "timestamp": 1596492856
    },
    {
        "content": "<p>yeah :/</p>\n<p>maybe TLB misses are like 'worst case'</p>",
        "id": 205853660,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492923
    },
    {
        "content": "<p>but I imagine those are quite low</p>",
        "id": 205853666,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492927
    },
    {
        "content": "<p>we can probably get L2 and L3 if we go read the cpu manual</p>",
        "id": 205853675,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492936
    },
    {
        "content": "<p>actually, one concern might be that this is all virtualized... somehow</p>",
        "id": 205853695,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492950
    },
    {
        "content": "<p>instructions are relatively stable but I think caches are presumably less so?</p>",
        "id": 205853749,
        "sender_full_name": "simulacrum",
        "timestamp": 1596492964
    },
    {
        "content": "<p>also there isn't just one counter so you'd have to read like at least two and aggregate them</p>",
        "id": 205853761,
        "sender_full_name": "eddyb",
        "timestamp": 1596492975
    },
    {
        "content": "<p>I would suspect non-determinism would mostly come from other address spaces, i.e. the context-switching I mentioned before (and memory allocation non-determinism, which I don't know the full difficulty of removing that, but that also impacts instruction counts through pointer hashing)</p>",
        "id": 205853911,
        "sender_full_name": "eddyb",
        "timestamp": 1596493094
    },
    {
        "content": "<p>well, we can at least try</p>",
        "id": 205854367,
        "sender_full_name": "simulacrum",
        "timestamp": 1596493441
    },
    {
        "content": "<p>worst case the data is just super noisy and we ignore it</p>",
        "id": 205854412,
        "sender_full_name": "simulacrum",
        "timestamp": 1596493448
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"119009\">@eddyb</span> If you want to improve measurement accuracy, you could always pin a process to a CPU, and enable full-no-hz. With that, you should get very low variance.</p>",
        "id": 206545491,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1597129386
    },
    {
        "content": "<p>In the absence of that, cache misses could vary more, but they're still useful.</p>",
        "id": 206545516,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1597129429
    },
    {
        "content": "<p>There are performance counters for it. Perf abstracts over the necessary ones for each CPU.</p>",
        "id": 206545571,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1597129471
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> how do you pin a process to a cpu? :0<br>\nAnd does it also give you exclusive access to its cache for the duration of the process?</p>",
        "id": 206588122,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1597159060
    },
    {
        "content": "<p>(I'm curious; didn't know this was a thing)</p>",
        "id": 206588156,
        "sender_full_name": "Félix Fischer",
        "timestamp": 1597159075
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> My impression was that the process pinning you describe requires us to dedicate N cores - currently rustc can use all 12 virtual cores on the collector but I think we'd need to limit to 11 with this, right?</p>",
        "id": 206589147,
        "sender_full_name": "simulacrum",
        "timestamp": 1597159545
    },
    {
        "content": "<p>Note that we also have <code>perf stat</code> running  on all of our runs and such.</p>",
        "id": 206589750,
        "sender_full_name": "simulacrum",
        "timestamp": 1597159792
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"212698\">Félix Fischer</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/cache.20misses/near/206588122\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> how do you pin a process to a cpu? :0<br>\nAnd does it also give you exclusive access to its cache for the duration of the process?</p>\n</blockquote>\n<p><code>taskset(1)</code></p>",
        "id": 206591440,
        "sender_full_name": "nagisa",
        "timestamp": 1597160648
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/cache.20misses/near/206589147\">said</a>:</p>\n<blockquote>\n<p>Josh Triplett My impression was that the process pinning you describe requires us to dedicate N cores - currently rustc can use all 12 virtual cores on the collector but I think we'd need to limit to 11 with this, right?</p>\n</blockquote>\n<p>Not necessarily. core pinning forces process to be scheduled on the particular cores when its ready to run, but it does not mean other processes cannot be run on those cores.</p>",
        "id": 206591633,
        "sender_full_name": "nagisa",
        "timestamp": 1597160759
    },
    {
        "content": "<p>Preventing linux (at least) from scheduling anything on particular cores requires fiddling with kernel cli</p>",
        "id": 206591784,
        "sender_full_name": "nagisa",
        "timestamp": 1597160827
    },
    {
        "content": "<p>so what you'd have to do to ensure core is dedicated to a particular process is: 1. fiddle with kernel cli to ensure scheduler never schedules anything on that core normally; 2. probably adjust something to ensure same holds for IRQs; 3. taskset the interesting process to run on the core that has been dedicated for this through steps 1 and 2.</p>",
        "id": 206592008,
        "sender_full_name": "nagisa",
        "timestamp": 1597160933
    },
    {
        "content": "<p>yeah I think that's going to be pretty untenable from what it sounds like for perf specifically, because we can't afford to serialize (or anything close to it) dependency building</p>",
        "id": 206614483,
        "sender_full_name": "simulacrum",
        "timestamp": 1597171476
    },
    {
        "content": "<p>maybe we can taskset a bunch of things onto the same set of cores though? I'd need to read up on how it all works out</p>",
        "id": 206614545,
        "sender_full_name": "simulacrum",
        "timestamp": 1597171505
    },
    {
        "content": "<p>You could taskset just the crate being benchmarked. If it is an executable or pipelining is disabled, that rustc instance will be the only rustc instance when it runs.</p>",
        "id": 206617233,
        "sender_full_name": "bjorn3",
        "timestamp": 1597172680
    },
    {
        "content": "<p>well we still need to build the dependencies, and if I understand <span class=\"user-mention\" data-user-id=\"123586\">@nagisa</span> right, if I configure the kernel to avoid (say) vcores 0-10 (out of 12) in normal functioning then I need to <em>always</em> taskset every process onto those cores if I want parallelism in dependency building</p>",
        "id": 206617564,
        "sender_full_name": "simulacrum",
        "timestamp": 1597172877
    },
    {
        "content": "<p>all this sounds doable on <a href=\"http://build.lyken.rs\">build.lyken.rs</a> which is 24C/48T (although we'd have to set it up with our sysadmin), so all of these details seem helpful, thanks!</p>",
        "id": 206620744,
        "sender_full_name": "eddyb",
        "timestamp": 1597174539
    },
    {
        "content": "<p>another thing is that most of the useful data, IMO, comes from the pre-LLVM part of the compilation, which can be kept single-threaded</p>",
        "id": 206620779,
        "sender_full_name": "eddyb",
        "timestamp": 1597174558
    },
    {
        "content": "<p>that is, I'd only measure check-only builds, in terms of optimizing rustc itself</p>",
        "id": 206620867,
        "sender_full_name": "eddyb",
        "timestamp": 1597174581
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/cache.20misses/near/206617564\">said</a>:</p>\n<blockquote>\n<p>well we still need to build the dependencies, and if I understand <span class=\"user-mention silent\" data-user-id=\"123586\">nagisa</span> right, if I configure the kernel to avoid (say) vcores 0-10 (out of 12) in normal functioning then I need to <em>always</em> taskset every process onto those cores if I want parallelism in dependency building</p>\n</blockquote>\n<p>You could configure the kernel to avoid some cores, then use taskset to also allow the rustc of dependencies on those cores and finally use taskset to limit the benchmarked crate to those cores once all dependencies are compiled.</p>",
        "id": 206627542,
        "sender_full_name": "bjorn3",
        "timestamp": 1597178081
    },
    {
        "content": "<p>yeah I'm not enthusiastic about \"taskset to also allow the rustc of dependencies on those cores\" -- I presume I can't just taskset cargo, right? I need to do so for every process (or thread?)</p>",
        "id": 206627649,
        "sender_full_name": "simulacrum",
        "timestamp": 1597178144
    },
    {
        "content": "<p>We are already using a rustc wrapper I think. That one could spawn rustc through taskset.</p>",
        "id": 206627898,
        "sender_full_name": "bjorn3",
        "timestamp": 1597178258
    },
    {
        "content": "<p>right, but if you need to do it for each process it won't cover build scripts etc which is pretty bad</p>",
        "id": 206627981,
        "sender_full_name": "simulacrum",
        "timestamp": 1597178284
    },
    {
        "content": "<p>Build scripts are generally not using multiple threads, right? So it should be fine to keep running them one the one or more cores not reserved for benchmarking.</p>",
        "id": 206628192,
        "sender_full_name": "bjorn3",
        "timestamp": 1597178384
    },
    {
        "content": "<p>they definitely are, for spawning c/c++ compilers</p>",
        "id": 206628302,
        "sender_full_name": "simulacrum",
        "timestamp": 1597178415
    },
    {
        "content": "<p>Ah, yes. More conplex but maybe add a gcc wrapper? The build scripts should look at the CC env var, right?</p>",
        "id": 206628638,
        "sender_full_name": "bjorn3",
        "timestamp": 1597178561
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/cache.20misses/near/206627649\">said</a>:</p>\n<blockquote>\n<p>I presume I can't just taskset cargo, right?</p>\n</blockquote>\n<p>Why not? AFAIK it would be inherited to child processes</p>",
        "id": 206628647,
        "sender_full_name": "cuviper",
        "timestamp": 1597178565
    },
    {
        "content": "<p>in fact I was using it that way in <a href=\"https://github.com/rust-lang/cargo/issues/8595\">cargo#8595</a></p>",
        "id": 206628775,
        "sender_full_name": "cuviper",
        "timestamp": 1597178640
    },
    {
        "content": "<p>Cargo processes the rustc output, which would cause a bit of noise when run on the same core as rustc.</p>",
        "id": 206629073,
        "sender_full_name": "bjorn3",
        "timestamp": 1597178764
    },
    {
        "content": "<p>The noise may be low enough though.</p>",
        "id": 206629117,
        "sender_full_name": "bjorn3",
        "timestamp": 1597178784
    },
    {
        "content": "<p>well, we can plausibly do something like this:</p>\n<ul>\n<li>by default, i.e., when building dependencies, run taskset with all cores allowed on cargo -- this should remove any harmful perf effects</li>\n<li>in the final compilation, when we're benchmarking rustc performance, we know that rustc will only get invoked once, so we can <em>not</em> taskset cargo and instead taskset the rustc that'll get spawned</li>\n</ul>",
        "id": 206629266,
        "sender_full_name": "simulacrum",
        "timestamp": 1597178875
    }
]