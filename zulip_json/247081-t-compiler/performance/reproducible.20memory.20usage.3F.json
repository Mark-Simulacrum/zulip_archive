[
    {
        "content": "<p>Hey <span class=\"user-mention\" data-user-id=\"119009\">@eddyb</span>, would the <em>extensive</em> work you did on reproducible instruction counts also make it possible to get reproducible memory usage, to make statistics like max-rss more useful and more usable? Right now they fluctuate too much to detect small changes in memory usage.</p>",
        "id": 232838174,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1617318812
    },
    {
        "content": "<p>No, I don't think so. The thing is that the memory usage should be deterministic it is very sensitive to the order, size and amount of allocations. To get more stable memory usage measurements during benchmarking, you need to hook into the allocator to get the amount of actually allocated memory.</p>",
        "id": 232871133,
        "sender_full_name": "bjorn3",
        "timestamp": 1617349574
    },
    {
        "content": "<p>I was under the impression that eddyb's work on deterministic instruction counts ended up having to deal with the same issue in order to get reproducible results.</p>",
        "id": 232876393,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1617353633
    },
    {
        "content": "<p>Jemalloc has a background thread that frees memory to the OS after a certain period. I believe this period is long enough to not trigger on most benchmarks though.</p>",
        "id": 232876611,
        "sender_full_name": "bjorn3",
        "timestamp": 1617353768
    },
    {
        "content": "<p>I wonder how zig-like allocator scheme fares in reproducibility here. But imho if we are looking to measure memory the easiest way to reproducible results is to record the current allocated size in the program itself potentially by wrapping an existing allocator.</p>",
        "id": 232911821,
        "sender_full_name": "nagisa",
        "timestamp": 1617377093
    },
    {
        "content": "<p>Current allocated size won't be affected by the implementation of allocator as much that way.</p>",
        "id": 232911923,
        "sender_full_name": "nagisa",
        "timestamp": 1617377151
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"123586\">nagisa</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/reproducible.20memory.20usage.3F/near/232911821\">said</a>:</p>\n<blockquote>\n<p>I wonder how zig-like allocator scheme fares in reproducibility here. But imho if we are looking to measure memory the easiest way to reproducible results is to record the current allocated size in the program itself potentially by wrapping an existing allocator.</p>\n</blockquote>\n<p>Which kind of wrapping do you mean? doing something with LD_PRELOAD to intercept <code>malloc</code>? Or overriding the Rust global allocator? (I would love to say “the latter”, but of course that doesn’t fully address the case I care most about, namely <code>rustc</code> itself.)</p>",
        "id": 232912146,
        "sender_full_name": "pnkfelix",
        "timestamp": 1617377277
    },
    {
        "content": "<p>Latter. I did employ that kind of strategy in embedded firmware to a great success. But I also had a chance to actually make all of the users actually go through the API that employed such tracking.</p>",
        "id": 232912580,
        "sender_full_name": "nagisa",
        "timestamp": 1617377509
    },
    {
        "content": "<p><code>massif</code> comes to mind as an external tool that would do the ld_preload kind of stuff for you.</p>",
        "id": 232912646,
        "sender_full_name": "nagisa",
        "timestamp": 1617377527
    },
    {
        "content": "<p>Would a dumb bump allocator without ASLR or guard pages and disabling free() be feasible for small benchmarks or would that still exhaust memory too quickly? Then RSS should be the sum of all allocations instead of the peak live set.</p>",
        "id": 232912654,
        "sender_full_name": "The 8472",
        "timestamp": 1617377533
    },
    {
        "content": "<p>I wonder if any of the jemalloc's diagnostic tooling/APIs expose anything like max allocated/total allocated too.</p>",
        "id": 232912784,
        "sender_full_name": "nagisa",
        "timestamp": 1617377602
    },
    {
        "content": "<p>yeah jemalloc collects some information it seems:</p>\n<blockquote>\n<p>stats.allocated (size_t) r- [--enable-stats]</p>\n<p>Total number of bytes allocated by the application. </p>\n<p>stats.active (size_t) r- [--enable-stats]</p>\n<p>Total number of bytes in active pages allocated by the application. This is a multiple of the page size, and greater than or equal to stats.allocated. This does not include stats.arenas.&lt;i&gt;.pdirty, stats.arenas.&lt;i&gt;.pmuzzy, nor pages entirely devoted to allocator metadata.</p>\n</blockquote>\n<p>from <a href=\"https://nxmnpg.lemoda.net/3/malloc_stats_print\">https://nxmnpg.lemoda.net/3/malloc_stats_print</a></p>",
        "id": 232913152,
        "sender_full_name": "nagisa",
        "timestamp": 1617377779
    },
    {
        "content": "<p>the question is if its possible to easily obtain these numbers more directly than printing them out and then parsing them back.</p>",
        "id": 232913238,
        "sender_full_name": "nagisa",
        "timestamp": 1617377832
    },
    {
        "content": "<p>(well at least one can ask the stats to be printed in json format… <span aria-label=\"lol\" class=\"emoji emoji-1f606\" role=\"img\" title=\"lol\">:lol:</span> )</p>",
        "id": 232913851,
        "sender_full_name": "pnkfelix",
        "timestamp": 1617378163
    },
    {
        "content": "<p>but: sort of sad that it really does only do a print out. Like, why not an interface with a callback that takes a <code>(key: *const char, val: *const u64)</code> pair?</p>",
        "id": 232914013,
        "sender_full_name": "pnkfelix",
        "timestamp": 1617378258
    },
    {
        "content": "<p>(security concerns?)</p>",
        "id": 232914113,
        "sender_full_name": "pnkfelix",
        "timestamp": 1617378330
    },
    {
        "content": "<p>Modifiability maybe? So that people don't depend on what's effectively an internal counter most likely.</p>",
        "id": 232914157,
        "sender_full_name": "nagisa",
        "timestamp": 1617378354
    },
    {
        "content": "<p>I think there are such apis</p>",
        "id": 232914544,
        "sender_full_name": "simulacrum",
        "timestamp": 1617378568
    },
    {
        "content": "<p><a href=\"https://docs.rs/jemalloc-ctl/0.3.3/jemalloc_ctl/stats/struct.allocated_mib.html\">https://docs.rs/jemalloc-ctl/0.3.3/jemalloc_ctl/stats/struct.allocated_mib.html</a></p>",
        "id": 232914578,
        "sender_full_name": "simulacrum",
        "timestamp": 1617378593
    },
    {
        "content": "<p>nice!</p>",
        "id": 232914794,
        "sender_full_name": "nagisa",
        "timestamp": 1617378701
    },
    {
        "content": "<p>Hmm! wish I had known about (slash bothered looking for) this before the shrink-mem sprint!</p>",
        "id": 232914915,
        "sender_full_name": "pnkfelix",
        "timestamp": 1617378762
    },
    {
        "content": "<p>I don't know if it, well, works</p>",
        "id": 232914956,
        "sender_full_name": "simulacrum",
        "timestamp": 1617378786
    },
    {
        "content": "<p>but seems plausible :)</p>",
        "id": 232915002,
        "sender_full_name": "simulacrum",
        "timestamp": 1617378807
    },
    {
        "content": "<p>heaptrack appears to work with rustc too AFAICT, but is not able to extract the allocation sizes (6MB peak is _very_ suspicious). Some interesting results though:</p>\n<div class=\"codehilite\"><pre><span></span><code>$ heaptrack_print heaptrack.rustc.28607.zst | tail -n5\ncalls to allocation functions: 22089 (69028/s)\ntemporary memory allocations: 2314 (7231/s)\npeak heap memory consumption: 5.66MB\npeak RSS (including heaptrack overhead): 106.91MB\ntotal memory leaked: 320.50KB\n$ heaptrack_print heaptrack.rustc.28653.zst | tail -n5\ncalls to allocation functions: 22089 (68813/s)\ntemporary memory allocations: 2355 (7336/s)\npeak heap memory consumption: 5.69MB\npeak RSS (including heaptrack overhead): 106.25MB\ntotal memory leaked: 320.50KB\n$ heaptrack_print heaptrack.rustc.28755.zst | tail -n5\ncalls to allocation functions: 22085 (69231/s)\ntemporary memory allocations: 2298 (7203/s)\npeak heap memory consumption: 5.68MB\npeak RSS (including heaptrack overhead): 109.49MB\ntotal memory leaked: 320.50KB\n$ heaptrack_print heaptrack.rustc.29012.zst | tail -n5\ncalls to allocation functions: 22086 (69018/s)\ntemporary memory allocations: 2322 (7256/s)\npeak heap memory consumption: 5.68MB\npeak RSS (including heaptrack overhead): 109.66MB\ntotal memory leaked: 320.50KB\n</code></pre></div>\n<p>Looks like number of allocations is still slightly not reproducible, even with <code>-Ccodegen-units=1</code>. The number of allocation function calls between runs differing is also somewhat curious.</p>",
        "id": 232916253,
        "sender_full_name": "nagisa",
        "timestamp": 1617379391
    },
    {
        "content": "<p>hmm I have not been able to get heaptrack to work with jemalloc - are you using the system allocator?</p>",
        "id": 232916532,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1617379515
    },
    {
        "content": "<p><a href=\"https://bugs.kde.org/show_bug.cgi?id=431746\">https://bugs.kde.org/show_bug.cgi?id=431746</a></p>",
        "id": 232916549,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1617379520
    },
    {
        "content": "<p>I am not, I bet its just counting whatever other allocations happen to go through the system allocator.</p>",
        "id": 232916576,
        "sender_full_name": "nagisa",
        "timestamp": 1617379539
    },
    {
        "content": "<p>very strange, for me it hangs indefinitely</p>",
        "id": 232916598,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1617379552
    },
    {
        "content": "<p>but I did see things like <code>RawVec</code> in stack traces so <span aria-label=\"shrug\" class=\"emoji emoji-1f937\" role=\"img\" title=\"shrug\">:shrug:</span></p>",
        "id": 232916603,
        "sender_full_name": "nagisa",
        "timestamp": 1617379554
    },
    {
        "content": "<p>what version of heaptrack do you have?</p>",
        "id": 232916611,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1617379561
    },
    {
        "content": "<p>this would be super useful for me locally</p>",
        "id": 232916651,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1617379565
    },
    {
        "content": "<p>1.2.0, from nixpkgs</p>",
        "id": 232916672,
        "sender_full_name": "nagisa",
        "timestamp": 1617379575
    },
    {
        "content": "<p>I have 1.1.80, maybe that's the issue?</p>",
        "id": 232916692,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1617379588
    },
    {
        "content": "<p>hm, it might be system allocator, <code>config.toml</code> says <code>jemalloc=false</code> commented out, so false could be the default (and I bet it is).</p>",
        "id": 232916925,
        "sender_full_name": "nagisa",
        "timestamp": 1617379710
    },
    {
        "content": "<p>FWIW the heaptrack maintainer seemed to think it was a fundamental issue with static linking, I would be surprised for it to be fixed so quickly</p>",
        "id": 232917033,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1617379754
    },
    {
        "content": "<p>Jemalloc is not the default locally</p>",
        "id": 232917738,
        "sender_full_name": "simulacrum",
        "timestamp": 1617380113
    },
    {
        "content": "<p>ah and we sadly cannot replace our various usual outputs with information we grab from jemalloc directly because many builds don't use jemalloc in the first place.</p>",
        "id": 232918419,
        "sender_full_name": "nagisa",
        "timestamp": 1617380406
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/reproducible.20memory.20usage.3F/near/232838174\">said</a>:</p>\n<blockquote>\n<p>Hey <span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span>, would the <em>extensive</em> work you did on reproducible instruction counts also make it possible to get reproducible memory usage, to make statistics like max-rss more useful and more usable? Right now they fluctuate too much to detect small changes in memory usage.</p>\n</blockquote>\n<p>how close is this to landing btw? I don't see a way to see the instructions diff per-query in perf.rlo</p>",
        "id": 233078144,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1617539248
    }
]