[
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"120989\">@nnethercote</span> <span class=\"user-mention\" data-user-id=\"116113\">@lqd</span>! In response to the Rust Compiler Ambitions 2022 blog post, I'd be interested in helping out with developing the compiler in my free time. One of the areas that interest me in general is improving compile times of <code>rustc</code>. So far I have worked on improving stable hashing (incremental) and rustdoc performance. I usually try to find ideas on what to improve by randomly profiling <code>rustc</code> on various crates, since I'm not that knowledgeable about the compiler yet to think of higher-level changes. If you have any ideas on what experiments or ideas could be explored, I'd be glad to try them out :)</p>",
        "id": 272881239,
        "sender_full_name": "Jakub Beránek",
        "timestamp": 1645572381
    },
    {
        "content": "<p>Hi Jakub!</p>",
        "id": 272881272,
        "sender_full_name": "nnethercote",
        "timestamp": 1645572413
    },
    {
        "content": "<p>Thank you for the offer. Profiling <code>rustc</code> on crates is much of what I've been doing for several years now, it's a good approach <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 272881328,
        "sender_full_name": "nnethercote",
        "timestamp": 1645572459
    },
    {
        "content": "<p>You may have seen the draft <a href=\"https://hackmd.io/YJQSj_nLSZWl2sbI84R1qA?view\">roadmap</a>, and also the <a href=\"https://hackmd.io/mxdn4U58Su-UQXwzOHpHag?view\">analysis</a> that is partly informing it. I am working on both of these documents right now, I hope to have drafts complete by the end of the week. Comments are welcome</p>",
        "id": 272881478,
        "sender_full_name": "nnethercote",
        "timestamp": 1645572567
    },
    {
        "content": "<p>The roadmap should serve as a helpful list of things to work on, I am very happy to have people helping with items</p>",
        "id": 272881595,
        "sender_full_name": "nnethercote",
        "timestamp": 1645572640
    },
    {
        "content": "<p>To be fair, the \"randomly profile\" approach is getting less effective with time, because a lot of the low-hanging fruit has been picked already. This is why @lqd's big data set is so useful, because it gives a much wider view of the ecosystem (beyond the benchmarks in <code>rustc-perf</code>), and also does some looking at full project build performance, not just single crate performance</p>",
        "id": 272881759,
        "sender_full_name": "nnethercote",
        "timestamp": 1645572748
    },
    {
        "content": "<p>I am happy to answer questions here, too</p>",
        "id": 272881784,
        "sender_full_name": "nnethercote",
        "timestamp": 1645572771
    },
    {
        "content": "<p>What platform do you use: Linux, Mac, something else?</p>",
        "id": 272881809,
        "sender_full_name": "nnethercote",
        "timestamp": 1645572795
    },
    {
        "content": "<p>Indeed I have been noticing that finding low-hanging fruits by random profiling is becoming harder and harder <span aria-label=\"grinning\" class=\"emoji emoji-1f600\" role=\"img\" title=\"grinning\">:grinning:</span> I work on Linux.</p>",
        "id": 272881842,
        "sender_full_name": "Jakub Beránek",
        "timestamp": 1645572836
    },
    {
        "content": "<p>Cool, Linux is probably the best-established platform, in terms of rustc profiler/benchmarking support.</p>",
        "id": 272881922,
        "sender_full_name": "nnethercote",
        "timestamp": 1645572886
    },
    {
        "content": "<p>Yeah the profiling support is actually quite nice. I'm usually either using perf for flamegraphs, cachegrind or dhat. Well, it seems that the profiling support is actually quite good because of you! :D I'll try to take a look at the lqd dataset eventually. If you'll have some ideas worth trying that you'll lack the bandwidth for, you can try to post them here and maybe someone (e.g. me) can try to pick them up. But I suppose that the document from lqd also serves for this purpose.</p>",
        "id": 272883310,
        "sender_full_name": "Jakub Beránek",
        "timestamp": 1645573782
    },
    {
        "content": "<p>The roadmap will be the main \"ideas for people to work on\" document.  lqd has his <a href=\"https://gist.github.com/lqd/2c92d351ed9eb2b846b3bc2f51cace6f\">thoughts</a> document, which has <em>lots</em> of ideas and would be worth reading, but the data gathering + analysis + roadmap is an attempt to reduce that down, be more focused on a smaller number of items that have a high chance of working</p>",
        "id": 272883788,
        "sender_full_name": "nnethercote",
        "timestamp": 1645574137
    },
    {
        "content": "<p>btw the latest version of that document is <a href=\"https://hackmd.io/3Dp68rTDSpWvRDfWF6lbMw?view\">https://hackmd.io/3Dp68rTDSpWvRDfWF6lbMw?view</a> where it’s much easier to comment/update (and is linked from the compiler aspirations blog post)</p>",
        "id": 272913448,
        "sender_full_name": "lqd",
        "timestamp": 1645601829
    },
    {
        "content": "<p>there are other interesting things like analyzing some behavior we rarely see, that’s happening <a href=\"https://lqd.github.io/rustc-benchmarking-data/results/round-14-self-profile-check/summarize/summarize-w-profiling-nalgebra-0.30.1-Check-Full.txt\">in nalgebra</a>. </p>\n<p>The <code>specialization_graph_of</code> query is extremely slow there. My guess is that it’s coherence checking (as the same thing has happened before, e.g. <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/windows-rs.20perf\">here</a>, an early rejection helped a lot at the time) but it could be slightly different and it would be good to check the reasons for that, and which parts of the crate trigger it. </p>\n<p>If that’s because of the quadratic coherence check it may not be easy to fix though, but it will be good to know what is the issue to begin with.</p>",
        "id": 272913793,
        "sender_full_name": "lqd",
        "timestamp": 1645602170
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> In the roadmap, you added \"PGO, etc. to tier-1 platforms\". What is the \"etc.\"?</p>",
        "id": 273030933,
        "sender_full_name": "nnethercote",
        "timestamp": 1645661860
    },
    {
        "content": "<p>PGO is the only one like that I know of. Unless you mean BOLT? (which is currently a separate bullet point)</p>",
        "id": 273030951,
        "sender_full_name": "nnethercote",
        "timestamp": 1645661880
    },
    {
        "content": "<p>I think we apply some other optimizations exclusive to Linux (well, x86_64-unknown-linux-gnu)</p>",
        "id": 273032739,
        "sender_full_name": "simulacrum",
        "timestamp": 1645663272
    },
    {
        "content": "<p>Yeah, llvm is built with thinlto and we enable jemalloc for example</p>",
        "id": 273032826,
        "sender_full_name": "simulacrum",
        "timestamp": 1645663324
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"120989\">@nnethercote</span> ^</p>",
        "id": 273032841,
        "sender_full_name": "simulacrum",
        "timestamp": 1645663346
    },
    {
        "content": "<p>Plus there's some medium effect from building LLVM with a recent clang, not some ancient toolchain, probably</p>",
        "id": 273032885,
        "sender_full_name": "simulacrum",
        "timestamp": 1645663385
    },
    {
        "content": "<p>Ok, thanks</p>",
        "id": 273032896,
        "sender_full_name": "nnethercote",
        "timestamp": 1645663399
    },
    {
        "content": "<p>Another question on that: you suggested 15-30% wins are possible... is that realistic? Seems high. Would be cool if true... <span aria-label=\"smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"smile\">:smile:</span></p>",
        "id": 273033175,
        "sender_full_name": "nnethercote",
        "timestamp": 1645663602
    },
    {
        "content": "<p>I think cumulative effect on Linux for pgo was in that range, yeah</p>",
        "id": 273033319,
        "sender_full_name": "simulacrum",
        "timestamp": 1645663697
    },
    {
        "content": "<p>The wins from BOLT for clang are in the 5-10% range IIRC, when applied atop PGO</p>",
        "id": 273033352,
        "sender_full_name": "simulacrum",
        "timestamp": 1645663729
    },
    {
        "content": "<p>k, thx</p>",
        "id": 273033366,
        "sender_full_name": "nnethercote",
        "timestamp": 1645663738
    }
]