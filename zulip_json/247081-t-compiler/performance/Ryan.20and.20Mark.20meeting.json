[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> and I had a great meeting today with the general goal of me taking on a bit more responsibility in the running and further development of perf.rlo and perf related processes. Here are some of the outcomes of our discussions for everyone's awareness:</p>\n<ul>\n<li><strong>Highest priority work:</strong> better data representation and automatic analysis. There's general consensus that it's not always clear how perf data should be interpreted. We want to make it easy for anyone who opens a PR to see how their PR is <em>actually</em> affecting performance. Perhaps first on this list will be quantifying noise on a per benchmark basis. </li>\n<li><strong>Second highest priority</strong>: continuing to improve the perf bot and further improving the perf process around perf runs done on PRs. This may see work before data representation work since it's still high priority, and there is low hanging fruit. </li>\n<li><strong>Other work</strong>: this is work we hope to be able to do if/when we have time: <ul>\n<li>helping run the perf infrastructure locally both for local development of perf.rlo but also (perhaps more importantly) just for anyone wanting to benchmark their local compilers on their local machine </li>\n<li>collecting more stats (though not necessarily displaying them yet). Before we display more stats we want to make progress on better data representation. For example, <span class=\"user-mention\" data-user-id=\"124287\">@mw</span> and I have a small side project for collecting more stats on incr-compilation overhead.</li>\n<li>Investigating sandboxing so that eventually we don't need a human to kick off perf runs. Maybe they can just be a part of CI....</li>\n</ul>\n</li>\n<li><strong>Other work along the way</strong>: These are things we hope to be able to do in service of achieving the goals above:<ul>\n<li>Improved performance of the service</li>\n<li>Easier manipulation of displayed data (i.e., allow different views on the same data)</li>\n<li>More easily allow running locally with synthetic or historical data to make local development of perf.rlo easier.</li>\n</ul>\n</li>\n</ul>",
        "id": 244708884,
        "sender_full_name": "rylev",
        "timestamp": 1625235540
    },
    {
        "content": "<blockquote>\n<p>Perhaps first on this list will be quantifying noise on a per benchmark basis. </p>\n</blockquote>\n<p>If we're willing to have false negatives for significant changes within the noise range (such as a change that shifts the mean but only within a standard deviation of the noise) then that shouldn't be too complex. Otherwise it would take multiple samples to detect such a shift after it occurred which makes it more difficult to attribute it to a specific commit.</p>\n<blockquote>\n<p>collecting more stats</p>\n</blockquote>\n<p>Is measuring runtime performance of generated code as opposed to measuring compiler performance in or out of scope for perf rlo?</p>",
        "id": 244712893,
        "sender_full_name": "The 8472",
        "timestamp": 1625237170
    },
    {
        "content": "<p>We did discuss runtime benchmarking, and while this is absolutely something we _have_ to do in the long run, it's too much work at the current moment to prioritize.</p>",
        "id": 244713288,
        "sender_full_name": "rylev",
        "timestamp": 1625237347
    },
    {
        "content": "<p>Oh I'd love to see ownership of perf.rlo get spread out a bit more. <span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> has way too much on their plate</p>",
        "id": 244718275,
        "sender_full_name": "pnkfelix",
        "timestamp": 1625239475
    },
    {
        "content": "<p>this is super exciting to me</p>",
        "id": 244718282,
        "sender_full_name": "pnkfelix",
        "timestamp": 1625239479
    }
]