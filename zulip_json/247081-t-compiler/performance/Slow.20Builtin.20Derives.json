[
    {
        "content": "<p><strong>tl;dr Using #[derive] for built in traits incurs significant overhead at scale</strong><br>\nI've created a benchmark which has 5,000 structs with one <code>i32</code> field. I then <code>#[derive(Copy, Clone, Default, Eq, PartialEq, Debug)]</code> for all the structs. This builds using the current nightly compiler  (f2bbdd0a3 2020-11-04) in ~5 seconds. When I manually implement these traits, the code compiles in ~2.5 seconds. It seems that <code>resolve_crate</code> is taking a significant amount of time in the <code>derive</code> case  specifically in <code>rustc_resolve::Resolver::finalize_macro_resolutions</code>. In particular there are a lot of calls to <code>early_resolve_ident_in_lexical_scope</code> when iterating <code>self.single_segment_macro_resolutions</code> AND especially so when iterating <code>self.builtin_attrs</code> which currently take 12% and 18% of compilation time respectively. This benchmark is inspired by a realworld crate I'm working on that has similar perf characteristics although it seems that calls to <code>early_resolve_ident_in_lexical_scope</code>on <code>self.builtin_attrs</code> take 40% of the time and calls when iterating <code>self.single_segment_macro_resolutions</code> only take 5% of the time on that crate.</p>",
        "id": 215750815,
        "sender_full_name": "rylev",
        "timestamp": 1604599265
    },
    {
        "content": "<p>cc <span class=\"user-mention\" data-user-id=\"123856\">@Vadim Petrochenkov</span> <span class=\"user-mention\" data-user-id=\"120989\">@njn</span></p>",
        "id": 215751066,
        "sender_full_name": "eddyb",
        "timestamp": 1604599363
    },
    {
        "content": "<p>I'm also going to push a WIP PR to rustc-perf since this seems like a benchmark that makes sense to have</p>",
        "id": 215751910,
        "sender_full_name": "rylev",
        "timestamp": 1604599748
    },
    {
        "content": "<p>And here is the benchmark PR: <a href=\"https://github.com/rust-lang/rustc-perf/pull/791\">https://github.com/rust-lang/rustc-perf/pull/791</a></p>",
        "id": 215752999,
        "sender_full_name": "rylev",
        "timestamp": 1604600235
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224872\">@Ryan Levick</span> have you compared different derives at all? I wonder if the performance is a particular derive or if it's all about the same</p>",
        "id": 215762993,
        "sender_full_name": "simulacrum",
        "timestamp": 1604604877
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224872\">@Ryan Levick</span> Is there already a small cache attached to that lookup?</p>",
        "id": 215766797,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1604606638
    },
    {
        "content": "<p>To ensure that the same type is readily at hand for a series of derives?</p>",
        "id": 215766876,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1604606663
    },
    {
        "content": "<p>it seems the more derives there are the slower it gets</p>",
        "id": 215767212,
        "sender_full_name": "lqd",
        "timestamp": 1604606850
    },
    {
        "content": "<p>That certainly <em>sounds</em> like it might be doing duplicate work between the derives.</p>",
        "id": 215767565,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1604607016
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224872\">@Ryan Levick</span> I just posted a comment suggesting some tweaks to the test to make it catch more issues.</p>",
        "id": 215767598,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1604607032
    },
    {
        "content": "<p>just for anecdata, cargo check on my machine:</p>\n<ul>\n<li>no derives: 47ms</li>\n<li>w/ Default: 350ms</li>\n<li>w/ Copy + Clone: 657ms (Clone by itself is 525)</li>\n<li>w/ Debug: 765ms</li>\n<li>w/ PartialEq + Eq: 1.29s (PartialEq by itself is 780)</li>\n<li>all of the above: 4.77s (while the sum is 3.1s even if it's meaningless)</li>\n</ul>",
        "id": 215767673,
        "sender_full_name": "lqd",
        "timestamp": 1604607080
    },
    {
        "content": "<p>It'd be helpful to be able to compare those to manual impls of the same traits.</p>",
        "id": 215767806,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1604607144
    },
    {
        "content": "<p>yup that was next on my list ^^</p>",
        "id": 215767831,
        "sender_full_name": "lqd",
        "timestamp": 1604607159
    },
    {
        "content": "<p>In particular, does it get slower the more traits you derive, disproportionately compared to the same code with more traits manually implemented?</p>",
        "id": 215767885,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1604607188
    },
    {
        "content": "<p>this will take a short while to check</p>",
        "id": 215769443,
        "sender_full_name": "lqd",
        "timestamp": 1604608024
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"116122\">simulacrum</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/Slow.20Builtin.20Derives/near/215762993\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"224872\">Ryan Levick</span> have you compared different derives at all? I wonder if the performance is a particular derive or if it's all about the same</p>\n</blockquote>\n<p>Yes, Copy has the least overhead, followed by Default, then Clone and Eq seem to be roughly the same and PartialEq and debug seem to be the slowest</p>",
        "id": 215769929,
        "sender_full_name": "rylev",
        "timestamp": 1604608281
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"239881\">Josh Triplett</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/Slow.20Builtin.20Derives/near/215766797\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"224872\">Ryan Levick</span> Is there already a small cache attached to that lookup?</p>\n</blockquote>\n<p>I'm still getting familiar with the code but I did not see one immediately. That's on my list for tomorrow</p>",
        "id": 215770085,
        "sender_full_name": "rylev",
        "timestamp": 1604608343
    },
    {
        "content": "<p>This is the first time I see anyone benchmarking this code ( <span aria-label=\"tada\" class=\"emoji emoji-1f389\" role=\"img\" title=\"tada\">:tada:</span> ).<br>\nI certainly didn't that myself, and only had time to work on its functional correctness.</p>",
        "id": 215770218,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1604608412
    },
    {
        "content": "<p>All the listed functions are necessary to ensure that macro resolution didn't result in time-traveling / paradoxes.<br>\nIf they are not run then some invalid code will be accepted, but otherwise everything should continue compiling.<br>\nPerhaps they can be optimized somehow, I don't know right away.</p>",
        "id": 215770664,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1604608663
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"123856\">@Vadim Petrochenkov</span> awesome! I’m really excited to help benchmark this code. I’m new to rustc dev so you’ll have to forgive me not knowing my way around. Do you think there might be repeated work between derives on the same type that would be helped by caching?</p>",
        "id": 215772903,
        "sender_full_name": "rylev",
        "timestamp": 1604609845
    },
    {
        "content": "<p>anecdata 2.0, electric boogaloo:</p>\n<ul>\n<li>no derives: 47ms</li>\n<li>Default -- derived: 350ms, manual: 240ms</li>\n<li>Copy + Clone -- derived: 657ms, manual w/ feature derive_clone_copy: 331ms, without the feature: 308ms</li>\n<li>Debug -- derived: 765ms, manual: 680ms</li>\n<li>PartialEq + Eq -- derived: 1.29s, manual w/ features derive_eq and structural_match impls: 934ms, without the features (so possibly with an incorrect equivalence relation): 677ms</li>\n<li>all of the above -- derived: 4.77s, manual w/ all the features: 2.16s, without the features: 1.84s</li>\n</ul>",
        "id": 215773078,
        "sender_full_name": "lqd",
        "timestamp": 1604609930
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224872\">@Ryan Levick</span> <br>\nNot sure about caching, but could you check, is the hot part of <code>early_resolve_ident_in_lexical_scope</code> located in this code by any chance?</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"w\">                    </span><span class=\"n\">Scope</span>::<span class=\"n\">MacroRules</span><span class=\"p\">(</span><span class=\"n\">macro_rules_scope</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">=&gt;</span><span class=\"w\"> </span><span class=\"k\">match</span><span class=\"w\"> </span><span class=\"n\">macro_rules_scope</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">                        </span><span class=\"n\">MacroRulesScope</span>::<span class=\"n\">Binding</span><span class=\"p\">(</span><span class=\"n\">macro_rules_binding</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"w\">                            </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"n\">ident</span><span class=\"w\"> </span><span class=\"o\">==</span><span class=\"w\"> </span><span class=\"n\">macro_rules_binding</span><span class=\"p\">.</span><span class=\"n\">ident</span><span class=\"w\"> </span><span class=\"o\">=&gt;</span><span class=\"w\"></span>\n<span class=\"w\">                        </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">                            </span><span class=\"nb\">Ok</span><span class=\"p\">((</span><span class=\"n\">macro_rules_binding</span><span class=\"p\">.</span><span class=\"n\">binding</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"n\">Flags</span>::<span class=\"n\">MACRO_RULES</span><span class=\"p\">))</span><span class=\"w\"></span>\n<span class=\"w\">                        </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"w\">                        </span><span class=\"n\">MacroRulesScope</span>::<span class=\"n\">Invocation</span><span class=\"p\">(</span><span class=\"n\">invoc_id</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"w\">                            </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"o\">!</span><span class=\"n\">this</span><span class=\"p\">.</span><span class=\"n\">output_macro_rules_scopes</span><span class=\"p\">.</span><span class=\"n\">contains_key</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">invoc_id</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">=&gt;</span><span class=\"w\"></span>\n<span class=\"w\">                        </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">                            </span><span class=\"nb\">Err</span><span class=\"p\">(</span><span class=\"n\">Determinacy</span>::<span class=\"n\">Undetermined</span><span class=\"p\">)</span><span class=\"w\"></span>\n<span class=\"w\">                        </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"w\">                        </span><span class=\"n\">_</span><span class=\"w\"> </span><span class=\"o\">=&gt;</span><span class=\"w\"> </span><span class=\"nb\">Err</span><span class=\"p\">(</span><span class=\"n\">Determinacy</span>::<span class=\"n\">Determined</span><span class=\"p\">),</span><span class=\"w\"></span>\n<span class=\"w\">                    </span><span class=\"p\">},</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 215774176,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1604610398
    },
    {
        "content": "<p>Every derive macro can potentially produce a <code>macro_rules</code> item, so every derive macro start a \"<code>macro_rules</code> scope\" that continues until the end of the module (or even further with <code>#[macro_use]</code>).<br>\nSo if you have a lot of derives in a module, the chain of <code>macro_rules</code> scopes may grow very large.</p>",
        "id": 215774540,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1604610598
    },
    {
        "content": "<p>(And you need to walk that chain in <code>early_resolve_ident_in_lexical_scope</code>.)</p>",
        "id": 215774629,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1604610629
    },
    {
        "content": "<p>As a side note this is a \"known\" issue already within small parts of the community, and for example <code>winapi</code> avoids all derives and manually implements all the impls for all of its structs.</p>",
        "id": 215781689,
        "sender_full_name": "Lokathor",
        "timestamp": 1604614729
    },
    {
        "content": "<p>I knew about winapi and always assumed that it's just \"expanding is slower than not expanding\".<br>\nBut the mentioned hot functions are not really about expansion (as in token stream juggling), and this is the first time I see them mentioned in this context.</p>",
        "id": 215787884,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1604619232
    },
    {
        "content": "<p>For posterity's sake, here's how the original codebase (not the benchmark) behaves when adding new traits to the derive attribute when compared to the previous version (i.e., each trait gets added to the list):</p>\n<ul>\n<li>No derive: 16s</li>\n<li>Clone: +1.76s</li>\n<li>Copy: +0.58s</li>\n<li>Default: +1.45s</li>\n<li>PartialEq: +3.04s</li>\n<li>Eq: +2.28s</li>\n<li>Debug: +3.11s</li>\n</ul>",
        "id": 215821355,
        "sender_full_name": "rylev",
        "timestamp": 1604654559
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"123856\">@Vadim Petrochenkov</span> the <code>MacroRules</code> handling does seem to be a hotspot. In one benchmark run it's being called 146969002 times and taking 13% of the time.</p>",
        "id": 215823483,
        "sender_full_name": "rylev",
        "timestamp": 1604655988
    },
    {
        "content": "<p>(I've tried yesterday splitting the one derive into one per trait, and it didn't seem to make much of a difference -- I mean +1-2% in addition to the mentioned 260% -- in addition to rustfmt collapsing them back into one)</p>",
        "id": 215828429,
        "sender_full_name": "lqd",
        "timestamp": 1604659039
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224872\">@Ryan Levick</span> one fun thing, if you're measuring exact counts of anything, is to use only powers of ten (or large primes if you're bored, but that's easier to pattern-match by eye) in the inputs, and try to find a formula in the outputs :P</p>",
        "id": 215834101,
        "sender_full_name": "eddyb",
        "timestamp": 1604662599
    },
    {
        "content": "<p>because <code>146969002</code> for example looks like <code>146969 * 1000 + 2</code>, but I'm not sure what other factors are used in the input</p>",
        "id": 215834148,
        "sender_full_name": "eddyb",
        "timestamp": 1604662640
    },
    {
        "content": "<p>Should be fixed in <a href=\"https://github.com/rust-lang/rust/pull/78826\">https://github.com/rust-lang/rust/pull/78826</a>.</p>",
        "id": 215918208,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1604706343
    },
    {
        "content": "<p>tried to understand it, hopefully I did correctly, r+!</p>",
        "id": 215945606,
        "sender_full_name": "eddyb",
        "timestamp": 1604739695
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"123856\">@Vadim Petrochenkov</span> Awesome, thank you!</p>",
        "id": 215973777,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1604783606
    },
    {
        "content": "<p>Awesome stuff. This change compiles the benchmark in half the time. Master: ~29.9s <span class=\"user-mention\" data-user-id=\"123856\">@Vadim Petrochenkov</span>'s changes: ~17.3s</p>",
        "id": 216062129,
        "sender_full_name": "rylev",
        "timestamp": 1604915534
    },
    {
        "content": "<p>The <code>resolve_crate</code> item goes from taking ~31% of time to ~1% of time.</p>",
        "id": 216062344,
        "sender_full_name": "rylev",
        "timestamp": 1604915683
    },
    {
        "content": "<p>The benchmark is now taking ~20.5% of time on <code>typeck</code> which I find a bit unexpected. Might be a good place to look next.</p>",
        "id": 216064143,
        "sender_full_name": "rylev",
        "timestamp": 1604916790
    },
    {
        "content": "<p>Also interesting: adding PartialOrd derive incurs a very large overhead. In local tests, the time to compile doubles when adding <code>PartialOrd</code> to the derive list</p>",
        "id": 216068084,
        "sender_full_name": "rylev",
        "timestamp": 1604919182
    },
    {
        "content": "<p>Also: using <code>#[derive]</code> (with <span class=\"user-mention\" data-user-id=\"123856\">@Vadim Petrochenkov</span>'s changes) still incurs around a 50% compile time penalty over implementing the traits manually (for Debug, PartialEq, Eq, Clone, Copy, Default)</p>",
        "id": 216068567,
        "sender_full_name": "rylev",
        "timestamp": 1604919470
    },
    {
        "content": "<p>My local test takes 4.8s when the traits are implemented manually vs 6.6s when using derive. I assume this is because the derive implementations are more expensive to compile</p>",
        "id": 216068710,
        "sender_full_name": "rylev",
        "timestamp": 1604919555
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224872\">@Ryan Levick</span> <br>\nCould you also copypaste the derived implementations from <code>cargo expand</code> or something, and measure how much time do they take to compile?</p>",
        "id": 216069205,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1604919876
    },
    {
        "content": "<p>Interestingly, while <code>typeck</code> and <code>mir_borrowck</code> are faster when manually implementing the traits, <code>LLVM_module_codegen_emit_obj</code> and <code>LLVM_passes</code> are both slower</p>",
        "id": 216069555,
        "sender_full_name": "rylev",
        "timestamp": 1604920097
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"123856\">@Vadim Petrochenkov</span> the copy-pasted expanded derived implementations take roughly just as long as the <code>derive</code>impl which would suggest that most of the overhead of expanding the derives has been removed by your PR and now it's the code that it gets expanded to itself that is causing further slowness. Here's the profiling data from all three types of compiles <a href=\"https://gist.github.com/rylev/14430d2e1ea384b1f10efae6b5c385f2\">https://gist.github.com/rylev/14430d2e1ea384b1f10efae6b5c385f2</a></p>",
        "id": 216071582,
        "sender_full_name": "rylev",
        "timestamp": 1604921360
    },
    {
        "content": "<p>note that deriving eg Eq and PartialEq has additional types your manual impl doesn't (this is the reason why I was mentioning the features <code>derive_clone_copy</code>, <code>derive_eq</code> and <code>structural_match</code> in my own numbers)</p>",
        "id": 216075348,
        "sender_full_name": "lqd",
        "timestamp": 1604923602
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224872\">@Ryan Levick</span> hm, so on <a href=\"https://github.com/rust-lang/rustc-perf/pull/791\">https://github.com/rust-lang/rustc-perf/pull/791</a>, did you want to add in the changes I suggested (and Josh's as well?)</p>",
        "id": 216085391,
        "sender_full_name": "simulacrum",
        "timestamp": 1604929711
    },
    {
        "content": "<p>I don't think we need the separate derive case</p>",
        "id": 216085428,
        "sender_full_name": "simulacrum",
        "timestamp": 1604929733
    },
    {
        "content": "<p>I did make most of the changes. I can get rid of the second type of derive (that includes copy). Is there anything else I’m missing?</p>",
        "id": 216085596,
        "sender_full_name": "rylev",
        "timestamp": 1604929826
    },
    {
        "content": "<p>hm not sure I followed that, what second type of derive?</p>",
        "id": 216085781,
        "sender_full_name": "simulacrum",
        "timestamp": 1604929939
    },
    {
        "content": "<p>But I think it looks good then and I can merge it</p>",
        "id": 216085802,
        "sender_full_name": "simulacrum",
        "timestamp": 1604929953
    },
    {
        "content": "<p>Ok, I'm going to merge -- I think it's good</p>",
        "id": 216085997,
        "sender_full_name": "simulacrum",
        "timestamp": 1604930073
    },
    {
        "content": "<p>should get picked up in the next perf run</p>",
        "id": 216086074,
        "sender_full_name": "simulacrum",
        "timestamp": 1604930120
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"116122\">@simulacrum</span> should we trigger a run for <a href=\"https://github.com/rust-lang/rust/pull/78826\">https://github.com/rust-lang/rust/pull/78826</a>?</p>",
        "id": 216095911,
        "sender_full_name": "rylev",
        "timestamp": 1604934262
    },
    {
        "content": "<p>I don't think it's necessary? It'll get collected on the master merge, and before then we don't yet have a master commit with the new benchmark</p>",
        "id": 216095963,
        "sender_full_name": "simulacrum",
        "timestamp": 1604934290
    },
    {
        "content": "<p>(I would rather not work to requeue it)</p>",
        "id": 216095982,
        "sender_full_name": "simulacrum",
        "timestamp": 1604934300
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224872\">@Ryan Levick</span> By the way, what are you using for profiling?</p>",
        "id": 216130163,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1604949058
    },
    {
        "content": "<p>I’m just using -Zself-profile.</p>",
        "id": 216135112,
        "sender_full_name": "rylev",
        "timestamp": 1604951429
    },
    {
        "content": "<p>Doing some additional perf on testing, it seems that PartialOrd is by far the most expensive to derive of the traits in std. The derive benchmark with <a href=\"https://gist.github.com/rylev/6240ab415e9f353c1582889cea41b4b1#file-partialeq-partialord\"><code>#[derive(PartialEq, PartialOrd)]</code></a> takes 9.1s on my machine while just <a href=\"https://gist.github.com/rylev/6240ab415e9f353c1582889cea41b4b1#file-partialeq\"><code>#[derive(PartialEq)]</code></a> takes 1.9s. This is presumably because the <code>PartialOrd</code> derive implements all of the methods of PartialOrd instead of only implementing <code>partial_cmp</code> and using the defaults for everything else. When I implement <a href=\"https://gist.github.com/rylev/6240ab415e9f353c1582889cea41b4b1#file-partialeq-partialord-manual-impl\"><code>PartialOrd</code> manually</a> with the same implementation the derive uses (but only implementing <code>partial_cmp</code>, it only takes 4.9s.</p>",
        "id": 216462846,
        "sender_full_name": "rylev",
        "timestamp": 1605185453
    },
    {
        "content": "<p>Beyond the obvious question of if implementing all methods of <code>PartialOrd</code> is the correct thing to do, it'd be interesting to dive more into why typeck takes up so much time. in all of the derive cases.</p>",
        "id": 216463226,
        "sender_full_name": "rylev",
        "timestamp": 1605185699
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224872\">@Ryan Levick</span> <code>cachegrind</code> from the valgrind suite (together with <code>kcachegrind</code>) are pretty good tools for diving into the details of some piece of single-threaded code.</p>",
        "id": 216469062,
        "sender_full_name": "mw",
        "timestamp": 1605188667
    },
    {
        "content": "<p>Thanks to <span class=\"user-mention\" data-user-id=\"124287\">@mw</span> we found that <span class=\"user-mention\" data-user-id=\"139363\">@bluss</span> last changed the code in PartialOrd derive to only impl all the methods in some cases. But this was 5 years ago, and it's not clear why we can't _always_ depend on the default impls of the non-<code>partial_cmp</code> methods</p>",
        "id": 216591369,
        "sender_full_name": "rylev",
        "timestamp": 1605262341
    },
    {
        "content": "<p>Here's the change from <span class=\"user-mention\" data-user-id=\"139363\">@bluss</span> <a href=\"https://github.com/rust-lang/rust/commit/edcc02bfee262ce8bc3f087d9793ce68d73b1a40\">https://github.com/rust-lang/rust/commit/edcc02bfee262ce8bc3f087d9793ce68d73b1a40</a></p>",
        "id": 216591384,
        "sender_full_name": "rylev",
        "timestamp": 1605262367
    },
    {
        "content": "<p>The <a href=\"https://doc.rust-lang.org/std/cmp/trait.PartialOrd.html#how-can-i-implement-partialord\">PartialOrd documentation</a> says that it should be OK to only implement <code>partial_cmp</code> and rely on the default implementations for the rest. One could argue that the same should be true for automatically derived impls. It would be interesting to see if someone can construct a counter example, e.g. the derived impl of a struct containing an <code>f32</code> field behaving differently in the two cases.</p>",
        "id": 216592352,
        "sender_full_name": "mw",
        "timestamp": 1605263153
    },
    {
        "content": "<p>From the PR description:</p>\n<blockquote>\n<p>One case where it's easy to recognize is when it's a C-like enum. Most other cases can not omit ne, because any value field may have a custom PartialEq implementation.</p>\n</blockquote>",
        "id": 216602968,
        "sender_full_name": "bjorn3",
        "timestamp": 1605270217
    },
    {
        "content": "<p>Hmm ok that's a shame, but it makes sense. I'm still surprised by how much overhead these implementations add. More than doubling compilation time just when adding a <code>partial_cmp</code> implementation</p>",
        "id": 216610240,
        "sender_full_name": "rylev",
        "timestamp": 1605274419
    },
    {
        "content": "<p>This might be infeasible but in my experience, if there's a <code>#[derive(PartialOrd)]</code> 99% of the time, there's also a <code>#[derive(PartialEq)]</code> and so there's no user-defined custom implementation for that trait. Could we detect this situation and only generate the implementation for <code>partial_cmp</code> then?</p>",
        "id": 216619762,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1605278460
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"119009\">@eddyb</span> <br>\nI implemented the lazy compression in <a href=\"https://github.com/rust-lang/rust/pull/79034\">https://github.com/rust-lang/rust/pull/79034</a>.<br>\nThere's no effect on performance, but the code certainly looks cleaner.</p>",
        "id": 216714815,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1605341047
    },
    {
        "content": "<p>heh, neat!</p>",
        "id": 216714889,
        "sender_full_name": "eddyb",
        "timestamp": 1605341192
    },
    {
        "content": "<p>FYI: The crate which prompted me to look into this issue and the foreign modules issue that we've also fixed compiles in 2m33s on stable and in 33 seconds on nightly!</p>",
        "id": 216859785,
        "sender_full_name": "rylev",
        "timestamp": 1605526576
    },
    {
        "content": "<p>(It was taking 58s before <span class=\"user-mention\" data-user-id=\"123856\">@Vadim Petrochenkov</span>'s change)</p>",
        "id": 216859929,
        "sender_full_name": "rylev",
        "timestamp": 1605526690
    },
    {
        "content": "<p>Nice!</p>",
        "id": 216867468,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1605531839
    },
    {
        "content": "<p>Wow, that's incredible!</p>",
        "id": 216871562,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1605534102
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"133247\">bjorn3</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/Slow.20Builtin.20Derives/near/216602968\">said</a>:</p>\n<blockquote>\n<p>From the PR description:</p>\n<blockquote>\n<p>One case where it's easy to recognize is when it's a C-like enum. Most other cases can not omit ne, because any value field may have a custom PartialEq implementation.</p>\n</blockquote>\n</blockquote>\n<p>Maybe the approach could be extended to other cases where we can syntactically detect that <code>eq</code> and <code>ne</code> are symmetrical? E.q. if all fields are non-float basic types?</p>",
        "id": 216982231,
        "sender_full_name": "mw",
        "timestamp": 1605606000
    },
    {
        "content": "<p>FYI: I tried to see if it's currently possible to determine if the user is deriving <code>PartialEq</code> when deriving <code>PartialOrd</code> and it does not seem it is.</p>\n<p>I'm not sure if it's worth trying <span class=\"user-mention\" data-user-id=\"124287\">@mw</span>'s idea of seeing if all of the fields of a type are non-float primitive types but of course simple things break this (e.g., new types, arrays, etc.)</p>",
        "id": 219241494,
        "sender_full_name": "rylev",
        "timestamp": 1607451152
    },
    {
        "content": "<p>You can <code>use ArbitraryType as u8;</code>, which would break this</p>",
        "id": 219243038,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1607451908
    },
    {
        "content": "<p>Another good point. So I think the only safe thing to do is determine if the user is deriving PartialEq as well which is not possible currently</p>",
        "id": 219243761,
        "sender_full_name": "rylev",
        "timestamp": 1607452286
    },
    {
        "content": "<p>We have a <code>Copy</code> + <code>Clone</code> optimzation I think, how does that work?</p>",
        "id": 219243823,
        "sender_full_name": "Jonas Schievink  [he/him]",
        "timestamp": 1607452320
    },
    {
        "content": "<p>Do you mean specializing Clone if the type is also copy to use fn clone(&amp;self) -&gt; Self { *self }?</p>",
        "id": 219244317,
        "sender_full_name": "rylev",
        "timestamp": 1607452510
    },
    {
        "content": "<p>Looks like <code>ExtCtxt</code> has a resolver field which implements ResolverExpand which has a method <code>has_derive_copy</code></p>",
        "id": 219244551,
        "sender_full_name": "rylev",
        "timestamp": 1607452600
    },
    {
        "content": "<p>the implementation of that also is only about copy</p>",
        "id": 219244722,
        "sender_full_name": "rylev",
        "timestamp": 1607452684
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"211727\">Jonas Schievink</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/Slow.20Builtin.20Derives/near/219243823\">said</a>:</p>\n<blockquote>\n<p>We have a <code>Copy</code> + <code>Clone</code> optimzation I think, how does that work?</p>\n</blockquote>\n<p>I think this generates MIR shims ...</p>",
        "id": 219245054,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1607452861
    },
    {
        "content": "<p>Either way, what I said above stands ^^ it seems there is specialized logic to know if a type derives Copy specifically</p>",
        "id": 219245648,
        "sender_full_name": "rylev",
        "timestamp": 1607453161
    },
    {
        "content": "<p><a href=\"https://doc.rust-lang.org/nightly/nightly-rustc/rustc_middle/ty/enum.InstanceDef.html#variant.CloneShim\">https://doc.rust-lang.org/nightly/nightly-rustc/rustc_middle/ty/enum.InstanceDef.html#variant.CloneShim</a></p>",
        "id": 219245842,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1607453242
    },
    {
        "content": "<p><a href=\"https://doc.rust-lang.org/nightly/nightly-rustc/rustc_mir/shim/fn.build_clone_shim.html\">https://doc.rust-lang.org/nightly/nightly-rustc/rustc_mir/shim/fn.build_clone_shim.html</a></p>",
        "id": 219246047,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1607453329
    },
    {
        "content": "<p>Do we think it's worth it to do this for other derives?</p>",
        "id": 219246464,
        "sender_full_name": "rylev",
        "timestamp": 1607453534
    },
    {
        "content": "<p>This was the PR that added the clone shim: <a href=\"https://github.com/rust-lang/rust/pull/43690\">https://github.com/rust-lang/rust/pull/43690</a></p>\n<p>Of note:</p>\n<blockquote>\n<p>My problem is not how it's implemented, but using this method only for some Clone impls. I'd be far more comfortable if all built-in derive impls were moved to MIR shims.</p>\n</blockquote>\n<p>So it sounds to me like this might have been wanted from the beginning.</p>",
        "id": 219251284,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1607456019
    },
    {
        "content": "<p>Regardless, the built-in derive macros seem a bit special to the compiler currently. If we can significantly improve performance in important cases, I don't see an issue with making them more special.</p>",
        "id": 219251554,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1607456158
    },
    {
        "content": "<p>My guess is that actually landing a PR that did this would probably need to go through the MCP process but having concrete data about what kind of performance improvement this creates would be invaluable for that MCP.</p>",
        "id": 219251692,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1607456216
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"125250\">Wesley Wiser</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/Slow.20Builtin.20Derives/near/219251692\">said</a>:</p>\n<blockquote>\n<p>My guess is that actually landing a PR that did this would probably need to go through the MCP process but having concrete data about what kind of performance improvement this creates would be invaluable for that MCP.</p>\n</blockquote>\n<p>Can you share your thoughts on how to gather this data? Should I implement it, and then open the MCP?</p>",
        "id": 219253062,
        "sender_full_name": "rylev",
        "timestamp": 1607456891
    },
    {
        "content": "<p>That's what I was thinking. While we could get an upper bound on how much this could possibly improve just by looking at how much time the derives add to compilation, I can't think of any way to get a reasonable estimate on what the likely improvement might be from doing this change without doing the change.</p>",
        "id": 219254770,
        "sender_full_name": "Wesley Wiser",
        "timestamp": 1607457744
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"224872\">Ryan Levick</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/Slow.20Builtin.20Derives/near/219245648\">said</a>:</p>\n<blockquote>\n<p>Either way, what I said above stands ^^ it seems there is specialized logic to know if a type derives Copy specifically</p>\n</blockquote>\n<p>A special case for build-in <code>PartialEq</code> could be added in exactly the same way if really necessary.<br>\nAlso the special case in derive expansion precedes MIR shims for <code>Clone</code>, perhaps it can even be removed now.</p>",
        "id": 219271593,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1607466208
    },
    {
        "content": "<p>I’m not sure if I should try to hack it in to see if there’s substantial perf gains or if I should try to find a suitable solution that isn’t a hack</p>",
        "id": 219276140,
        "sender_full_name": "rylev",
        "timestamp": 1607469113
    },
    {
        "content": "<p>FYI: I have a PR open which special cases <code>PartialOrd</code> to only implement <code>partial_cmp</code> when the user is also deriving <code>PartialEq</code>. We'll see how much this helps. <a href=\"https://github.com/rust-lang/rust/pull/80050\">https://github.com/rust-lang/rust/pull/80050</a></p>",
        "id": 219961741,
        "sender_full_name": "rylev",
        "timestamp": 1608029305
    },
    {
        "content": "<p>Interesting that only clap incremental regresses.</p>",
        "id": 220012376,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1608053025
    },
    {
        "content": "<p>I closed the above PR due to issues brought up by <span class=\"user-mention\" data-user-id=\"123856\">@Vadim Petrochenkov</span> and moved the discussion into an issue <a href=\"https://github.com/rust-lang/rust/issues/80118\">https://github.com/rust-lang/rust/issues/80118</a>.</p>",
        "id": 220246809,
        "sender_full_name": "rylev",
        "timestamp": 1608213979
    },
    {
        "content": "<p>The <code>Clone+Copy</code> optimization can work but only because there was an RFC that established a bunch of rules around what the compiler may assume.</p>",
        "id": 220397061,
        "sender_full_name": "nagisa",
        "timestamp": 1608310279
    },
    {
        "content": "<p>if we wanted to optimise <code>PartialEq</code> implementation to defer to <code>PartialOrd::partial_ord</code> we cannot really do that because that affects observable behaviour.</p>",
        "id": 220397128,
        "sender_full_name": "nagisa",
        "timestamp": 1608310307
    },
    {
        "content": "<p>(if a field type implements either of the traits manually, it can observe that the derived <code>PartialEq</code> is actually invoking field's <code>PartialOrd</code>, rather than <code>PartialEq</code>)</p>",
        "id": 220397260,
        "sender_full_name": "nagisa",
        "timestamp": 1608310358
    },
    {
        "content": "<p>(this is likely to also be the cause of runtime regressions)</p>",
        "id": 220397289,
        "sender_full_name": "nagisa",
        "timestamp": 1608310370
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"123586\">nagisa</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/Slow.20Builtin.20Derives/near/220397260\">said</a>:</p>\n<blockquote>\n<p>(if a field type implements either of the traits manually, it can observe that the derived <code>PartialEq</code> is actually invoking field's <code>PartialOrd</code>, rather than <code>PartialEq</code>)</p>\n</blockquote>\n<p>This is exactly why the above pull request was closed.</p>",
        "id": 220397326,
        "sender_full_name": "rylev",
        "timestamp": 1608310387
    },
    {
        "content": "<p>Right. Didn't read the issue closely enough to tell exact reason.</p>",
        "id": 220397343,
        "sender_full_name": "nagisa",
        "timestamp": 1608310393
    },
    {
        "content": "<p>My bad.</p>",
        "id": 220397946,
        "sender_full_name": "nagisa",
        "timestamp": 1608310601
    },
    {
        "content": "<p>I wonder if it would make sense to have some sort of an attribute for macros that would effectively be \"assume typechecked, borrowchecked etc\"</p>",
        "id": 220398051,
        "sender_full_name": "nagisa",
        "timestamp": 1608310645
    },
    {
        "content": "<p>Which would add additional requirements on the code generated (e.g. no types that would need inference), but also avoid a huge time sink.</p>",
        "id": 220398238,
        "sender_full_name": "nagisa",
        "timestamp": 1608310696
    },
    {
        "content": "<p>This could help. We may also want to try to check that the generated code is \"friendly\" to the type/borrow checkers</p>",
        "id": 220398260,
        "sender_full_name": "rylev",
        "timestamp": 1608310703
    },
    {
        "content": "<p>Yeah, the friendly code came up in <a href=\"https://github.com/rust-lang/rust/issues/79671\">#79671</a> briefly where adding some type annotations helped with build times somewhat as per <a href=\"https://github.com/rust-lang/rust/issues/79671#issuecomment-738761965\">this comment</a>.</p>",
        "id": 220398615,
        "sender_full_name": "nagisa",
        "timestamp": 1608310827
    },
    {
        "content": "<p>If #[derive(PartialOrd)] is simplified to only emit partial_cmp for structs, then I'd be worried for performance of float struct fields. <code>f64::partial_cmp</code> is slow, does extra work compared to <code>f64::lt</code>, so it would be preferred to keep using <code>f64::lt</code> directly where it is possible.</p>",
        "id": 223826936,
        "sender_full_name": "bluss",
        "timestamp": 1611512030
    },
    {
        "content": "<p>The derived implementation of PartialOrd for &lt;, &lt;=, &gt;, &gt;= is quite complex. It contains nested closures with depth proportional to the number of fields. Such use of closures have been observed to cause various exponential behaviours. There is a small test case which generates more incremental cache data than during compilation of the whole rustc.</p>",
        "id": 224021814,
        "sender_full_name": "tm",
        "timestamp": 1611657875
    },
    {
        "content": "<p>BTW, I think the earlier proposal to simply skip deriving those operators was correct. There is only one correct behaviour of those operators given the implementation of partial_cmp.</p>",
        "id": 224022006,
        "sender_full_name": "tm",
        "timestamp": 1611658041
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"139363\">bluss</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/Slow.20Builtin.20Derives/near/223826936\">said</a>:</p>\n<blockquote>\n<p>If #[derive(PartialOrd)] is simplified to only emit partial_cmp for structs, then I'd be worried for performance of float struct fields. <code>f64::partial_cmp</code> is slow, does extra work compared to <code>f64::lt</code>, so it would be preferred to keep using <code>f64::lt</code> directly where it is possible.</p>\n</blockquote>\n<p>All methods of PartialOrd are derived in terms of partial_cmp, so perf concerns apply to them as well.</p>",
        "id": 224036524,
        "sender_full_name": "tm",
        "timestamp": 1611666938
    }
]