[
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> <span class=\"user-mention\" data-user-id=\"124287\">@mw</span> wild random idea for <code>measureme</code>: non-temporal stores to memory for events and maybe even tweaking the paging system so the event stream itself doesn't need buffering. specifically I'm imaginging we would trash the cache less this way, but I haven't actually measured what the overhead of <code>-Z self-profile</code> is, compared to not having it enabled</p>",
        "id": 215497210,
        "sender_full_name": "eddyb",
        "timestamp": 1604430204
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"119009\">@eddyb</span> <br>\nHave you measured how much faster does the profiling works if the profile is written into memory rather than into a file?<br>\nNon-temporal stores are not a wild idea, streaming data to somewhere is exactly why they exist, but they are unlikely to help if you have <em>too</em> much data so that it's IO bound (or even if there's not so much data, but still enough for the profiling to be store port bound).</p>",
        "id": 215504209,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1604434178
    },
    {
        "content": "<p>I think the implementation has  changed a bunch, but I've never measured the total overhead</p>",
        "id": 215504287,
        "sender_full_name": "eddyb",
        "timestamp": 1604434210
    },
    {
        "content": "<p>I didn't even realized the <code>mmap</code> I saw was an anonymous one etc.</p>",
        "id": 215504308,
        "sender_full_name": "eddyb",
        "timestamp": 1604434225
    },
    {
        "content": "<p>wait let me split this out into its own topic</p>",
        "id": 215504316,
        "sender_full_name": "eddyb",
        "timestamp": 1604434230
    },
    {
        "content": "<p>the implementation has changed quite a bit recently. we now write everything into a smallish in-memory buffer and then, once that is full, write that to disk.</p>",
        "id": 215712472,
        "sender_full_name": "mw",
        "timestamp": 1604583841
    },
    {
        "content": "<p>access to the buffer is synchronized via a mutex and can happen from multiple threads. I'm not sure how that would affect non-temporal stores.</p>",
        "id": 215712633,
        "sender_full_name": "mw",
        "timestamp": 1604583914
    },
    {
        "content": "<p>In theory it sounds like a valid use case for them though.</p>",
        "id": 215712784,
        "sender_full_name": "mw",
        "timestamp": 1604583977
    },
    {
        "content": "<p>what I found while doing the current implementation: the code is not really I/O bound (at least on Linux) because writing to disk without flushing will actually just copy the data into kernel memory and then return, while disk I/O happens in the background.</p>",
        "id": 215713046,
        "sender_full_name": "mw",
        "timestamp": 1604584104
    },
    {
        "content": "<p>which is why having a manual implementation of writing stuff to disk in a background thread made almost no difference</p>",
        "id": 215713108,
        "sender_full_name": "mw",
        "timestamp": 1604584142
    },
    {
        "content": "<p>I'm sure there is still a lot of potential for making this faster (esp. if using platform-specific stuff like IO_uring) but I ran out of time and was satisfied with the new implementation performing as well as the previous one.</p>",
        "id": 215713309,
        "sender_full_name": "mw",
        "timestamp": 1604584247
    },
    {
        "content": "<p>as far as I could tell, the current implementation's bottleneck is the mutex around the memory buffer</p>",
        "id": 215713429,
        "sender_full_name": "mw",
        "timestamp": 1604584308
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> mentioned wanting to try using thread-local storage to git rid of that</p>",
        "id": 215713545,
        "sender_full_name": "mw",
        "timestamp": 1604584340
    },
    {
        "content": "<p>that should not be too hard, if we can assume that recording code does not run on the main thread (which I think it doesn't for rustc, right?)</p>",
        "id": 215713737,
        "sender_full_name": "mw",
        "timestamp": 1604584431
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span> you can avoid the mutex if you don't page events :P</p>",
        "id": 215750377,
        "sender_full_name": "eddyb",
        "timestamp": 1604599098
    },
    {
        "content": "<p>I've never seen the point of \"background threads\" tbh, and I want to eventually take a look at any we might still be using</p>",
        "id": 215750526,
        "sender_full_name": "eddyb",
        "timestamp": 1604599167
    },
    {
        "content": "<p>with <code>mmap</code>'d files, you avoid hitting that userspace-&gt;kernel copy from <code>write</code>, IIUC, and non-temporal stores <em>to that</em> could be interesting in that only the kernel will bring them in cache (if at all, it might just send them to DMA and they might never show up in cache until e.g. <code>summarize</code> reads the file)</p>",
        "id": 215750781,
        "sender_full_name": "eddyb",
        "timestamp": 1604599255
    },
    {
        "content": "<p>Also, you can put a guard page after the mmaped page, and handle all the necessary unmapping/remapping in the signal handler firing on store to that guard page.<br>\nThen you get the purest stream of stores not tainted by any bound checking.<br>\nI'm not sure it's a reasonable thing to do in this case though (but in some cases it is).</p>",
        "id": 215771531,
        "sender_full_name": "Vadim Petrochenkov",
        "timestamp": 1604609130
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"119009\">eddyb</span> <a href=\"#narrow/stream/247081-t-compiler.2Fperformance/topic/non-temporal.20stores.20for.20.60mm_profdata.60/near/215750377\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"124287\">mw</span> you can avoid the mutex if you don't page events :P</p>\n</blockquote>\n<p>Well, we moved away from having one file per stream and towards paging things because people kept complaining that they want to have everything in a single file <code>:)</code></p>",
        "id": 215820290,
        "sender_full_name": "mw",
        "timestamp": 1604653915
    },
    {
        "content": "<p>unfortunately both the string table and the events stream both can be gigabytes in size, so we kinda have to write everything to disk asap if we want avoid both high memory consumption and dumping lots of data to disk at once, right?</p>",
        "id": 215820563,
        "sender_full_name": "mw",
        "timestamp": 1604654065
    },
    {
        "content": "<p>it does sound like a lot of fun to optimize this whole thing further, if one can spend a couple of months on it <code>:)</code> From a practical standpoint though, I think it would be good to first proof that the current overhead is high enough to warrant the additional complexity. The current implementation is rather simple.</p>",
        "id": 215820927,
        "sender_full_name": "mw",
        "timestamp": 1604654287
    },
    {
        "content": "<p>that being said, I of course have no objections to do simple optimizations that keep things as maintainable as they are <code>:)</code></p>",
        "id": 215821063,
        "sender_full_name": "mw",
        "timestamp": 1604654389
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span> yeah, I was one of those people :P. but my point is that you can page everything else while keeping individual events basically their own \"page\" (you only need like one bit to indicate you have an event and not a page. ooor you could always leave a \"footer\" at the end of each page that gets filled by the number of bytes from it to the next page, when the next page gets written, that way iterating the pages shouldn't be slower than today)</p>",
        "id": 215830574,
        "sender_full_name": "eddyb",
        "timestamp": 1604660331
    },
    {
        "content": "<p>going forward it might be nice to keep compatibility in the data format even if not in the API</p>",
        "id": 215830645,
        "sender_full_name": "eddyb",
        "timestamp": 1604660378
    },
    {
        "content": "<p>at least we could argue that multiple files is too much to keep around but in single-file we could have several approaches, and \"just\" paper over the differences between them when decoding</p>",
        "id": 215830766,
        "sender_full_name": "eddyb",
        "timestamp": 1604660434
    },
    {
        "content": "<p>actually... hmm... if the pages are flexible enough, we don't need to change the format, haha</p>",
        "id": 215830916,
        "sender_full_name": "eddyb",
        "timestamp": 1604660525
    },
    {
        "content": "<p>just always start an \"events\" page after any other page, and fill in the details when writing in the next page</p>",
        "id": 215830957,
        "sender_full_name": "eddyb",
        "timestamp": 1604660546
    },
    {
        "content": "<p>maybe I should open an issue</p>",
        "id": 215831042,
        "sender_full_name": "eddyb",
        "timestamp": 1604660613
    },
    {
        "content": "<p>oh yeaaaah the format is great :D</p>",
        "id": 215831127,
        "sender_full_name": "eddyb",
        "timestamp": 1604660647
    },
    {
        "content": "<p>although... there is that whole thing where I don't think we ever properly <code>mmap</code>'d files?? what's up with that</p>",
        "id": 215831809,
        "sender_full_name": "eddyb",
        "timestamp": 1604661045
    },
    {
        "content": "<p>done <a href=\"https://github.com/rust-lang/measureme/issues/144\">https://github.com/rust-lang/measureme/issues/144</a></p>",
        "id": 215833829,
        "sender_full_name": "eddyb",
        "timestamp": 1604662411
    },
    {
        "content": "<p>I had an implementation with <code>mmap</code>'d files a while ago here: <a href=\"https://github.com/rust-lang/measureme/pull/16\">https://github.com/rust-lang/measureme/pull/16</a><br>\nI abandoned it after it wasn't faster than the other <code>mmap</code> based implementation. It always made me uneasy to allocate a number of huge files on disk (3x 1 GB in that case) and only truncating them in the <code>Drop</code> impl of the <code>SerializationSink</code>.</p>",
        "id": 216205532,
        "sender_full_name": "mw",
        "timestamp": 1605012233
    },
    {
        "content": "<p>I'm also sure that I did not eke out all the performance to be had there. I just stopped looking into it because I ran out of time.</p>",
        "id": 216205722,
        "sender_full_name": "mw",
        "timestamp": 1605012325
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span> ah, good to know! ideally we could inform the OS to lazily allocate space on disk, but I'm not sure how to do that exactly</p>",
        "id": 216451513,
        "sender_full_name": "eddyb",
        "timestamp": 1605177481
    },
    {
        "content": "<p>On the terminal you can use <code>fallocate --posix --length 1G</code>/<code>truncate -s 1g</code> to create a sparse file. I don't know if Windows supports it though.</p>",
        "id": 216451777,
        "sender_full_name": "bjorn3",
        "timestamp": 1605177618
    },
    {
        "content": "<p>interesting, I guess there's no way to have a <code>mmap</code> where writes determine the size of the file</p>",
        "id": 216452236,
        "sender_full_name": "eddyb",
        "timestamp": 1605177953
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span> there is one hilarious way to deal with having a tiny <code>mmap</code> size and running out of it, without locks in the fast path: put the fallback in the bounds checking failure path. you can probably even remap the same area of memory but pointing to the next same-size chunk on disk etc.</p>",
        "id": 216452540,
        "sender_full_name": "eddyb",
        "timestamp": 1605178166
    },
    {
        "content": "<p>you just need that chunk size to be small enough relative to <code>AtomicUsize</code> to allow \"going on\" by the number of maximum threads you might have, and not overflow (or I guess you can panic on overflow instead of panicking on out-of-bounds, even if the data on disk might already be corrupted by the time everything winds down)</p>",
        "id": 216452767,
        "sender_full_name": "eddyb",
        "timestamp": 1605178313
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"124287\">@mw</span> wrote it down here <a href=\"https://github.com/rust-lang/measureme/issues/144#issuecomment-726012677\">https://github.com/rust-lang/measureme/issues/144#issuecomment-726012677</a></p>",
        "id": 216454826,
        "sender_full_name": "eddyb",
        "timestamp": 1605179618
    },
    {
        "content": "<p>starting to wonder if we're seriously mishandling threads <span aria-label=\"sweat smile\" class=\"emoji emoji-1f605\" role=\"img\" title=\"sweat smile\">:sweat_smile:</span></p>",
        "id": 216454847,
        "sender_full_name": "eddyb",
        "timestamp": 1605179639
    },
    {
        "content": "<p>maybe each should have their own file? wouldn't work great for parallel rustc</p>",
        "id": 216454902,
        "sender_full_name": "eddyb",
        "timestamp": 1605179655
    },
    {
        "content": "<p>I'm probably not aware of all the design constraints here, but wouldn't it be simpler to have a dedicated thread writing to the file? Idea being that you'd have a thread-local ring-buffer that all the normal threads write to. The background thread then has the job of gathering from those buffers and writing out to a file.</p>",
        "id": 216462926,
        "sender_full_name": "Diggsey",
        "timestamp": 1605185512
    },
    {
        "content": "<p>I'm still not sure what problem such threads solve in userspace</p>",
        "id": 216488218,
        "sender_full_name": "eddyb",
        "timestamp": 1605196952
    },
    {
        "content": "<p>since you're effectively reimplementing part of the OS</p>",
        "id": 216488235,
        "sender_full_name": "eddyb",
        "timestamp": 1605196961
    },
    {
        "content": "<p>I guess batching syscalls?</p>",
        "id": 216488261,
        "sender_full_name": "eddyb",
        "timestamp": 1605196972
    },
    {
        "content": "<p>you can still run out of space in the buffer so it's not easier than what I'm suggesting, nor more deterministic</p>",
        "id": 216488346,
        "sender_full_name": "eddyb",
        "timestamp": 1605197012
    },
    {
        "content": "<p>Well you don't need any locking when accessing the file because only one thread does that. Passing buffers back and forth in a lock-free fashion is a solved problem. Each thread could have two buffers, and each time one is filled it passes it to the writer thread to flush to disk, and switches to the other buffer. When the writer is done it sends the original buffer back.</p>",
        "id": 216544385,
        "sender_full_name": "Diggsey",
        "timestamp": 1605223775
    },
    {
        "content": "<p>ah hmm double-buffering</p>",
        "id": 216570535,
        "sender_full_name": "eddyb",
        "timestamp": 1605246930
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"295632\">@Diggory Blake</span> but how would the threads get interleaved? if you don't interleave at the event level, you can also do this without a separate thread</p>",
        "id": 216570616,
        "sender_full_name": "eddyb",
        "timestamp": 1605246983
    },
    {
        "content": "<p>like if the result on disk is significantly different, you can also tweak my scheme to do something similar (and presumably simplify it because of that)</p>",
        "id": 216570666,
        "sender_full_name": "eddyb",
        "timestamp": 1605247072
    },
    {
        "content": "<p>anyway, the advantage of <code>mmap</code>d IMO files is removing one set of copies (and a bunch of userspace work)</p>",
        "id": 216570719,
        "sender_full_name": "eddyb",
        "timestamp": 1605247111
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"125250\">@Wesley Wiser</span> mentioned that he wanted to look into using TLS -- which I think is the only way to have per-thread buffers (due to <code>Profiler</code> having to be <code>Sync</code>, IIUC)</p>",
        "id": 216590317,
        "sender_full_name": "mw",
        "timestamp": 1605261706
    }
]