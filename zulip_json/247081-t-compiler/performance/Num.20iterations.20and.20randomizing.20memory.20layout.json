[
    {
        "content": "<p>I'd like to talk about the amount of iterations we're doing per test run and the effects of memory layout on performance.</p>\n<p>There's a great talk about how to control for the effects of memory <a href=\"https://www.youtube.com/watch?v=r-TLSBdHe1A\">layout</a> along with a corresponding <a href=\"https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.363.802&amp;rep=rep1&amp;type=pdf\">paper</a>. The tl;dr is that uninteresting factors such as environment variables, linker arg order, etc. can cause pretty large performance impacts because they shift things in memory.</p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"r-TLSBdHe1A\" href=\"https://www.youtube.com/watch?v=r-TLSBdHe1A\"><img src=\"https://uploads.zulipusercontent.net/06bee759c1dbe2c4354c820cedf34a8b3c178c93/68747470733a2f2f692e7974696d672e636f6d2f76692f722d544c534264486531412f64656661756c742e6a7067\"></a></div><p>The talk and paper introduce a <a href=\"https://github.com/ccurtsinger/stabilizer\">tool</a> called Stabilizer which randomly lays out programs in memory and continuously re-randomizes the layout during execution to try to control for these effects. Unfortunately, the tool isn't usable today as it only works with LLVM 3.0 and it's missing many features that Rust uses (like handling stack unwinding).</p>\n<p>I do wonder if we could try to control more for things like memory layout by running more iterations and doing some things like randomizing linker arg order. Ultimately it would be good if we could produce normal distributions for at least some test cases, but that might be a pipe dream because even under perfect conditions we'd likely have to run a test case ~30 times or so which we might not have the resources for. </p>\n<p>Any thoughts on number of iterations of test runs and how to control for the effects of memory layout in our benchmarking?</p>",
        "id": 249369895,
        "sender_full_name": "rylev",
        "timestamp": 1628866274
    },
    {
        "content": "<p>My memory is that \"Rigorous benchmarking in reasonable time” by Kalibera and Jones is a good paper on the subject of determining an appropriate number of iterations, though its been a while since I looked at it.</p>",
        "id": 249373135,
        "sender_full_name": "pnkfelix",
        "timestamp": 1628867684
    },
    {
        "content": "<p>What \"things\" are being shifted? stacks? dynamic libs? allocator calls? ...?</p>",
        "id": 249378005,
        "sender_full_name": "The 8472",
        "timestamp": 1628870080
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224872\">@rylev</span> FWIW, it's pretty easy for us to queue up a one-off run to collect 30x repetitions on some benchmarks (or doing so locally). For some benchmarks we could plausibly do that for all runs, too, though I personally am not sure we're quite at that level of precision yet.</p>\n<p>My impression historically has been that the benchmarks we call noisy (e.g., coercions-debug) are not such due to perturbations of memory layout and such, rather, it's hashmaps or other such sources that aren't really external actors, it's built in noise we can't eliminate without changes to program structure.</p>",
        "id": 249378844,
        "sender_full_name": "simulacrum",
        "timestamp": 1628870484
    },
    {
        "content": "<blockquote>\n<p>My impression historically has been that the benchmarks we call noisy (e.g., coercions-debug) are not such due to perturbations of memory layout and such, rather, it's hashmaps or other such sources that aren't really external actors, it's built in noise we can't eliminate</p>\n</blockquote>\n<p>To be clear, I think the utility of doing more runs is to build distributions for test cases for a given artifact that we could use to more accurately compare against runs for a different artifact. This would allow us to more accurately tell when differences between two artifacts are actually significant. Right now the 0.2% significance threshold is completely arbitrary</p>",
        "id": 249379372,
        "sender_full_name": "rylev",
        "timestamp": 1628870742
    },
    {
        "content": "<p>This is all likely to not be feasible but it’s just something I wanted us to think about</p>",
        "id": 249380631,
        "sender_full_name": "rylev",
        "timestamp": 1628871444
    },
    {
        "content": "<p>Has the new <a href=\"https://github.com/rust-lang/rust/pull/87868\">-Z randomize-layout</a> feature been discussed as a way to improve perf run fidelity?</p>",
        "id": 258333368,
        "sender_full_name": "rylev",
        "timestamp": 1634719928
    },
    {
        "content": "<p>how would it help?</p>",
        "id": 258417187,
        "sender_full_name": "Joshua Nelson",
        "timestamp": 1634753823
    },
    {
        "content": "<p>it would introduce perturbation of memory layout. But I think it would be small compared to what we want…?</p>",
        "id": 258492544,
        "sender_full_name": "pnkfelix",
        "timestamp": 1634796251
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"232545\">@Joshua Nelson</span> they posted this <a href=\"https://youtu.be/r-TLSBdHe1A\">video</a> awhile back on this thread. </p>\n<div class=\"youtube-video message_inline_image\"><a data-id=\"r-TLSBdHe1A\" href=\"https://youtu.be/r-TLSBdHe1A\"><img src=\"https://uploads.zulipusercontent.net/06bee759c1dbe2c4354c820cedf34a8b3c178c93/68747470733a2f2f692e7974696d672e636f6d2f76692f722d544c534264486531412f64656661756c742e6a7067\"></a></div><p>FWIW I had the same question and thought the video did a good job of explaining it.</p>",
        "id": 258604100,
        "sender_full_name": "Timothy Maloney",
        "timestamp": 1634844842
    }
]