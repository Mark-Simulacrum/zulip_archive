[
    {
        "content": "<p>I saw that after this landed, the follow-up performance benchmarking run said \"no regressions\". It would be nice to maybe 1. keep track of instances of this kind of \"noisy/unstable benchmarking\" and 2. brainstorm about how we could correct for it (which has me once again thinking about Berger+Curtsinger's Stabilizer work)</p>",
        "id": 274560052,
        "sender_full_name": "pnkfelix",
        "timestamp": 1646754920
    },
    {
        "content": "<p>Yeah. I wasn't entirely shocked to see this go away, but it would be good to track.</p>",
        "id": 274565798,
        "sender_full_name": "Jack Huey",
        "timestamp": 1646756966
    },
    {
        "content": "<p>Not sure how we could correct for it. If my hunch is correct, and it's an inlining change by llvm, then that's difficult.</p>",
        "id": 274565969,
        "sender_full_name": "Jack Huey",
        "timestamp": 1646757015
    },
    {
        "content": "<p>I guess we could get a \"confidence interval\" of some sort by forcing more pessimism in the inlining.</p>",
        "id": 274566152,
        "sender_full_name": "Jack Huey",
        "timestamp": 1646757084
    },
    {
        "content": "<p>more pessimism, or maybe even just more outright control</p>",
        "id": 274567559,
        "sender_full_name": "pnkfelix",
        "timestamp": 1646757645
    },
    {
        "content": "<p>e.g. embed our own heuristics</p>",
        "id": 274567596,
        "sender_full_name": "pnkfelix",
        "timestamp": 1646757659
    },
    {
        "content": "<p>though that may just end up being a complicated way of saying \"worse results.\"</p>",
        "id": 274567651,
        "sender_full_name": "pnkfelix",
        "timestamp": 1646757686
    }
]