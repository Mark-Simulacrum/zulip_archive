[
    {
        "content": "<p>Is there any particular reason for these to require a <code>GenericArray</code> instead of consuming some <code>&amp;mut [MaybeUninit&lt;u8&gt;]</code> from the caller to allocate into?</p>",
        "id": 203108542,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594131687
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"229913\">@HeroicKatora</span> that sounds like the same question as \"why use arrays when you could use slices\" — is that the intent?</p>",
        "id": 203109896,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1594132293
    },
    {
        "content": "<p>Not really. I intended to say that const generics surely are one way to solve thes problems but alternatives exist. For example, an allocator API that wasn't necessarily global—but e.g. stack bound—would allow embedded to utilize the standard containers which are currently heavily gated in <code>alloc</code>, and that is the underlying cause why that part of the ecosystem relies on arrays so much. And if those were available I doubt there would be any need for this in the first place. I do see the prevalance of <code>GenericArray</code> as a kind of XY problem tbh. And using <code>[MaybeUninit&lt;u8&gt;]</code> is a way to make up for this via a sort of local allocator. Plus it requires <code>unsafe</code> and that is scary.</p>",
        "id": 203121745,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594137413
    },
    {
        "content": "<p>But i digress, probably should have forked the thread instead..</p>",
        "id": 203121951,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594137505
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"229913\">HeroicKatora</span> <a href=\"#narrow/stream/213817-t-lang/topic/why.20does.20bbqueue.20use.20GenericArray.3F/near/203121951\">said</a>:</p>\n<blockquote>\n<p>But i digress, probably should have forked the thread instead..</p>\n</blockquote>\n<p>Done <span aria-label=\"wink\" class=\"emoji emoji-1f609\" role=\"img\" title=\"wink\">:wink:</span></p>",
        "id": 203122565,
        "sender_full_name": "Jake Goulding",
        "timestamp": 1594137783
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 203124114,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594138350
    },
    {
        "content": "<p>Hey <span class=\"user-mention\" data-user-id=\"229913\">@HeroicKatora</span>, I'm the author of bbqueue</p>",
        "id": 203212922,
        "sender_full_name": "James Munns",
        "timestamp": 1594162309
    },
    {
        "content": "<p>Generally the answer is: it was way easier to keep the scary unsafe code inside of bbqueue, instead of forcing the user to (usually) use unsafe to pass a static mut slice into the constructor.</p>",
        "id": 203213057,
        "sender_full_name": "James Munns",
        "timestamp": 1594162379
    },
    {
        "content": "<p>The most heavy use case of bbqueue is for embedded DMA, where slices generally have to be <code>'static</code>, as there is no reliable way to give ownership of data to the hardware itself.</p>",
        "id": 203213097,
        "sender_full_name": "James Munns",
        "timestamp": 1594162417
    },
    {
        "content": "<p>If you look at earlier versions of bbqueue, it actually did take a &amp;mut [u8], though it also meant I needed to provide a macro to encapsulate the creation of the item.</p>",
        "id": 203213179,
        "sender_full_name": "James Munns",
        "timestamp": 1594162479
    },
    {
        "content": "<p>Feel free to @ me here if you have any other questions, or I also hang out on the rust-embedded matrix server.</p>",
        "id": 203213191,
        "sender_full_name": "James Munns",
        "timestamp": 1594162499
    },
    {
        "content": "<p>Once const generic arrays land, I very much would like to switch bbqueue over to that instead. Most of the unsafe and even most of the code itself is to work around being able to have:</p>\n<ul>\n<li>const/static constructors</li>\n<li>variable size payloads</li>\n</ul>",
        "id": 203213375,
        "sender_full_name": "James Munns",
        "timestamp": 1594162656
    },
    {
        "content": "<p>Though, likely it will always require some unsafe, because there is a special runtime checked slice ownership, because producer and consumer access is unsynchronized, and I want the grants to have non-linear ownership lifetimes without heap allocation (e.g. you can store the grant somewhere longer than the lifetime of the borrow of the producer/consumer).</p>",
        "id": 203213504,
        "sender_full_name": "James Munns",
        "timestamp": 1594162762
    },
    {
        "content": "<p>(I just realized this conversation came from the \"stable subset\" thread, which is probably how you heard about bbqueue)</p>",
        "id": 203213682,
        "sender_full_name": "James Munns",
        "timestamp": 1594162861
    },
    {
        "content": "<blockquote>\n<p>The most heavy use case of bbqueue is for embedded DMA, where slices generally have to be 'static, as there is no reliable way to give ownership of data to the hardware itself.</p>\n</blockquote>\n<p>Does that mean using the linker to place the bbqueue at the right address? Because that would sound a whole lot scarier than linking a slice and using that.</p>",
        "id": 203254772,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594206455
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228912\">@James Munns</span> The need to use <code>unsafe</code> for all of this is also heavily connected to the allocator problem: The task of giving you a <code>&amp;'static mut [u8]</code> is _exactly_ what the allocator would encapsulate into a safe interface. No-one questsions vec![] to be safe to use either, of course a proper redesign would make it fallible so that you'd reserve your mutable slice once at program start and then pass it around but those are minor details.</p>",
        "id": 203254941,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594206593
    },
    {
        "content": "<p>Same thing for runtime checked slice ownership, that's sounds very much like a specialized allocator or a SlotMap would solve. Which also is gated by being able to use allocated datastructures despite the lack of a global allocator.</p>",
        "id": 203255050,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594206703
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228912\">@James Munns</span> could you go into a little more detail about the DMA? In your scenario, how is the DMA signaled to start and stop, and also does the CPU continue to run while the DMA is occurring?</p>",
        "id": 203262927,
        "sender_full_name": "Lokathor",
        "timestamp": 1594212618
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"229913\">@HeroicKatora</span> so, bbqueue is sort of like a specific use case allocator, however it is generally deterministic (due to to bounded access time with no garbage collection). You're right, an allocator is also another way to handle this concern, if you have one, which I don't typically.</p>",
        "id": 203297455,
        "sender_full_name": "James Munns",
        "timestamp": 1594229493
    },
    {
        "content": "<p>The placement of bbqueue isn't managed by the linker, but rather by existing at <code>static</code> scope, we can guarantee the buffer that backs bbqueue is always valid. This wouldn't be true for example when using a stack allocated frame.</p>",
        "id": 203297633,
        "sender_full_name": "James Munns",
        "timestamp": 1594229559
    },
    {
        "content": "<p>For example, if you stack allocate space, start a DMA transaction, but it keeps running after you've returned from that stack frame. In that case, the DMA will potentially corrupt a later stack frame!</p>",
        "id": 203297700,
        "sender_full_name": "James Munns",
        "timestamp": 1594229607
    },
    {
        "content": "<p>There are some ways to mitigate this (halt the DMA transaction on <code>drop</code>), however <code>mem::forget</code> is still a thing, so we can't guarantee the destructor will run. This is very similar to the issues @boats has raised re: io_uring and ringbahn.</p>",
        "id": 203297830,
        "sender_full_name": "James Munns",
        "timestamp": 1594229661
    },
    {
        "content": "<p>However for embedded: It's the hardware that needs to \"own\" the buffer, rather than the kernel.</p>",
        "id": 203297865,
        "sender_full_name": "James Munns",
        "timestamp": 1594229679
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"224471\">@Lokathor</span> I'm speaking about DMA in general, however I most commonly work with Arm Cortex-M devices. In this case, DMA is usually started by configuring a memory mapped (MMIO) peripheral, typically giving it a \"start pointer\" and a \"number of bytes\". It then copies from/to that address range, in parallel with the main CPU.</p>",
        "id": 203298094,
        "sender_full_name": "James Munns",
        "timestamp": 1594229785
    },
    {
        "content": "<p>Ah okay, so this is the \"DMA is another thread\" model, basically?</p>",
        "id": 203298150,
        "sender_full_name": "Lokathor",
        "timestamp": 1594229824
    },
    {
        "content": "<p>Since the \"control flow\" of the hardware is totally orthogonal to the control flow of the software, and the hardware knows nothing of lifetimes etc., we need to carefully work around that.</p>",
        "id": 203298158,
        "sender_full_name": "James Munns",
        "timestamp": 1594229828
    },
    {
        "content": "<p>Yeah! That's a good analogy.</p>",
        "id": 203298165,
        "sender_full_name": "James Munns",
        "timestamp": 1594229833
    },
    {
        "content": "<p>But also \"another thread written in C that does whatever it feels like\" :D</p>",
        "id": 203298188,
        "sender_full_name": "James Munns",
        "timestamp": 1594229849
    },
    {
        "content": "<p>I've heard of that but never used it myself. On GBA the DMA unit cuts in and the CPU is halted while DMA unit is active (makes it generally much simpler to reason about!)</p>",
        "id": 203298330,
        "sender_full_name": "Lokathor",
        "timestamp": 1594229913
    },
    {
        "content": "<p>That's why bbqueue is <code>Send</code>able: You can have one half of the Producer/Consumer pair in different \"thread\" contexts, including:</p>\n<ul>\n<li>The main program</li>\n<li>Interrupt context</li>\n<li>DMA context</li>\n</ul>\n<p>All of which act like unsynchronized \"threads\", essentially.</p>",
        "id": 203298331,
        "sender_full_name": "James Munns",
        "timestamp": 1594229913
    },
    {
        "content": "<p>Ahh, what's the point of the DMA then? Does it copy faster than mem to mem transfers?</p>",
        "id": 203298357,
        "sender_full_name": "James Munns",
        "timestamp": 1594229934
    },
    {
        "content": "<p>yeah about 2x as fast</p>",
        "id": 203298376,
        "sender_full_name": "Lokathor",
        "timestamp": 1594229945
    },
    {
        "content": "<p>Cortex-M typically has a number of memory buses, when multiple items (CPU, DMA, Flash controller) want to use the same memory bus, the hardware round robin arbitrates the different actors</p>",
        "id": 203298418,
        "sender_full_name": "James Munns",
        "timestamp": 1594229974
    },
    {
        "content": "<p>When different parts use different busses, they can run totally in parallel.</p>",
        "id": 203298439,
        "sender_full_name": "James Munns",
        "timestamp": 1594229991
    },
    {
        "content": "<p>the poor GBA is from 2003 and using tech that's mostly from like 1995 or so ;_;</p>",
        "id": 203298563,
        "sender_full_name": "Lokathor",
        "timestamp": 1594230045
    },
    {
        "content": "<p>We're all playing with concepts that were invented some time between 1960 and 1985, anyway :)</p>",
        "id": 203298637,
        "sender_full_name": "James Munns",
        "timestamp": 1594230099
    },
    {
        "content": "<p>bbqueue is an iterative improvement over bipbuffers, which are from the 80s/90s?</p>",
        "id": 203298715,
        "sender_full_name": "James Munns",
        "timestamp": 1594230129
    },
    {
        "content": "<p>Though Rust makes it easier to enforce invariants through the type system and ownership model.</p>",
        "id": 203298743,
        "sender_full_name": "James Munns",
        "timestamp": 1594230148
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"229913\">@HeroicKatora</span> if you're interested, we did a write up around the time we designed bbqueue: <a href=\"https://ferrous-systems.com/blog/lock-free-ring-buffer/\">https://ferrous-systems.com/blog/lock-free-ring-buffer/</a></p>",
        "id": 203298881,
        "sender_full_name": "James Munns",
        "timestamp": 1594230229
    },
    {
        "content": "<p>fwiw I do plan to make a version of bbqueue that can be heap allocated, so you don't need the nasty <code>static</code> for <code>std</code> (or <code>alloc</code>) programs, though I don't particularly see the need for embedded systems where the buffer is preallocated anyway.</p>",
        "id": 203299151,
        "sender_full_name": "James Munns",
        "timestamp": 1594230342
    },
    {
        "content": "<p>If you're interested, here's a driver that uses a pair of BBQueues to implement a hardware accelerated/managed serial port, abstracting the full hardware into basically just an input stream and output stream:</p>\n<p><a href=\"https://github.com/jamesmunns/home-fleet/tree/main/embedded/fleet-uarte\">https://github.com/jamesmunns/home-fleet/tree/main/embedded/fleet-uarte</a></p>",
        "id": 203299306,
        "sender_full_name": "James Munns",
        "timestamp": 1594230402
    },
    {
        "content": "<p>It does all of:</p>\n<ul>\n<li>Automatically draining outgoing bytes using DMA transactions that \"auto reload\" until the outgoing queue is empty</li>\n<li>Uses DMA to receive incoming bytes, will automatically flush and start a new DMA transaction if the buffer is full</li>\n<li>If there have been no bytes over the wire for the last N microseconds, it \"flushes\" the input buffer to make it available to the user</li>\n</ul>",
        "id": 203299549,
        "sender_full_name": "James Munns",
        "timestamp": 1594230501
    },
    {
        "content": "<p>Here's a fully hardware accelerated loopback example (<a href=\"https://github.com/jamesmunns/home-fleet/blob/main/embedded/test-modem/src/main.rs#L159-L174\">https://github.com/jamesmunns/home-fleet/blob/main/embedded/test-modem/src/main.rs#L159-L174</a>):</p>\n<div class=\"codehilite\"><pre><span></span><code><span class=\"k\">loop</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"nb\">Ok</span><span class=\"p\">(</span><span class=\"n\">rgr</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">uarte_app</span><span class=\"p\">.</span><span class=\"n\">read</span><span class=\"p\">()</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"n\">len</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">rgr</span><span class=\"p\">.</span><span class=\"n\">len</span><span class=\"p\">();</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"k\">if</span><span class=\"w\"> </span><span class=\"kd\">let</span><span class=\"w\"> </span><span class=\"nb\">Ok</span><span class=\"p\">(</span><span class=\"k\">mut</span><span class=\"w\"> </span><span class=\"n\">wgr</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">uarte_app</span><span class=\"p\">.</span><span class=\"n\">write_grant</span><span class=\"p\">(</span><span class=\"n\">len</span><span class=\"p\">)</span><span class=\"w\"> </span><span class=\"p\">{</span><span class=\"w\"></span>\n<span class=\"w\">            </span><span class=\"n\">wgr</span><span class=\"p\">.</span><span class=\"n\">copy_from_slice</span><span class=\"p\">(</span><span class=\"o\">&amp;</span><span class=\"n\">rgr</span><span class=\"p\">);</span><span class=\"w\"></span>\n<span class=\"w\">            </span><span class=\"n\">wgr</span><span class=\"p\">.</span><span class=\"n\">commit</span><span class=\"p\">(</span><span class=\"n\">len</span><span class=\"p\">);</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"w\">        </span><span class=\"n\">rgr</span><span class=\"p\">.</span><span class=\"n\">release</span><span class=\"p\">(</span><span class=\"n\">len</span><span class=\"p\">);</span><span class=\"w\"></span>\n<span class=\"w\">    </span><span class=\"p\">}</span><span class=\"w\"></span>\n<span class=\"p\">}</span><span class=\"w\"></span>\n</code></pre></div>",
        "id": 203299737,
        "sender_full_name": "James Munns",
        "timestamp": 1594230595
    },
    {
        "content": "<p>Well, I guess the CPU copies from the RX buffer to the TX buffer, but the actual RX and TX are handled by hardware/dma/interrupts/bbqueue</p>",
        "id": 203299823,
        "sender_full_name": "James Munns",
        "timestamp": 1594230624
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"228912\">James Munns</span> <a href=\"#narrow/stream/213817-t-lang/topic/why.20does.20bbqueue.20use.20GenericArray.3F/near/203297455\">said</a>:</p>\n<blockquote>\n<p><span class=\"user-mention silent\" data-user-id=\"229913\">HeroicKatora</span> so, bbqueue is sort of like a specific use case allocator, however it is generally deterministic (due to to bounded access time with no garbage collection). You're right, an allocator is also another way to handle this concern, if you have one, which I don't typically.</p>\n</blockquote>\n<p>I suppose more specifically, bbqueue is a \"FIFO allocator\"</p>",
        "id": 203300059,
        "sender_full_name": "James Munns",
        "timestamp": 1594230763
    },
    {
        "content": "<p>Okay, thanks for the large allocation of an explanation <span aria-label=\"slight smile\" class=\"emoji emoji-1f642\" role=\"img\" title=\"slight smile\">:slight_smile:</span></p>",
        "id": 203300810,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594231140
    },
    {
        "content": "<p>However, I'm still not sure why bbqueue is its own allocator instead of using some underlying one.</p>",
        "id": 203300858,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594231171
    },
    {
        "content": "<p>In particular even without <code>GlobalAlloc</code>, <code>alloc</code>, I can embed a raw chunk of memory in the program image and do a sound bump allocator on top of it. This is similar to the technique of using GenericArray but it doesn't require const generics. Then I could still construct the bbqueue at runtime, using that static chunks of memory to allocate the two queues which will always succeed if its the only use of that memory. It's never returned so a bump allocator is fine as well. I know such a bump allocator can be done because I've already written the crate when doing no_std networking (now used in a riscv baremetal or so I've heard).</p>",
        "id": 203301296,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594231389
    },
    {
        "content": "<p>This would fully decouple the allocator portion, the embedding of raw memory in the binary, and the bbqueue as a composed allocator while simultaneously making const generics unecessary.</p>",
        "id": 203301490,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594231460
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228912\">@James Munns</span> I think it's worth mentioning that a similar concept, \"the kernel owns the buffer\", has been discussed in the context of <code>io_uring</code> implementations for Rust.</p>",
        "id": 203301502,
        "sender_full_name": "Josh Triplett",
        "timestamp": 1594231464
    },
    {
        "content": "<p>(deleted)</p>",
        "id": 203302287,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594231870
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"228912\">@James Munns</span>  the one instances that I know of where my technique becomes more complicated is if you need to have your meta data appear inline of the data buffer. It still works but you'd have to do some workarounds of unsizing your type instead. I can show you an example if you're interested.</p>",
        "id": 203302510,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594232013
    },
    {
        "content": "<p>You can only implement an allocator in nightly, currently.</p>",
        "id": 203302634,
        "sender_full_name": "James Munns",
        "timestamp": 1594232075
    },
    {
        "content": "<p>You can implement <code>GlobalAlloc</code> only on nightly, that doesn't stop you from defining your own allocator-like interface.</p>",
        "id": 203302691,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594232102
    },
    {
        "content": "<p>Like bbqueue? :D</p>",
        "id": 203302716,
        "sender_full_name": "James Munns",
        "timestamp": 1594232114
    },
    {
        "content": "<p>Allocators are less fun when you can't use all of collections with them.</p>",
        "id": 203302736,
        "sender_full_name": "James Munns",
        "timestamp": 1594232128
    },
    {
        "content": "<p>More general and without GenericArray ;)</p>",
        "id": 203302740,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594232129
    },
    {
        "content": "<p>Like I said, the choice of GenericArray/Const Generics is a UX decision.</p>",
        "id": 203302772,
        "sender_full_name": "James Munns",
        "timestamp": 1594232154
    },
    {
        "content": "<p>Previous versions took a user provided buffer, but I decided I liked that less.</p>",
        "id": 203302826,
        "sender_full_name": "James Munns",
        "timestamp": 1594232171
    },
    {
        "content": "<p>Your tastes may vary.</p>",
        "id": 203302842,
        "sender_full_name": "James Munns",
        "timestamp": 1594232182
    },
    {
        "content": "<p>I can show you how to avoid the GenericArray even without require the user to give a layout</p>",
        "id": 203302865,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594232196
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"239881\">@Josh Triplett</span> yup! I think it's the same concern here.</p>",
        "id": 203302877,
        "sender_full_name": "James Munns",
        "timestamp": 1594232204
    },
    {
        "content": "<p>It will be like magic ;)</p>",
        "id": 203302878,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594232204
    },
    {
        "content": "<p>I mentioned that above.</p>",
        "id": 203302886,
        "sender_full_name": "James Munns",
        "timestamp": 1594232210
    },
    {
        "content": "<p>Concept executed here: <a href=\"https://github.com/HeroicKatora/static-alloc/tree/master/static-alloc\">https://github.com/HeroicKatora/static-alloc/tree/master/static-alloc</a><br>\nNo GenericArray, instead the user supplies any type that is as large as the buffer they want. A useful choice is of course using <code>[u8; N]</code> but anything works. Since this doesn't have a const generic but only a generic type parameter, it fully works on stable.</p>",
        "id": 203303096,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594232304
    },
    {
        "content": "<p>minor nit: GlobalAlloc trait and global_allocator attribute are both stable, it's just that alloc_error_handler isn't stable</p>",
        "id": 203303127,
        "sender_full_name": "Lokathor",
        "timestamp": 1594232323
    },
    {
        "content": "<p>Thanks, <span class=\"user-mention\" data-user-id=\"224471\">@Lokathor</span> . Yeah, the real deal is that you wouldn't want a global instance but <code>extern crate alloc</code> requires one. You'd only want the interface.</p>",
        "id": 203303230,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594232368
    },
    {
        "content": "<p>there's probably a lot to dislike about <code>alloc</code> ;P</p>",
        "id": 203303339,
        "sender_full_name": "Lokathor",
        "timestamp": 1594232407
    },
    {
        "content": "<p>I'll check that out, thanks!</p>",
        "id": 203307239,
        "sender_full_name": "James Munns",
        "timestamp": 1594234375
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"229913\">@HeroicKatora</span> btw, <a href=\"https://github.com/rust-lang/rust/pull/60667\">https://github.com/rust-lang/rust/pull/60667</a> has landed (I saw some notes about unsized support in static-alloc)</p>",
        "id": 203440751,
        "sender_full_name": "James Munns",
        "timestamp": 1594328735
    },
    {
        "content": "<p>Or rather, <a href=\"https://github.com/rust-lang/rust/pull/68234\">https://github.com/rust-lang/rust/pull/68234</a></p>",
        "id": 203440928,
        "sender_full_name": "James Munns",
        "timestamp": 1594328795
    },
    {
        "content": "<p>Thanks for the notice! I might have missed the stabilization. I'll have a look.</p>",
        "id": 203441111,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594328906
    },
    {
        "content": "<p>Is there any benefit to marking a bump alloc as <code>#[global_allocator]</code> without <code>extern crate alloc</code>?</p>",
        "id": 203441938,
        "sender_full_name": "James Munns",
        "timestamp": 1594329436
    },
    {
        "content": "<p>Also worth noting that I don't think <code>static-alloc</code> would support <code>thumbv6</code> targets, as they don't have compare and swap (bbqueue does support those targets - with a target specific critical section)</p>",
        "id": 203442768,
        "sender_full_name": "James Munns",
        "timestamp": 1594329886
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"228912\">James Munns</span> <a href=\"#narrow/stream/213817-t-lang/topic/why.20does.20bbqueue.20use.20GenericArray.3F/near/203441938\">said</a>:</p>\n<blockquote>\n<p>Is there any benefit to marking a bump alloc as <code>#[global_allocator]</code> without <code>extern crate alloc</code>?</p>\n</blockquote>\n<p>I don't think so, no. The example was mainly targetted at <code>no_std</code> with <code>alloc</code>. The rest of the interface is for without <code>alloc</code>. Yes, I noticed that difference. Is there anything in particular I should avoid in the critical sections, if I were to change all atomic operations to use one?</p>",
        "id": 203443266,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594330185
    },
    {
        "content": "<p>Unfortunately critical sections are generally non portable - they are target specific.</p>",
        "id": 203443406,
        "sender_full_name": "James Munns",
        "timestamp": 1594330262
    },
    {
        "content": "<p>For cortex-m targets, it generally means disabling interrupts, because then you know preemption is impossible</p>",
        "id": 203443453,
        "sender_full_name": "James Munns",
        "timestamp": 1594330289
    },
    {
        "content": "<p>We have a shim around this that makes it reasonably easier to maintain in bbqueue</p>",
        "id": 203443482,
        "sender_full_name": "James Munns",
        "timestamp": 1594330305
    },
    {
        "content": "<p><a href=\"https://github.com/jamesmunns/bbqueue/blob/master/core/src/bbbuffer.rs#L983-L1037\">https://github.com/jamesmunns/bbqueue/blob/master/core/src/bbbuffer.rs#L983-L1037</a></p>",
        "id": 203443569,
        "sender_full_name": "James Munns",
        "timestamp": 1594330341
    },
    {
        "content": "<p>I'm not volunteering at the moment, but would it be reasonable/feasible/interesting to implement a more complicated allocator for <code>static-alloc</code>?</p>",
        "id": 203443834,
        "sender_full_name": "James Munns",
        "timestamp": 1594330474
    },
    {
        "content": "<p>e.g. a non-bump allocator?</p>",
        "id": 203443846,
        "sender_full_name": "James Munns",
        "timestamp": 1594330482
    },
    {
        "content": "<p>probably something like <a href=\"https://github.com/phil-opp/linked-list-allocator\">https://github.com/phil-opp/linked-list-allocator</a></p>",
        "id": 203444086,
        "sender_full_name": "James Munns",
        "timestamp": 1594330604
    },
    {
        "content": "<p>Yes, it would. Although I would really recommend to only implement more complicated allocators as a non-<code>Sync</code> version and have them only run thread-local. Since you can of chunk the original bump allocator once when you start the program, and send each individual chunk to the thread that needs it. (Which is how safety critical programs handle allocation anyways if I am up-to-date).</p>",
        "id": 203444193,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594330680
    },
    {
        "content": "<p>Depends on the industry :)</p>",
        "id": 203444255,
        "sender_full_name": "James Munns",
        "timestamp": 1594330705
    },
    {
        "content": "<p>You can reset the bump allocator if you are able to collect all using allocations and re-acquire a <code>&amp;mut _</code> to it</p>",
        "id": 203444334,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594330760
    },
    {
        "content": "<p>Are you working in safety critical currently, btw?</p>",
        "id": 203444459,
        "sender_full_name": "James Munns",
        "timestamp": 1594330811
    },
    {
        "content": "<p>No, not currently. But I do certain things close to hardware and automation.<br>\nBut I would if given the chance and the time is right.</p>",
        "id": 203444575,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594330884
    },
    {
        "content": "<p>Though I really, really like what I'm doing right now which is mainly performance oriented. As I've noted elsewhere there is an overlap between performance and safety critical in that safety most often also means predictable and predictable is very good for tuning. Evidence: seL4 is simultaneously highly secure, safe, and real-time capable, and has lower system call latency than many (most) alternatives.</p>",
        "id": 203444928,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594331059
    },
    {
        "content": "<p>No worries, I was just wondering!</p>",
        "id": 203444962,
        "sender_full_name": "James Munns",
        "timestamp": 1594331079
    },
    {
        "content": "<p>(I'm trying to make safety critical Rust a thing, which is why I asked)</p>",
        "id": 203445088,
        "sender_full_name": "James Munns",
        "timestamp": 1594331151
    },
    {
        "content": "<p>Generally IMO, the places where allocators help the most in embedded are situations like:</p>\n<ul>\n<li>Boxed closures, which can be used as interrupt handlers with late assignment of resources</li>\n<li>DMA, allowing for lifetimes that extend beyond regular control flow</li>\n</ul>",
        "id": 203445696,
        "sender_full_name": "James Munns",
        "timestamp": 1594331433
    },
    {
        "content": "<p>The former I don't think is possible without global alloc, though maybe with unsized support you could do with <code>static-alloc</code>?</p>",
        "id": 203445776,
        "sender_full_name": "James Munns",
        "timestamp": 1594331478
    },
    {
        "content": "<p>DMA could definitely be possible, though you'd want to have reclaimable slices.</p>",
        "id": 203445849,
        "sender_full_name": "James Munns",
        "timestamp": 1594331515
    },
    {
        "content": "<p><a href=\"https://docs.rs/heapless/0.5.5/heapless/pool/struct.Pool.html\">https://docs.rs/heapless/0.5.5/heapless/pool/struct.Pool.html</a> is useful for the latter, though you are fixed to a single T, unlike static-alloc (which can be wasteful with variable sized DMA transactions, e.g. radio frames that could be anywhere between 2-255 bytes)</p>",
        "id": 203445971,
        "sender_full_name": "James Munns",
        "timestamp": 1594331574
    },
    {
        "content": "<p>bbqueue is also designed to help with the latter, though it is restricted to byte arrays, and has FIFO semantics, which is usually okay, but not always.</p>",
        "id": 203446024,
        "sender_full_name": "James Munns",
        "timestamp": 1594331609
    },
    {
        "content": "<p>The first case requires the container to <code>Unsize</code> the exact type to a dyn trait object. This is, apart from nightly, only possible for the standard types and without alloc that is specifically <code>&amp;_</code> and <code>&amp;mut _</code>.</p>",
        "id": 203446025,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594331610
    },
    {
        "content": "<p>aw :/</p>",
        "id": 203446062,
        "sender_full_name": "James Munns",
        "timestamp": 1594331634
    },
    {
        "content": "<p>can you turn it into a dyn FnMut?</p>",
        "id": 203446155,
        "sender_full_name": "James Munns",
        "timestamp": 1594331677
    },
    {
        "content": "<p>and box that?</p>",
        "id": 203446166,
        "sender_full_name": "James Munns",
        "timestamp": 1594331684
    },
    {
        "content": "<p>You probably could do it with static-alloc though. You don't need to deallocate anything if you just reclaim all memory after you're done using the closure. That way, you avoid having to use any Box or other wrapper and can use <code>&amp;</code> just fine</p>",
        "id": 203446176,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594331690
    },
    {
        "content": "<p>So, the typical workflow for interrupt handlers is to do something like:</p>\n<ul>\n<li>Set up some peripherals</li>\n<li>\"move\" them into the interrupt handler</li>\n</ul>",
        "id": 203446235,
        "sender_full_name": "James Munns",
        "timestamp": 1594331736
    },
    {
        "content": "<p>Because interrupts are essentially <code>fn()</code> (with no args or return value), you typically have to do something tricky to hand them \"context\".</p>",
        "id": 203446344,
        "sender_full_name": "James Munns",
        "timestamp": 1594331779
    },
    {
        "content": "<p>You know the patter to declare a variable and assign it in one branch?</p>\n<div class=\"codehilite\"><pre><span></span><code>let case_a;\nlet case_b;\nlet generic: &amp;dyn FnOnce();\nif some_condition {\n    case_a = creat_a();\n    generic = &amp;case_a;\n} else {\n    case_b = creat_b();\n    generic = &amp;case_b;\n}\n</code></pre></div>",
        "id": 203446462,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594331861
    },
    {
        "content": "<p>You could probably do the same to get an unsized <code>&amp;dyn FnOnce()</code> while using <code>without_alloc::boxed::Box</code> to drop the closures after use.</p>",
        "id": 203446541,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594331898
    },
    {
        "content": "<p>interesting</p>",
        "id": 203446560,
        "sender_full_name": "James Munns",
        "timestamp": 1594331910
    },
    {
        "content": "<p>If you replace <code>creat_a</code> with <code>local_bump_allocator.boxed(value)</code> (from the LocalAllocLeakExt trait)</p>",
        "id": 203446615,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594331946
    },
    {
        "content": "<p>I'd have to store that somewhere, probably some kind of static AtomicPtr that nops if the ptr is null, and calls the closure as a <code>dyn FnMut()</code></p>",
        "id": 203446642,
        "sender_full_name": "James Munns",
        "timestamp": 1594331969
    },
    {
        "content": "<p>Yep, the hard part is getting the <code>&amp;'static mut dyn FnOnce()</code> to store in that.</p>",
        "id": 203446774,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594332027
    },
    {
        "content": "<p>something like:</p>\n<ul>\n<li>static AtomicPtr::new(0)</li>\n<li>on init: heap allocate closure, set atomicptr to closure ptr</li>\n<li>on call: match on atomicptr, if null, nop, otherwise cast + call</li>\n</ul>",
        "id": 203446792,
        "sender_full_name": "James Munns",
        "timestamp": 1594332038
    },
    {
        "content": "<p>Hm, so if you're fine with an <code>FnMut()</code> you can store it as a dyn trait ptr and call that directly without casting</p>",
        "id": 203446989,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594332139
    },
    {
        "content": "<p>Yeah, most interrupts need to be called N times, so I assume I need a fnmut</p>",
        "id": 203447028,
        "sender_full_name": "James Munns",
        "timestamp": 1594332163
    },
    {
        "content": "<p>That should work out then. FnOnce requires either a value (which is unsized so you don't have it) or a Box (which requires alloc) so sadly that wouldn't work</p>",
        "id": 203447283,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594332273
    },
    {
        "content": "<p>Really, you only need this if you want to swap interrupt handlers at runtime, otherwise we have other tricks to move data to handler context</p>",
        "id": 203447369,
        "sender_full_name": "James Munns",
        "timestamp": 1594332332
    },
    {
        "content": "<p><a href=\"https://therealprof.github.io/blog/interrupt-comparison/\">https://therealprof.github.io/blog/interrupt-comparison/</a> is a good overview of the variety of tricks we have</p>",
        "id": 203447405,
        "sender_full_name": "James Munns",
        "timestamp": 1594332356
    },
    {
        "content": "<p>But all of them sort of fall over if you have different handlers that can be swapped at runtime, which is sometimes a thing you want to do, and might be more useful with async/await now working on core.</p>",
        "id": 203447519,
        "sender_full_name": "James Munns",
        "timestamp": 1594332412
    },
    {
        "content": "<p>but anyway, thanks for humoring me and answering all the questions :)</p>",
        "id": 203447531,
        "sender_full_name": "James Munns",
        "timestamp": 1594332426
    },
    {
        "content": "<p>Thanks for being interested and open to it as well.</p>",
        "id": 203447724,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1594332519
    },
    {
        "content": "<p>Waking up this thread a bit, but I wanted to see if this was still true <span class=\"user-mention\" data-user-id=\"229913\">@HeroicKatora</span>: <a href=\"https://docs.rs/static-alloc/0.2.2/static_alloc/bump/struct.Bump.html#limitations\">https://docs.rs/static-alloc/0.2.2/static_alloc/bump/struct.Bump.html#limitations</a>, the mentioned method has now landed</p>",
        "id": 236922831,
        "sender_full_name": "James Munns",
        "timestamp": 1619830889
    },
    {
        "content": "<p>I'm attempting to have something like a:</p>\n<div class=\"codehilite\" data-code-language=\"Rust\"><pre><span></span><code><span class=\"k\">static</span><span class=\"w\"> </span><span class=\"n\">OMLF</span>: <span class=\"nc\">OnceCell</span><span class=\"o\">&lt;</span><span class=\"n\">Mutex</span><span class=\"o\">&lt;</span><span class=\"n\">LeakBox</span><span class=\"o\">&lt;'</span><span class=\"nb\">static</span><span class=\"p\">,</span><span class=\"w\"> </span><span class=\"k\">dyn</span><span class=\"w\"> </span><span class=\"n\">Future</span><span class=\"o\">&lt;</span><span class=\"n\">Output</span><span class=\"o\">=</span><span class=\"p\">()</span><span class=\"o\">&gt;&gt;&gt;&gt;</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span><span class=\"n\">OnceCell</span>::<span class=\"n\">new</span><span class=\"p\">();</span><span class=\"w\"></span>\n</code></pre></div>\n<p>And tried to do this with the <a href=\"https://docs.rs/unsize/1.1.0/unsize/macro.Coercion.html\">unsize</a> crate, but still ran into problems</p>",
        "id": 236922968,
        "sender_full_name": "James Munns",
        "timestamp": 1619830958
    },
    {
        "content": "<p>Ha Ha! I made it work, in probably a terrible way!</p>\n<p><a href=\"https://github.com/jamesmunns/cassette/pull/3/files#diff-ed3100414beca7e0d41c4f7a0765209dd2430a54dc6f3287355869919ca7404aR14-R72\">https://github.com/jamesmunns/cassette/pull/3/files#diff-ed3100414beca7e0d41c4f7a0765209dd2430a54dc6f3287355869919ca7404aR14-R72</a></p>",
        "id": 236929070,
        "sender_full_name": "James Munns",
        "timestamp": 1619836657
    },
    {
        "content": "<p>Hm, I might have some ideas how to avoid the unsafe pinning but it requires the <code>pin_static_ref</code> feature.<br>\nAlternatively, it might be sound to initialize <code>LeakBox&lt;'static, MaybeUninit&lt;T&gt;&gt;</code> into a <code>Pin&lt;LeakBox&lt;'static, T&gt;&gt;</code> by writing a T.<br>\nThis works for static with the same correctness argument as std's pin_static_ref.</p>",
        "id": 237393872,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1620160634
    },
    {
        "content": "<p>And can you describe a bit more detailed how <code>unsize</code> did not work? Was it just the unpublished integration?</p>",
        "id": 237394051,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1620160712
    },
    {
        "content": "<p>Full disclosure, I'm not <em>super</em> sure what I needed to be doing. I actually realized that I'm not sure I even needed unsize, as I was able to do the coersion directly?</p>",
        "id": 237412978,
        "sender_full_name": "James Munns",
        "timestamp": 1620168792
    },
    {
        "content": "<p>You'd need <code>unsize</code>for unsizing <code>LeakBox&lt;T&gt;</code> to <code>LeakBox&lt;dyn Future&lt;..&gt;&gt;</code>. But if you can make due with the reference type, for which coercion is implemented in std, then you do not need to create.</p>",
        "id": 237506062,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1620225623
    },
    {
        "content": "<p>I'll add some more examples to <code>unsize</code> as it's getting used more often.</p>",
        "id": 237506224,
        "sender_full_name": "HeroicKatora",
        "timestamp": 1620225677
    }
]