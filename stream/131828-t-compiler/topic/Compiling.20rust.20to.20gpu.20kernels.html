<html>
<head><meta charset="utf-8"><title>Compiling rust to gpu kernels · t-compiler · Zulip Chat Archive</title></head>
<h2>Stream: <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/index.html">t-compiler</a></h2>
<h3>Topic: <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html">Compiling rust to gpu kernels</a></h3>

<hr>

<base href="https://rust-lang.zulipchat.com">

<head><link href="https://zulip-archive.rust-lang.org/style.css" rel="stylesheet"></head>

<a name="251294593"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/251294593" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Riccardo D&#x27;Ambrosio <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#251294593">(Aug 30 2021 at 21:02)</a>:</h4>
<p>Hello! I just wanted to showcase something ive been working on for a couple of months and get your thoughts.</p>
<p>For some time now ive been writing a custom rustc backend which targets a closed source nvidia cuda library that uses a subset of llvm ir to compile code to gpu kernels that can be run on nvidia gpus using a library. I was tempted because the llvm ptx backend does not really work on windows, it doesnt have some closed source opts, and it makes broken ptx. </p>
<p>Today i was finally able to compile all of core and compile a simple kernel!</p>
<div class="codehilite" data-code-language="Rust"><pre><span></span><code><span class="k">extern</span><span class="w"> </span><span class="s">"C"</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="cp">#[link_name = </span><span class="s">"llvm.nvvm.read.ptx.sreg.tid.x"</span><span class="cp">]</span><span class="w"></span>
<span class="w">    </span><span class="k">fn</span> <span class="nf">thread_id_x</span><span class="p">()</span><span class="w"> </span>-&gt; <span class="kt">u32</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>

<span class="cp">#[no_mangle]</span><span class="w"></span>
<span class="k">pub</span><span class="w"> </span><span class="k">unsafe</span><span class="w"> </span><span class="k">fn</span> <span class="nf">kernel</span><span class="p">(</span><span class="n">foo</span>: <span class="o">*</span><span class="k">mut</span><span class="w"> </span><span class="kt">u32</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">thread_id_x</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="kt">isize</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">elem</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">foo</span><span class="p">.</span><span class="n">offset</span><span class="p">(</span><span class="n">idx</span><span class="p">).</span><span class="n">as_mut</span><span class="p">().</span><span class="n">unwrap</span><span class="p">();</span><span class="w"></span>
<span class="w">    </span><span class="o">*</span><span class="n">elem</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">elem</span><span class="p">.</span><span class="n">wrapping_add</span><span class="p">(</span><span class="mi">6</span><span class="p">);</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>
<p>was compiled into a ptx function: <a href="https://paste.rs/ge1">https://paste.rs/ge1</a><br>
which can then be run as a gpu kernel using a rust wrapper for the cuda driver api i forked from rustacuda. <br>
This is very exciting for me because i have been wanting to write gpu code in rust for a long time, but never could do so because i needed CUDA things and the llvm ptx backend didnt really work. <br>
This is just a POC right now, i have tons of housekeeping to do before its usable, but once it is, i will make it open source to hopefully get more people using rust for gpu computing since it seems to be one of rust's big weak points right now.</p>



<a name="251296034"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/251296034" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Riccardo D&#x27;Ambrosio <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#251296034">(Aug 30 2021 at 21:13)</a>:</h4>
<p>skipping the as_mut makes it generate much better code, i need to investigate if nvvm wants you to run llvm passes before giving it the llvm ir, because it should have inlined the unwrap there </p>
<div class="codehilite"><pre><span></span><code>.visible .func kernel(
    .param .b64 kernel_param_0
)
{
    .reg .b32     %r&lt;4&gt;;
    .reg .b64     %rd&lt;5&gt;;


    ld.param.u64     %rd2, [kernel_param_0];
    mov.u32     %r1, %tid.x;
    bra.uni     $L__BB0_1;

$L__BB0_1:
    cvt.u64.u32     %rd3, %r1;
    shl.b64     %rd4, %rd3, 2;
    add.s64     %rd1, %rd2, %rd4;
    bra.uni     $L__BB0_2;

$L__BB0_2:
    ld.u32     %r3, [%rd1];
    add.s32     %r2, %r3, 6;
    bra.uni     $L__BB0_3;

$L__BB0_3:
    st.u32     [%rd1], %r2;
    ret;

}
</code></pre></div>



<a name="251339522"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/251339522" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Riccardo D&#x27;Ambrosio <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#251339522">(Aug 31 2021 at 06:45)</a>:</h4>
<p>im also working on a crate for managing common operations as well as having a simple way of binding to nvvm ir things. This should make things much easier, for example, <code>thread::index()</code> automatically accounts for any dimension of grid/block/thread, so it will work with 3d blocks or 1d blocks just fine, while in cuda C++ youd have to do the calculation yourself and potentially mess it up and cause UB</p>
<div class="codehilite" data-code-language="Rust"><pre><span></span><code><span class="cp">#![no_std]</span><span class="w"></span>

<span class="k">use</span><span class="w"> </span><span class="n">cuda_std</span>::<span class="n">thread</span><span class="p">;</span><span class="w"></span>

<span class="cp">#[no_mangle]</span><span class="w"></span>
<span class="k">pub</span><span class="w"> </span><span class="k">unsafe</span><span class="w"> </span><span class="k">fn</span> <span class="nf">kernel</span><span class="p">(</span><span class="n">foo</span>: <span class="o">*</span><span class="k">mut</span><span class="w"> </span><span class="kt">u32</span><span class="p">,</span><span class="w"> </span><span class="n">bar</span>: <span class="kp">&amp;</span><span class="p">[</span><span class="kt">u32</span><span class="p">])</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">idx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">thread</span>::<span class="n">index</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="kt">isize</span><span class="p">;</span><span class="w"></span>
<span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">&amp;</span><span class="k">mut</span><span class="w"> </span><span class="o">*</span><span class="n">foo</span><span class="p">.</span><span class="n">offset</span><span class="p">(</span><span class="n">idx</span><span class="p">);</span><span class="w"></span>
<span class="w">    </span><span class="o">*</span><span class="n">a</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">bar</span><span class="p">[</span><span class="n">idx</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="kt">usize</span><span class="p">];</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</code></pre></div>
<p>this compiles just fine</p>



<a name="253702351"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/253702351" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ben Reeves <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#253702351">(Sep 17 2021 at 07:32)</a>:</h4>
<p>Replying to express interest. Interested to hear any other updates you have.</p>



<a name="254949405"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/254949405" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Riccardo D&#x27;Ambrosio <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#254949405">(Sep 26 2021 at 17:59)</a>:</h4>
<p><span class="user-mention" data-user-id="435059">@Ben Reeves</span> Since then ive:</p>
<ul>
<li>Started adding CUDA graph support to the driver API wrapper</li>
<li>Implemented lazily loading dependency modules, bringing the ptx down from ~12mb to a couple of kb (and hopefully optimizing better)</li>
<li>Added raw intrinsics for __nv intrinsics from libdevice in cuda_std (i will wrap these in extension traits in cuda_std eventually)</li>
<li>Added a <code>#[kernel]</code> attr for managing boilerplate and making sure kernel args are correct (as well as special handling inside the codegen)</li>
<li>Started working on PTX lexing/parsing (for more dead code elimination in the final PTX as well as safety checking kernel launches)</li>
<li>Enforced all kernels be extern "C" (the kernel attr does this automatically) so that i can override the C call conv in the codegen to pass everything by value, mitigating any weirdness from ScalarPair and hopefully increasing performance (since aggregates and unions are passed as byte arrays)</li>
<li>Bothered <span class="user-mention" data-user-id="232545">@Joshua Nelson</span> way too much about my struggles with cuda's <em>v e r y</em> odd APIs</li>
<li>Made a picture :O (relevant picture attached)</li>
<li>Fixed alloc not working (i forgot to add the allocator module i codegen to the final result <span aria-label="face palm" class="emoji emoji-1f926" role="img" title="face palm">:face_palm:</span>)</li>
<li>Made cuda_std build on non-nvptx (albeit it wont link if you actually use the functions, but gpu-specific functions go in functions with the kernel attr and kernel cfgs the function for nvptx)</li>
<li>Wrote high level bindings to the ptx-compiler APIs</li>
<li>Wrote high level bindings to linker APIs in the driver API, inside of the driver API wrapper</li>
<li>Fixed i128 not working</li>
<li>Fixed integers not <code>i1, i8, i16, i32, i64</code> segfaulting (i promise its not my fault ok, its nvvm :(</li>
<li>Fixed llvm.used not working, and consequently </li>
<li>Fixed lang items being compiled out (they are now put in llvm.used so that nvvm keeps them when lazy loading, same with no_mangle things)</li>
<li>Added LLVM opts (turns out you <em>are</em> supposed to run llvm opts before), so the code is basically all inlined now</li>
<li>Started writing an mdbook on how to use the codegen as well as how the codegen works.</li>
<li>Panicking code now works (albeit with no nice message because i am still fighting cuda errors if i try vprintf-ing inside panic_handler)</li>
</ul>



<a name="254949432"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/254949432" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Riccardo D&#x27;Ambrosio <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#254949432">(Sep 26 2021 at 17:59)</a>:</h4>
<p>here is the glorious picture :O <a href="/user_uploads/4715/mLFlhUkYkzlvivZBy5vhfkrK/out.png">out.png</a></p>
<div class="message_inline_image"><a href="/user_uploads/4715/mLFlhUkYkzlvivZBy5vhfkrK/out.png" title="out.png"><img src="/user_uploads/4715/mLFlhUkYkzlvivZBy5vhfkrK/out.png"></a></div>



<a name="254949698"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/254949698" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Riccardo D&#x27;Ambrosio <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#254949698">(Sep 26 2021 at 18:02)</a>:</h4>
<p>I still have a lot to do, i need to kinda polish everything, it <em>works</em> currently but it needs a really long command for building a crate and you need llvm 7 installed. So i need to set up something to download prebuilt llvm 7 libraries. As well as... a lot more things i want to finish</p>



<a name="254949725"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/254949725" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Joshua Nelson <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#254949725">(Sep 26 2021 at 18:02)</a>:</h4>
<p><span class="user-mention" data-user-id="276242">@Riccardo D'Ambrosio</span> you told me but I forgot - is the llvm 7 limitation inherent because CUDA uses it? or could it be fixed at some point?</p>



<a name="254949747"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/254949747" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Riccardo D&#x27;Ambrosio <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#254949747">(Sep 26 2021 at 18:03)</a>:</h4>
<p>Its because libnvvm expects llvm 7 bitcode, trying to feed it llvm 13 bitcode does not work (ive tried)</p>



<a name="254949761"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/254949761" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Riccardo D&#x27;Ambrosio <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#254949761">(Sep 26 2021 at 18:03)</a>:</h4>
<p>nvidia would need to update libnvvm to use a newer llvm and push a new libnvvm version</p>



<a name="254949909"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/254949909" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Riccardo D&#x27;Ambrosio <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#254949909">(Sep 26 2021 at 18:05)</a>:</h4>
<p>If anyone is wondering, yes, existing CUDA tools work with rust kernels :D<br>
Although they do not have the original source because i havent done debug info yet <a href="/user_uploads/4715/l6UDrx8gkoZRFhlUKsZuDInQ/Screenshot_371.png">Screenshot_371.png</a> </p>
<div class="message_inline_image"><a href="/user_uploads/4715/l6UDrx8gkoZRFhlUKsZuDInQ/Screenshot_371.png" title="Screenshot_371.png"><img src="/user_uploads/4715/l6UDrx8gkoZRFhlUKsZuDInQ/Screenshot_371.png"></a></div><p>(This is nsight compute)</p>



<a name="254950036"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/254950036" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Riccardo D&#x27;Ambrosio <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#254950036">(Sep 26 2021 at 18:07)</a>:</h4>
<p>surprisingly, cuda is almost fully frontend-agnostic, internally it works off of PTX and cubin (the step after ptx), so basically any tool that works with CUDA C/C++ will work with Rust, which is great.</p>



<a name="255078984"></a>
<h4><a href="https://rust-lang.zulipchat.com#narrow/stream/131828-t-compiler/topic/Compiling%20rust%20to%20gpu%20kernels/near/255078984" class="zl"><img src="https://zulip-archive.rust-lang.org/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Riccardo D&#x27;Ambrosio <a href="https://zulip-archive.rust-lang.org/stream/131828-t-compiler/topic/Compiling.20rust.20to.20gpu.20kernels.html#255078984">(Sep 27 2021 at 16:36)</a>:</h4>
<p>I was also bikeshedding something which i think could be greatly useful for ensuring more safety inside of kernel launches (which are insanely dangerous).</p>
<p>As background, one of the main issues in CUDA is that you use thread and block indices to index into an array. This is dangerous because oftentimes people implicitly expect a 1d configuration (where y and z indices are always 0), but the kernel is launched with an invalid configuration. Which yields data races. </p>
<p>Currently i kind of solve this by providing a <code>thread::index()</code> function which provides a globally unique index which accounts for any configuration. This is fast because it is just a couple math ops and reading special ptx registers, but id rather avoid useless math ops when possible. So, i was thinking of adding a way to hint to the codegen and to LLVM/NVVM that the launch configuration is always 1d/2d/3d:</p>
<div class="codehilite" data-code-language="Rust"><pre><span></span><code><span class="cp">#[kernel(grid_dim = 2d, block_dim = 1d)]</span><span class="w"></span>
</code></pre></div>
<p>This is going to do a couple of things:</p>
<ul>
<li>Add a special hint in the final PTX as a comment (this is part of a larger thing im calling ptx validation) which will be checked during launch by the driver api wrapper.</li>
<li>Insert assertions at the top of the kernel that ensure that the configuration is correct, and abort (well, call __assertfail which returns an AssertionFailure to the caller).</li>
<li>Get recognized by custom lints (which im planning to add for checking other things)</li>
</ul>
<p>This would add basically zero overhead, i will bench it, i can probably only run the assertions once on the first thread, but due to the way GPUs work, it would not add overhead to branch like that (it isnt even a branch on the gpu).</p>



<hr><p>Last updated: Apr 12 2022 at 20:01 UTC</p>
</html>